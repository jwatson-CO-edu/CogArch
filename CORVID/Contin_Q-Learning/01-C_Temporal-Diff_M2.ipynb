{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.02148 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 # 0.00782 # 0.00391\n",
    "gamma    = 1.00 \n",
    "swapDiv  = 64\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes = 64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   = 32 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "beta   = 0.15\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = true\n",
    "N_peaks =   8\n",
    "N_steps = 128\n",
    "lambda  =   0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.16, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.13999999999999999, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 1.5600000000000012, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.37000000000000016, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.6700000000000004, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.3100000000000001, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.2900000000000001, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.2039062500000001\n",
      "\n",
      "Epoch 2, Best Score: 1.5600000000000012\n",
      "Training Iteration 4 score: 0.19000000000000003, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.5500000000000003, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 1.0500000000000007, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 2.439999999999992, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.8300000000000005, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.09, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.13999999999999999, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.09999999999999999, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.10999999999999999, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.27890624999999997\n",
      "\n",
      "Epoch 3, Best Score: 2.439999999999992\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.7600000000000005, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.18000000000000002, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.18000000000000002, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.26000000000000006, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.26000000000000006, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.18000000000000002, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.12999999999999998, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.36000000000000015, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.10999999999999999, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.22562500000000002\n",
      "\n",
      "Epoch 4, Best Score: 2.439999999999992\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 5, Best Score: 2.439999999999992\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.11999999999999998, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.2700000000000001, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.24000000000000007, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.22000000000000006, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.18000000000000002, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.20000000000000004, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.10999999999999999, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.4200000000000002, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.25000000000000006, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.2800000000000001, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.36000000000000015, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.18062500000000004\n",
      "\n",
      "Epoch 6, Best Score: 2.439999999999992\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.9600000000000006, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.09, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.6600000000000004, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.6100000000000003, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.5600000000000003, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.7800000000000005, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.5100000000000002, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.18000000000000002, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.6500000000000004, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.15, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.15, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.3171875000000001\n",
      "\n",
      "Epoch 7, Best Score: 2.439999999999992\n",
      "Training Iteration 4 score: 0.11999999999999998, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.9200000000000006, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 5.2499999999999325, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 31.330000000002098, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.10999999999999999, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 29.16000000000176, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.47000000000000025, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 29.860000000001868, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 29.890000000001873, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 31.130000000002067, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.5000000000000002, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 1.2400000000000009, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 32.08000000000219, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.5800000000000003, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 29.510000000001813, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 3.7699999999999636, epsilon: 8.881784197001252e-16\n",
      "Average Score: 11.67984375000072\n",
      "\n",
      "Epoch 8, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 1.260000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 1.0000000000000007, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 1.360000000000001, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 2.7999999999999843, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 1.300000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 4.519999999999948, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 2.5499999999999896, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 3.759999999999964, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 1.1600000000000008, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 3.369999999999972, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 2.909999999999982, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 5.459999999999928, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 4.179999999999955, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 3.849999999999962, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 4.339999999999952, epsilon: 8.881784197001252e-16\n",
      "Average Score: 2.5951562499999805\n",
      "\n",
      "Epoch 9, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 1.8500000000000014, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.5700000000000003, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 7.839999999999877, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 9.54999999999984, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 12.779999999999772, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 11.609999999999797, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 15.66999999999971, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.3900000000000002, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 20.35000000000038, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 18.060000000000024, epsilon: 8.881784197001252e-16\n",
      "Average Score: 4.437812499999958\n",
      "\n",
      "Epoch 10, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 0.6800000000000004, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.22000000000000006, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.18000000000000002, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.8000000000000005, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.5300000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.7100000000000004, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.9300000000000006, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.5400000000000003, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.21000000000000005, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 1.0400000000000007, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.5700000000000003, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.4100000000000002, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.6300000000000003, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.4317187500000002\n",
      "\n",
      "Epoch 11, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.3900000000000002, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.06281249999999948\n",
      "\n",
      "Epoch 12, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 13, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 0.8400000000000005, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 2.3299999999999943, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.8400000000000005, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.7400000000000004, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 1.7300000000000013, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 1.6300000000000012, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.5800000000000003, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 2.9899999999999802, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 2.2199999999999966, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 2.7899999999999845, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 4.589999999999947, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 1.390000000000001, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 6.619999999999903, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 4.549999999999947, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 8.099999999999872, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 8.309999999999867, epsilon: 8.881784197001252e-16\n",
      "Average Score: 3.016406249999968\n",
      "\n",
      "Epoch 14, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 0.19000000000000003, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.09, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.08, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.21000000000000005, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.2800000000000001, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.34000000000000014, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.11999999999999998, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.09999999999999999, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.49000000000000027, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.7800000000000005, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.4300000000000002, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.17, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.18406250000000005\n",
      "\n",
      "Epoch 15, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 0.46000000000000024, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.11999999999999998, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.6900000000000004, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.6900000000000004, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.5100000000000002, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.17, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.2800000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.09999999999999999, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.16, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.10999999999999999, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.6300000000000003, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.5400000000000003, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 1.7000000000000013, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.18000000000000002, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.43796874999999974\n",
      "\n",
      "Epoch 16, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.24000000000000007, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.08093750000000004\n",
      "\n",
      "Epoch 17, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.3100000000000001, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.04687500000000002\n",
      "\n",
      "Epoch 18, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 0.19000000000000003, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.34000000000000014, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.3900000000000002, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.10999999999999999, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.09999999999999999, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.13999999999999999, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.3300000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.35000000000000014, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.34000000000000014, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.24000000000000007, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.2900000000000001, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.3100000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.22000000000000006, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.4200000000000002, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.2390625000000002\n",
      "\n",
      "Epoch 19, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 1.1300000000000008, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 1.2300000000000009, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.08, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.03812500000000003\n",
      "\n",
      "Epoch 20, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 0.5400000000000003, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.9800000000000006, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.7400000000000004, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.34000000000000014, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.7300000000000004, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 1.2000000000000008, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.3000000000000001, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 2.5499999999999896, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.7100000000000004, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.9800000000000006, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.7700000000000005, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 1.480000000000001, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.7200000000000004, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.5900000000000003, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.8735937500000004\n",
      "\n",
      "Epoch 21, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 22, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 1.300000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.4000000000000002, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.3100000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.24000000000000007, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.8800000000000006, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.2900000000000001, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.9100000000000006, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.7700000000000005, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.49000000000000027, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.2700000000000001, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.5200000000000002, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.4257812500000003\n",
      "\n",
      "Epoch 23, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 0.6200000000000003, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.7300000000000004, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.5600000000000003, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.3000000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 1.1600000000000008, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.8600000000000005, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 1.460000000000001, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.7700000000000014, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 2.07, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 1.8800000000000014, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 2.52999999999999, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 2.209999999999997, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 4.619999999999946, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 3.9099999999999606, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 5.409999999999929, epsilon: 8.881784197001252e-16\n",
      "Average Score: 2.114374999999986\n",
      "\n",
      "Epoch 24, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 25, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 26, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 0.3900000000000002, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.3900000000000002, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.05375000000000002\n",
      "\n",
      "Epoch 27, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 0.25000000000000006, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.02031250000000001\n",
      "\n",
      "Epoch 28, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.7400000000000004, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.4000000000000002, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.4400000000000002, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.2800000000000001, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.3100000000000001, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.11875000000000008\n",
      "\n",
      "Epoch 29, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0009375000000000001\n",
      "\n",
      "Epoch 30, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 0.13999999999999999, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.7800000000000005, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.35000000000000014, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.25000000000000006, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.36000000000000015, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.16, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.9200000000000006, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 1.7200000000000013, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.19000000000000003, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.21000000000000005, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.26000000000000006, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.21000000000000005, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 1.0600000000000007, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 3.229999999999975, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 2.6399999999999877, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 1.6200000000000012, epsilon: 8.881784197001252e-16\n",
      "Average Score: 1.2059374999999906\n",
      "\n",
      "Epoch 31, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.05796875000000003\n",
      "\n",
      "Epoch 32, Best Score: 32.08000000000219\n",
      "Training Iteration 4 score: 0.3900000000000002, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.49000000000000027, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.13999999999999999, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 1.430000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.7100000000000004, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.5100000000000002, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.5200000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.23000000000000007, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.3100000000000001, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.25000000000000006, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.3000000000000001, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.8100000000000005, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.7095312499999953\n",
      "Saved a trained Q-table with size (76032,), After 29.56996958255768 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip180\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip180)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip181\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip180)\" d=\"\n",
       "M184.191 1486.45 L2352.76 1486.45 L2352.76 47.2441 L184.191 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip182\">\n",
       "    <rect x=\"184\" y=\"47\" width=\"2170\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip182)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  509.541,1486.45 509.541,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip182)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  839.512,1486.45 839.512,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip182)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1169.48,1486.45 1169.48,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip182)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1499.45,1486.45 1499.45,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip182)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1829.42,1486.45 1829.42,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip182)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2159.39,1486.45 2159.39,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  509.541,1486.45 509.541,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  839.512,1486.45 839.512,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1169.48,1486.45 1169.48,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1499.45,1486.45 1499.45,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1829.42,1486.45 1829.42,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2159.39,1486.45 2159.39,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip180)\" d=\"M499.819 1514.29 L518.176 1514.29 L518.176 1518.22 L504.102 1518.22 L504.102 1526.7 Q505.12 1526.35 506.139 1526.19 Q507.157 1526 508.176 1526 Q513.963 1526 517.342 1529.17 Q520.722 1532.34 520.722 1537.76 Q520.722 1543.34 517.25 1546.44 Q513.778 1549.52 507.458 1549.52 Q505.282 1549.52 503.014 1549.15 Q500.768 1548.78 498.361 1548.04 L498.361 1543.34 Q500.444 1544.47 502.666 1545.03 Q504.889 1545.58 507.366 1545.58 Q511.37 1545.58 513.708 1543.48 Q516.046 1541.37 516.046 1537.76 Q516.046 1534.15 513.708 1532.04 Q511.37 1529.94 507.366 1529.94 Q505.491 1529.94 503.616 1530.35 Q501.764 1530.77 499.819 1531.65 L499.819 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M814.199 1544.91 L821.838 1544.91 L821.838 1518.55 L813.528 1520.21 L813.528 1515.95 L821.792 1514.29 L826.468 1514.29 L826.468 1544.91 L834.107 1544.91 L834.107 1548.85 L814.199 1548.85 L814.199 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M853.551 1517.37 Q849.94 1517.37 848.111 1520.93 Q846.306 1524.47 846.306 1531.6 Q846.306 1538.71 848.111 1542.27 Q849.94 1545.82 853.551 1545.82 Q857.185 1545.82 858.991 1542.27 Q860.82 1538.71 860.82 1531.6 Q860.82 1524.47 858.991 1520.93 Q857.185 1517.37 853.551 1517.37 M853.551 1513.66 Q859.361 1513.66 862.417 1518.27 Q865.495 1522.85 865.495 1531.6 Q865.495 1540.33 862.417 1544.94 Q859.361 1549.52 853.551 1549.52 Q847.741 1549.52 844.662 1544.94 Q841.607 1540.33 841.607 1531.6 Q841.607 1522.85 844.662 1518.27 Q847.741 1513.66 853.551 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M1144.67 1544.91 L1152.31 1544.91 L1152.31 1518.55 L1144 1520.21 L1144 1515.95 L1152.26 1514.29 L1156.94 1514.29 L1156.94 1544.91 L1164.57 1544.91 L1164.57 1548.85 L1144.67 1548.85 L1144.67 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M1174.07 1514.29 L1192.42 1514.29 L1192.42 1518.22 L1178.35 1518.22 L1178.35 1526.7 Q1179.37 1526.35 1180.38 1526.19 Q1181.4 1526 1182.42 1526 Q1188.21 1526 1191.59 1529.17 Q1194.97 1532.34 1194.97 1537.76 Q1194.97 1543.34 1191.5 1546.44 Q1188.02 1549.52 1181.7 1549.52 Q1179.53 1549.52 1177.26 1549.15 Q1175.01 1548.78 1172.61 1548.04 L1172.61 1543.34 Q1174.69 1544.47 1176.91 1545.03 Q1179.13 1545.58 1181.61 1545.58 Q1185.62 1545.58 1187.95 1543.48 Q1190.29 1541.37 1190.29 1537.76 Q1190.29 1534.15 1187.95 1532.04 Q1185.62 1529.94 1181.61 1529.94 Q1179.74 1529.94 1177.86 1530.35 Q1176.01 1530.77 1174.07 1531.65 L1174.07 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M1478.23 1544.91 L1494.55 1544.91 L1494.55 1548.85 L1472.6 1548.85 L1472.6 1544.91 Q1475.26 1542.16 1479.85 1537.53 Q1484.45 1532.88 1485.63 1531.53 Q1487.88 1529.01 1488.76 1527.27 Q1489.66 1525.51 1489.66 1523.82 Q1489.66 1521.07 1487.72 1519.33 Q1485.8 1517.6 1482.69 1517.6 Q1480.49 1517.6 1478.04 1518.36 Q1475.61 1519.13 1472.83 1520.68 L1472.83 1515.95 Q1475.66 1514.82 1478.11 1514.24 Q1480.56 1513.66 1482.6 1513.66 Q1487.97 1513.66 1491.17 1516.35 Q1494.36 1519.03 1494.36 1523.52 Q1494.36 1525.65 1493.55 1527.57 Q1492.76 1529.47 1490.66 1532.07 Q1490.08 1532.74 1486.98 1535.95 Q1483.87 1539.15 1478.23 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M1514.36 1517.37 Q1510.75 1517.37 1508.92 1520.93 Q1507.11 1524.47 1507.11 1531.6 Q1507.11 1538.71 1508.92 1542.27 Q1510.75 1545.82 1514.36 1545.82 Q1517.99 1545.82 1519.8 1542.27 Q1521.63 1538.71 1521.63 1531.6 Q1521.63 1524.47 1519.8 1520.93 Q1517.99 1517.37 1514.36 1517.37 M1514.36 1513.66 Q1520.17 1513.66 1523.23 1518.27 Q1526.3 1522.85 1526.3 1531.6 Q1526.3 1540.33 1523.23 1544.94 Q1520.17 1549.52 1514.36 1549.52 Q1508.55 1549.52 1505.47 1544.94 Q1502.42 1540.33 1502.42 1531.6 Q1502.42 1522.85 1505.47 1518.27 Q1508.55 1513.66 1514.36 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M1808.69 1544.91 L1825.01 1544.91 L1825.01 1548.85 L1803.07 1548.85 L1803.07 1544.91 Q1805.73 1542.16 1810.31 1537.53 Q1814.92 1532.88 1816.1 1531.53 Q1818.35 1529.01 1819.23 1527.27 Q1820.13 1525.51 1820.13 1523.82 Q1820.13 1521.07 1818.18 1519.33 Q1816.26 1517.6 1813.16 1517.6 Q1810.96 1517.6 1808.51 1518.36 Q1806.08 1519.13 1803.3 1520.68 L1803.3 1515.95 Q1806.12 1514.82 1808.58 1514.24 Q1811.03 1513.66 1813.07 1513.66 Q1818.44 1513.66 1821.63 1516.35 Q1824.83 1519.03 1824.83 1523.52 Q1824.83 1525.65 1824.02 1527.57 Q1823.23 1529.47 1821.12 1532.07 Q1820.55 1532.74 1817.44 1535.95 Q1814.34 1539.15 1808.69 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M1834.87 1514.29 L1853.23 1514.29 L1853.23 1518.22 L1839.16 1518.22 L1839.16 1526.7 Q1840.18 1526.35 1841.19 1526.19 Q1842.21 1526 1843.23 1526 Q1849.02 1526 1852.4 1529.17 Q1855.78 1532.34 1855.78 1537.76 Q1855.78 1543.34 1852.3 1546.44 Q1848.83 1549.52 1842.51 1549.52 Q1840.34 1549.52 1838.07 1549.15 Q1835.82 1548.78 1833.42 1548.04 L1833.42 1543.34 Q1835.5 1544.47 1837.72 1545.03 Q1839.94 1545.58 1842.42 1545.58 Q1846.43 1545.58 1848.76 1543.48 Q1851.1 1541.37 1851.1 1537.76 Q1851.1 1534.15 1848.76 1532.04 Q1846.43 1529.94 1842.42 1529.94 Q1840.55 1529.94 1838.67 1530.35 Q1836.82 1530.77 1834.87 1531.65 L1834.87 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M2148.24 1530.21 Q2151.59 1530.93 2153.47 1533.2 Q2155.37 1535.47 2155.37 1538.8 Q2155.37 1543.92 2151.85 1546.72 Q2148.33 1549.52 2141.85 1549.52 Q2139.67 1549.52 2137.36 1549.08 Q2135.06 1548.66 2132.61 1547.81 L2132.61 1543.29 Q2134.56 1544.43 2136.87 1545.01 Q2139.19 1545.58 2141.71 1545.58 Q2146.11 1545.58 2148.4 1543.85 Q2150.71 1542.11 2150.71 1538.8 Q2150.71 1535.75 2148.56 1534.03 Q2146.43 1532.3 2142.61 1532.3 L2138.58 1532.3 L2138.58 1528.45 L2142.8 1528.45 Q2146.25 1528.45 2148.07 1527.09 Q2149.9 1525.7 2149.9 1523.11 Q2149.9 1520.45 2148 1519.03 Q2146.13 1517.6 2142.61 1517.6 Q2140.69 1517.6 2138.49 1518.01 Q2136.29 1518.43 2133.65 1519.31 L2133.65 1515.14 Q2136.31 1514.4 2138.63 1514.03 Q2140.97 1513.66 2143.03 1513.66 Q2148.35 1513.66 2151.45 1516.09 Q2154.56 1518.5 2154.56 1522.62 Q2154.56 1525.49 2152.91 1527.48 Q2151.27 1529.45 2148.24 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M2174.23 1517.37 Q2170.62 1517.37 2168.79 1520.93 Q2166.99 1524.47 2166.99 1531.6 Q2166.99 1538.71 2168.79 1542.27 Q2170.62 1545.82 2174.23 1545.82 Q2177.87 1545.82 2179.67 1542.27 Q2181.5 1538.71 2181.5 1531.6 Q2181.5 1524.47 2179.67 1520.93 Q2177.87 1517.37 2174.23 1517.37 M2174.23 1513.66 Q2180.04 1513.66 2183.1 1518.27 Q2186.18 1522.85 2186.18 1531.6 Q2186.18 1540.33 2183.1 1544.94 Q2180.04 1549.52 2174.23 1549.52 Q2168.42 1549.52 2165.34 1544.94 Q2162.29 1540.33 2162.29 1531.6 Q2162.29 1522.85 2165.34 1518.27 Q2168.42 1513.66 2174.23 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip182)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,1445.72 2352.76,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip182)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,1155.1 2352.76,1155.1 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip182)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,864.484 2352.76,864.484 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip182)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,573.868 2352.76,573.868 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip182)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,283.252 2352.76,283.252 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,1486.45 184.191,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,1445.72 203.088,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,1155.1 203.088,1155.1 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,864.484 203.088,864.484 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,573.868 203.088,573.868 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,283.252 203.088,283.252 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip180)\" d=\"M91.0151 1431.51 Q87.404 1431.51 85.5753 1435.08 Q83.7697 1438.62 83.7697 1445.75 Q83.7697 1452.86 85.5753 1456.42 Q87.404 1459.96 91.0151 1459.96 Q94.6493 1459.96 96.4548 1456.42 Q98.2835 1452.86 98.2835 1445.75 Q98.2835 1438.62 96.4548 1435.08 Q94.6493 1431.51 91.0151 1431.51 M91.0151 1427.81 Q96.8252 1427.81 99.8808 1432.42 Q102.959 1437 102.959 1445.75 Q102.959 1454.48 99.8808 1459.08 Q96.8252 1463.67 91.0151 1463.67 Q85.2049 1463.67 82.1262 1459.08 Q79.0707 1454.48 79.0707 1445.75 Q79.0707 1437 82.1262 1432.42 Q85.2049 1427.81 91.0151 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M111.177 1457.12 L116.061 1457.12 L116.061 1463 L111.177 1463 L111.177 1457.12 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M136.246 1431.51 Q132.635 1431.51 130.807 1435.08 Q129.001 1438.62 129.001 1445.75 Q129.001 1452.86 130.807 1456.42 Q132.635 1459.96 136.246 1459.96 Q139.881 1459.96 141.686 1456.42 Q143.515 1452.86 143.515 1445.75 Q143.515 1438.62 141.686 1435.08 Q139.881 1431.51 136.246 1431.51 M136.246 1427.81 Q142.056 1427.81 145.112 1432.42 Q148.191 1437 148.191 1445.75 Q148.191 1454.48 145.112 1459.08 Q142.056 1463.67 136.246 1463.67 Q130.436 1463.67 127.357 1459.08 Q124.302 1454.48 124.302 1445.75 Q124.302 1437 127.357 1432.42 Q130.436 1427.81 136.246 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M86.0382 1168.44 L102.358 1168.44 L102.358 1172.38 L80.4133 1172.38 L80.4133 1168.44 Q83.0753 1165.69 87.6586 1161.06 Q92.2651 1156.41 93.4456 1155.07 Q95.691 1152.54 96.5706 1150.81 Q97.4734 1149.05 97.4734 1147.36 Q97.4734 1144.6 95.5289 1142.87 Q93.6076 1141.13 90.5058 1141.13 Q88.3067 1141.13 85.8531 1141.89 Q83.4225 1142.66 80.6447 1144.21 L80.6447 1139.49 Q83.4688 1138.35 85.9225 1137.77 Q88.3762 1137.19 90.4132 1137.19 Q95.7836 1137.19 98.978 1139.88 Q102.172 1142.57 102.172 1147.06 Q102.172 1149.19 101.362 1151.11 Q100.575 1153 98.4687 1155.6 Q97.89 1156.27 94.7882 1159.49 Q91.6864 1162.68 86.0382 1168.44 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M112.172 1166.5 L117.057 1166.5 L117.057 1172.38 L112.172 1172.38 L112.172 1166.5 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M127.288 1137.82 L145.644 1137.82 L145.644 1141.75 L131.57 1141.75 L131.57 1150.23 Q132.589 1149.88 133.607 1149.72 Q134.626 1149.53 135.644 1149.53 Q141.431 1149.53 144.811 1152.7 Q148.191 1155.88 148.191 1161.29 Q148.191 1166.87 144.718 1169.97 Q141.246 1173.05 134.927 1173.05 Q132.751 1173.05 130.482 1172.68 Q128.237 1172.31 125.83 1171.57 L125.83 1166.87 Q127.913 1168 130.135 1168.56 Q132.357 1169.12 134.834 1169.12 Q138.839 1169.12 141.177 1167.01 Q143.515 1164.9 143.515 1161.29 Q143.515 1157.68 141.177 1155.57 Q138.839 1153.47 134.834 1153.47 Q132.959 1153.47 131.084 1153.88 Q129.232 1154.3 127.288 1155.18 L127.288 1137.82 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M81.0614 847.204 L99.4178 847.204 L99.4178 851.139 L85.3438 851.139 L85.3438 859.611 Q86.3623 859.264 87.3808 859.102 Q88.3993 858.917 89.4178 858.917 Q95.2049 858.917 98.5845 862.088 Q101.964 865.259 101.964 870.676 Q101.964 876.255 98.4919 879.356 Q95.0197 882.435 88.7003 882.435 Q86.5243 882.435 84.2558 882.065 Q82.0105 881.694 79.6031 880.954 L79.6031 876.255 Q81.6864 877.389 83.9086 877.944 Q86.1308 878.5 88.6077 878.5 Q92.6123 878.5 94.9502 876.394 Q97.2882 874.287 97.2882 870.676 Q97.2882 867.065 94.9502 864.958 Q92.6123 862.852 88.6077 862.852 Q86.7327 862.852 84.8577 863.269 Q83.0058 863.685 81.0614 864.565 L81.0614 847.204 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M111.177 875.884 L116.061 875.884 L116.061 881.764 L111.177 881.764 L111.177 875.884 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M136.246 850.283 Q132.635 850.283 130.807 853.847 Q129.001 857.389 129.001 864.519 Q129.001 871.625 130.807 875.19 Q132.635 878.731 136.246 878.731 Q139.881 878.731 141.686 875.19 Q143.515 871.625 143.515 864.519 Q143.515 857.389 141.686 853.847 Q139.881 850.283 136.246 850.283 M136.246 846.579 Q142.056 846.579 145.112 851.185 Q148.191 855.769 148.191 864.519 Q148.191 873.245 145.112 877.852 Q142.056 882.435 136.246 882.435 Q130.436 882.435 127.357 877.852 Q124.302 873.245 124.302 864.519 Q124.302 855.769 127.357 851.185 Q130.436 846.579 136.246 846.579 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M80.8299 556.588 L103.052 556.588 L103.052 558.579 L90.5058 591.148 L85.6216 591.148 L97.4271 560.523 L80.8299 560.523 L80.8299 556.588 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M112.172 585.268 L117.057 585.268 L117.057 591.148 L112.172 591.148 L112.172 585.268 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M127.288 556.588 L145.644 556.588 L145.644 560.523 L131.57 560.523 L131.57 568.995 Q132.589 568.648 133.607 568.486 Q134.626 568.301 135.644 568.301 Q141.431 568.301 144.811 571.472 Q148.191 574.643 148.191 580.06 Q148.191 585.639 144.718 588.741 Q141.246 591.819 134.927 591.819 Q132.751 591.819 130.482 591.449 Q128.237 591.078 125.83 590.338 L125.83 585.639 Q127.913 586.773 130.135 587.329 Q132.357 587.884 134.834 587.884 Q138.839 587.884 141.177 585.778 Q143.515 583.671 143.515 580.06 Q143.515 576.449 141.177 574.342 Q138.839 572.236 134.834 572.236 Q132.959 572.236 131.084 572.653 Q129.232 573.069 127.288 573.949 L127.288 556.588 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M51.6634 296.597 L59.3023 296.597 L59.3023 270.231 L50.9921 271.898 L50.9921 267.639 L59.256 265.972 L63.9319 265.972 L63.9319 296.597 L71.5707 296.597 L71.5707 300.532 L51.6634 300.532 L51.6634 296.597 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M91.0151 269.051 Q87.404 269.051 85.5753 272.615 Q83.7697 276.157 83.7697 283.287 Q83.7697 290.393 85.5753 293.958 Q87.404 297.5 91.0151 297.5 Q94.6493 297.5 96.4548 293.958 Q98.2835 290.393 98.2835 283.287 Q98.2835 276.157 96.4548 272.615 Q94.6493 269.051 91.0151 269.051 M91.0151 265.347 Q96.8252 265.347 99.8808 269.953 Q102.959 274.537 102.959 283.287 Q102.959 292.014 99.8808 296.62 Q96.8252 301.203 91.0151 301.203 Q85.2049 301.203 82.1262 296.62 Q79.0707 292.014 79.0707 283.287 Q79.0707 274.537 82.1262 269.953 Q85.2049 265.347 91.0151 265.347 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M111.177 294.652 L116.061 294.652 L116.061 300.532 L111.177 300.532 L111.177 294.652 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M136.246 269.051 Q132.635 269.051 130.807 272.615 Q129.001 276.157 129.001 283.287 Q129.001 290.393 130.807 293.958 Q132.635 297.5 136.246 297.5 Q139.881 297.5 141.686 293.958 Q143.515 290.393 143.515 283.287 Q143.515 276.157 141.686 272.615 Q139.881 269.051 136.246 269.051 M136.246 265.347 Q142.056 265.347 145.112 269.953 Q148.191 274.537 148.191 283.287 Q148.191 292.014 145.112 296.62 Q142.056 301.203 136.246 301.203 Q130.436 301.203 127.357 296.62 Q124.302 292.014 124.302 283.287 Q124.302 274.537 127.357 269.953 Q130.436 265.347 136.246 265.347 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip182)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  245.565,1422.01 311.559,1413.29 377.553,1419.49 443.547,1445.72 509.541,1424.72 575.536,1408.84 641.53,87.9763 707.524,1144.04 773.518,929.836 839.512,1395.53 \n",
       "  905.506,1438.41 971.5,1445.72 1037.49,1095.07 1103.49,1424.32 1169.48,1394.8 1235.48,1436.31 1301.47,1440.27 1367.46,1417.93 1433.46,1441.28 1499.45,1344.16 \n",
       "  1565.45,1445.72 1631.44,1396.22 1697.43,1199.93 1763.43,1445.72 1829.42,1445.72 1895.42,1439.47 1961.41,1443.35 2027.41,1431.91 2093.4,1445.61 2159.39,1305.53 \n",
       "  2225.39,1438.98 2291.38,1363.24 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip180)\" d=\"\n",
       "M2011.18 198.898 L2280.47 198.898 L2280.47 95.2176 L2011.18 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2011.18,198.898 2280.47,198.898 2280.47,95.2176 2011.18,95.2176 2011.18,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2035.28,147.058 2179.85,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip180)\" d=\"M2217.79 166.745 Q2215.98 171.375 2214.27 172.787 Q2212.56 174.199 2209.69 174.199 L2206.28 174.199 L2206.28 170.634 L2208.78 170.634 Q2210.54 170.634 2211.51 169.8 Q2212.49 168.967 2213.67 165.865 L2214.43 163.921 L2203.94 138.412 L2208.46 138.412 L2216.56 158.689 L2224.66 138.412 L2229.18 138.412 L2217.79 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M2236.47 160.402 L2244.11 160.402 L2244.11 134.037 L2235.8 135.703 L2235.8 131.444 L2244.06 129.778 L2248.74 129.778 L2248.74 160.402 L2256.38 160.402 L2256.38 164.338 L2236.47 164.338 L2236.47 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    bestEpSc    = -100.0;\n",
    "    statesBest  = zeros( size( X_0, 1 ), T )\n",
    "    actionsBest = zeros( T );\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/(episodes-1)\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        s_l = 0.0\n",
    "        # while s_l == 0\n",
    "        \n",
    "            X  = X_0\n",
    "\n",
    "            ##### Double Q-Learning ###########################################\n",
    "\n",
    "            for k = 1:T\n",
    "\n",
    "                # 1. Choose action\n",
    "                if rand() < epsilon\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                else\n",
    "\n",
    "                    A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                    if A == 1000.0 # Indicates no values in this region\n",
    "                        if rand() < EXPrand \n",
    "                            A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                        else\n",
    "                            A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                # 2. Cache last state\n",
    "                qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "                # 3. Generate the next stae\n",
    "                Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "                # 4. Collect reward R( s, a, s' )\n",
    "                R_t = cartpole_reward( Xp )\n",
    "\n",
    "                # 5. Get the optimal action at the next state\n",
    "                a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "                # 6. Compute the value at the next state\n",
    "\n",
    "                V_tp1_opt = query_value_fuzzy( \n",
    "                    Q_kdTree, G, V, \n",
    "                    get_Q( \n",
    "                        select_X_vector( Xp ), \n",
    "                        a_tp1_opt \n",
    "                    ); \n",
    "                    k = vNN \n",
    "                )\n",
    "                if isnan( V_tp1_opt )\n",
    "                    V_tp1_opt = 0.0\n",
    "                end\n",
    "\n",
    "\n",
    "                # 7. Blend the value back into nearest points\n",
    "\n",
    "                idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "                nNear      = size( idxs, 1 )\n",
    "                for i = 1:nNear\n",
    "                    j    = idxs[i]\n",
    "                    if !isnan( wgts[i] ) \n",
    "\n",
    "                        # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                        VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                states[:,k] = Xp\n",
    "                actions[k]  = A\n",
    "\n",
    "                X = Xp\n",
    "            end\n",
    "\n",
    "            s_l    = vertical_score_s( states, aMargin, ts )\n",
    "            \n",
    "        # end\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if s_l > bestEpSc\n",
    "            bestEpSc    = s_l\n",
    "            statesBest  = copy( states  )\n",
    "            actionsBest = copy( actions )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        # if useElig && (s_l > s_Totl/(1.0*l)) && (s_l > 0.0) \n",
    "        # if useElig && (s_l > 0.0) \n",
    "        if useElig \n",
    "            \n",
    "            # if s_l == 0.0\n",
    "            #     states  = copy( bestXs )\n",
    "            #     actions = copy( bestAs )\n",
    "            # end\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "            # println(\"SWAP\")\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709555b9-2598-4281-a634-c7b0681277d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Method 2 Performance, Average Vertical Duration [s]\n",
    "Each score is the best average score of the last two epochs: 32 epochs of 64 episodes each, Q-function swap after every episode \n",
    "\n",
    "### TD Tuning\n",
    "\n",
    "$\\gamma = 1.00$  \n",
    "\n",
    "| Param                |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|----------------------|------| ------- | ------- | ------- | ------- | ------- |------| ----- |\n",
    "| $$\\alpha = 0.99$$    |&nbsp;| 0.251   | 0.198   | 0.146   | 0.147   | 0.210   |&nbsp;| 0.190 |\n",
    "| $$\\alpha = 0.75$$    |&nbsp;| 0.179   | 0.185   | 0.239   | 0.179   | 0.175   |&nbsp;| 0.191 |\n",
    "| $$\\alpha = 0.50$$    |&nbsp;| 0.204   | 0.100   | 0.238   | 0.158   | 0.139   |&nbsp;| 0.168 |\n",
    "| $$\\alpha = 0.25$$    |&nbsp;| 0.294   | 0.170   | 0.107   | 0.223   | 0.147   |&nbsp;| 0.188 |\n",
    "| $$\\alpha = 0.125$$   |&nbsp;| 0.187   | 0.254   | 0.177   | 0.163   | 0.204   |&nbsp;| 0.197 |  \n",
    "| $$\\alpha = 0.0625$$  |&nbsp;| 0.113   | 0.241   | 0.353   | 0.134   | 0.749   |&nbsp;| 0.318 |\n",
    "| $$\\alpha = 0.03125$$ |&nbsp;| 0.231   | 0.322   | 0.018   | 0.098   | 0.000   |&nbsp;| 0.134 |\n",
    "| $$\\alpha = 0.02344$$ |&nbsp;| 1.289   | 0.119   | 0.380   | 0.168   | 0.086   |&nbsp;| 0.408 |\n",
    "| $$\\alpha = \\mathbf{0.02148}$$ |&nbsp;| 0.498   | 0.813   | 0.286   | 7.130   | 0.281   |&nbsp;| **1.802** |\n",
    "| $$\\alpha = 0.01953$$ |&nbsp;| 0.234   | 0.113   | 0.445   | 0.119   | 1.637   |&nbsp;| 0.510 |\n",
    "| $$\\alpha = 0.01758$$ |&nbsp;| 0.175   | 0.249   | 0.217   | 0.047   | 1.006   |&nbsp;| 0.339 |\n",
    "| $$\\alpha = 0.01563$$ |&nbsp;| 0.281   | 1.371   | 0.066   | 0.037   | 0.751   |&nbsp;| 0.501 |\n",
    "| $$\\alpha = 0.00782$$ |&nbsp;| 0.133   | 0.241   | 0.149   | 0.493   | 0.146   |&nbsp;| 0.232 |\n",
    "| $$\\alpha = 0.00391$$ |&nbsp;| 0.037   | 0.626   | 1.000   | 0.525   | 0.139   |&nbsp;| 0.465 |\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "### $\\gamma$ Tuning\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "\n",
    "| Param                 |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "| :-------------------- |------| ------- | ------- | ------- | ------- | ------- |------| ----- |\n",
    "| $$\\gamma = 0.999$$    |&nbsp;| 0.925   | 0.247   | 0.145   | 0.364   | 3.038   |&nbsp;| 0.944 |\n",
    "| $$\\gamma = 0.99$$     |&nbsp;| 0.011   | 0.448   | 0.453   | 0.915   | 0.013   |&nbsp;| 0.368 |\n",
    "| $$\\gamma = 0.85$$     |&nbsp;| 0.314   | 2.778   | 0.275   | 1.183   | 0.079   |&nbsp;| 0.926 |\n",
    "| $$\\gamma = 0.80$$     |&nbsp;| 0.082   | 0.033   | 0.173   | 0.251   | 1.741   |&nbsp;| 0.456 |\n",
    "| $$\\gamma = 0.75$$     |&nbsp;| 0.283   | 0.239   | 2.223   | 0.264   | 0.753   |&nbsp;| 0.752 |\n",
    "| $$\\gamma = 0.50$$     |&nbsp;| 0.167   | 0.289   | 0.474   | 0.266   | 0.230   |&nbsp;| 0.285 |\n",
    "\n",
    " \n",
    "### Double-Q Tuning, Swap Evey N Episodes  \n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "Epochs = 32\n",
    "\n",
    "| Param                 |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|-----------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| $$\\%\\ \\ 2$$           |&nbsp;|  0.570  | 0.132   | 1.053   | 0.731   | 0.900   |&nbsp;| 0.677 |\n",
    "| $$\\%\\ \\ 4$$           |&nbsp;|  1.313  | 0.087   | 2.282   | 0.417   | 0.409   |&nbsp;| 0.901 |\n",
    "| $$\\%\\ \\ 8$$           |&nbsp;|  0.097  | 0.040   | 0.621   | 0.030   | 0.608   |&nbsp;| 0.279 |\n",
    "| $$\\%16$$              |&nbsp;|  0.260  | 0.219   | 0.054   | 0.407   | 0.845   |&nbsp;| 0.357 |\n",
    "| $$\\%32$$              |&nbsp;|  0.674  | 0.130   | 0.301   | 0.286   | 0.313   |&nbsp;| 0.341 |\n",
    "| $$\\%\\mathbf{64}$$     |&nbsp;| 15.261  | 2.072   | 0.380   | 0.056   | 0.727   |&nbsp;| **3.699** |\n",
    "  \n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "Episodes = 128  \n",
    "Epochs = 16  \n",
    "\n",
    "| Param            |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| $$\\%\\ \\ \\ \\ 4$$  |&nbsp;|  1.333  | 0.117   | 0.138   | 0.430   | 0.149   |&nbsp;| 0.433 |\n",
    "| $$\\%\\ \\ 64$$     |&nbsp;|  0.166  | 0.110   | 0.240   | 1.615   | 0.049   |&nbsp;| 0.436 |\n",
    "| $$\\%128$$        |&nbsp;|  2.700  | 0.228   | 0.222   | 0.183   | 0.002   |&nbsp;| 0.667 |\n",
    "\n",
    "  \n",
    "### Trace Tuning\n",
    "\n",
    "This is not a Sutton and Barto eligibility trace.  Instead, I look for $N_\\text{peak}$ peaks in the value history of the episode, and apply the learning rule in reverse order from the peak through $N_\\text{step}$ previous timesteps, with a $\\lambda$ decay each step. This is neither classical nor rigorous, and if it does not work, then I will switch to one of the classic $Q(\\lambda)$ methods found in Sutton and Barto.\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "$\\lambda = 0.95$  \n",
    "Peaks = 16  \n",
    "Episodes = 64  \n",
    "Swap = \\%64  \n",
    "Epochs = 32  \n",
    "\n",
    "\n",
    "| Param                  |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|------------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| Steps: &nbsp; &nbsp; 4 |&nbsp;| 0.418   | 0.098   | 0.231   | 0.080   | 0.571   |&nbsp;| 0.280 |\n",
    "| Steps: &nbsp; 16       |&nbsp;| 0.540   | 0.365   | 1.629   | 0.215   | 0.470   |&nbsp;| 0.644 |\n",
    "| Steps: &nbsp; 64       |&nbsp;| 1.197   | 0.410   | 1.187   | 1.017   | 0.975   |&nbsp;| 0.957 |\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "$\\lambda = 0.99$  \n",
    "Peaks = 32  \n",
    "Episodes = 64  \n",
    "Swap = \\%64  \n",
    "Epochs = 32  \n",
    "\n",
    "Variations\n",
    "* Only trace non-zero uptime episodes, Result: Many more zero score episodes and no improvement\n",
    "* Only trace episodes with above-average uptime, Result: Many more zero score episodes and no improvement\n",
    "* Re-run the episode until there is non-zero uptime, Result: Extremely slow and no improvement in average uptime  \n",
    "\n",
    "| Param                  |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|------------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| Steps: &nbsp; 64       |&nbsp;| 0.265   |  1.204  | 6.919   | 1.575   |  3.940  |&nbsp;| 2.781 |\n",
    "| Steps: &nbsp; 96       |&nbsp;| 0.212   | 12.012  | 0.213   | 0.195   | 13.896  |&nbsp;| 5.306 |\n",
    "| **Steps: 128**         |&nbsp;| 0.065   | 17.540  | 0.493   | 0.325   | 15.345  |&nbsp;| **6.754** |\n",
    "| Steps: 192             |&nbsp;| 0.271   |  0.127  | 0.220   | 0.299   |  0.600  |&nbsp;| 0.303 |\n",
    "| Steps: 256             |&nbsp;| 0.958   |  2.014  | 0.947   | 0.433   |  0.045  |&nbsp;| 0.879 |\n",
    "| Steps: 512             |&nbsp;| 1.487   |  0.343  | 0.159   | 1.057   |  0.640  |&nbsp;| 0.737 |  \n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "$\\lambda = 0.99$  \n",
    "Steps = 128  \n",
    "Episodes = 64  \n",
    "Swap = \\%64  \n",
    "Epochs = 32  \n",
    "\n",
    "| Param                  |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|------------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| Peaks: &nbsp; &nbsp; 2 |&nbsp;|  0.635  | 5.336   | 0.198   | 0.069   | 0.624   |&nbsp;|       |\n",
    "| Peaks: &nbsp; &nbsp; 4 |&nbsp;|  0.086  | 0.270   | 0.286   | 0.704   | 0.122   |&nbsp;|       |\n",
    "| Peaks: &nbsp; &nbsp; 8 |&nbsp;| 17.591  | 0.446   | 0.334   | 0.317   | 1.206   |&nbsp;|       |\n",
    "| Peaks: &nbsp; 16       |&nbsp;|         |         |         |         |         |&nbsp;|       |\n",
    "| Peaks: &nbsp; 64       |&nbsp;|         |         |         |         |         |&nbsp;|       |\n",
    "| Peaks: 128             |&nbsp;|         |         |         |         |         |&nbsp;|       |\n",
    "\n",
    "### Learning Rate Decay\n",
    "\n",
    "### Blend: Best Episode\n",
    "\n",
    "$\\beta = 0.07$:  \n",
    "$\\beta = 0.15$: 0.244\n",
    "\n",
    "| Method      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n",
    "| ----------- | ------- | ------- | ------- | ------- | ------- | ---- |\n",
    "| Blend (Epi) |         |         |         |         |         |      |\n",
    "| Blend (Epo) |         |         |         |         |         |      |\n",
    "| TD          |         |         |         |         |         |      |\n",
    "| TD  + ????? |         |         |         |         |         |      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Process(`\u001b[4mplay\u001b[24m \u001b[4m-nq\u001b[24m \u001b[4m-t\u001b[24m \u001b[4malsa\u001b[24m \u001b[4msynth\u001b[24m \u001b[4m3\u001b[24m \u001b[4msine\u001b[24m \u001b[4m300\u001b[24m`, ProcessExited(0))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(`play -nq -t alsa synth 3 sine 300`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b5ade7-5f94-43b1-837f-85ccdd6b5c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
