{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.02148 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 # 0.00782 # 0.00391\n",
    "gamma    = 1.00 \n",
    "swapDiv  = 128\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes = 128 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   =  16 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "beta   = 0.15\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = false\n",
    "N_peaks =  40\n",
    "N_steps = 200\n",
    "lambda  =   0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.16, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.23000000000000007, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.7100000000000004, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 2.4599999999999915, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.46000000000000024, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.36000000000000015, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.8200000000000005, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.4000000000000002, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.12999999999999998, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.17, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.20000000000000004, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.18000000000000002, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.9400000000000006, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.8100000000000005, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.15, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.3100000000000001, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.26000000000000006, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.26000000000000006, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.19000000000000003, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.2418750000000001\n",
      "\n",
      "Epoch 2, Best Score: 2.4599999999999915\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.20000000000000004, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 1.0400000000000007, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.16, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.15, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.4200000000000002, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.35000000000000014, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.7200000000000004, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.3100000000000001, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 3.379999999999972, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.24000000000000007, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.49000000000000027, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.15, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 1.2100000000000009, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.4200000000000002, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.7100000000000004, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.19000000000000003, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.9500000000000006, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.25000000000000006, epsilon: 0.00390625\n",
      "Average Score: 0.6107812499999961\n",
      "\n",
      "Epoch 3, Best Score: 14.079999999999744\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 1.0100000000000007, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.13999999999999999, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.09, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.10999999999999999, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.25000000000000006, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 1.280000000000001, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.3000000000000001, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.46000000000000024, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.2700000000000001, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.3000000000000001, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.11999999999999998, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.3000000000000001, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.4300000000000002, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.46000000000000024, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.5400000000000003, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.3200000000000001, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.09, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.08, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.09999999999999999, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.5500000000000003, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.08, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.4200000000000002, epsilon: 0.00390625\n",
      "Average Score: 0.25257812500000004\n",
      "\n",
      "Epoch 4, Best Score: 14.079999999999744\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.12999999999999998, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.004609375000000001\n",
      "\n",
      "Epoch 5, Best Score: 14.079999999999744\n",
      "Training Iteration 4 score: 0.2700000000000001, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.3200000000000001, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.20000000000000004, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.2700000000000001, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.2900000000000001, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.15, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.35000000000000014, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.9700000000000006, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.25000000000000006, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.2900000000000001, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.22000000000000006, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.4300000000000002, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.3200000000000001, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.19000000000000003, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.16, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.07, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.5000000000000002, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.35000000000000014, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.34000000000000014, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.2700000000000001, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.2800000000000001, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.12999999999999998, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.34000000000000014, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.23000000000000007, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.18000000000000002, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.20000000000000004, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.19000000000000003, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.07, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.2800000000000001, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.18000000000000002, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.2700000000000001, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.18000000000000002, epsilon: 0.00390625\n",
      "Average Score: 0.22929687500000007\n",
      "\n",
      "Epoch 6, Best Score: 14.079999999999744\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 7, Best Score: 14.079999999999744\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.21000000000000005, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.24000000000000007, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.5800000000000003, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.26000000000000006, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.5700000000000003, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.26000000000000006, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.6900000000000004, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.09999999999999999, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.8700000000000006, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.3100000000000001, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.3100000000000001, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.5800000000000003, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.20000000000000004, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.49000000000000027, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.11999999999999998, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.5600000000000003, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.7400000000000004, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.2700000000000001, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.5000000000000002, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.9400000000000006, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.34000000000000014, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.3200000000000001, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.6300000000000003, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.26000000000000006, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.5000000000000002, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.49000000000000027, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.46000000000000024, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.3200000000000001, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.5600000000000003, epsilon: 0.00390625\n",
      "Average Score: 0.39468750000000014\n",
      "\n",
      "Epoch 8, Best Score: 14.079999999999744\n",
      "Training Iteration 4 score: 2.709999999999986, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.08, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.22000000000000006, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 2.06, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 1.0700000000000007, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.11999999999999998, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 2.8299999999999836, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 1.6300000000000012, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.2700000000000001, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 2.4499999999999917, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 2.099999999999999, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 3.179999999999976, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 1.7600000000000013, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.5200000000000002, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.49000000000000027, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 1.1900000000000008, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 7.309999999999889, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.21000000000000005, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.7718749999999978\n",
      "\n",
      "Epoch 9, Best Score: 14.079999999999744\n",
      "Training Iteration 4 score: 0.21000000000000005, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.19000000000000003, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.23000000000000007, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.07, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.5600000000000003, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.20000000000000004, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.6400000000000003, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.21000000000000005, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.21000000000000005, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.18000000000000002, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.22000000000000006, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.38000000000000017, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.5500000000000003, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.13999999999999999, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.23000000000000007, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.26000000000000006, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.4200000000000002, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.17, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.25000000000000006, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.21000000000000005, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.47000000000000025, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.22000000000000006, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.22000000000000006, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.26000000000000006, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.6300000000000003, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.2800000000000001, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.5900000000000003, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.17, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.5900000000000003, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.3000000000000001, epsilon: 0.00390625\n",
      "Average Score: 0.3028125000000004\n",
      "\n",
      "Epoch 10, Best Score: 14.079999999999744\n",
      "Training Iteration 4 score: 0.3300000000000001, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.5100000000000002, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 1.1000000000000008, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.9600000000000006, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.9700000000000006, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.7100000000000004, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.3000000000000001, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.8600000000000005, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.35000000000000014, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 1.0900000000000007, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.6400000000000003, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.4200000000000002, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.18000000000000002, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.6900000000000004, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.35000000000000014, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.7100000000000004, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.6800000000000004, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.6400000000000003, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.9400000000000006, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.9000000000000006, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.6900000000000004, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.8200000000000005, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.6700000000000004, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.9100000000000006, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 1.2200000000000009, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.9000000000000006, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.18000000000000002, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.4300000000000002, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.5800000000000003, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 1.0700000000000007, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.8600000000000005, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 1.1200000000000008, epsilon: 0.00390625\n",
      "Average Score: 0.7550000000000008\n",
      "\n",
      "Epoch 11, Best Score: 14.079999999999744\n",
      "Training Iteration 4 score: 0.4100000000000002, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.3100000000000001, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.09, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 1.0300000000000007, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.5900000000000003, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.48000000000000026, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.7900000000000005, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.20000000000000004, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.5400000000000003, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.5500000000000003, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 1.0100000000000007, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.8400000000000005, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.8100000000000005, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 1.1200000000000008, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.7400000000000004, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.6700000000000004, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 1.9500000000000015, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.6400000000000003, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 1.6800000000000013, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.8700000000000006, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.5200000000000002, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 1.460000000000001, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.8800000000000006, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 2.9699999999999807, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.8800000000000006, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 4.609999999999946, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 4.3599999999999515, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 4.999999999999938, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 4.059999999999958, epsilon: 0.00390625\n",
      "Average Score: 1.1142187499999958\n",
      "\n",
      "Epoch 12, Best Score: 14.079999999999744\n",
      "Training Iteration 4 score: 1.460000000000001, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.26000000000000006, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.8200000000000005, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.4400000000000002, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.24000000000000007, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.4300000000000002, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 1.1400000000000008, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.8000000000000005, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.24000000000000007, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 1.260000000000001, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.5900000000000003, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.8100000000000005, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.8300000000000005, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 1.8000000000000014, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.3300000000000001, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 1.370000000000001, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.16, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.5400000000000003, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 1.340000000000001, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 1.340000000000001, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.5800000000000003, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.6900000000000004, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.15, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.22000000000000006, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.19000000000000003, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.7400000000000004, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.5300000000000002, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 1.0700000000000007, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.6700000000000004, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.6500000000000004, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.7300000000000004, epsilon: 0.00390625\n",
      "Average Score: 0.7562500000000008\n",
      "\n",
      "Epoch 13, Best Score: 14.079999999999744\n",
      "Training Iteration 4 score: 0.9000000000000006, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.38000000000000017, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.34000000000000014, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.35000000000000014, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.5500000000000003, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.45000000000000023, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.36000000000000015, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.3200000000000001, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.4300000000000002, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.49000000000000027, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.26000000000000006, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.7100000000000004, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.49000000000000027, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.6600000000000004, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.3100000000000001, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.3100000000000001, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.3900000000000002, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.36000000000000015, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.8700000000000006, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.5800000000000003, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.6100000000000003, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.3900000000000002, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.37000000000000016, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.5200000000000002, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.25000000000000006, epsilon: 0.00390625\n",
      "Average Score: 0.35359375000000015\n",
      "\n",
      "Epoch 14, Best Score: 14.079999999999744\n",
      "Training Iteration 4 score: 0.46000000000000024, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.23000000000000007, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.008671875000000004\n",
      "\n",
      "Epoch 15, Best Score: 14.079999999999744\n",
      "Training Iteration 4 score: 0.3900000000000002, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.36000000000000015, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.09999999999999999, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.3300000000000001, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.4000000000000002, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.3900000000000002, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.2800000000000001, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.38000000000000017, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.13999999999999999, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.34000000000000014, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.3000000000000001, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.2700000000000001, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.36000000000000015, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.15, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.19000000000000003, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.4400000000000002, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.2800000000000001, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.3100000000000001, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.35000000000000014, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.09999999999999999, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.11999999999999998, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.22828125000000007\n",
      "\n",
      "Epoch 16, Best Score: 14.079999999999744\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.0\n",
      "Saved a trained Q-table with size (76032,), After 12.495086034138998 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip120\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip120)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip121\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip120)\" d=\"\n",
       "M186.274 1486.45 L2352.76 1486.45 L2352.76 47.2441 L186.274 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip122\">\n",
       "    <rect x=\"186\" y=\"47\" width=\"2167\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip122)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  520.103,1486.45 520.103,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip122)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  928.873,1486.45 928.873,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip122)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1337.64,1486.45 1337.64,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip122)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1746.41,1486.45 1746.41,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip122)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2155.18,1486.45 2155.18,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  520.103,1486.45 520.103,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  928.873,1486.45 928.873,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1337.64,1486.45 1337.64,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1746.41,1486.45 1746.41,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2155.18,1486.45 2155.18,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip120)\" d=\"M524.351 1530.21 Q527.707 1530.93 529.582 1533.2 Q531.48 1535.47 531.48 1538.8 Q531.48 1543.92 527.962 1546.72 Q524.443 1549.52 517.962 1549.52 Q515.786 1549.52 513.471 1549.08 Q511.179 1548.66 508.726 1547.81 L508.726 1543.29 Q510.67 1544.43 512.985 1545.01 Q515.3 1545.58 517.823 1545.58 Q522.221 1545.58 524.513 1543.85 Q526.827 1542.11 526.827 1538.8 Q526.827 1535.75 524.675 1534.03 Q522.545 1532.3 518.726 1532.3 L514.698 1532.3 L514.698 1528.45 L518.911 1528.45 Q522.36 1528.45 524.189 1527.09 Q526.017 1525.7 526.017 1523.11 Q526.017 1520.45 524.119 1519.03 Q522.244 1517.6 518.726 1517.6 Q516.804 1517.6 514.605 1518.01 Q512.406 1518.43 509.767 1519.31 L509.767 1515.14 Q512.429 1514.4 514.744 1514.03 Q517.082 1513.66 519.142 1513.66 Q524.466 1513.66 527.568 1516.09 Q530.67 1518.5 530.67 1522.62 Q530.67 1525.49 529.027 1527.48 Q527.383 1529.45 524.351 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M929.278 1529.7 Q926.13 1529.7 924.278 1531.86 Q922.45 1534.01 922.45 1537.76 Q922.45 1541.49 924.278 1543.66 Q926.13 1545.82 929.278 1545.82 Q932.426 1545.82 934.255 1543.66 Q936.107 1541.49 936.107 1537.76 Q936.107 1534.01 934.255 1531.86 Q932.426 1529.7 929.278 1529.7 M938.561 1515.05 L938.561 1519.31 Q936.801 1518.48 934.996 1518.04 Q933.213 1517.6 931.454 1517.6 Q926.825 1517.6 924.371 1520.72 Q921.94 1523.85 921.593 1530.17 Q922.959 1528.15 925.019 1527.09 Q927.079 1526 929.556 1526 Q934.764 1526 937.774 1529.17 Q940.806 1532.32 940.806 1537.76 Q940.806 1543.08 937.658 1546.3 Q934.51 1549.52 929.278 1549.52 Q923.283 1549.52 920.112 1544.94 Q916.94 1540.33 916.94 1531.6 Q916.94 1523.41 920.829 1518.55 Q924.718 1513.66 931.269 1513.66 Q933.028 1513.66 934.811 1514.01 Q936.616 1514.36 938.561 1515.05 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M1327.94 1548.13 L1327.94 1543.87 Q1329.7 1544.7 1331.51 1545.14 Q1333.31 1545.58 1335.05 1545.58 Q1339.68 1545.58 1342.11 1542.48 Q1344.56 1539.36 1344.91 1533.01 Q1343.57 1535.01 1341.51 1536.07 Q1339.45 1537.13 1336.95 1537.13 Q1331.76 1537.13 1328.73 1534.01 Q1325.72 1530.86 1325.72 1525.42 Q1325.72 1520.1 1328.87 1516.88 Q1332.02 1513.66 1337.25 1513.66 Q1343.25 1513.66 1346.39 1518.27 Q1349.56 1522.85 1349.56 1531.6 Q1349.56 1539.77 1345.68 1544.66 Q1341.81 1549.52 1335.26 1549.52 Q1333.5 1549.52 1331.69 1549.17 Q1329.89 1548.82 1327.94 1548.13 M1337.25 1533.48 Q1340.4 1533.48 1342.23 1531.32 Q1344.08 1529.17 1344.08 1525.42 Q1344.08 1521.7 1342.23 1519.54 Q1340.4 1517.37 1337.25 1517.37 Q1334.1 1517.37 1332.25 1519.54 Q1330.42 1521.7 1330.42 1525.42 Q1330.42 1529.17 1332.25 1531.32 Q1334.1 1533.48 1337.25 1533.48 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M1721.9 1544.91 L1729.54 1544.91 L1729.54 1518.55 L1721.23 1520.21 L1721.23 1515.95 L1729.49 1514.29 L1734.17 1514.29 L1734.17 1544.91 L1741.81 1544.91 L1741.81 1548.85 L1721.9 1548.85 L1721.9 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M1755.28 1544.91 L1771.6 1544.91 L1771.6 1548.85 L1749.65 1548.85 L1749.65 1544.91 Q1752.32 1542.16 1756.9 1537.53 Q1761.51 1532.88 1762.69 1531.53 Q1764.93 1529.01 1765.81 1527.27 Q1766.71 1525.51 1766.71 1523.82 Q1766.71 1521.07 1764.77 1519.33 Q1762.85 1517.6 1759.75 1517.6 Q1757.55 1517.6 1755.09 1518.36 Q1752.66 1519.13 1749.89 1520.68 L1749.89 1515.95 Q1752.71 1514.82 1755.16 1514.24 Q1757.62 1513.66 1759.65 1513.66 Q1765.02 1513.66 1768.22 1516.35 Q1771.41 1519.03 1771.41 1523.52 Q1771.41 1525.65 1770.6 1527.57 Q1769.82 1529.47 1767.71 1532.07 Q1767.13 1532.74 1764.03 1535.95 Q1760.93 1539.15 1755.28 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M2130.37 1544.91 L2138.01 1544.91 L2138.01 1518.55 L2129.7 1520.21 L2129.7 1515.95 L2137.96 1514.29 L2142.64 1514.29 L2142.64 1544.91 L2150.28 1544.91 L2150.28 1548.85 L2130.37 1548.85 L2130.37 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M2159.77 1514.29 L2178.12 1514.29 L2178.12 1518.22 L2164.05 1518.22 L2164.05 1526.7 Q2165.07 1526.35 2166.09 1526.19 Q2167.1 1526 2168.12 1526 Q2173.91 1526 2177.29 1529.17 Q2180.67 1532.34 2180.67 1537.76 Q2180.67 1543.34 2177.2 1546.44 Q2173.73 1549.52 2167.41 1549.52 Q2165.23 1549.52 2162.96 1549.15 Q2160.72 1548.78 2158.31 1548.04 L2158.31 1543.34 Q2160.39 1544.47 2162.61 1545.03 Q2164.84 1545.58 2167.31 1545.58 Q2171.32 1545.58 2173.66 1543.48 Q2175.99 1541.37 2175.99 1537.76 Q2175.99 1534.15 2173.66 1532.04 Q2171.32 1529.94 2167.31 1529.94 Q2165.44 1529.94 2163.56 1530.35 Q2161.71 1530.77 2159.77 1531.65 L2159.77 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip122)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,1445.72 2352.76,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip122)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,1141.08 2352.76,1141.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip122)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,836.437 2352.76,836.437 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip122)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,531.798 2352.76,531.798 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip122)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,227.158 2352.76,227.158 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,1486.45 186.274,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,1445.72 205.172,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,1141.08 205.172,1141.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,836.437 205.172,836.437 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,531.798 205.172,531.798 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,227.158 205.172,227.158 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip120)\" d=\"M62.9365 1431.51 Q59.3254 1431.51 57.4967 1435.08 Q55.6912 1438.62 55.6912 1445.75 Q55.6912 1452.86 57.4967 1456.42 Q59.3254 1459.96 62.9365 1459.96 Q66.5707 1459.96 68.3763 1456.42 Q70.205 1452.86 70.205 1445.75 Q70.205 1438.62 68.3763 1435.08 Q66.5707 1431.51 62.9365 1431.51 M62.9365 1427.81 Q68.7467 1427.81 71.8022 1432.42 Q74.8809 1437 74.8809 1445.75 Q74.8809 1454.48 71.8022 1459.08 Q68.7467 1463.67 62.9365 1463.67 Q57.1264 1463.67 54.0477 1459.08 Q50.9921 1454.48 50.9921 1445.75 Q50.9921 1437 54.0477 1432.42 Q57.1264 1427.81 62.9365 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M83.0984 1457.12 L87.9827 1457.12 L87.9827 1463 L83.0984 1463 L83.0984 1457.12 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M108.168 1431.51 Q104.557 1431.51 102.728 1435.08 Q100.922 1438.62 100.922 1445.75 Q100.922 1452.86 102.728 1456.42 Q104.557 1459.96 108.168 1459.96 Q111.802 1459.96 113.608 1456.42 Q115.436 1452.86 115.436 1445.75 Q115.436 1438.62 113.608 1435.08 Q111.802 1431.51 108.168 1431.51 M108.168 1427.81 Q113.978 1427.81 117.033 1432.42 Q120.112 1437 120.112 1445.75 Q120.112 1454.48 117.033 1459.08 Q113.978 1463.67 108.168 1463.67 Q102.358 1463.67 99.2789 1459.08 Q96.2234 1454.48 96.2234 1445.75 Q96.2234 1437 99.2789 1432.42 Q102.358 1427.81 108.168 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M138.33 1431.51 Q134.719 1431.51 132.89 1435.08 Q131.084 1438.62 131.084 1445.75 Q131.084 1452.86 132.89 1456.42 Q134.719 1459.96 138.33 1459.96 Q141.964 1459.96 143.769 1456.42 Q145.598 1452.86 145.598 1445.75 Q145.598 1438.62 143.769 1435.08 Q141.964 1431.51 138.33 1431.51 M138.33 1427.81 Q144.14 1427.81 147.195 1432.42 Q150.274 1437 150.274 1445.75 Q150.274 1454.48 147.195 1459.08 Q144.14 1463.67 138.33 1463.67 Q132.519 1463.67 129.441 1459.08 Q126.385 1454.48 126.385 1445.75 Q126.385 1437 129.441 1432.42 Q132.519 1427.81 138.33 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M63.9319 1126.88 Q60.3208 1126.88 58.4921 1130.44 Q56.6865 1133.98 56.6865 1141.11 Q56.6865 1148.22 58.4921 1151.78 Q60.3208 1155.32 63.9319 1155.32 Q67.5661 1155.32 69.3717 1151.78 Q71.2004 1148.22 71.2004 1141.11 Q71.2004 1133.98 69.3717 1130.44 Q67.5661 1126.88 63.9319 1126.88 M63.9319 1123.17 Q69.742 1123.17 72.7976 1127.78 Q75.8763 1132.36 75.8763 1141.11 Q75.8763 1149.84 72.7976 1154.44 Q69.742 1159.03 63.9319 1159.03 Q58.1217 1159.03 55.043 1154.44 Q51.9875 1149.84 51.9875 1141.11 Q51.9875 1132.36 55.043 1127.78 Q58.1217 1123.17 63.9319 1123.17 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M84.0938 1152.48 L88.978 1152.48 L88.978 1158.36 L84.0938 1158.36 L84.0938 1152.48 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M103.191 1154.42 L119.51 1154.42 L119.51 1158.36 L97.566 1158.36 L97.566 1154.42 Q100.228 1151.67 104.811 1147.04 Q109.418 1142.38 110.598 1141.04 Q112.844 1138.52 113.723 1136.78 Q114.626 1135.02 114.626 1133.33 Q114.626 1130.58 112.682 1128.84 Q110.76 1127.11 107.658 1127.11 Q105.459 1127.11 103.006 1127.87 Q100.575 1128.63 97.7974 1130.19 L97.7974 1125.46 Q100.621 1124.33 103.075 1123.75 Q105.529 1123.17 107.566 1123.17 Q112.936 1123.17 116.131 1125.86 Q119.325 1128.54 119.325 1133.03 Q119.325 1135.16 118.515 1137.08 Q117.728 1138.98 115.621 1141.57 Q115.043 1142.25 111.941 1145.46 Q108.839 1148.66 103.191 1154.42 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M129.371 1123.8 L147.728 1123.8 L147.728 1127.73 L133.654 1127.73 L133.654 1136.2 Q134.672 1135.86 135.691 1135.69 Q136.709 1135.51 137.728 1135.51 Q143.515 1135.51 146.894 1138.68 Q150.274 1141.85 150.274 1147.27 Q150.274 1152.85 146.802 1155.95 Q143.33 1159.03 137.01 1159.03 Q134.834 1159.03 132.566 1158.66 Q130.32 1158.29 127.913 1157.55 L127.913 1152.85 Q129.996 1153.98 132.219 1154.54 Q134.441 1155.09 136.918 1155.09 Q140.922 1155.09 143.26 1152.99 Q145.598 1150.88 145.598 1147.27 Q145.598 1143.66 143.26 1141.55 Q140.922 1139.44 136.918 1139.44 Q135.043 1139.44 133.168 1139.86 Q131.316 1140.28 129.371 1141.16 L129.371 1123.8 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M62.9365 822.236 Q59.3254 822.236 57.4967 825.801 Q55.6912 829.342 55.6912 836.472 Q55.6912 843.578 57.4967 847.143 Q59.3254 850.685 62.9365 850.685 Q66.5707 850.685 68.3763 847.143 Q70.205 843.578 70.205 836.472 Q70.205 829.342 68.3763 825.801 Q66.5707 822.236 62.9365 822.236 M62.9365 818.532 Q68.7467 818.532 71.8022 823.138 Q74.8809 827.722 74.8809 836.472 Q74.8809 845.199 71.8022 849.805 Q68.7467 854.388 62.9365 854.388 Q57.1264 854.388 54.0477 849.805 Q50.9921 845.199 50.9921 836.472 Q50.9921 827.722 54.0477 823.138 Q57.1264 818.532 62.9365 818.532 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M83.0984 847.837 L87.9827 847.837 L87.9827 853.717 L83.0984 853.717 L83.0984 847.837 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M98.2141 819.157 L116.57 819.157 L116.57 823.092 L102.496 823.092 L102.496 831.564 Q103.515 831.217 104.534 831.055 Q105.552 830.87 106.571 830.87 Q112.358 830.87 115.737 834.041 Q119.117 837.212 119.117 842.629 Q119.117 848.208 115.645 851.31 Q112.172 854.388 105.853 854.388 Q103.677 854.388 101.409 854.018 Q99.1632 853.648 96.7558 852.907 L96.7558 848.208 Q98.8391 849.342 101.061 849.898 Q103.284 850.453 105.76 850.453 Q109.765 850.453 112.103 848.347 Q114.441 846.24 114.441 842.629 Q114.441 839.018 112.103 836.912 Q109.765 834.805 105.76 834.805 Q103.885 834.805 102.01 835.222 Q100.159 835.638 98.2141 836.518 L98.2141 819.157 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M138.33 822.236 Q134.719 822.236 132.89 825.801 Q131.084 829.342 131.084 836.472 Q131.084 843.578 132.89 847.143 Q134.719 850.685 138.33 850.685 Q141.964 850.685 143.769 847.143 Q145.598 843.578 145.598 836.472 Q145.598 829.342 143.769 825.801 Q141.964 822.236 138.33 822.236 M138.33 818.532 Q144.14 818.532 147.195 823.138 Q150.274 827.722 150.274 836.472 Q150.274 845.199 147.195 849.805 Q144.14 854.388 138.33 854.388 Q132.519 854.388 129.441 849.805 Q126.385 845.199 126.385 836.472 Q126.385 827.722 129.441 823.138 Q132.519 818.532 138.33 818.532 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M63.9319 517.596 Q60.3208 517.596 58.4921 521.161 Q56.6865 524.703 56.6865 531.832 Q56.6865 538.939 58.4921 542.504 Q60.3208 546.045 63.9319 546.045 Q67.5661 546.045 69.3717 542.504 Q71.2004 538.939 71.2004 531.832 Q71.2004 524.703 69.3717 521.161 Q67.5661 517.596 63.9319 517.596 M63.9319 513.893 Q69.742 513.893 72.7976 518.499 Q75.8763 523.082 75.8763 531.832 Q75.8763 540.559 72.7976 545.166 Q69.742 549.749 63.9319 549.749 Q58.1217 549.749 55.043 545.166 Q51.9875 540.559 51.9875 531.832 Q51.9875 523.082 55.043 518.499 Q58.1217 513.893 63.9319 513.893 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M84.0938 543.198 L88.978 543.198 L88.978 549.078 L84.0938 549.078 L84.0938 543.198 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M97.9826 514.518 L120.205 514.518 L120.205 516.508 L107.658 549.078 L102.774 549.078 L114.58 518.453 L97.9826 518.453 L97.9826 514.518 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M129.371 514.518 L147.728 514.518 L147.728 518.453 L133.654 518.453 L133.654 526.925 Q134.672 526.578 135.691 526.416 Q136.709 526.231 137.728 526.231 Q143.515 526.231 146.894 529.402 Q150.274 532.573 150.274 537.99 Q150.274 543.568 146.802 546.67 Q143.33 549.749 137.01 549.749 Q134.834 549.749 132.566 549.379 Q130.32 549.008 127.913 548.268 L127.913 543.568 Q129.996 544.703 132.219 545.258 Q134.441 545.814 136.918 545.814 Q140.922 545.814 143.26 543.707 Q145.598 541.601 145.598 537.99 Q145.598 534.379 143.26 532.272 Q140.922 530.166 136.918 530.166 Q135.043 530.166 133.168 530.582 Q131.316 530.999 129.371 531.879 L129.371 514.518 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M53.7467 240.503 L61.3856 240.503 L61.3856 214.138 L53.0754 215.804 L53.0754 211.545 L61.3393 209.878 L66.0152 209.878 L66.0152 240.503 L73.654 240.503 L73.654 244.438 L53.7467 244.438 L53.7467 240.503 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M83.0984 238.559 L87.9827 238.559 L87.9827 244.438 L83.0984 244.438 L83.0984 238.559 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M108.168 212.957 Q104.557 212.957 102.728 216.522 Q100.922 220.064 100.922 227.193 Q100.922 234.3 102.728 237.864 Q104.557 241.406 108.168 241.406 Q111.802 241.406 113.608 237.864 Q115.436 234.3 115.436 227.193 Q115.436 220.064 113.608 216.522 Q111.802 212.957 108.168 212.957 M108.168 209.253 Q113.978 209.253 117.033 213.86 Q120.112 218.443 120.112 227.193 Q120.112 235.92 117.033 240.526 Q113.978 245.11 108.168 245.11 Q102.358 245.11 99.2789 240.526 Q96.2234 235.92 96.2234 227.193 Q96.2234 218.443 99.2789 213.86 Q102.358 209.253 108.168 209.253 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M138.33 212.957 Q134.719 212.957 132.89 216.522 Q131.084 220.064 131.084 227.193 Q131.084 234.3 132.89 237.864 Q134.719 241.406 138.33 241.406 Q141.964 241.406 143.769 237.864 Q145.598 234.3 145.598 227.193 Q145.598 220.064 143.769 216.522 Q141.964 212.957 138.33 212.957 M138.33 209.253 Q144.14 209.253 147.195 213.86 Q150.274 218.443 150.274 227.193 Q150.274 235.92 147.195 240.526 Q144.14 245.11 138.33 245.11 Q132.519 245.11 129.441 240.526 Q126.385 235.92 126.385 227.193 Q126.385 218.443 129.441 213.86 Q132.519 209.253 138.33 209.253 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip122)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  247.59,1150.98 383.846,701.444 520.103,1137.93 656.36,1440.1 792.616,1166.3 928.873,1445.72 1065.13,964.766 1201.39,505.142 1337.64,1076.72 1473.9,525.705 \n",
       "  1610.16,87.9763 1746.41,524.182 1882.67,1014.84 2018.93,1435.15 2155.18,1167.54 2291.44,1445.72 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip120)\" d=\"\n",
       "M1987.39 198.898 L2280.54 198.898 L2280.54 95.2176 L1987.39 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1987.39,198.898 2280.54,198.898 2280.54,95.2176 1987.39,95.2176 1987.39,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2011.46,147.058 2155.89,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip120)\" d=\"M2193.81 166.745 Q2192 171.375 2190.29 172.787 Q2188.58 174.199 2185.71 174.199 L2182.3 174.199 L2182.3 170.634 L2184.8 170.634 Q2186.56 170.634 2187.53 169.8 Q2188.51 168.967 2189.69 165.865 L2190.45 163.921 L2179.97 138.412 L2184.48 138.412 L2192.58 158.689 L2200.68 138.412 L2205.2 138.412 L2193.81 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M2212.49 160.402 L2220.13 160.402 L2220.13 134.037 L2211.82 135.703 L2211.82 131.444 L2220.08 129.778 L2224.76 129.778 L2224.76 160.402 L2232.4 160.402 L2232.4 164.338 L2212.49 164.338 L2212.49 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/episodes\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        X  = X_0\n",
    "        \n",
    "        ##### Double Q-Learning ###########################################\n",
    "\n",
    "        for k = 1:T\n",
    "\n",
    "            # 1. Choose action\n",
    "            if rand() < epsilon\n",
    "                if rand() < EXPrand \n",
    "                    A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                else\n",
    "                    A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                end\n",
    "            else\n",
    "\n",
    "                A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                if A == 1000.0 # Indicates no values in this region\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "\n",
    "            # 2. Cache last state\n",
    "            qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "            # 3. Generate the next stae\n",
    "            Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "            # 4. Collect reward R( s, a, s' )\n",
    "            R_t = cartpole_reward( Xp )\n",
    "\n",
    "            # 5. Get the optimal action at the next state\n",
    "            a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "            # 6. Compute the value at the next state\n",
    "\n",
    "            V_tp1_opt = query_value_fuzzy( \n",
    "                Q_kdTree, G, V, \n",
    "                get_Q( \n",
    "                    select_X_vector( Xp ), \n",
    "                    a_tp1_opt \n",
    "                ); \n",
    "                k = vNN \n",
    "            )\n",
    "            if isnan( V_tp1_opt )\n",
    "                V_tp1_opt = 0.0\n",
    "            end\n",
    "\n",
    "\n",
    "            # 7. Blend the value back into nearest points\n",
    "\n",
    "            idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "            nNear      = size( idxs, 1 )\n",
    "            for i = 1:nNear\n",
    "                j    = idxs[i]\n",
    "                if !isnan( wgts[i] ) \n",
    "\n",
    "                    # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                    VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "                    \n",
    "                end\n",
    "            end\n",
    "\n",
    "            states[:,k] = Xp\n",
    "            actions[k]  = A\n",
    "\n",
    "            X = Xp\n",
    "        end\n",
    "\n",
    "        s_l    = vertical_score_s( states, aMargin, ts )\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        if useElig\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "            # println(\"SWAP\")\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709555b9-2598-4281-a634-c7b0681277d0",
   "metadata": {},
   "source": [
    "# Method 2 Performance, Average Vertical Duration [s]\n",
    "Each score is the best average score of the last two epochs: 32 epochs of 64 episodes each, Q-function swap after every episode \n",
    "\n",
    "### TD Tuning\n",
    "\n",
    "$\\gamma = 1.00$  \n",
    "\n",
    "| Param                |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|----------------------|------| ------- | ------- | ------- | ------- | ------- |------| ----- |\n",
    "| $$\\alpha = 0.99$$    |&nbsp;| 0.251   | 0.198   | 0.146   | 0.147   | 0.210   |&nbsp;| 0.190 |\n",
    "| $$\\alpha = 0.75$$    |&nbsp;| 0.179   | 0.185   | 0.239   | 0.179   | 0.175   |&nbsp;| 0.191 |\n",
    "| $$\\alpha = 0.50$$    |&nbsp;| 0.204   | 0.100   | 0.238   | 0.158   | 0.139   |&nbsp;| 0.168 |\n",
    "| $$\\alpha = 0.25$$    |&nbsp;| 0.294   | 0.170   | 0.107   | 0.223   | 0.147   |&nbsp;| 0.188 |\n",
    "| $$\\alpha = 0.125$$   |&nbsp;| 0.187   | 0.254   | 0.177   | 0.163   | 0.204   |&nbsp;| 0.197 |  \n",
    "| $$\\alpha = 0.0625$$  |&nbsp;| 0.113   | 0.241   | 0.353   | 0.134   | 0.749   |&nbsp;| 0.318 |\n",
    "| $$\\alpha = 0.03125$$ |&nbsp;| 0.231   | 0.322   | 0.018   | 0.098   | 0.000   |&nbsp;| 0.134 |\n",
    "| $$\\alpha = 0.02344$$ |&nbsp;| 1.289   | 0.119   | 0.380   | 0.168   | 0.086   |&nbsp;| 0.408 |\n",
    "| $$\\alpha = \\mathbf{0.02148}$$ |&nbsp;| 0.498   | 0.813   | 0.286   | 7.130   | 0.281   |&nbsp;| **1.802** |\n",
    "| $$\\alpha = 0.01953$$ |&nbsp;| 0.234   | 0.113   | 0.445   | 0.119   | 1.637   |&nbsp;| 0.510 |\n",
    "| $$\\alpha = 0.01758$$ |&nbsp;| 0.175   | 0.249   | 0.217   | 0.047   | 1.006   |&nbsp;| 0.339 |\n",
    "| $$\\alpha = 0.01563$$ |&nbsp;| 0.281   | 1.371   | 0.066   | 0.037   | 0.751   |&nbsp;| 0.501 |\n",
    "| $$\\alpha = 0.00782$$ |&nbsp;| 0.133   | 0.241   | 0.149   | 0.493   | 0.146   |&nbsp;| 0.232 |\n",
    "| $$\\alpha = 0.00391$$ |&nbsp;| 0.037   | 0.626   | 1.000   | 0.525   | 0.139   |&nbsp;| 0.465 |\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "### $\\gamma$ Tuning\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "\n",
    "| Param                 |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "| :-------------------- |------| ------- | ------- | ------- | ------- | ------- |------| ----- |\n",
    "| $$\\gamma = 0.999$$    |&nbsp;| 0.925   | 0.247   | 0.145   | 0.364   | 3.038   |&nbsp;| 0.944 |\n",
    "| $$\\gamma = 0.99$$     |&nbsp;| 0.011   | 0.448   | 0.453   | 0.915   | 0.013   |&nbsp;| 0.368 |\n",
    "| $$\\gamma = 0.85$$     |&nbsp;| 0.314   | 2.778   | 0.275   | 1.183   | 0.079   |&nbsp;| 0.926 |\n",
    "| $$\\gamma = 0.80$$     |&nbsp;| 0.082   | 0.033   | 0.173   | 0.251   | 1.741   |&nbsp;| 0.456 |\n",
    "| $$\\gamma = 0.75$$     |&nbsp;| 0.283   | 0.239   | 2.223   | 0.264   | 0.753   |&nbsp;| 0.752 |\n",
    "| $$\\gamma = 0.50$$     |&nbsp;| 0.167   | 0.289   | 0.474   | 0.266   | 0.230   |&nbsp;| 0.285 |\n",
    "\n",
    " \n",
    "### Double-Q Tuning, Swap Evey N Episodes\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "Epochs = 32\n",
    "\n",
    "| Param                 |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|-----------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| $$\\%\\ \\ 2$$           |&nbsp;|  0.570  | 0.132   | 1.053   | 0.731   | 0.900   |&nbsp;| 0.677 |\n",
    "| $$\\%\\ \\ 4$$           |&nbsp;|  1.313  | 0.087   | 2.282   | 0.417   | 0.409   |&nbsp;| 0.901 |\n",
    "| $$\\%\\ \\ 8$$           |&nbsp;|  0.097  | 0.040   | 0.621   | 0.030   | 0.608   |&nbsp;| 0.279 |\n",
    "| $$\\%16$$              |&nbsp;|  0.260  | 0.219   | 0.054   | 0.407   | 0.845   |&nbsp;| 0.357 |\n",
    "| $$\\%32$$              |&nbsp;|  0.674  | 0.130   | 0.301   | 0.286   | 0.313   |&nbsp;| 0.341 |\n",
    "| $$\\%\\mathbf{64}$$     |&nbsp;| 15.261  | 2.072   | 0.380   | 0.056   | 0.727   |&nbsp;| **3.699** |\n",
    "  \n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "Episodes = 128\n",
    "Epochs = 16\n",
    "\n",
    "| Param            |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| $$\\%\\ \\ \\ \\ 4$$  |&nbsp;|  1.333  | 0.117   |         |         |         |&nbsp;|       |\n",
    "| $$\\%\\ \\ 64$$     |&nbsp;|  0.166  | 0.110   |         |         |         |&nbsp;|       |\n",
    "| $$\\%128$$        |&nbsp;|  2.700  | 0.228   |         |         |         |&nbsp;|       |\n",
    "\n",
    "  \n",
    "### Trace Tuning\n",
    "\n",
    "\n",
    "### Blend: Best Episode\n",
    "\n",
    "$\\beta = 0.07$:  \n",
    "$\\beta = 0.15$: 0.244\n",
    "\n",
    "| Method      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n",
    "| ----------- | ------- | ------- | ------- | ------- | ------- | ---- |\n",
    "| Blend (Epi) |         |         |         |         |         |      |\n",
    "| Blend (Epo) |         |         |         |         |         |      |\n",
    "| TD          |         |         |         |         |         |      |\n",
    "| TD  + ????? |         |         |         |         |         |      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Process(`\u001b[4mplay\u001b[24m \u001b[4m-nq\u001b[24m \u001b[4m-t\u001b[24m \u001b[4malsa\u001b[24m \u001b[4msynth\u001b[24m \u001b[4m3\u001b[24m \u001b[4msine\u001b[24m \u001b[4m300\u001b[24m`, ProcessExited(0))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(`play -nq -t alsa synth 3 sine 300`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b5ade7-5f94-43b1-837f-85ccdd6b5c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
