{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.02148 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 # 0.00782 # 0.00391\n",
    "gamma    = 0.80 \n",
    "swapDiv  = 1\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes =  64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   =  32 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "beta   = 0.15\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = false\n",
    "N_peaks =  40\n",
    "N_steps = 200\n",
    "lambda  =   0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.8300000000000005, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.08, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.07, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.48000000000000026, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.11218750000000006\n",
      "\n",
      "Epoch 2, Best Score: 0.9900000000000007\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.05812500000000003\n",
      "\n",
      "Epoch 3, Best Score: 0.9900000000000007\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 1.0000000000000007, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 1.9900000000000015, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 2.719999999999986, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.4532812499999987\n",
      "\n",
      "Epoch 4, Best Score: 4.009999999999959\n",
      "Training Iteration 4 score: 0.34000000000000014, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 1.2400000000000009, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.08, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.5800000000000003, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.21000000000000005, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.17, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.15, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.22000000000000006, epsilon: 0.0078125\n",
      "Average Score: 0.2606250000000001\n",
      "\n",
      "Epoch 5, Best Score: 4.009999999999959\n",
      "Training Iteration 4 score: 0.24000000000000007, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.8900000000000006, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.45000000000000023, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.5400000000000003, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.4200000000000002, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.45000000000000023, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.09999999999999999, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.3900000000000002, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 1.6000000000000012, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 2.149999999999998, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.5600000000000003, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.48000000000000026, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.46000000000000024, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.2700000000000001, epsilon: 0.0078125\n",
      "Average Score: 0.5484375000000001\n",
      "\n",
      "Epoch 6, Best Score: 4.009999999999959\n",
      "Training Iteration 4 score: 0.19000000000000003, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.17, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.23000000000000007, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.8100000000000005, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.7800000000000005, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.4000000000000002, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.5600000000000003, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.6600000000000004, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.2800000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.18000000000000002, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.35000000000000014, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 1.2200000000000009, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.5600000000000003, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.11999999999999998, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.4100000000000002, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.26000000000000006, epsilon: 0.0078125\n",
      "Average Score: 0.4162500000000001\n",
      "\n",
      "Epoch 7, Best Score: 4.009999999999959\n",
      "Training Iteration 4 score: 0.6900000000000004, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.9200000000000006, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.3382812500000002\n",
      "\n",
      "Epoch 8, Best Score: 4.009999999999959\n",
      "Training Iteration 4 score: 0.7800000000000005, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.31453124999999815\n",
      "\n",
      "Epoch 9, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.38000000000000017, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.039218750000000024\n",
      "\n",
      "Epoch 10, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 1.6000000000000012, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.4100000000000002, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.16, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.6400000000000003, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.6200000000000003, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.10359375000000007\n",
      "\n",
      "Epoch 11, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.5300000000000002, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.3900000000000002, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.38000000000000017, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.25000000000000006, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.06890625000000003\n",
      "\n",
      "Epoch 12, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 0.5000000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.23000000000000007, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.36000000000000015, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.4100000000000002, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.16, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.17, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.34000000000000014, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.4200000000000002, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.07875000000000003\n",
      "\n",
      "Epoch 13, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 0.6000000000000003, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.21000000000000005, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.19000000000000003, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.35000000000000014, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.49000000000000027, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.24000000000000007, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.4300000000000002, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.47000000000000025, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.34000000000000014, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.11343750000000005\n",
      "\n",
      "Epoch 14, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.20000000000000004, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.026875\n",
      "\n",
      "Epoch 15, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.04, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.2900000000000001, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.26000000000000006, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.5000000000000002, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.15859375000000012\n",
      "\n",
      "Epoch 16, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.03187500000000001\n",
      "\n",
      "Epoch 17, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.9100000000000006, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.12999999999999998, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.020781250000000008\n",
      "\n",
      "Epoch 18, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 5.219999999999933, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 6.159999999999913, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 2.489999999999991, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.9000000000000006, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.8500000000000005, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.46812499999999635\n",
      "\n",
      "Epoch 19, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 0.4200000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.3300000000000001, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.033750000000000016\n",
      "\n",
      "Epoch 20, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 0.12999999999999998, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.03375\n",
      "\n",
      "Epoch 21, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.4100000000000002, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.5800000000000003, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.13843750000000007\n",
      "\n",
      "Epoch 22, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.13359375000000007\n",
      "\n",
      "Epoch 23, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.11999999999999998, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.042656250000000014\n",
      "\n",
      "Epoch 24, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 1.280000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.3100000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.5200000000000002, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.8600000000000005, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 1.350000000000001, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 2.209999999999997, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.5900000000000003, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 1.440000000000001, epsilon: 0.0078125\n",
      "Average Score: 0.36531250000000004\n",
      "\n",
      "Epoch 25, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 1.480000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.48000000000000026, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.36000000000000015, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 1.1200000000000008, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.19000000000000003, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.34000000000000014, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 1.0200000000000007, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.24000000000000007, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.6800000000000004, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.8100000000000005, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.25000000000000006, epsilon: 0.0078125\n",
      "Average Score: 0.24421874999999976\n",
      "\n",
      "Epoch 26, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 0.8300000000000005, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.3100000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.3300000000000001, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.21000000000000005, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 1.1900000000000008, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.2700000000000001, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.17, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 1.9200000000000015, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.48000000000000026, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.19000000000000003, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.3100000000000001, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.20000000000000004, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 3.329999999999973, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 5.969999999999917, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 2.6399999999999877, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 3.1099999999999777, epsilon: 0.0078125\n",
      "Average Score: 0.6789062499999947\n",
      "\n",
      "Epoch 27, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 0.7700000000000005, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.8600000000000005, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.38000000000000017, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.5300000000000002, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.19000000000000003, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.5300000000000002, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 1.2400000000000009, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.13999999999999999, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.8300000000000005, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.11999999999999998, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.1725000000000001\n",
      "\n",
      "Epoch 28, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.4200000000000002, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.34000000000000014, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.09, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.5300000000000002, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.5000000000000002, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.5000000000000002, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.13999999999999999, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.05, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.5500000000000003, epsilon: 0.0078125\n",
      "Average Score: 0.2771875000000002\n",
      "\n",
      "Epoch 29, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 0.2900000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.8600000000000005, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.5700000000000003, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.26000000000000006, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.5400000000000003, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.3100000000000001, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.5000000000000002, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.20000000000000004, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 1.0500000000000007, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.20000000000000004, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.6200000000000003, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.5300000000000002, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.34859375000000015\n",
      "\n",
      "Epoch 30, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 0.6000000000000003, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.5000000000000002, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.47000000000000025, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.45000000000000023, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.7800000000000005, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.35000000000000014, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.3300000000000001, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.23000000000000007, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.45000000000000023, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.1764062500000001\n",
      "\n",
      "Epoch 31, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 1.2100000000000009, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.3900000000000002, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.46000000000000024, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.22000000000000006, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.2900000000000001, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.10999999999999999, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.21000000000000005, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.23000000000000007, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.07, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.5000000000000002, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.35000000000000014, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.09999999999999999, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.11999999999999998, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.9900000000000007, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.17, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.7400000000000004, epsilon: 0.0078125\n",
      "Average Score: 0.2535937500000001\n",
      "\n",
      "Epoch 32, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 0.6900000000000004, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.4100000000000002, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.45000000000000023, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.5600000000000003, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.10999999999999999, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.09999999999999999, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.4000000000000002, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.09999999999999999, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 1.7415625000000163\n",
      "Saved a trained Q-table with size (76032,), After 12.255063569545745 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip750\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip750)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip751\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip750)\" d=\"\n",
       "M156.112 1486.45 L2352.76 1486.45 L2352.76 47.2441 L156.112 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip752\">\n",
       "    <rect x=\"156\" y=\"47\" width=\"2198\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip752)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  485.676,1486.45 485.676,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip752)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  819.918,1486.45 819.918,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip752)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1154.16,1486.45 1154.16,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip752)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1488.4,1486.45 1488.4,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip752)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1822.65,1486.45 1822.65,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip752)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2156.89,1486.45 2156.89,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip750)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip750)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  485.676,1486.45 485.676,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip750)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  819.918,1486.45 819.918,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip750)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1154.16,1486.45 1154.16,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip750)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1488.4,1486.45 1488.4,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip750)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1822.65,1486.45 1822.65,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip750)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2156.89,1486.45 2156.89,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip750)\" d=\"M475.953 1514.29 L494.31 1514.29 L494.31 1518.22 L480.236 1518.22 L480.236 1526.7 Q481.254 1526.35 482.273 1526.19 Q483.291 1526 484.31 1526 Q490.097 1526 493.476 1529.17 Q496.856 1532.34 496.856 1537.76 Q496.856 1543.34 493.384 1546.44 Q489.912 1549.52 483.592 1549.52 Q481.416 1549.52 479.148 1549.15 Q476.902 1548.78 474.495 1548.04 L474.495 1543.34 Q476.578 1544.47 478.801 1545.03 Q481.023 1545.58 483.5 1545.58 Q487.504 1545.58 489.842 1543.48 Q492.18 1541.37 492.18 1537.76 Q492.18 1534.15 489.842 1532.04 Q487.504 1529.94 483.5 1529.94 Q481.625 1529.94 479.75 1530.35 Q477.898 1530.77 475.953 1531.65 L475.953 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip750)\" d=\"M794.606 1544.91 L802.245 1544.91 L802.245 1518.55 L793.935 1520.21 L793.935 1515.95 L802.199 1514.29 L806.874 1514.29 L806.874 1544.91 L814.513 1544.91 L814.513 1548.85 L794.606 1548.85 L794.606 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip750)\" d=\"M833.958 1517.37 Q830.347 1517.37 828.518 1520.93 Q826.712 1524.47 826.712 1531.6 Q826.712 1538.71 828.518 1542.27 Q830.347 1545.82 833.958 1545.82 Q837.592 1545.82 839.397 1542.27 Q841.226 1538.71 841.226 1531.6 Q841.226 1524.47 839.397 1520.93 Q837.592 1517.37 833.958 1517.37 M833.958 1513.66 Q839.768 1513.66 842.823 1518.27 Q845.902 1522.85 845.902 1531.6 Q845.902 1540.33 842.823 1544.94 Q839.768 1549.52 833.958 1549.52 Q828.147 1549.52 825.069 1544.94 Q822.013 1540.33 822.013 1531.6 Q822.013 1522.85 825.069 1518.27 Q828.147 1513.66 833.958 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip750)\" d=\"M1129.35 1544.91 L1136.99 1544.91 L1136.99 1518.55 L1128.68 1520.21 L1128.68 1515.95 L1136.94 1514.29 L1141.61 1514.29 L1141.61 1544.91 L1149.25 1544.91 L1149.25 1548.85 L1129.35 1548.85 L1129.35 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip750)\" d=\"M1158.74 1514.29 L1177.1 1514.29 L1177.1 1518.22 L1163.03 1518.22 L1163.03 1526.7 Q1164.05 1526.35 1165.06 1526.19 Q1166.08 1526 1167.1 1526 Q1172.89 1526 1176.27 1529.17 Q1179.65 1532.34 1179.65 1537.76 Q1179.65 1543.34 1176.17 1546.44 Q1172.7 1549.52 1166.38 1549.52 Q1164.21 1549.52 1161.94 1549.15 Q1159.69 1548.78 1157.29 1548.04 L1157.29 1543.34 Q1159.37 1544.47 1161.59 1545.03 Q1163.81 1545.58 1166.29 1545.58 Q1170.3 1545.58 1172.63 1543.48 Q1174.97 1541.37 1174.97 1537.76 Q1174.97 1534.15 1172.63 1532.04 Q1170.3 1529.94 1166.29 1529.94 Q1164.42 1529.94 1162.54 1530.35 Q1160.69 1530.77 1158.74 1531.65 L1158.74 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip750)\" d=\"M1467.18 1544.91 L1483.5 1544.91 L1483.5 1548.85 L1461.55 1548.85 L1461.55 1544.91 Q1464.21 1542.16 1468.8 1537.53 Q1473.4 1532.88 1474.58 1531.53 Q1476.83 1529.01 1477.71 1527.27 Q1478.61 1525.51 1478.61 1523.82 Q1478.61 1521.07 1476.67 1519.33 Q1474.75 1517.6 1471.64 1517.6 Q1469.45 1517.6 1466.99 1518.36 Q1464.56 1519.13 1461.78 1520.68 L1461.78 1515.95 Q1464.61 1514.82 1467.06 1514.24 Q1469.52 1513.66 1471.55 1513.66 Q1476.92 1513.66 1480.12 1516.35 Q1483.31 1519.03 1483.31 1523.52 Q1483.31 1525.65 1482.5 1527.57 Q1481.71 1529.47 1479.61 1532.07 Q1479.03 1532.74 1475.93 1535.95 Q1472.83 1539.15 1467.18 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip750)\" d=\"M1503.31 1517.37 Q1499.7 1517.37 1497.87 1520.93 Q1496.07 1524.47 1496.07 1531.6 Q1496.07 1538.71 1497.87 1542.27 Q1499.7 1545.82 1503.31 1545.82 Q1506.95 1545.82 1508.75 1542.27 Q1510.58 1538.71 1510.58 1531.6 Q1510.58 1524.47 1508.75 1520.93 Q1506.95 1517.37 1503.31 1517.37 M1503.31 1513.66 Q1509.12 1513.66 1512.18 1518.27 Q1515.26 1522.85 1515.26 1531.6 Q1515.26 1540.33 1512.18 1544.94 Q1509.12 1549.52 1503.31 1549.52 Q1497.5 1549.52 1494.42 1544.94 Q1491.37 1540.33 1491.37 1531.6 Q1491.37 1522.85 1494.42 1518.27 Q1497.5 1513.66 1503.31 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip750)\" d=\"M1801.92 1544.91 L1818.24 1544.91 L1818.24 1548.85 L1796.29 1548.85 L1796.29 1544.91 Q1798.95 1542.16 1803.54 1537.53 Q1808.14 1532.88 1809.33 1531.53 Q1811.57 1529.01 1812.45 1527.27 Q1813.35 1525.51 1813.35 1523.82 Q1813.35 1521.07 1811.41 1519.33 Q1809.49 1517.6 1806.39 1517.6 Q1804.19 1517.6 1801.73 1518.36 Q1799.3 1519.13 1796.52 1520.68 L1796.52 1515.95 Q1799.35 1514.82 1801.8 1514.24 Q1804.26 1513.66 1806.29 1513.66 Q1811.66 1513.66 1814.86 1516.35 Q1818.05 1519.03 1818.05 1523.52 Q1818.05 1525.65 1817.24 1527.57 Q1816.45 1529.47 1814.35 1532.07 Q1813.77 1532.74 1810.67 1535.95 Q1807.57 1539.15 1801.92 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip750)\" d=\"M1828.1 1514.29 L1846.45 1514.29 L1846.45 1518.22 L1832.38 1518.22 L1832.38 1526.7 Q1833.4 1526.35 1834.42 1526.19 Q1835.44 1526 1836.45 1526 Q1842.24 1526 1845.62 1529.17 Q1849 1532.34 1849 1537.76 Q1849 1543.34 1845.53 1546.44 Q1842.06 1549.52 1835.74 1549.52 Q1833.56 1549.52 1831.29 1549.15 Q1829.05 1548.78 1826.64 1548.04 L1826.64 1543.34 Q1828.72 1544.47 1830.95 1545.03 Q1833.17 1545.58 1835.64 1545.58 Q1839.65 1545.58 1841.99 1543.48 Q1844.32 1541.37 1844.32 1537.76 Q1844.32 1534.15 1841.99 1532.04 Q1839.65 1529.94 1835.64 1529.94 Q1833.77 1529.94 1831.89 1530.35 Q1830.04 1530.77 1828.1 1531.65 L1828.1 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip750)\" d=\"M2145.73 1530.21 Q2149.09 1530.93 2150.96 1533.2 Q2152.86 1535.47 2152.86 1538.8 Q2152.86 1543.92 2149.34 1546.72 Q2145.82 1549.52 2139.34 1549.52 Q2137.17 1549.52 2134.85 1549.08 Q2132.56 1548.66 2130.11 1547.81 L2130.11 1543.29 Q2132.05 1544.43 2134.37 1545.01 Q2136.68 1545.58 2139.2 1545.58 Q2143.6 1545.58 2145.89 1543.85 Q2148.21 1542.11 2148.21 1538.8 Q2148.21 1535.75 2146.06 1534.03 Q2143.93 1532.3 2140.11 1532.3 L2136.08 1532.3 L2136.08 1528.45 L2140.29 1528.45 Q2143.74 1528.45 2145.57 1527.09 Q2147.4 1525.7 2147.4 1523.11 Q2147.4 1520.45 2145.5 1519.03 Q2143.63 1517.6 2140.11 1517.6 Q2138.19 1517.6 2135.99 1518.01 Q2133.79 1518.43 2131.15 1519.31 L2131.15 1515.14 Q2133.81 1514.4 2136.13 1514.03 Q2138.46 1513.66 2140.52 1513.66 Q2145.85 1513.66 2148.95 1516.09 Q2152.05 1518.5 2152.05 1522.62 Q2152.05 1525.49 2150.41 1527.48 Q2148.76 1529.45 2145.73 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip750)\" d=\"M2171.73 1517.37 Q2168.12 1517.37 2166.29 1520.93 Q2164.48 1524.47 2164.48 1531.6 Q2164.48 1538.71 2166.29 1542.27 Q2168.12 1545.82 2171.73 1545.82 Q2175.36 1545.82 2177.17 1542.27 Q2179 1538.71 2179 1531.6 Q2179 1524.47 2177.17 1520.93 Q2175.36 1517.37 2171.73 1517.37 M2171.73 1513.66 Q2177.54 1513.66 2180.59 1518.27 Q2183.67 1522.85 2183.67 1531.6 Q2183.67 1540.33 2180.59 1544.94 Q2177.54 1549.52 2171.73 1549.52 Q2165.92 1549.52 2162.84 1544.94 Q2159.78 1540.33 2159.78 1531.6 Q2159.78 1522.85 2162.84 1518.27 Q2165.92 1513.66 2171.73 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip752)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,1462.11 2352.76,1462.11 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip752)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,1067.6 2352.76,1067.6 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip752)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,673.088 2352.76,673.088 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip752)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,278.575 2352.76,278.575 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip750)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,1486.45 156.112,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip750)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,1462.11 175.01,1462.11 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip750)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,1067.6 175.01,1067.6 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip750)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,673.088 175.01,673.088 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip750)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,278.575 175.01,278.575 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip750)\" d=\"M62.9365 1447.91 Q59.3254 1447.91 57.4967 1451.48 Q55.6912 1455.02 55.6912 1462.15 Q55.6912 1469.25 57.4967 1472.82 Q59.3254 1476.36 62.9365 1476.36 Q66.5707 1476.36 68.3763 1472.82 Q70.205 1469.25 70.205 1462.15 Q70.205 1455.02 68.3763 1451.48 Q66.5707 1447.91 62.9365 1447.91 M62.9365 1444.21 Q68.7467 1444.21 71.8022 1448.81 Q74.8809 1453.4 74.8809 1462.15 Q74.8809 1470.87 71.8022 1475.48 Q68.7467 1480.06 62.9365 1480.06 Q57.1264 1480.06 54.0477 1475.48 Q50.9921 1470.87 50.9921 1462.15 Q50.9921 1453.4 54.0477 1448.81 Q57.1264 1444.21 62.9365 1444.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip750)\" d=\"M83.0984 1473.51 L87.9827 1473.51 L87.9827 1479.39 L83.0984 1479.39 L83.0984 1473.51 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip750)\" d=\"M108.168 1447.91 Q104.557 1447.91 102.728 1451.48 Q100.922 1455.02 100.922 1462.15 Q100.922 1469.25 102.728 1472.82 Q104.557 1476.36 108.168 1476.36 Q111.802 1476.36 113.608 1472.82 Q115.436 1469.25 115.436 1462.15 Q115.436 1455.02 113.608 1451.48 Q111.802 1447.91 108.168 1447.91 M108.168 1444.21 Q113.978 1444.21 117.033 1448.81 Q120.112 1453.4 120.112 1462.15 Q120.112 1470.87 117.033 1475.48 Q113.978 1480.06 108.168 1480.06 Q102.358 1480.06 99.2789 1475.48 Q96.2234 1470.87 96.2234 1462.15 Q96.2234 1453.4 99.2789 1448.81 Q102.358 1444.21 108.168 1444.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip750)\" d=\"M63.9319 1053.4 Q60.3208 1053.4 58.4921 1056.96 Q56.6865 1060.51 56.6865 1067.63 Q56.6865 1074.74 58.4921 1078.31 Q60.3208 1081.85 63.9319 1081.85 Q67.5661 1081.85 69.3717 1078.31 Q71.2004 1074.74 71.2004 1067.63 Q71.2004 1060.51 69.3717 1056.96 Q67.5661 1053.4 63.9319 1053.4 M63.9319 1049.7 Q69.742 1049.7 72.7976 1054.3 Q75.8763 1058.88 75.8763 1067.63 Q75.8763 1076.36 72.7976 1080.97 Q69.742 1085.55 63.9319 1085.55 Q58.1217 1085.55 55.043 1080.97 Q51.9875 1076.36 51.9875 1067.63 Q51.9875 1058.88 55.043 1054.3 Q58.1217 1049.7 63.9319 1049.7 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip750)\" d=\"M84.0938 1079 L88.978 1079 L88.978 1084.88 L84.0938 1084.88 L84.0938 1079 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip750)\" d=\"M99.2095 1050.32 L117.566 1050.32 L117.566 1054.26 L103.492 1054.26 L103.492 1062.73 Q104.51 1062.38 105.529 1062.22 Q106.547 1062.03 107.566 1062.03 Q113.353 1062.03 116.733 1065.2 Q120.112 1068.38 120.112 1073.79 Q120.112 1079.37 116.64 1082.47 Q113.168 1085.55 106.848 1085.55 Q104.672 1085.55 102.404 1085.18 Q100.159 1084.81 97.7511 1084.07 L97.7511 1079.37 Q99.8345 1080.51 102.057 1081.06 Q104.279 1081.62 106.756 1081.62 Q110.76 1081.62 113.098 1079.51 Q115.436 1077.4 115.436 1073.79 Q115.436 1070.18 113.098 1068.07 Q110.76 1065.97 106.756 1065.97 Q104.881 1065.97 103.006 1066.38 Q101.154 1066.8 99.2095 1067.68 L99.2095 1050.32 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip750)\" d=\"M53.7467 686.432 L61.3856 686.432 L61.3856 660.067 L53.0754 661.734 L53.0754 657.474 L61.3393 655.808 L66.0152 655.808 L66.0152 686.432 L73.654 686.432 L73.654 690.368 L53.7467 690.368 L53.7467 686.432 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip750)\" d=\"M83.0984 684.488 L87.9827 684.488 L87.9827 690.368 L83.0984 690.368 L83.0984 684.488 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip750)\" d=\"M108.168 658.886 Q104.557 658.886 102.728 662.451 Q100.922 665.993 100.922 673.122 Q100.922 680.229 102.728 683.794 Q104.557 687.335 108.168 687.335 Q111.802 687.335 113.608 683.794 Q115.436 680.229 115.436 673.122 Q115.436 665.993 113.608 662.451 Q111.802 658.886 108.168 658.886 M108.168 655.183 Q113.978 655.183 117.033 659.789 Q120.112 664.372 120.112 673.122 Q120.112 681.849 117.033 686.456 Q113.978 691.039 108.168 691.039 Q102.358 691.039 99.2789 686.456 Q96.2234 681.849 96.2234 673.122 Q96.2234 664.372 99.2789 659.789 Q102.358 655.183 108.168 655.183 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip750)\" d=\"M54.7421 291.92 L62.381 291.92 L62.381 265.554 L54.0708 267.221 L54.0708 262.962 L62.3347 261.295 L67.0106 261.295 L67.0106 291.92 L74.6494 291.92 L74.6494 295.855 L54.7421 295.855 L54.7421 291.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip750)\" d=\"M84.0938 289.976 L88.978 289.976 L88.978 295.855 L84.0938 295.855 L84.0938 289.976 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip750)\" d=\"M99.2095 261.295 L117.566 261.295 L117.566 265.23 L103.492 265.23 L103.492 273.702 Q104.51 273.355 105.529 273.193 Q106.547 273.008 107.566 273.008 Q113.353 273.008 116.733 276.179 Q120.112 279.351 120.112 284.767 Q120.112 290.346 116.64 293.448 Q113.168 296.526 106.848 296.526 Q104.672 296.526 102.404 296.156 Q100.159 295.786 97.7511 295.045 L97.7511 290.346 Q99.8345 291.48 102.057 292.036 Q104.279 292.591 106.756 292.591 Q110.76 292.591 113.098 290.485 Q115.436 288.378 115.436 284.767 Q115.436 281.156 113.098 279.05 Q110.76 276.943 106.756 276.943 Q104.881 276.943 103.006 277.36 Q101.154 277.777 99.2095 278.656 L99.2095 261.295 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip752)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  218.281,1373.59 285.13,1416.25 351.978,1104.46 418.827,1256.47 485.676,1029.38 552.524,1133.68 619.373,1195.2 686.221,1213.94 753.07,1431.17 819.918,1380.37 \n",
       "  886.767,1407.74 953.615,1399.98 1020.46,1372.61 1087.31,1440.91 1154.16,1336.98 1221.01,1436.96 1287.86,1445.72 1354.71,1092.75 1421.56,1435.48 1488.4,1435.48 \n",
       "  1555.25,1352.88 1622.1,1356.7 1688.95,1428.46 1755.8,1173.87 1822.65,1269.42 1889.5,926.439 1956.34,1326.01 2023.19,1243.4 2090.04,1187.06 2156.89,1322.92 \n",
       "  2223.74,1262.02 2290.59,87.9763 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip750)\" d=\"\n",
       "M1983.03 198.898 L2279.53 198.898 L2279.53 95.2176 L1983.03 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip750)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1983.03,198.898 2279.53,198.898 2279.53,95.2176 1983.03,95.2176 1983.03,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip750)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2007.44,147.058 2153.88,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip750)\" d=\"M2192.13 166.745 Q2190.33 171.375 2188.61 172.787 Q2186.9 174.199 2184.03 174.199 L2180.63 174.199 L2180.63 170.634 L2183.13 170.634 Q2184.89 170.634 2185.86 169.8 Q2186.83 168.967 2188.01 165.865 L2188.78 163.921 L2178.29 138.412 L2182.8 138.412 L2190.91 158.689 L2199.01 138.412 L2203.52 138.412 L2192.13 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip750)\" d=\"M2210.81 160.402 L2218.45 160.402 L2218.45 134.037 L2210.14 135.703 L2210.14 131.444 L2218.41 129.778 L2223.08 129.778 L2223.08 160.402 L2230.72 160.402 L2230.72 164.338 L2210.81 164.338 L2210.81 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/episodes\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        X  = X_0\n",
    "        \n",
    "        ##### Double Q-Learning ###########################################\n",
    "\n",
    "        for k = 1:T\n",
    "\n",
    "            # 1. Choose action\n",
    "            if rand() < epsilon\n",
    "                if rand() < EXPrand \n",
    "                    A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                else\n",
    "                    A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                end\n",
    "            else\n",
    "\n",
    "                A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                if A == 1000.0 # Indicates no values in this region\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "\n",
    "            # 2. Cache last state\n",
    "            qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "            # 3. Generate the next stae\n",
    "            Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "            # 4. Collect reward R( s, a, s' )\n",
    "            R_t = cartpole_reward( Xp )\n",
    "\n",
    "            # 5. Get the optimal action at the next state\n",
    "            a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "            # 6. Compute the value at the next state\n",
    "\n",
    "            V_tp1_opt = query_value_fuzzy( \n",
    "                Q_kdTree, G, V, \n",
    "                get_Q( \n",
    "                    select_X_vector( Xp ), \n",
    "                    a_tp1_opt \n",
    "                ); \n",
    "                k = vNN \n",
    "            )\n",
    "            if isnan( V_tp1_opt )\n",
    "                V_tp1_opt = 0.0\n",
    "            end\n",
    "\n",
    "\n",
    "            # 7. Blend the value back into nearest points\n",
    "\n",
    "            idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "            nNear      = size( idxs, 1 )\n",
    "            for i = 1:nNear\n",
    "                j    = idxs[i]\n",
    "                if !isnan( wgts[i] ) \n",
    "\n",
    "                    # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                    VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "                    \n",
    "                end\n",
    "            end\n",
    "\n",
    "            states[:,k] = Xp\n",
    "            actions[k]  = A\n",
    "\n",
    "            X = Xp\n",
    "        end\n",
    "\n",
    "        s_l    = vertical_score_s( states, aMargin, ts )\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        if useElig\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "            # println(\"SWAP\")\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709555b9-2598-4281-a634-c7b0681277d0",
   "metadata": {},
   "source": [
    "# Method 2 Performance, Average Vertical Duration [s]\n",
    "Each score is the best average score of the last two epochs: 32 epochs of 64 episodes each, Q-function swap after every episode \n",
    "\n",
    "### TD Tuning\n",
    "\n",
    "$\\gamma = 1.00$  \n",
    "\n",
    "| Param                |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|----------------------|------| ------- | ------- | ------- | ------- | ------- |------| ----- |\n",
    "| $$\\alpha = 0.99$$    |&nbsp;| 0.251   | 0.198   | 0.146   | 0.147   | 0.210   |&nbsp;| 0.190 |\n",
    "| $$\\alpha = 0.75$$    |&nbsp;| 0.179   | 0.185   | 0.239   | 0.179   | 0.175   |&nbsp;| 0.191 |\n",
    "| $$\\alpha = 0.50$$    |&nbsp;| 0.204   | 0.100   | 0.238   | 0.158   | 0.139   |&nbsp;| 0.168 |\n",
    "| $$\\alpha = 0.25$$    |&nbsp;| 0.294   | 0.170   | 0.107   | 0.223   | 0.147   |&nbsp;| 0.188 |\n",
    "| $$\\alpha = 0.125$$   |&nbsp;| 0.187   | 0.254   | 0.177   | 0.163   | 0.204   |&nbsp;| 0.197 |  \n",
    "| $$\\alpha = 0.0625$$  |&nbsp;| 0.113   | 0.241   | 0.353   | 0.134   | 0.749   |&nbsp;| 0.318 |\n",
    "| $$\\alpha = 0.03125$$ |&nbsp;| 0.231   | 0.322   | 0.018   | 0.098   | 0.000   |&nbsp;| 0.134 |\n",
    "| $$\\alpha = 0.02344$$ |&nbsp;| 1.289   | 0.119   | 0.380   | 0.168   | 0.086   |&nbsp;| 0.408 |\n",
    "| $$\\alpha = \\mathbf{0.02148}$$ |&nbsp;| 0.498   | 0.813   | 0.286   | 7.130   | 0.281   |&nbsp;| **1.802** |\n",
    "| $$\\alpha = 0.01953$$ |&nbsp;| 0.234   | 0.113   | 0.445   | 0.119   | 1.637   |&nbsp;| 0.510 |\n",
    "| $$\\alpha = 0.01758$$ |&nbsp;| 0.175   | 0.249   | 0.217   | 0.047   | 1.006   |&nbsp;| 0.339 |\n",
    "| $$\\alpha = 0.01563$$ |&nbsp;| 0.281   | 1.371   | 0.066   | 0.037   | 0.751   |&nbsp;| 0.501 |\n",
    "| $$\\alpha = 0.00782$$ |&nbsp;| 0.133   | 0.241   | 0.149   | 0.493   | 0.146   |&nbsp;| 0.232 |\n",
    "| $$\\alpha = 0.00391$$ |&nbsp;| 0.037   | 0.626   | 1.000   | 0.525   | 0.139   |&nbsp;| 0.465 |\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "### $\\gamma$ Tuning\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "\n",
    "| Param                 |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "| :-------------------- |------| ------- | ------- | ------- | ------- | ------- |------| ----- |\n",
    "| $$\\gamma = 0.999$$    |&nbsp;| 0.925   | 0.247   | 0.145   | 0.364   | 3.038   |&nbsp;| 0.944 |\n",
    "| $$\\gamma = 0.99$$     |&nbsp;| 0.011   | 0.448   | 0.453   | 0.915   | 0.013   |&nbsp;| 0.368 |\n",
    "| $$\\gamma = 0.85$$     |&nbsp;| 0.314   | 2.778   | 0.275   | 1.183   | 0.079   |&nbsp;| 0.926 |\n",
    "| $$\\gamma = 0.80$$     |&nbsp;| 0.082   | 0.033   | 0.173   | 0.251   | 1.741   |&nbsp;| 0.456 |\n",
    "| $$\\gamma = 0.75$$     |&nbsp;| 0.283   | 0.239   | 2.223   | 0.264   | 0.753   |&nbsp;| 0.752 |\n",
    "| $$\\gamma = 0.50$$     |&nbsp;| 0.167   | 0.289   | 0.474   | 0.266   | 0.230   |&nbsp;| 0.285 |\n",
    "\n",
    " \n",
    "### Double-Q Tuning, Swap Evey N Episodes\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "\n",
    "$\\%\\ \\ 2$:  \n",
    "$\\%\\ \\ 4$:  \n",
    "$\\%\\ \\ 8$:  \n",
    "$\\%16$:  \n",
    "$\\%32$:  \n",
    "$\\%64$:  \n",
    "\n",
    "\n",
    "\n",
    "### Blend: Best Episode\n",
    "\n",
    "$\\beta = 0.07$:  \n",
    "$\\beta = 0.15$: 0.244\n",
    "\n",
    "| Method      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n",
    "| ----------- | ------- | ------- | ------- | ------- | ------- | ---- |\n",
    "| Blend (Epi) |         |         |         |         |         |      |\n",
    "| Blend (Epo) |         |         |         |         |         |      |\n",
    "| TD          |         |         |         |         |         |      |\n",
    "| TD  + ????? |         |         |         |         |         |      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Process(`\u001b[4mplay\u001b[24m \u001b[4m-nq\u001b[24m \u001b[4m-t\u001b[24m \u001b[4malsa\u001b[24m \u001b[4msynth\u001b[24m \u001b[4m3\u001b[24m \u001b[4msine\u001b[24m \u001b[4m300\u001b[24m`, ProcessExited(0))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(`play -nq -t alsa synth 3 sine 300`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b5ade7-5f94-43b1-837f-85ccdd6b5c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
