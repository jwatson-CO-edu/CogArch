{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.02148 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 # 0.00782 # 0.00391\n",
    "beta     = 0.70\n",
    "gamma    = 1.00 \n",
    "swapDiv  = 64\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes = 64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   = 32 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = true\n",
    "N_peaks =  32\n",
    "N_steps = 128\n",
    "lambda  =   0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.26000000000000006, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.22000000000000006, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.6100000000000003, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.5100000000000002, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.6700000000000004, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.5000000000000002, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.35000000000000014, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.20000000000000004, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.22421875000000002\n",
      "\n",
      "Epoch 2, Best Score: 1.280000000000001\n",
      "Training Iteration 4 score: 0.8800000000000006, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.09, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.24000000000000007, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.20000000000000004, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.23000000000000007, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.12999999999999998, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.11999999999999998, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.0500000000000007, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.3900000000000002, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.38000000000000017, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.3900000000000002, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.15, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.21000000000000005, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.24000000000000007, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.22406250000000016\n",
      "\n",
      "Epoch 3, Best Score: 1.280000000000001\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 4, Best Score: 1.280000000000001\n",
      "Training Iteration 4 score: 0.2700000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.21000000000000005, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.25000000000000006, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.7500000000000004, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.7900000000000005, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.16, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.3900000000000002, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.5000000000000002, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 1.270000000000001, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.1568750000000001\n",
      "\n",
      "Epoch 5, Best Score: 1.5900000000000012\n",
      "Training Iteration 4 score: 0.08, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.4100000000000002, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.3200000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.5900000000000003, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.5600000000000003, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.060000000000000005, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.07, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.6900000000000004, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 1.270000000000001, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.8000000000000005, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.37000000000000016, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.6100000000000003, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.4515624999999999\n",
      "\n",
      "Epoch 6, Best Score: 2.489999999999991\n",
      "Training Iteration 4 score: 0.08, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.26000000000000006, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.13999999999999999, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.19000000000000003, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.4000000000000002, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.09999999999999999, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.08343750000000004\n",
      "\n",
      "Epoch 7, Best Score: 2.489999999999991\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.13999999999999999, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.007031250000000001\n",
      "\n",
      "Epoch 8, Best Score: 2.489999999999991\n",
      "Training Iteration 4 score: 0.10999999999999999, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.13999999999999999, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.9500000000000006, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.13999999999999999, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.5000000000000002, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.7000000000000004, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.8800000000000006, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.21000000000000005, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.5200000000000002, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.18062500000000006\n",
      "\n",
      "Epoch 9, Best Score: 2.489999999999991\n",
      "Training Iteration 4 score: 4.279999999999953, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 1.7200000000000013, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 8.409999999999865, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.22000000000000006, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.4000000000000002, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 12.579999999999776, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.8200000000000005, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.3200000000000001, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.34000000000000014, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.2800000000000001, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.2900000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.3100000000000001, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 1.3610937499999862\n",
      "\n",
      "Epoch 10, Best Score: 16.779999999999824\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.5400000000000003, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.20000000000000004, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.09, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.36000000000000015, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.09999999999999999, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.4000000000000002, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.09, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.4100000000000002, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 1.0100000000000007, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.5000000000000002, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.37000000000000016, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.11999999999999998, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.2800000000000001, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.3064062500000001\n",
      "\n",
      "Epoch 11, Best Score: 16.779999999999824\n",
      "Training Iteration 4 score: 4.109999999999957, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.5100000000000002, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.22000000000000006, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.3300000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.46000000000000024, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.3300000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.26000000000000006, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.4200000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.10999999999999999, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 8.319999999999867, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.35000000000000014, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.10999999999999999, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.37000000000000016, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.37000000000000016, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.34000000000000014, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.34000000000000014, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.8932812499999924\n",
      "\n",
      "Epoch 12, Best Score: 16.779999999999824\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.8000000000000005, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.2700000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.2700000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.3000000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.2800000000000001, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.5800000000000003, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.21015625000000007\n",
      "\n",
      "Epoch 13, Best Score: 16.779999999999824\n",
      "Training Iteration 4 score: 0.20000000000000004, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 1.400000000000001, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.9100000000000006, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.9400000000000006, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.08, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 1.270000000000001, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.13999999999999999, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.10999999999999999, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.7700000000000005, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.42874999999999897\n",
      "\n",
      "Epoch 14, Best Score: 16.779999999999824\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.5000000000000002, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.47000000000000025, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.6000000000000003, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 19.080000000000183, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 17.14999999999988, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 24.600000000001046, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 1.8273437500000116\n",
      "\n",
      "Epoch 15, Best Score: 24.600000000001046\n",
      "Training Iteration 4 score: 0.46000000000000024, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.09999999999999999, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.16, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.7300000000000004, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.2270312499999997\n",
      "\n",
      "Epoch 16, Best Score: 24.600000000001046\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.3100000000000001, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 1.7400000000000013, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.3100000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 1.480000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.25000000000000006, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 1.410000000000001, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.20000000000000004, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.6900000000000004, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.9000000000000006, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.37000000000000016, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.13999999999999999, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.7600000000000005, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 1.380000000000001, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 1.1100000000000008, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.7993749999999974\n",
      "\n",
      "Epoch 17, Best Score: 24.600000000001046\n",
      "Training Iteration 4 score: 0.9100000000000006, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.36000000000000015, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.12999999999999998, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.4000000000000002, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.8300000000000005, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 3.4999999999999694, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 2.6899999999999866, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.280000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.4000000000000002, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 2.099999999999999, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.7500000000000004, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.5300000000000002, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.8800000000000006, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.15, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.16, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.6365624999999994\n",
      "\n",
      "Epoch 18, Best Score: 24.600000000001046\n",
      "Training Iteration 4 score: 0.5900000000000003, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.6900000000000004, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.36000000000000015, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.6200000000000003, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 8.889999999999855, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 1.1400000000000008, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 14.23999999999974, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.9862499999999865\n",
      "\n",
      "Epoch 19, Best Score: 24.600000000001046\n",
      "Training Iteration 4 score: 0.8500000000000005, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.18000000000000002, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.9200000000000006, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.22000000000000006, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.8200000000000005, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.6000000000000003, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.11999999999999998, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.4100000000000002, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.5600000000000003, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.6800000000000004, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.47000000000000025, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.5800000000000003, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.5300000000000002, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 1.1500000000000008, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.6385937499999994\n",
      "\n",
      "Epoch 20, Best Score: 24.600000000001046\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.7200000000000004, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.8000000000000005, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.6900000000000004, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 1.370000000000001, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.9800000000000006, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.7400000000000004, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.4167187500000003\n",
      "\n",
      "Epoch 21, Best Score: 24.600000000001046\n",
      "Training Iteration 4 score: 0.4100000000000002, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.3000000000000001, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 1.8200000000000014, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.12999999999999998, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.46000000000000024, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.7000000000000004, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.5500000000000003, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.3100000000000001, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.5400000000000003, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.7500000000000004, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.6800000000000004, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.5100000000000002, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.49406250000000024\n",
      "\n",
      "Epoch 22, Best Score: 24.600000000001046\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.5300000000000002, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.6800000000000004, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.9800000000000006, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.38000000000000017, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.3200000000000001, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.37000000000000016, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.34000000000000014, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.21125000000000016\n",
      "\n",
      "Epoch 23, Best Score: 24.600000000001046\n",
      "Training Iteration 4 score: 0.2800000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.9400000000000006, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.46000000000000024, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.6100000000000003, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.6100000000000003, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.5400000000000003, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.6100000000000003, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.3300000000000001, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.5400000000000003, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.47000000000000025, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.48000000000000026, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.4723437500000002\n",
      "\n",
      "Epoch 24, Best Score: 24.600000000001046\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.07, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.2900000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.3300000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.19000000000000003, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.4100000000000002, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.17, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.15375000000000005\n",
      "\n",
      "Epoch 25, Best Score: 24.600000000001046\n",
      "Training Iteration 4 score: 0.35000000000000014, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.5300000000000002, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.4200000000000002, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.6900000000000004, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.46000000000000024, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.5000000000000002, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.5200000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.5700000000000003, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.5200000000000002, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.47000000000000025, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.5100000000000002, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.5000000000000002, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.5200000000000002, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.5200000000000002, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.48000000000000026, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.5734374999999998\n",
      "\n",
      "Epoch 26, Best Score: 24.600000000001046\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.7300000000000004, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 1.0300000000000007, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.7400000000000004, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.16, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.4200000000000002, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.15500000000000008\n",
      "\n",
      "Epoch 27, Best Score: 24.600000000001046\n",
      "Training Iteration 4 score: 0.3000000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.49000000000000027, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 1.260000000000001, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.6200000000000003, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.48000000000000026, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 2.1699999999999977, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.5300000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.4300000000000002, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.5000000000000002, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.7000000000000004, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.37000000000000016, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.48000000000000026, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.6100000000000003, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.47000000000000025, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.5600000000000003, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.52484375\n",
      "\n",
      "Epoch 28, Best Score: 24.600000000001046\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.16, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.7500000000000004, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.4200000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.13999999999999999, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.17250000000000007\n",
      "\n",
      "Epoch 29, Best Score: 24.600000000001046\n",
      "Training Iteration 4 score: 0.23000000000000007, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.5700000000000003, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.25000000000000006, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.3100000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.5200000000000002, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.47000000000000025, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.5300000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.48000000000000026, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.47000000000000025, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.46000000000000024, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.5100000000000002, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.49000000000000027, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.45000000000000023, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.46000000000000024, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.46000000000000024, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.5449999999999996\n",
      "\n",
      "Epoch 30, Best Score: 24.600000000001046\n",
      "Training Iteration 4 score: 0.2900000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.35000000000000014, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.09, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 1.6400000000000012, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.07, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.3900000000000002, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.4100000000000002, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.19000000000000003, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.07, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.07, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.15515625000000008\n",
      "\n",
      "Epoch 31, Best Score: 24.600000000001046\n",
      "Training Iteration 4 score: 0.5400000000000003, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.5400000000000003, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.3000000000000001, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.7200000000000004, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.8600000000000005, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.11999999999999998, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.5000000000000002, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.49000000000000027, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.09999999999999999, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.10999999999999999, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.08, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 1.0200000000000007, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.22000000000000006, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.6600000000000004, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.47000000000000025, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.46000000000000024, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.820312499999996\n",
      "\n",
      "Epoch 32, Best Score: 24.600000000001046\n",
      "Training Iteration 4 score: 0.13999999999999999, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.3200000000000001, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.4400000000000002, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.5000000000000002, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.16, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.18000000000000002, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.5500000000000003, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.4000000000000002, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.21000000000000005, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.16046875000000008\n",
      "Saved a trained Q-table with size (76032,), After 27.1801233847936 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip900\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip900)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip901\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip900)\" d=\"\n",
       "M156.112 1486.45 L2352.76 1486.45 L2352.76 47.2441 L156.112 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip902\">\n",
       "    <rect x=\"156\" y=\"47\" width=\"2198\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip902)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  485.676,1486.45 485.676,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip902)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  819.918,1486.45 819.918,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip902)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1154.16,1486.45 1154.16,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip902)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1488.4,1486.45 1488.4,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip902)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1822.65,1486.45 1822.65,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip902)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2156.89,1486.45 2156.89,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip900)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip900)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  485.676,1486.45 485.676,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip900)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  819.918,1486.45 819.918,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip900)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1154.16,1486.45 1154.16,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip900)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1488.4,1486.45 1488.4,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip900)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1822.65,1486.45 1822.65,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip900)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2156.89,1486.45 2156.89,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip900)\" d=\"M475.953 1514.29 L494.31 1514.29 L494.31 1518.22 L480.236 1518.22 L480.236 1526.7 Q481.254 1526.35 482.273 1526.19 Q483.291 1526 484.31 1526 Q490.097 1526 493.476 1529.17 Q496.856 1532.34 496.856 1537.76 Q496.856 1543.34 493.384 1546.44 Q489.912 1549.52 483.592 1549.52 Q481.416 1549.52 479.148 1549.15 Q476.902 1548.78 474.495 1548.04 L474.495 1543.34 Q476.578 1544.47 478.801 1545.03 Q481.023 1545.58 483.5 1545.58 Q487.504 1545.58 489.842 1543.48 Q492.18 1541.37 492.18 1537.76 Q492.18 1534.15 489.842 1532.04 Q487.504 1529.94 483.5 1529.94 Q481.625 1529.94 479.75 1530.35 Q477.898 1530.77 475.953 1531.65 L475.953 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip900)\" d=\"M794.606 1544.91 L802.245 1544.91 L802.245 1518.55 L793.935 1520.21 L793.935 1515.95 L802.199 1514.29 L806.874 1514.29 L806.874 1544.91 L814.513 1544.91 L814.513 1548.85 L794.606 1548.85 L794.606 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip900)\" d=\"M833.958 1517.37 Q830.347 1517.37 828.518 1520.93 Q826.712 1524.47 826.712 1531.6 Q826.712 1538.71 828.518 1542.27 Q830.347 1545.82 833.958 1545.82 Q837.592 1545.82 839.397 1542.27 Q841.226 1538.71 841.226 1531.6 Q841.226 1524.47 839.397 1520.93 Q837.592 1517.37 833.958 1517.37 M833.958 1513.66 Q839.768 1513.66 842.823 1518.27 Q845.902 1522.85 845.902 1531.6 Q845.902 1540.33 842.823 1544.94 Q839.768 1549.52 833.958 1549.52 Q828.147 1549.52 825.069 1544.94 Q822.013 1540.33 822.013 1531.6 Q822.013 1522.85 825.069 1518.27 Q828.147 1513.66 833.958 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip900)\" d=\"M1129.35 1544.91 L1136.99 1544.91 L1136.99 1518.55 L1128.68 1520.21 L1128.68 1515.95 L1136.94 1514.29 L1141.61 1514.29 L1141.61 1544.91 L1149.25 1544.91 L1149.25 1548.85 L1129.35 1548.85 L1129.35 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip900)\" d=\"M1158.74 1514.29 L1177.1 1514.29 L1177.1 1518.22 L1163.03 1518.22 L1163.03 1526.7 Q1164.05 1526.35 1165.06 1526.19 Q1166.08 1526 1167.1 1526 Q1172.89 1526 1176.27 1529.17 Q1179.65 1532.34 1179.65 1537.76 Q1179.65 1543.34 1176.17 1546.44 Q1172.7 1549.52 1166.38 1549.52 Q1164.21 1549.52 1161.94 1549.15 Q1159.69 1548.78 1157.29 1548.04 L1157.29 1543.34 Q1159.37 1544.47 1161.59 1545.03 Q1163.81 1545.58 1166.29 1545.58 Q1170.3 1545.58 1172.63 1543.48 Q1174.97 1541.37 1174.97 1537.76 Q1174.97 1534.15 1172.63 1532.04 Q1170.3 1529.94 1166.29 1529.94 Q1164.42 1529.94 1162.54 1530.35 Q1160.69 1530.77 1158.74 1531.65 L1158.74 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip900)\" d=\"M1467.18 1544.91 L1483.5 1544.91 L1483.5 1548.85 L1461.55 1548.85 L1461.55 1544.91 Q1464.21 1542.16 1468.8 1537.53 Q1473.4 1532.88 1474.58 1531.53 Q1476.83 1529.01 1477.71 1527.27 Q1478.61 1525.51 1478.61 1523.82 Q1478.61 1521.07 1476.67 1519.33 Q1474.75 1517.6 1471.64 1517.6 Q1469.45 1517.6 1466.99 1518.36 Q1464.56 1519.13 1461.78 1520.68 L1461.78 1515.95 Q1464.61 1514.82 1467.06 1514.24 Q1469.52 1513.66 1471.55 1513.66 Q1476.92 1513.66 1480.12 1516.35 Q1483.31 1519.03 1483.31 1523.52 Q1483.31 1525.65 1482.5 1527.57 Q1481.71 1529.47 1479.61 1532.07 Q1479.03 1532.74 1475.93 1535.95 Q1472.83 1539.15 1467.18 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip900)\" d=\"M1503.31 1517.37 Q1499.7 1517.37 1497.87 1520.93 Q1496.07 1524.47 1496.07 1531.6 Q1496.07 1538.71 1497.87 1542.27 Q1499.7 1545.82 1503.31 1545.82 Q1506.95 1545.82 1508.75 1542.27 Q1510.58 1538.71 1510.58 1531.6 Q1510.58 1524.47 1508.75 1520.93 Q1506.95 1517.37 1503.31 1517.37 M1503.31 1513.66 Q1509.12 1513.66 1512.18 1518.27 Q1515.26 1522.85 1515.26 1531.6 Q1515.26 1540.33 1512.18 1544.94 Q1509.12 1549.52 1503.31 1549.52 Q1497.5 1549.52 1494.42 1544.94 Q1491.37 1540.33 1491.37 1531.6 Q1491.37 1522.85 1494.42 1518.27 Q1497.5 1513.66 1503.31 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip900)\" d=\"M1801.92 1544.91 L1818.24 1544.91 L1818.24 1548.85 L1796.29 1548.85 L1796.29 1544.91 Q1798.95 1542.16 1803.54 1537.53 Q1808.14 1532.88 1809.33 1531.53 Q1811.57 1529.01 1812.45 1527.27 Q1813.35 1525.51 1813.35 1523.82 Q1813.35 1521.07 1811.41 1519.33 Q1809.49 1517.6 1806.39 1517.6 Q1804.19 1517.6 1801.73 1518.36 Q1799.3 1519.13 1796.52 1520.68 L1796.52 1515.95 Q1799.35 1514.82 1801.8 1514.24 Q1804.26 1513.66 1806.29 1513.66 Q1811.66 1513.66 1814.86 1516.35 Q1818.05 1519.03 1818.05 1523.52 Q1818.05 1525.65 1817.24 1527.57 Q1816.45 1529.47 1814.35 1532.07 Q1813.77 1532.74 1810.67 1535.95 Q1807.57 1539.15 1801.92 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip900)\" d=\"M1828.1 1514.29 L1846.45 1514.29 L1846.45 1518.22 L1832.38 1518.22 L1832.38 1526.7 Q1833.4 1526.35 1834.42 1526.19 Q1835.44 1526 1836.45 1526 Q1842.24 1526 1845.62 1529.17 Q1849 1532.34 1849 1537.76 Q1849 1543.34 1845.53 1546.44 Q1842.06 1549.52 1835.74 1549.52 Q1833.56 1549.52 1831.29 1549.15 Q1829.05 1548.78 1826.64 1548.04 L1826.64 1543.34 Q1828.72 1544.47 1830.95 1545.03 Q1833.17 1545.58 1835.64 1545.58 Q1839.65 1545.58 1841.99 1543.48 Q1844.32 1541.37 1844.32 1537.76 Q1844.32 1534.15 1841.99 1532.04 Q1839.65 1529.94 1835.64 1529.94 Q1833.77 1529.94 1831.89 1530.35 Q1830.04 1530.77 1828.1 1531.65 L1828.1 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip900)\" d=\"M2145.73 1530.21 Q2149.09 1530.93 2150.96 1533.2 Q2152.86 1535.47 2152.86 1538.8 Q2152.86 1543.92 2149.34 1546.72 Q2145.82 1549.52 2139.34 1549.52 Q2137.17 1549.52 2134.85 1549.08 Q2132.56 1548.66 2130.11 1547.81 L2130.11 1543.29 Q2132.05 1544.43 2134.37 1545.01 Q2136.68 1545.58 2139.2 1545.58 Q2143.6 1545.58 2145.89 1543.85 Q2148.21 1542.11 2148.21 1538.8 Q2148.21 1535.75 2146.06 1534.03 Q2143.93 1532.3 2140.11 1532.3 L2136.08 1532.3 L2136.08 1528.45 L2140.29 1528.45 Q2143.74 1528.45 2145.57 1527.09 Q2147.4 1525.7 2147.4 1523.11 Q2147.4 1520.45 2145.5 1519.03 Q2143.63 1517.6 2140.11 1517.6 Q2138.19 1517.6 2135.99 1518.01 Q2133.79 1518.43 2131.15 1519.31 L2131.15 1515.14 Q2133.81 1514.4 2136.13 1514.03 Q2138.46 1513.66 2140.52 1513.66 Q2145.85 1513.66 2148.95 1516.09 Q2152.05 1518.5 2152.05 1522.62 Q2152.05 1525.49 2150.41 1527.48 Q2148.76 1529.45 2145.73 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip900)\" d=\"M2171.73 1517.37 Q2168.12 1517.37 2166.29 1520.93 Q2164.48 1524.47 2164.48 1531.6 Q2164.48 1538.71 2166.29 1542.27 Q2168.12 1545.82 2171.73 1545.82 Q2175.36 1545.82 2177.17 1542.27 Q2179 1538.71 2179 1531.6 Q2179 1524.47 2177.17 1520.93 Q2175.36 1517.37 2171.73 1517.37 M2171.73 1513.66 Q2177.54 1513.66 2180.59 1518.27 Q2183.67 1522.85 2183.67 1531.6 Q2183.67 1540.33 2180.59 1544.94 Q2177.54 1549.52 2171.73 1549.52 Q2165.92 1549.52 2162.84 1544.94 Q2159.78 1540.33 2159.78 1531.6 Q2159.78 1522.85 2162.84 1518.27 Q2165.92 1513.66 2171.73 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip902)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,1445.72 2352.76,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip902)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,1074.21 2352.76,1074.21 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip902)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,702.703 2352.76,702.703 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip902)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,331.197 2352.76,331.197 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip900)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,1486.45 156.112,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip900)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,1445.72 175.01,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip900)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,1074.21 175.01,1074.21 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip900)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,702.703 175.01,702.703 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip900)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,331.197 175.01,331.197 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip900)\" d=\"M62.9365 1431.51 Q59.3254 1431.51 57.4967 1435.08 Q55.6912 1438.62 55.6912 1445.75 Q55.6912 1452.86 57.4967 1456.42 Q59.3254 1459.96 62.9365 1459.96 Q66.5707 1459.96 68.3763 1456.42 Q70.205 1452.86 70.205 1445.75 Q70.205 1438.62 68.3763 1435.08 Q66.5707 1431.51 62.9365 1431.51 M62.9365 1427.81 Q68.7467 1427.81 71.8022 1432.42 Q74.8809 1437 74.8809 1445.75 Q74.8809 1454.48 71.8022 1459.08 Q68.7467 1463.67 62.9365 1463.67 Q57.1264 1463.67 54.0477 1459.08 Q50.9921 1454.48 50.9921 1445.75 Q50.9921 1437 54.0477 1432.42 Q57.1264 1427.81 62.9365 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip900)\" d=\"M83.0984 1457.12 L87.9827 1457.12 L87.9827 1463 L83.0984 1463 L83.0984 1457.12 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip900)\" d=\"M108.168 1431.51 Q104.557 1431.51 102.728 1435.08 Q100.922 1438.62 100.922 1445.75 Q100.922 1452.86 102.728 1456.42 Q104.557 1459.96 108.168 1459.96 Q111.802 1459.96 113.608 1456.42 Q115.436 1452.86 115.436 1445.75 Q115.436 1438.62 113.608 1435.08 Q111.802 1431.51 108.168 1431.51 M108.168 1427.81 Q113.978 1427.81 117.033 1432.42 Q120.112 1437 120.112 1445.75 Q120.112 1454.48 117.033 1459.08 Q113.978 1463.67 108.168 1463.67 Q102.358 1463.67 99.2789 1459.08 Q96.2234 1454.48 96.2234 1445.75 Q96.2234 1437 99.2789 1432.42 Q102.358 1427.81 108.168 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip900)\" d=\"M63.9319 1060.01 Q60.3208 1060.01 58.4921 1063.57 Q56.6865 1067.11 56.6865 1074.24 Q56.6865 1081.35 58.4921 1084.92 Q60.3208 1088.46 63.9319 1088.46 Q67.5661 1088.46 69.3717 1084.92 Q71.2004 1081.35 71.2004 1074.24 Q71.2004 1067.11 69.3717 1063.57 Q67.5661 1060.01 63.9319 1060.01 M63.9319 1056.3 Q69.742 1056.3 72.7976 1060.91 Q75.8763 1065.49 75.8763 1074.24 Q75.8763 1082.97 72.7976 1087.58 Q69.742 1092.16 63.9319 1092.16 Q58.1217 1092.16 55.043 1087.58 Q51.9875 1082.97 51.9875 1074.24 Q51.9875 1065.49 55.043 1060.91 Q58.1217 1056.3 63.9319 1056.3 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip900)\" d=\"M84.0938 1085.61 L88.978 1085.61 L88.978 1091.49 L84.0938 1091.49 L84.0938 1085.61 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip900)\" d=\"M99.2095 1056.93 L117.566 1056.93 L117.566 1060.86 L103.492 1060.86 L103.492 1069.34 Q104.51 1068.99 105.529 1068.83 Q106.547 1068.64 107.566 1068.64 Q113.353 1068.64 116.733 1071.81 Q120.112 1074.98 120.112 1080.4 Q120.112 1085.98 116.64 1089.08 Q113.168 1092.16 106.848 1092.16 Q104.672 1092.16 102.404 1091.79 Q100.159 1091.42 97.7511 1090.68 L97.7511 1085.98 Q99.8345 1087.11 102.057 1087.67 Q104.279 1088.23 106.756 1088.23 Q110.76 1088.23 113.098 1086.12 Q115.436 1084.01 115.436 1080.4 Q115.436 1076.79 113.098 1074.68 Q110.76 1072.58 106.756 1072.58 Q104.881 1072.58 103.006 1072.99 Q101.154 1073.41 99.2095 1074.29 L99.2095 1056.93 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip900)\" d=\"M53.7467 716.048 L61.3856 716.048 L61.3856 689.682 L53.0754 691.349 L53.0754 687.09 L61.3393 685.423 L66.0152 685.423 L66.0152 716.048 L73.654 716.048 L73.654 719.983 L53.7467 719.983 L53.7467 716.048 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip900)\" d=\"M83.0984 714.104 L87.9827 714.104 L87.9827 719.983 L83.0984 719.983 L83.0984 714.104 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip900)\" d=\"M108.168 688.502 Q104.557 688.502 102.728 692.067 Q100.922 695.608 100.922 702.738 Q100.922 709.844 102.728 713.409 Q104.557 716.951 108.168 716.951 Q111.802 716.951 113.608 713.409 Q115.436 709.844 115.436 702.738 Q115.436 695.608 113.608 692.067 Q111.802 688.502 108.168 688.502 M108.168 684.798 Q113.978 684.798 117.033 689.405 Q120.112 693.988 120.112 702.738 Q120.112 711.465 117.033 716.071 Q113.978 720.654 108.168 720.654 Q102.358 720.654 99.2789 716.071 Q96.2234 711.465 96.2234 702.738 Q96.2234 693.988 99.2789 689.405 Q102.358 684.798 108.168 684.798 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip900)\" d=\"M54.7421 344.542 L62.381 344.542 L62.381 318.176 L54.0708 319.843 L54.0708 315.583 L62.3347 313.917 L67.0106 313.917 L67.0106 344.542 L74.6494 344.542 L74.6494 348.477 L54.7421 348.477 L54.7421 344.542 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip900)\" d=\"M84.0938 342.597 L88.978 342.597 L88.978 348.477 L84.0938 348.477 L84.0938 342.597 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip900)\" d=\"M99.2095 313.917 L117.566 313.917 L117.566 317.852 L103.492 317.852 L103.492 326.324 Q104.51 325.977 105.529 325.815 Q106.547 325.63 107.566 325.63 Q113.353 325.63 116.733 328.801 Q120.112 331.972 120.112 337.389 Q120.112 342.968 116.64 346.069 Q113.168 349.148 106.848 349.148 Q104.672 349.148 102.404 348.778 Q100.159 348.407 97.7511 347.667 L97.7511 342.968 Q99.8345 344.102 102.057 344.657 Q104.279 345.213 106.756 345.213 Q110.76 345.213 113.098 343.106 Q115.436 341 115.436 337.389 Q115.436 333.778 113.098 331.671 Q110.76 329.565 106.756 329.565 Q104.881 329.565 103.006 329.982 Q101.154 330.398 99.2095 331.278 L99.2095 313.917 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip902)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  218.281,1279.12 285.13,1279.23 351.978,1445.72 418.827,1329.16 485.676,1110.2 552.524,1383.72 619.373,1440.49 686.221,1311.51 753.07,434.406 819.918,1218.05 \n",
       "  886.767,781.996 953.615,1289.57 1020.46,1127.15 1087.31,87.9763 1154.16,1277.03 1221.01,851.77 1287.86,972.742 1354.71,712.92 1421.56,971.232 1488.4,1136.09 \n",
       "  1555.25,1078.62 1622.1,1288.75 1688.95,1094.76 1755.8,1331.48 1822.65,1019.64 1889.5,1330.55 1956.34,1055.75 2023.19,1317.55 2090.04,1040.77 2156.89,1330.43 \n",
       "  2223.74,836.213 2290.59,1326.49 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip900)\" d=\"\n",
       "M2007.44 198.898 L2279.53 198.898 L2279.53 95.2176 L2007.44 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip900)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2007.44,198.898 2279.53,198.898 2279.53,95.2176 2007.44,95.2176 2007.44,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip900)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2031.85,147.058 2178.29,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip900)\" d=\"M2216.54 166.745 Q2214.73 171.375 2213.02 172.787 Q2211.31 174.199 2208.44 174.199 L2205.03 174.199 L2205.03 170.634 L2207.53 170.634 Q2209.29 170.634 2210.27 169.8 Q2211.24 168.967 2212.42 165.865 L2213.18 163.921 L2202.7 138.412 L2207.21 138.412 L2215.31 158.689 L2223.41 138.412 L2227.93 138.412 L2216.54 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip900)\" d=\"M2235.22 160.402 L2242.86 160.402 L2242.86 134.037 L2234.55 135.703 L2234.55 131.444 L2242.81 129.778 L2247.49 129.778 L2247.49 160.402 L2255.13 160.402 L2255.13 164.338 L2235.22 164.338 L2235.22 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    bestEpSc    = -100.0;\n",
    "    statesBest  = zeros( size( X_0, 1 ), T )\n",
    "    actionsBest = zeros( T );\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/(episodes-1)\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        s_l = 0.0\n",
    "        # while s_l == 0\n",
    "        \n",
    "            X  = X_0\n",
    "\n",
    "            ##### Double Q-Learning ###########################################\n",
    "\n",
    "            for k = 1:T\n",
    "\n",
    "                # 1. Choose action\n",
    "                if rand() < epsilon\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                else\n",
    "\n",
    "                    A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                    if A == 1000.0 # Indicates no values in this region\n",
    "                        if rand() < EXPrand \n",
    "                            A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                        else\n",
    "                            A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                # 2. Cache last state\n",
    "                qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "                # 3. Generate the next stae\n",
    "                Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "                # 4. Collect reward R( s, a, s' )\n",
    "                R_t = cartpole_reward( Xp )\n",
    "\n",
    "                # 5. Get the optimal action at the next state\n",
    "                a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "                # 6. Compute the value at the next state\n",
    "\n",
    "                V_tp1_opt = query_value_fuzzy( \n",
    "                    Q_kdTree, G, V, \n",
    "                    get_Q( \n",
    "                        select_X_vector( Xp ), \n",
    "                        a_tp1_opt \n",
    "                    ); \n",
    "                    k = vNN \n",
    "                )\n",
    "                if isnan( V_tp1_opt )\n",
    "                    V_tp1_opt = 0.0\n",
    "                end\n",
    "\n",
    "\n",
    "                # 7. Blend the value back into nearest points\n",
    "\n",
    "                idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "                nNear      = size( idxs, 1 )\n",
    "                for i = 1:nNear\n",
    "                    j    = idxs[i]\n",
    "                    if !isnan( wgts[i] ) \n",
    "\n",
    "                        # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                        VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                states[:,k] = Xp\n",
    "                actions[k]  = A\n",
    "\n",
    "                X = Xp\n",
    "            end\n",
    "\n",
    "            s_l    = vertical_score_s( states, aMargin, ts )\n",
    "            \n",
    "        # end\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if s_l > bestEpSc\n",
    "            bestEpSc    = s_l\n",
    "            statesBest  = copy( states  )\n",
    "            actionsBest = copy( actions )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        # if useElig && (s_l > s_Totl/(1.0*l)) && (s_l > 0.0) \n",
    "        # if useElig && (s_l > 0.0) \n",
    "        if useElig \n",
    "            \n",
    "            # if s_l == 0.0\n",
    "            #     states  = copy( bestXs )\n",
    "            #     actions = copy( bestAs )\n",
    "            # end\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "            # println(\"SWAP\")\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    ##### Learning Rate Schedule ##########################################\n",
    "    alpha *= beta\n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709555b9-2598-4281-a634-c7b0681277d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Method 2 Performance, Average Vertical Duration [s]\n",
    "Each score is the best average score of the last two epochs: 32 epochs of 64 episodes each, Q-function swap after every episode \n",
    "\n",
    "### TD Tuning\n",
    "\n",
    "$\\gamma = 1.00$  \n",
    "\n",
    "| Param                |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|----------------------|------| ------- | ------- | ------- | ------- | ------- |------| ----- |\n",
    "| $$\\alpha = 0.99$$    |&nbsp;| 0.251   | 0.198   | 0.146   | 0.147   | 0.210   |&nbsp;| 0.190 |\n",
    "| $$\\alpha = 0.75$$    |&nbsp;| 0.179   | 0.185   | 0.239   | 0.179   | 0.175   |&nbsp;| 0.191 |\n",
    "| $$\\alpha = 0.50$$    |&nbsp;| 0.204   | 0.100   | 0.238   | 0.158   | 0.139   |&nbsp;| 0.168 |\n",
    "| $$\\alpha = 0.25$$    |&nbsp;| 0.294   | 0.170   | 0.107   | 0.223   | 0.147   |&nbsp;| 0.188 |\n",
    "| $$\\alpha = 0.125$$   |&nbsp;| 0.187   | 0.254   | 0.177   | 0.163   | 0.204   |&nbsp;| 0.197 |  \n",
    "| $$\\alpha = 0.0625$$  |&nbsp;| 0.113   | 0.241   | 0.353   | 0.134   | 0.749   |&nbsp;| 0.318 |\n",
    "| $$\\alpha = 0.03125$$ |&nbsp;| 0.231   | 0.322   | 0.018   | 0.098   | 0.000   |&nbsp;| 0.134 |\n",
    "| $$\\alpha = 0.02344$$ |&nbsp;| 1.289   | 0.119   | 0.380   | 0.168   | 0.086   |&nbsp;| 0.408 |\n",
    "| $$\\alpha = \\mathbf{0.02148}$$ |&nbsp;| 0.498   | 0.813   | 0.286   | 7.130   | 0.281   |&nbsp;| **1.802** |\n",
    "| $$\\alpha = 0.01953$$ |&nbsp;| 0.234   | 0.113   | 0.445   | 0.119   | 1.637   |&nbsp;| 0.510 |\n",
    "| $$\\alpha = 0.01758$$ |&nbsp;| 0.175   | 0.249   | 0.217   | 0.047   | 1.006   |&nbsp;| 0.339 |\n",
    "| $$\\alpha = 0.01563$$ |&nbsp;| 0.281   | 1.371   | 0.066   | 0.037   | 0.751   |&nbsp;| 0.501 |\n",
    "| $$\\alpha = 0.00782$$ |&nbsp;| 0.133   | 0.241   | 0.149   | 0.493   | 0.146   |&nbsp;| 0.232 |\n",
    "| $$\\alpha = 0.00391$$ |&nbsp;| 0.037   | 0.626   | 1.000   | 0.525   | 0.139   |&nbsp;| 0.465 |\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "### $\\gamma$ Tuning\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "\n",
    "| Param                 |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "| :-------------------- |------| ------- | ------- | ------- | ------- | ------- |------| ----- |\n",
    "| $$\\gamma = 0.999$$    |&nbsp;| 0.925   | 0.247   | 0.145   | 0.364   | 3.038   |&nbsp;| 0.944 |\n",
    "| $$\\gamma = 0.99$$     |&nbsp;| 0.011   | 0.448   | 0.453   | 0.915   | 0.013   |&nbsp;| 0.368 |\n",
    "| $$\\gamma = 0.85$$     |&nbsp;| 0.314   | 2.778   | 0.275   | 1.183   | 0.079   |&nbsp;| 0.926 |\n",
    "| $$\\gamma = 0.80$$     |&nbsp;| 0.082   | 0.033   | 0.173   | 0.251   | 1.741   |&nbsp;| 0.456 |\n",
    "| $$\\gamma = 0.75$$     |&nbsp;| 0.283   | 0.239   | 2.223   | 0.264   | 0.753   |&nbsp;| 0.752 |\n",
    "| $$\\gamma = 0.50$$     |&nbsp;| 0.167   | 0.289   | 0.474   | 0.266   | 0.230   |&nbsp;| 0.285 |\n",
    "\n",
    " \n",
    "### Double-Q Tuning, Swap Evey N Episodes  \n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "Epochs = 32\n",
    "\n",
    "| Param                 |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|-----------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| $$\\%\\ \\ 2$$           |&nbsp;|  0.570  | 0.132   | 1.053   | 0.731   | 0.900   |&nbsp;| 0.677 |\n",
    "| $$\\%\\ \\ 4$$           |&nbsp;|  1.313  | 0.087   | 2.282   | 0.417   | 0.409   |&nbsp;| 0.901 |\n",
    "| $$\\%\\ \\ 8$$           |&nbsp;|  0.097  | 0.040   | 0.621   | 0.030   | 0.608   |&nbsp;| 0.279 |\n",
    "| $$\\%16$$              |&nbsp;|  0.260  | 0.219   | 0.054   | 0.407   | 0.845   |&nbsp;| 0.357 |\n",
    "| $$\\%32$$              |&nbsp;|  0.674  | 0.130   | 0.301   | 0.286   | 0.313   |&nbsp;| 0.341 |\n",
    "| $$\\%\\mathbf{64}$$     |&nbsp;| 15.261  | 2.072   | 0.380   | 0.056   | 0.727   |&nbsp;| **3.699** |\n",
    "  \n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "Episodes = 128  \n",
    "Epochs = 16  \n",
    "\n",
    "| Param            |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| $$\\%\\ \\ \\ \\ 4$$  |&nbsp;|  1.333  | 0.117   | 0.138   | 0.430   | 0.149   |&nbsp;| 0.433 |\n",
    "| $$\\%\\ \\ 64$$     |&nbsp;|  0.166  | 0.110   | 0.240   | 1.615   | 0.049   |&nbsp;| 0.436 |\n",
    "| $$\\%128$$        |&nbsp;|  2.700  | 0.228   | 0.222   | 0.183   | 0.002   |&nbsp;| 0.667 |\n",
    "\n",
    "  \n",
    "### Trace Tuning\n",
    "\n",
    "This is not a Sutton and Barto eligibility trace.  Instead, I look for $N_\\text{peak}$ peaks in the value history of the episode, and apply the learning rule in reverse order from the peak through $N_\\text{step}$ previous timesteps, with a $\\lambda$ decay each step. This is neither classical nor rigorous, and if it does not work, then I will switch to one of the classic $Q(\\lambda)$ methods found in Sutton and Barto.\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "$\\lambda = 0.95$  \n",
    "Peaks = 16  \n",
    "Episodes = 64  \n",
    "Swap = \\%64  \n",
    "Epochs = 32  \n",
    "\n",
    "\n",
    "| Param                  |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|------------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| Steps: &nbsp; &nbsp; 4 |&nbsp;| 0.418   | 0.098   | 0.231   | 0.080   | 0.571   |&nbsp;| 0.280 |\n",
    "| Steps: &nbsp; 16       |&nbsp;| 0.540   | 0.365   | 1.629   | 0.215   | 0.470   |&nbsp;| 0.644 |\n",
    "| Steps: &nbsp; 64       |&nbsp;| 1.197   | 0.410   | 1.187   | 1.017   | 0.975   |&nbsp;| 0.957 |\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "$\\lambda = 0.99$  \n",
    "Peaks = 32  \n",
    "Episodes = 64  \n",
    "Swap = \\%64  \n",
    "Epochs = 32  \n",
    "\n",
    "Variations\n",
    "* Only trace non-zero uptime episodes, Result: Many more zero score episodes and no improvement\n",
    "* Only trace episodes with above-average uptime, Result: Many more zero score episodes and no improvement\n",
    "* Re-run the episode until there is non-zero uptime, Result: Extremely slow and no improvement in average uptime  \n",
    "\n",
    "| Param                  |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|------------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| Steps: &nbsp; 64       |&nbsp;| 0.265   |  1.204  | 6.919   | 1.575   |  3.940  |&nbsp;| 2.781 |\n",
    "| Steps: &nbsp; 96       |&nbsp;| 0.212   | 12.012  | 0.213   | 0.195   | 13.896  |&nbsp;| 5.306 |\n",
    "| **Steps: 128**         |&nbsp;| 0.065   | 17.540  | 0.493   | 0.325   | 15.345  |&nbsp;| **6.754** |\n",
    "| Steps: 192             |&nbsp;| 0.271   |  0.127  | 0.220   | 0.299   |  0.600  |&nbsp;| 0.303 |\n",
    "| Steps: 256             |&nbsp;| 0.958   |  2.014  | 0.947   | 0.433   |  0.045  |&nbsp;| 0.879 |\n",
    "| Steps: 512             |&nbsp;| 1.487   |  0.343  | 0.159   | 1.057   |  0.640  |&nbsp;| 0.737 |  \n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "$\\lambda = 0.99$  \n",
    "Steps = 128  \n",
    "Episodes = 64  \n",
    "Swap = \\%64  \n",
    "Epochs = 32  \n",
    "\n",
    "| Param                  |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|------------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| Peaks: &nbsp; &nbsp; 2 |&nbsp;|  0.635  | 5.336   | 0.198   |  0.069  | 0.624   |&nbsp;|       |\n",
    "| Peaks: &nbsp; &nbsp; 4 |&nbsp;|  0.086  | 0.270   | 0.286   |  0.704  | 0.122   |&nbsp;|       |\n",
    "| Peaks: &nbsp; &nbsp; 8 |&nbsp;| 17.591  | 0.446   | 0.334   |  0.317  | 1.206   |&nbsp;| 3.979 |\n",
    "| Peaks: &nbsp; 16       |&nbsp;|  0.449  | 6.393   | 0.763   | 11.826  | 0.089   |&nbsp;|       |\n",
    "| Peaks: &nbsp; 64       |&nbsp;|  0.455  | 0.910   | 1.000   |  0.555  | 0.891   |&nbsp;|       |\n",
    "| Peaks: 128             |&nbsp;|  0.354  | 0.242   | 1.780   |  0.393  | 0.166   |&nbsp;|       |\n",
    "\n",
    "\n",
    "### Value Estimation Tuning\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "$\\lambda = 0.99$  \n",
    "Peaks =  32  \n",
    "Steps = 128 \n",
    "Episodes = 64  \n",
    "Swap = \\%64  \n",
    "Epochs = 32 \n",
    "\n",
    "| Param 1   | Param 2     |&nbsp;| Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |&nbsp;| Mean  |\n",
    "|-----------|-------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| Inputs: 2 | Outputs: 1  |      | 1.172   | 0.413   |  0.057  | 0.130   | 0.092   |      |       | \n",
    "| Inputs: 2 | Outputs: 2  |      | 1.327   | 0.258   | 12.772  | 0.361   | 0.321   |      |       |\n",
    "| Inputs: 3 | Outputs: 1  |      | 0.365   | 0.575   |  0.033  | 0.046   | 0.415   |      |       | \n",
    "| Inputs: 3 | Outputs: 2  |      | 0.279   | 1.335   |  0.438  | 1.413   | 0.121   |      |       | \n",
    "| Inputs: 3 | Outputs: 3  |      | 0.415   | 0.352   |  0.195  | 0.884   | 1.048   |      |       | \n",
    "| Inputs: 4 | Outputs: 2  |      | 0.083   | 1.845   |  0.437  | 0.418   | 3.486   |      |       | \n",
    "| Inputs: 4 | Outputs: 3  |      | 0.273   | 0.566   |  0.266  | 0.174   | 0.487   |      |       | \n",
    "| Inputs: 4 | Outputs: 4  |      | 0.620   | 0.145   |  1.528  | 0.418   | 0.130   |      |       | \n",
    "| Inputs: 5 | Outputs: 1  |      | 0.203   | 0.406   |  0.281  | 1.045   | 1.341   |      |       | \n",
    "\n",
    "### Learning Rate Decay\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "$\\lambda = 0.99$  \n",
    "Peaks =  32  \n",
    "Steps = 128  \n",
    "Episodes = 64  \n",
    "Swap = \\%64  \n",
    "Epochs = 32  \n",
    "Inputs = 4  \n",
    "Outputs = 1  \n",
    "\n",
    "| Param                  |&nbsp;| Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |&nbsp;| Mean  |\n",
    "|------------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| $$\\beta = 0.999$$      |      | 1.347   | 0.185   | 11.403  | 0.890   | 0.333   |      | 2.832 | \n",
    "| $$\\beta = 0.99\\ $$     |      | 0.482   | 0.089   |  1.839  | 8.804   | 0.144   |      | 2.272 | \n",
    "| $$\\beta = 0.95\\ $$     |      | 0.470   | 1.620   |  1.122  | 5.594   | 0.951   |      | 1.951 | \n",
    "| $$\\beta = 0.925 $$     |      |         |         |         |         |         |      |       | \n",
    "| $$\\beta = 0.90\\ $$     |      | 0.500   | 4.234   |  5.158  | 1.656   | 5.795   |      |       | \n",
    "| $$\\beta = 0.85\\ $$     |      |         |         |         |         |         |      |       | \n",
    "| $$\\beta = 0.80\\ $$     |      | 4.467   | 4.096   |  2.152  | 0.767   | 0.328   |      |       | \n",
    "| $$\\beta = 0.75\\ $$     |      |         |         |         |         |         |      |       | \n",
    "| $$\\beta = 0.70\\ $$     |      | 0.313   | 0.916   |  1.234  | 0.378   | 0.820   |      |       | \n",
    "\n",
    "### `!!!` IMPLEMENTATION CHECK `!!!`\n",
    "\n",
    "#### Action Selection\n",
    "\n",
    "### Blend: Best Episode\n",
    "\n",
    "$\\beta = 0.07$:  \n",
    "$\\beta = 0.15$: 0.244\n",
    "\n",
    "| Method      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n",
    "| ----------- | ------- | ------- | ------- | ------- | ------- | ---- |\n",
    "| Blend (Epi) |         |         |         |         |         |      |\n",
    "| Blend (Epo) |         |         |         |         |         |      |\n",
    "| TD          |         |         |         |         |         |      |\n",
    "| TD  + ????? |         |         |         |         |         |      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Process(`\u001b[4mplay\u001b[24m \u001b[4m-nq\u001b[24m \u001b[4m-t\u001b[24m \u001b[4malsa\u001b[24m \u001b[4msynth\u001b[24m \u001b[4m3\u001b[24m \u001b[4msine\u001b[24m \u001b[4m300\u001b[24m`, ProcessExited(0))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(`play -nq -t alsa synth 3 sine 300`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b5ade7-5f94-43b1-837f-85ccdd6b5c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
