{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Calc the unit vector in the same direction as arg, but only for the non-negative elements\n",
    "\"\"\"\n",
    "function vec_unit_nonneg( vec )\n",
    "    vcP = vec[:]\n",
    "    N   = size( vec, 1 )\n",
    "    for i in 1:N\n",
    "        if vec[i] < 0.0\n",
    "            vcP[i] = 0.0\n",
    "        end\n",
    "    end\n",
    "    len = norm( vcP )\n",
    "    if len == 0.0\n",
    "        return vcP\n",
    "    else\n",
    "        return vcP / len\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_fuzzy( kdTree, pnts, vals, q; k = 3 )\n",
    "    idxs, wgts = K_kNN( kdTree, q; k = k )\n",
    "    if !(-1 in idxs)\n",
    "        p_  , v_  = fetch_by_indices( pnts, vals, idxs )\n",
    "        wgts      = manhatt_contrib_to_q( p_, q )\n",
    "        vP        = vec_unit_nonneg( v_ )\n",
    "        action    = 0.0\n",
    "        N         = size( idxs, 1 )\n",
    "        wgtP      = vec_unit( wgts .* vP )\n",
    "        for j in  1:N\n",
    "            action += p_[ nX+1, j ] * wgtP[j]\n",
    "        end\n",
    "        return action\n",
    "    else\n",
    "        return 1000.0\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.02148 # 0.02148 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 # 0.00782 # 0.00391\n",
    "beta     = 1.000 # 0.913\n",
    "gamma    = 1.00 \n",
    "swapDiv  = 64\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes = 64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   = 32 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = true\n",
    "N_peaks =  32\n",
    "N_steps = 128\n",
    "lambda  =   0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.23000000000000007, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.9700000000000006, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.9500000000000006, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.15, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.34000000000000014, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.3900000000000002, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.46000000000000024, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.20000000000000004, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.27359375000000025\n",
      "\n",
      "Epoch 2, Best Score: 1.5800000000000012\n",
      "Training Iteration 4 score: 0.11999999999999998, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.2800000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.48000000000000026, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.2900000000000001, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.23000000000000007, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 1.0700000000000007, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.10999999999999999, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 1.1100000000000008, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.09999999999999999, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.20000000000000004, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.17156250000000006\n",
      "\n",
      "Epoch 3, Best Score: 1.5800000000000012\n",
      "Training Iteration 4 score: 0.34000000000000014, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.7900000000000005, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.09999999999999999, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.15, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.47000000000000025, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.16, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.2800000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.08, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.12046875000000001\n",
      "\n",
      "Epoch 4, Best Score: 1.5800000000000012\n",
      "Training Iteration 4 score: 0.15, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.15, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.5100000000000002, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.5100000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.11999999999999998, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.25000000000000006, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.11999999999999998, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.09, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.09999999999999999, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.20000000000000004, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.09999999999999999, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.11437500000000002\n",
      "\n",
      "Epoch 5, Best Score: 1.5800000000000012\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.16, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.08, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.23000000000000007, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.20000000000000004, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.37000000000000016, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.17, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.36000000000000015, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.07, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.7300000000000004, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.21000000000000005, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.7600000000000005, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.20000000000000004, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.24312500000000012\n",
      "\n",
      "Epoch 6, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.15, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.09999999999999999, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.060000000000000005, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.49000000000000027, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.15, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.3900000000000002, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.24000000000000007, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.8300000000000005, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.10999999999999999, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.25000000000000006, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.060000000000000005, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.17, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.20656250000000012\n",
      "\n",
      "Epoch 7, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.09999999999999999, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.38000000000000017, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.4200000000000002, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.23000000000000007, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.45000000000000023, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.10999999999999999, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.5000000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.5200000000000002, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.4200000000000002, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.2700000000000001, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.07, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.12999999999999998, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.6300000000000003, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.5600000000000003, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.19937500000000008\n",
      "\n",
      "Epoch 8, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.22000000000000006, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.12999999999999998, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.15, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.16, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.23000000000000007, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.10999999999999999, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.19000000000000003, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.37000000000000016, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.07, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.19000000000000003, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.1965625000000001\n",
      "\n",
      "Epoch 9, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.38000000000000017, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.09999999999999999, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.12999999999999998, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.4300000000000002, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.7800000000000005, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.07, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.37000000000000016, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.20000000000000004, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.2800000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.3000000000000001, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.17562500000000006\n",
      "\n",
      "Epoch 10, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.19000000000000003, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.16, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.10999999999999999, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.17, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.6200000000000003, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.35000000000000014, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 1.0700000000000007, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.08, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.20000000000000004, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.22390625000000006\n",
      "\n",
      "Epoch 11, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.5500000000000003, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.18000000000000002, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.05, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.3200000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.10999999999999999, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.4400000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.08, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.3200000000000001, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.09, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.11999999999999998, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.060000000000000005, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.5500000000000003, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.2143750000000001\n",
      "\n",
      "Epoch 12, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.7300000000000004, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.5200000000000002, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.24000000000000007, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.2800000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.09, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.21000000000000005, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.10999999999999999, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.060000000000000005, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.4100000000000002, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.07, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.09, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.4000000000000002, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.3000000000000001, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.1862500000000001\n",
      "\n",
      "Epoch 13, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.11999999999999998, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.17, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.21000000000000005, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.5900000000000003, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.3300000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.08, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.17, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.45000000000000023, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.16, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.9900000000000007, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.08, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.2700000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.26000000000000006, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.21000000000000005\n",
      "\n",
      "Epoch 14, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.13999999999999999, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.09, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.2900000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.2800000000000001, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.5800000000000003, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.16, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.22000000000000006, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.16000000000000006\n",
      "\n",
      "Epoch 15, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.07, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.10999999999999999, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.2700000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.48000000000000026, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.4300000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.08, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.47000000000000025, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.19000000000000003, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.08, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.16984375000000004\n",
      "\n",
      "Epoch 16, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.09, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.09, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.09999999999999999, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.3200000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.10999999999999999, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.09999999999999999, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.8100000000000005, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.09999999999999999, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.23000000000000007, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.09999999999999999, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.05, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.3000000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.3200000000000001, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.18484375000000008\n",
      "\n",
      "Epoch 17, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.8000000000000005, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.09999999999999999, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.8700000000000006, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.35000000000000014, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.12999999999999998, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.07, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.6000000000000003, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.46000000000000024, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.08, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.05, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.1893750000000002\n",
      "\n",
      "Epoch 18, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.13999999999999999, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.10999999999999999, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.38000000000000017, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.09, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.3300000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.2800000000000001, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.10999999999999999, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.07, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.09999999999999999, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.3200000000000001, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.18937500000000007\n",
      "\n",
      "Epoch 19, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.19000000000000003, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.7900000000000005, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.5100000000000002, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.2700000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.060000000000000005, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.5200000000000002, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.08, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.11999999999999998, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.09, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.6100000000000003, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.20328125000000002\n",
      "\n",
      "Epoch 20, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.3900000000000002, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 1.1100000000000008, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.12999999999999998, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.18000000000000002, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.22000000000000006, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.3300000000000001, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.08, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.05, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.3100000000000001, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.07, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.34000000000000014, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.08, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.07, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.21000000000000005, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.08, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.2623437500000001\n",
      "\n",
      "Epoch 21, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.2700000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.7700000000000005, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 1.0100000000000007, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.060000000000000005, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.45000000000000023, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.22000000000000006, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.08, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.6800000000000004, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.20000000000000004, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.04, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.4300000000000002, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.17, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.18000000000000002, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.23000000000000007, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.2575000000000001\n",
      "\n",
      "Epoch 22, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.12999999999999998, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.46000000000000024, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.19000000000000003, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.37000000000000016, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.17, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.11999999999999998, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.11999999999999998, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.20000000000000004, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.20000000000000004, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.5100000000000002, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.060000000000000005, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.24531250000000013\n",
      "\n",
      "Epoch 23, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.11999999999999998, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.6200000000000003, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.2800000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.34000000000000014, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.12999999999999998, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.2800000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.45000000000000023, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.16, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.49000000000000027, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.17, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.09999999999999999, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.2800000000000001, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.5000000000000002, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.20921875000000012\n",
      "\n",
      "Epoch 24, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.22000000000000006, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.12999999999999998, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.15, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.09999999999999999, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.21000000000000005, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.08, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.6300000000000003, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.07, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.09999999999999999, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.05, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.09999999999999999, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.09, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.4400000000000002, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.18062500000000012\n",
      "\n",
      "Epoch 25, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.5800000000000003, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.48000000000000026, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.7700000000000005, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.13999999999999999, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.3200000000000001, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.09, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.12999999999999998, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.09, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.08, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.05, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.20000000000000004, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.1831250000000001\n",
      "\n",
      "Epoch 26, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.09999999999999999, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.25000000000000006, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 1.270000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.7200000000000004, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.13999999999999999, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.16, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.5500000000000003, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.36000000000000015, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 1.1600000000000008, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.23000000000000007, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.18000000000000002, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.7600000000000005, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.09, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.2167187500000001\n",
      "\n",
      "Epoch 27, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.21000000000000005, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.17, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.24000000000000007, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.3200000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.12999999999999998, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.26000000000000006, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.05, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.4300000000000002, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.11999999999999998, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.48000000000000026, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.09, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.16, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.22000000000000006, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.7400000000000004, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.2131250000000001\n",
      "\n",
      "Epoch 28, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.24000000000000007, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 1.500000000000001, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.12999999999999998, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.0300000000000007, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.08, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.15, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.2800000000000001, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.08, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.13999999999999999, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.16, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.04, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.22484375000000012\n",
      "\n",
      "Epoch 29, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.6100000000000003, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.20000000000000004, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.12999999999999998, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.3100000000000001, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.12999999999999998, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.060000000000000005, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.26000000000000006, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.17, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.24000000000000007, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.12999999999999998, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.15, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.19171875000000008\n",
      "\n",
      "Epoch 30, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.7400000000000004, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.36000000000000015, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 1.0700000000000007, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.16, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.7000000000000004, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.12999999999999998, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.09999999999999999, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.16, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 1.0200000000000007, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.07, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.05, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.4300000000000002, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.13999999999999999, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.2101562500000001\n",
      "\n",
      "Epoch 31, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.46000000000000024, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.22000000000000006, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.2900000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.5200000000000002, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.09, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.21000000000000005, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.2700000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.4000000000000002, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.10999999999999999, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.4300000000000002, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.09, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.16, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.09, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.2173437500000001\n",
      "\n",
      "Epoch 32, Best Score: 1.9500000000000015\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.48000000000000026, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.19000000000000003, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.37000000000000016, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.25000000000000006, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.04, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.15, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.11999999999999998, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.060000000000000005, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.10999999999999999, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.3100000000000001, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.060000000000000005, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.08, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.15, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.19156250000000005\n",
      "Saved a trained Q-table with size (76032,), After 6.53839871486028 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip710\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip710)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip711\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip710)\" d=\"\n",
       "M186.76 1486.45 L2352.76 1486.45 L2352.76 47.2441 L186.76 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip712\">\n",
       "    <rect x=\"186\" y=\"47\" width=\"2167\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip712)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  511.725,1486.45 511.725,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip712)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  841.305,1486.45 841.305,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip712)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1170.88,1486.45 1170.88,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip712)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1500.46,1486.45 1500.46,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip712)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1830.04,1486.45 1830.04,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip712)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2159.62,1486.45 2159.62,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.76,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  511.725,1486.45 511.725,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  841.305,1486.45 841.305,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1170.88,1486.45 1170.88,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1500.46,1486.45 1500.46,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1830.04,1486.45 1830.04,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2159.62,1486.45 2159.62,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip710)\" d=\"M502.003 1514.29 L520.36 1514.29 L520.36 1518.22 L506.286 1518.22 L506.286 1526.7 Q507.304 1526.35 508.323 1526.19 Q509.341 1526 510.36 1526 Q516.147 1526 519.526 1529.17 Q522.906 1532.34 522.906 1537.76 Q522.906 1543.34 519.434 1546.44 Q515.961 1549.52 509.642 1549.52 Q507.466 1549.52 505.198 1549.15 Q502.952 1548.78 500.545 1548.04 L500.545 1543.34 Q502.628 1544.47 504.85 1545.03 Q507.073 1545.58 509.549 1545.58 Q513.554 1545.58 515.892 1543.48 Q518.23 1541.37 518.23 1537.76 Q518.23 1534.15 515.892 1532.04 Q513.554 1529.94 509.549 1529.94 Q507.674 1529.94 505.8 1530.35 Q503.948 1530.77 502.003 1531.65 L502.003 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M815.992 1544.91 L823.631 1544.91 L823.631 1518.55 L815.321 1520.21 L815.321 1515.95 L823.585 1514.29 L828.261 1514.29 L828.261 1544.91 L835.9 1544.91 L835.9 1548.85 L815.992 1548.85 L815.992 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M855.344 1517.37 Q851.733 1517.37 849.904 1520.93 Q848.099 1524.47 848.099 1531.6 Q848.099 1538.71 849.904 1542.27 Q851.733 1545.82 855.344 1545.82 Q858.978 1545.82 860.784 1542.27 Q862.613 1538.71 862.613 1531.6 Q862.613 1524.47 860.784 1520.93 Q858.978 1517.37 855.344 1517.37 M855.344 1513.66 Q861.154 1513.66 864.21 1518.27 Q867.288 1522.85 867.288 1531.6 Q867.288 1540.33 864.21 1544.94 Q861.154 1549.52 855.344 1549.52 Q849.534 1549.52 846.455 1544.94 Q843.4 1540.33 843.4 1531.6 Q843.4 1522.85 846.455 1518.27 Q849.534 1513.66 855.344 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1146.07 1544.91 L1153.71 1544.91 L1153.71 1518.55 L1145.4 1520.21 L1145.4 1515.95 L1153.66 1514.29 L1158.34 1514.29 L1158.34 1544.91 L1165.98 1544.91 L1165.98 1548.85 L1146.07 1548.85 L1146.07 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1175.47 1514.29 L1193.82 1514.29 L1193.82 1518.22 L1179.75 1518.22 L1179.75 1526.7 Q1180.77 1526.35 1181.79 1526.19 Q1182.81 1526 1183.82 1526 Q1189.61 1526 1192.99 1529.17 Q1196.37 1532.34 1196.37 1537.76 Q1196.37 1543.34 1192.9 1546.44 Q1189.43 1549.52 1183.11 1549.52 Q1180.93 1549.52 1178.66 1549.15 Q1176.42 1548.78 1174.01 1548.04 L1174.01 1543.34 Q1176.09 1544.47 1178.31 1545.03 Q1180.54 1545.58 1183.01 1545.58 Q1187.02 1545.58 1189.36 1543.48 Q1191.69 1541.37 1191.69 1537.76 Q1191.69 1534.15 1189.36 1532.04 Q1187.02 1529.94 1183.01 1529.94 Q1181.14 1529.94 1179.26 1530.35 Q1177.41 1530.77 1175.47 1531.65 L1175.47 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1479.24 1544.91 L1495.56 1544.91 L1495.56 1548.85 L1473.61 1548.85 L1473.61 1544.91 Q1476.27 1542.16 1480.86 1537.53 Q1485.46 1532.88 1486.64 1531.53 Q1488.89 1529.01 1489.77 1527.27 Q1490.67 1525.51 1490.67 1523.82 Q1490.67 1521.07 1488.73 1519.33 Q1486.81 1517.6 1483.7 1517.6 Q1481.51 1517.6 1479.05 1518.36 Q1476.62 1519.13 1473.84 1520.68 L1473.84 1515.95 Q1476.67 1514.82 1479.12 1514.24 Q1481.57 1513.66 1483.61 1513.66 Q1488.98 1513.66 1492.18 1516.35 Q1495.37 1519.03 1495.37 1523.52 Q1495.37 1525.65 1494.56 1527.57 Q1493.77 1529.47 1491.67 1532.07 Q1491.09 1532.74 1487.99 1535.95 Q1484.88 1539.15 1479.24 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1515.37 1517.37 Q1511.76 1517.37 1509.93 1520.93 Q1508.13 1524.47 1508.13 1531.6 Q1508.13 1538.71 1509.93 1542.27 Q1511.76 1545.82 1515.37 1545.82 Q1519.01 1545.82 1520.81 1542.27 Q1522.64 1538.71 1522.64 1531.6 Q1522.64 1524.47 1520.81 1520.93 Q1519.01 1517.37 1515.37 1517.37 M1515.37 1513.66 Q1521.18 1513.66 1524.24 1518.27 Q1527.32 1522.85 1527.32 1531.6 Q1527.32 1540.33 1524.24 1544.94 Q1521.18 1549.52 1515.37 1549.52 Q1509.56 1549.52 1506.48 1544.94 Q1503.43 1540.33 1503.43 1531.6 Q1503.43 1522.85 1506.48 1518.27 Q1509.56 1513.66 1515.37 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1809.31 1544.91 L1825.63 1544.91 L1825.63 1548.85 L1803.69 1548.85 L1803.69 1544.91 Q1806.35 1542.16 1810.93 1537.53 Q1815.54 1532.88 1816.72 1531.53 Q1818.97 1529.01 1819.85 1527.27 Q1820.75 1525.51 1820.75 1523.82 Q1820.75 1521.07 1818.8 1519.33 Q1816.88 1517.6 1813.78 1517.6 Q1811.58 1517.6 1809.13 1518.36 Q1806.7 1519.13 1803.92 1520.68 L1803.92 1515.95 Q1806.74 1514.82 1809.2 1514.24 Q1811.65 1513.66 1813.69 1513.66 Q1819.06 1513.66 1822.25 1516.35 Q1825.45 1519.03 1825.45 1523.52 Q1825.45 1525.65 1824.64 1527.57 Q1823.85 1529.47 1821.74 1532.07 Q1821.17 1532.74 1818.06 1535.95 Q1814.96 1539.15 1809.31 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1835.49 1514.29 L1853.85 1514.29 L1853.85 1518.22 L1839.78 1518.22 L1839.78 1526.7 Q1840.8 1526.35 1841.81 1526.19 Q1842.83 1526 1843.85 1526 Q1849.64 1526 1853.02 1529.17 Q1856.4 1532.34 1856.4 1537.76 Q1856.4 1543.34 1852.92 1546.44 Q1849.45 1549.52 1843.13 1549.52 Q1840.96 1549.52 1838.69 1549.15 Q1836.44 1548.78 1834.04 1548.04 L1834.04 1543.34 Q1836.12 1544.47 1838.34 1545.03 Q1840.56 1545.58 1843.04 1545.58 Q1847.05 1545.58 1849.38 1543.48 Q1851.72 1541.37 1851.72 1537.76 Q1851.72 1534.15 1849.38 1532.04 Q1847.05 1529.94 1843.04 1529.94 Q1841.17 1529.94 1839.29 1530.35 Q1837.44 1530.77 1835.49 1531.65 L1835.49 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M2148.47 1530.21 Q2151.82 1530.93 2153.7 1533.2 Q2155.59 1535.47 2155.59 1538.8 Q2155.59 1543.92 2152.08 1546.72 Q2148.56 1549.52 2142.08 1549.52 Q2139.9 1549.52 2137.59 1549.08 Q2135.29 1548.66 2132.84 1547.81 L2132.84 1543.29 Q2134.78 1544.43 2137.1 1545.01 Q2139.41 1545.58 2141.94 1545.58 Q2146.34 1545.58 2148.63 1543.85 Q2150.94 1542.11 2150.94 1538.8 Q2150.94 1535.75 2148.79 1534.03 Q2146.66 1532.3 2142.84 1532.3 L2138.81 1532.3 L2138.81 1528.45 L2143.03 1528.45 Q2146.47 1528.45 2148.3 1527.09 Q2150.13 1525.7 2150.13 1523.11 Q2150.13 1520.45 2148.23 1519.03 Q2146.36 1517.6 2142.84 1517.6 Q2140.92 1517.6 2138.72 1518.01 Q2136.52 1518.43 2133.88 1519.31 L2133.88 1515.14 Q2136.54 1514.4 2138.86 1514.03 Q2141.2 1513.66 2143.26 1513.66 Q2148.58 1513.66 2151.68 1516.09 Q2154.78 1518.5 2154.78 1522.62 Q2154.78 1525.49 2153.14 1527.48 Q2151.5 1529.45 2148.47 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M2174.46 1517.37 Q2170.85 1517.37 2169.02 1520.93 Q2167.21 1524.47 2167.21 1531.6 Q2167.21 1538.71 2169.02 1542.27 Q2170.85 1545.82 2174.46 1545.82 Q2178.09 1545.82 2179.9 1542.27 Q2181.73 1538.71 2181.73 1531.6 Q2181.73 1524.47 2179.9 1520.93 Q2178.09 1517.37 2174.46 1517.37 M2174.46 1513.66 Q2180.27 1513.66 2183.33 1518.27 Q2186.4 1522.85 2186.4 1531.6 Q2186.4 1540.33 2183.33 1544.94 Q2180.27 1549.52 2174.46 1549.52 Q2168.65 1549.52 2165.57 1544.94 Q2162.52 1540.33 2162.52 1531.6 Q2162.52 1522.85 2165.57 1518.27 Q2168.65 1513.66 2174.46 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip712)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.76,1397.75 2352.76,1397.75 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip712)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.76,1227.2 2352.76,1227.2 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip712)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.76,1056.65 2352.76,1056.65 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip712)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.76,886.098 2352.76,886.098 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip712)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.76,715.548 2352.76,715.548 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip712)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.76,544.997 2352.76,544.997 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip712)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.76,374.447 2352.76,374.447 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip712)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.76,203.897 2352.76,203.897 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.76,1486.45 186.76,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.76,1397.75 205.658,1397.75 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.76,1227.2 205.658,1227.2 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.76,1056.65 205.658,1056.65 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.76,886.098 205.658,886.098 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.76,715.548 205.658,715.548 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.76,544.997 205.658,544.997 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.76,374.447 205.658,374.447 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.76,203.897 205.658,203.897 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip710)\" d=\"M65.0198 1383.55 Q61.4087 1383.55 59.58 1387.11 Q57.7745 1390.65 57.7745 1397.78 Q57.7745 1404.89 59.58 1408.45 Q61.4087 1412 65.0198 1412 Q68.6541 1412 70.4596 1408.45 Q72.2883 1404.89 72.2883 1397.78 Q72.2883 1390.65 70.4596 1387.11 Q68.6541 1383.55 65.0198 1383.55 M65.0198 1379.84 Q70.83 1379.84 73.8855 1384.45 Q76.9642 1389.03 76.9642 1397.78 Q76.9642 1406.51 73.8855 1411.12 Q70.83 1415.7 65.0198 1415.7 Q59.2097 1415.7 56.131 1411.12 Q53.0754 1406.51 53.0754 1397.78 Q53.0754 1389.03 56.131 1384.45 Q59.2097 1379.84 65.0198 1379.84 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M85.1818 1409.15 L90.066 1409.15 L90.066 1415.03 L85.1818 1415.03 L85.1818 1409.15 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M101.061 1411.09 L108.7 1411.09 L108.7 1384.73 L100.39 1386.39 L100.39 1382.14 L108.654 1380.47 L113.33 1380.47 L113.33 1411.09 L120.969 1411.09 L120.969 1415.03 L101.061 1415.03 L101.061 1411.09 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M134.441 1411.09 L150.76 1411.09 L150.76 1415.03 L128.816 1415.03 L128.816 1411.09 Q131.478 1408.34 136.061 1403.71 Q140.668 1399.06 141.848 1397.71 Q144.093 1395.19 144.973 1393.45 Q145.876 1391.7 145.876 1390.01 Q145.876 1387.25 143.931 1385.51 Q142.01 1383.78 138.908 1383.78 Q136.709 1383.78 134.256 1384.54 Q131.825 1385.31 129.047 1386.86 L129.047 1382.14 Q131.871 1381 134.325 1380.42 Q136.779 1379.84 138.816 1379.84 Q144.186 1379.84 147.38 1382.53 Q150.575 1385.21 150.575 1389.7 Q150.575 1391.83 149.765 1393.76 Q148.978 1395.65 146.871 1398.25 Q146.293 1398.92 143.191 1402.14 Q140.089 1405.33 134.441 1411.09 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M62.9365 1213 Q59.3254 1213 57.4967 1216.56 Q55.6912 1220.1 55.6912 1227.23 Q55.6912 1234.34 57.4967 1237.9 Q59.3254 1241.45 62.9365 1241.45 Q66.5707 1241.45 68.3763 1237.9 Q70.205 1234.34 70.205 1227.23 Q70.205 1220.1 68.3763 1216.56 Q66.5707 1213 62.9365 1213 M62.9365 1209.29 Q68.7467 1209.29 71.8022 1213.9 Q74.8809 1218.48 74.8809 1227.23 Q74.8809 1235.96 71.8022 1240.57 Q68.7467 1245.15 62.9365 1245.15 Q57.1264 1245.15 54.0477 1240.57 Q50.9921 1235.96 50.9921 1227.23 Q50.9921 1218.48 54.0477 1213.9 Q57.1264 1209.29 62.9365 1209.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M83.0984 1238.6 L87.9827 1238.6 L87.9827 1244.48 L83.0984 1244.48 L83.0984 1238.6 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M98.978 1240.54 L106.617 1240.54 L106.617 1214.18 L98.3067 1215.84 L98.3067 1211.58 L106.571 1209.92 L111.246 1209.92 L111.246 1240.54 L118.885 1240.54 L118.885 1244.48 L98.978 1244.48 L98.978 1240.54 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M141.177 1213.99 L129.371 1232.44 L141.177 1232.44 L141.177 1213.99 M139.95 1209.92 L145.83 1209.92 L145.83 1232.44 L150.76 1232.44 L150.76 1236.33 L145.83 1236.33 L145.83 1244.48 L141.177 1244.48 L141.177 1236.33 L125.575 1236.33 L125.575 1231.82 L139.95 1209.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M63.2606 1042.45 Q59.6495 1042.45 57.8208 1046.01 Q56.0152 1049.55 56.0152 1056.68 Q56.0152 1063.79 57.8208 1067.35 Q59.6495 1070.9 63.2606 1070.9 Q66.8948 1070.9 68.7004 1067.35 Q70.5291 1063.79 70.5291 1056.68 Q70.5291 1049.55 68.7004 1046.01 Q66.8948 1042.45 63.2606 1042.45 M63.2606 1038.74 Q69.0707 1038.74 72.1263 1043.35 Q75.205 1047.93 75.205 1056.68 Q75.205 1065.41 72.1263 1070.02 Q69.0707 1074.6 63.2606 1074.6 Q57.4504 1074.6 54.3717 1070.02 Q51.3162 1065.41 51.3162 1056.68 Q51.3162 1047.93 54.3717 1043.35 Q57.4504 1038.74 63.2606 1038.74 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M83.4225 1068.05 L88.3067 1068.05 L88.3067 1073.93 L83.4225 1073.93 L83.4225 1068.05 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M99.3021 1069.99 L106.941 1069.99 L106.941 1043.63 L98.6308 1045.29 L98.6308 1041.03 L106.895 1039.37 L111.571 1039.37 L111.571 1069.99 L119.209 1069.99 L119.209 1073.93 L99.3021 1073.93 L99.3021 1069.99 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M139.232 1054.78 Q136.084 1054.78 134.232 1056.94 Q132.404 1059.09 132.404 1062.84 Q132.404 1066.57 134.232 1068.74 Q136.084 1070.9 139.232 1070.9 Q142.381 1070.9 144.209 1068.74 Q146.061 1066.57 146.061 1062.84 Q146.061 1059.09 144.209 1056.94 Q142.381 1054.78 139.232 1054.78 M148.515 1040.13 L148.515 1044.39 Q146.756 1043.56 144.95 1043.12 Q143.168 1042.68 141.408 1042.68 Q136.779 1042.68 134.325 1045.8 Q131.894 1048.93 131.547 1055.25 Q132.913 1053.23 134.973 1052.17 Q137.033 1051.08 139.51 1051.08 Q144.718 1051.08 147.728 1054.25 Q150.76 1057.4 150.76 1062.84 Q150.76 1068.16 147.612 1071.38 Q144.464 1074.6 139.232 1074.6 Q133.237 1074.6 130.066 1070.02 Q126.894 1065.41 126.894 1056.68 Q126.894 1048.49 130.783 1043.63 Q134.672 1038.74 141.223 1038.74 Q142.982 1038.74 144.765 1039.09 Q146.57 1039.44 148.515 1040.13 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M63.5152 871.897 Q59.9041 871.897 58.0754 875.461 Q56.2699 879.003 56.2699 886.133 Q56.2699 893.239 58.0754 896.804 Q59.9041 900.345 63.5152 900.345 Q67.1494 900.345 68.955 896.804 Q70.7837 893.239 70.7837 886.133 Q70.7837 879.003 68.955 875.461 Q67.1494 871.897 63.5152 871.897 M63.5152 868.193 Q69.3254 868.193 72.3809 872.799 Q75.4596 877.383 75.4596 886.133 Q75.4596 894.859 72.3809 899.466 Q69.3254 904.049 63.5152 904.049 Q57.7051 904.049 54.6264 899.466 Q51.5708 894.859 51.5708 886.133 Q51.5708 877.383 54.6264 872.799 Q57.7051 868.193 63.5152 868.193 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M83.6771 897.498 L88.5614 897.498 L88.5614 903.378 L83.6771 903.378 L83.6771 897.498 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M99.5567 899.443 L107.196 899.443 L107.196 873.077 L98.8854 874.744 L98.8854 870.485 L107.149 868.818 L111.825 868.818 L111.825 899.443 L119.464 899.443 L119.464 903.378 L99.5567 903.378 L99.5567 899.443 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M138.908 886.966 Q135.575 886.966 133.654 888.748 Q131.756 890.531 131.756 893.656 Q131.756 896.781 133.654 898.563 Q135.575 900.345 138.908 900.345 Q142.242 900.345 144.163 898.563 Q146.084 896.758 146.084 893.656 Q146.084 890.531 144.163 888.748 Q142.265 886.966 138.908 886.966 M134.232 884.975 Q131.223 884.234 129.533 882.174 Q127.867 880.114 127.867 877.151 Q127.867 873.008 130.807 870.6 Q133.769 868.193 138.908 868.193 Q144.07 868.193 147.01 870.6 Q149.95 873.008 149.95 877.151 Q149.95 880.114 148.26 882.174 Q146.593 884.234 143.607 884.975 Q146.987 885.762 148.862 888.054 Q150.76 890.346 150.76 893.656 Q150.76 898.679 147.681 901.364 Q144.626 904.049 138.908 904.049 Q133.191 904.049 130.112 901.364 Q127.057 898.679 127.057 893.656 Q127.057 890.346 128.955 888.054 Q130.853 885.762 134.232 884.975 M132.519 877.591 Q132.519 880.276 134.186 881.781 Q135.876 883.285 138.908 883.285 Q141.918 883.285 143.607 881.781 Q145.32 880.276 145.32 877.591 Q145.32 874.906 143.607 873.401 Q141.918 871.897 138.908 871.897 Q135.876 871.897 134.186 873.401 Q132.519 874.906 132.519 877.591 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M63.4226 701.346 Q59.8115 701.346 57.9828 704.911 Q56.1773 708.453 56.1773 715.582 Q56.1773 722.689 57.9828 726.254 Q59.8115 729.795 63.4226 729.795 Q67.0569 729.795 68.8624 726.254 Q70.6911 722.689 70.6911 715.582 Q70.6911 708.453 68.8624 704.911 Q67.0569 701.346 63.4226 701.346 M63.4226 697.643 Q69.2328 697.643 72.2883 702.249 Q75.367 706.832 75.367 715.582 Q75.367 724.309 72.2883 728.916 Q69.2328 733.499 63.4226 733.499 Q57.6125 733.499 54.5338 728.916 Q51.4782 724.309 51.4782 715.582 Q51.4782 706.832 54.5338 702.249 Q57.6125 697.643 63.4226 697.643 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M83.5845 726.948 L88.4688 726.948 L88.4688 732.828 L83.5845 732.828 L83.5845 726.948 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M102.682 728.893 L119.001 728.893 L119.001 732.828 L97.0567 732.828 L97.0567 728.893 Q99.7187 726.138 104.302 721.508 Q108.908 716.856 110.089 715.513 Q112.334 712.99 113.214 711.254 Q114.117 709.494 114.117 707.805 Q114.117 705.05 112.172 703.314 Q110.251 701.578 107.149 701.578 Q104.95 701.578 102.496 702.342 Q100.066 703.106 97.2882 704.657 L97.2882 699.934 Q100.112 698.8 102.566 698.221 Q105.02 697.643 107.057 697.643 Q112.427 697.643 115.621 700.328 Q118.816 703.013 118.816 707.504 Q118.816 709.633 118.006 711.555 Q117.219 713.453 115.112 716.045 Q114.533 716.717 111.432 719.934 Q108.33 723.129 102.682 728.893 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M138.816 701.346 Q135.205 701.346 133.376 704.911 Q131.57 708.453 131.57 715.582 Q131.57 722.689 133.376 726.254 Q135.205 729.795 138.816 729.795 Q142.45 729.795 144.256 726.254 Q146.084 722.689 146.084 715.582 Q146.084 708.453 144.256 704.911 Q142.45 701.346 138.816 701.346 M138.816 697.643 Q144.626 697.643 147.681 702.249 Q150.76 706.832 150.76 715.582 Q150.76 724.309 147.681 728.916 Q144.626 733.499 138.816 733.499 Q133.006 733.499 129.927 728.916 Q126.871 724.309 126.871 715.582 Q126.871 706.832 129.927 702.249 Q133.006 697.643 138.816 697.643 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M65.0198 530.796 Q61.4087 530.796 59.58 534.361 Q57.7745 537.903 57.7745 545.032 Q57.7745 552.139 59.58 555.703 Q61.4087 559.245 65.0198 559.245 Q68.6541 559.245 70.4596 555.703 Q72.2883 552.139 72.2883 545.032 Q72.2883 537.903 70.4596 534.361 Q68.6541 530.796 65.0198 530.796 M65.0198 527.092 Q70.83 527.092 73.8855 531.699 Q76.9642 536.282 76.9642 545.032 Q76.9642 553.759 73.8855 558.365 Q70.83 562.949 65.0198 562.949 Q59.2097 562.949 56.131 558.365 Q53.0754 553.759 53.0754 545.032 Q53.0754 536.282 56.131 531.699 Q59.2097 527.092 65.0198 527.092 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M85.1818 556.398 L90.066 556.398 L90.066 562.277 L85.1818 562.277 L85.1818 556.398 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M104.279 558.342 L120.598 558.342 L120.598 562.277 L98.6539 562.277 L98.6539 558.342 Q101.316 555.588 105.899 550.958 Q110.506 546.305 111.686 544.963 Q113.932 542.44 114.811 540.704 Q115.714 538.944 115.714 537.254 Q115.714 534.5 113.77 532.764 Q111.848 531.028 108.746 531.028 Q106.547 531.028 104.094 531.792 Q101.663 532.555 98.8854 534.106 L98.8854 529.384 Q101.709 528.25 104.163 527.671 Q106.617 527.092 108.654 527.092 Q114.024 527.092 117.219 529.778 Q120.413 532.463 120.413 536.954 Q120.413 539.083 119.603 541.004 Q118.816 542.903 116.709 545.495 Q116.131 546.166 113.029 549.384 Q109.927 552.578 104.279 558.342 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M134.441 558.342 L150.76 558.342 L150.76 562.277 L128.816 562.277 L128.816 558.342 Q131.478 555.588 136.061 550.958 Q140.668 546.305 141.848 544.963 Q144.093 542.44 144.973 540.704 Q145.876 538.944 145.876 537.254 Q145.876 534.5 143.931 532.764 Q142.01 531.028 138.908 531.028 Q136.709 531.028 134.256 531.792 Q131.825 532.555 129.047 534.106 L129.047 529.384 Q131.871 528.25 134.325 527.671 Q136.779 527.092 138.816 527.092 Q144.186 527.092 147.38 529.778 Q150.575 532.463 150.575 536.954 Q150.575 539.083 149.765 541.004 Q148.978 542.903 146.871 545.495 Q146.293 546.166 143.191 549.384 Q140.089 552.578 134.441 558.342 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M62.9365 360.246 Q59.3254 360.246 57.4967 363.811 Q55.6912 367.352 55.6912 374.482 Q55.6912 381.588 57.4967 385.153 Q59.3254 388.695 62.9365 388.695 Q66.5707 388.695 68.3763 385.153 Q70.205 381.588 70.205 374.482 Q70.205 367.352 68.3763 363.811 Q66.5707 360.246 62.9365 360.246 M62.9365 356.542 Q68.7467 356.542 71.8022 361.149 Q74.8809 365.732 74.8809 374.482 Q74.8809 383.209 71.8022 387.815 Q68.7467 392.399 62.9365 392.399 Q57.1264 392.399 54.0477 387.815 Q50.9921 383.209 50.9921 374.482 Q50.9921 365.732 54.0477 361.149 Q57.1264 356.542 62.9365 356.542 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M83.0984 385.848 L87.9827 385.848 L87.9827 391.727 L83.0984 391.727 L83.0984 385.848 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M102.196 387.792 L118.515 387.792 L118.515 391.727 L96.5706 391.727 L96.5706 387.792 Q99.2326 385.038 103.816 380.408 Q108.422 375.755 109.603 374.413 Q111.848 371.889 112.728 370.153 Q113.631 368.394 113.631 366.704 Q113.631 363.95 111.686 362.214 Q109.765 360.477 106.663 360.477 Q104.464 360.477 102.01 361.241 Q99.5798 362.005 96.8021 363.556 L96.8021 358.834 Q99.6261 357.7 102.08 357.121 Q104.534 356.542 106.571 356.542 Q111.941 356.542 115.135 359.227 Q118.33 361.913 118.33 366.403 Q118.33 368.533 117.52 370.454 Q116.733 372.352 114.626 374.945 Q114.047 375.616 110.946 378.834 Q107.844 382.028 102.196 387.792 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M141.177 361.241 L129.371 379.69 L141.177 379.69 L141.177 361.241 M139.95 357.167 L145.83 357.167 L145.83 379.69 L150.76 379.69 L150.76 383.579 L145.83 383.579 L145.83 391.727 L141.177 391.727 L141.177 383.579 L125.575 383.579 L125.575 379.065 L139.95 357.167 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M63.2606 189.696 Q59.6495 189.696 57.8208 193.261 Q56.0152 196.802 56.0152 203.932 Q56.0152 211.038 57.8208 214.603 Q59.6495 218.145 63.2606 218.145 Q66.8948 218.145 68.7004 214.603 Q70.5291 211.038 70.5291 203.932 Q70.5291 196.802 68.7004 193.261 Q66.8948 189.696 63.2606 189.696 M63.2606 185.992 Q69.0707 185.992 72.1263 190.599 Q75.205 195.182 75.205 203.932 Q75.205 212.659 72.1263 217.265 Q69.0707 221.848 63.2606 221.848 Q57.4504 221.848 54.3717 217.265 Q51.3162 212.659 51.3162 203.932 Q51.3162 195.182 54.3717 190.599 Q57.4504 185.992 63.2606 185.992 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M83.4225 215.298 L88.3067 215.298 L88.3067 221.177 L83.4225 221.177 L83.4225 215.298 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M102.52 217.242 L118.839 217.242 L118.839 221.177 L96.8947 221.177 L96.8947 217.242 Q99.5567 214.487 104.14 209.858 Q108.746 205.205 109.927 203.862 Q112.172 201.339 113.052 199.603 Q113.955 197.844 113.955 196.154 Q113.955 193.399 112.01 191.663 Q110.089 189.927 106.987 189.927 Q104.788 189.927 102.334 190.691 Q99.9039 191.455 97.1261 193.006 L97.1261 188.284 Q99.9502 187.15 102.404 186.571 Q104.858 185.992 106.895 185.992 Q112.265 185.992 115.459 188.677 Q118.654 191.362 118.654 195.853 Q118.654 197.983 117.844 199.904 Q117.057 201.802 114.95 204.395 Q114.371 205.066 111.27 208.284 Q108.168 211.478 102.52 217.242 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M139.232 202.034 Q136.084 202.034 134.232 204.186 Q132.404 206.339 132.404 210.089 Q132.404 213.816 134.232 215.992 Q136.084 218.145 139.232 218.145 Q142.381 218.145 144.209 215.992 Q146.061 213.816 146.061 210.089 Q146.061 206.339 144.209 204.186 Q142.381 202.034 139.232 202.034 M148.515 187.381 L148.515 191.64 Q146.756 190.807 144.95 190.367 Q143.168 189.927 141.408 189.927 Q136.779 189.927 134.325 193.052 Q131.894 196.177 131.547 202.497 Q132.913 200.483 134.973 199.418 Q137.033 198.33 139.51 198.33 Q144.718 198.33 147.728 201.501 Q150.76 204.649 150.76 210.089 Q150.76 215.413 147.612 218.631 Q144.464 221.848 139.232 221.848 Q133.237 221.848 130.066 217.265 Q126.894 212.659 126.894 203.932 Q126.894 195.737 130.783 190.876 Q134.672 185.992 141.223 185.992 Q142.982 185.992 144.765 186.339 Q146.57 186.687 148.515 187.381 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip712)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  248.062,87.9763 313.978,958.049 379.894,1393.75 445.81,1445.72 511.725,347.799 577.641,659.586 643.557,720.877 709.473,744.861 775.389,923.406 841.305,511.687 \n",
       "  907.221,592.965 973.137,832.801 1039.05,630.273 1104.97,1056.65 1170.88,972.705 1236.8,844.793 1302.72,806.152 1368.63,806.152 1434.55,687.567 1500.46,183.911 \n",
       "  1566.38,225.216 1632.3,329.145 1698.21,636.935 1764.13,880.768 1830.04,859.449 1895.96,572.978 1961.87,603.624 2027.79,503.692 2093.71,786.166 2159.62,628.94 \n",
       "  2225.54,567.649 2291.45,787.499 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip710)\" d=\"\n",
       "M1987.46 198.898 L2280.56 198.898 L2280.56 95.2176 L1987.46 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1987.46,198.898 2280.56,198.898 2280.56,95.2176 1987.46,95.2176 1987.46,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip710)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2011.53,147.058 2155.93,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip710)\" d=\"M2193.84 166.745 Q2192.03 171.375 2190.32 172.787 Q2188.6 174.199 2185.73 174.199 L2182.33 174.199 L2182.33 170.634 L2184.83 170.634 Q2186.59 170.634 2187.56 169.8 Q2188.53 168.967 2189.71 165.865 L2190.48 163.921 L2179.99 138.412 L2184.51 138.412 L2192.61 158.689 L2200.71 138.412 L2205.22 138.412 L2193.84 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M2212.52 160.402 L2220.15 160.402 L2220.15 134.037 L2211.84 135.703 L2211.84 131.444 L2220.11 129.778 L2224.78 129.778 L2224.78 160.402 L2232.42 160.402 L2232.42 164.338 L2212.52 164.338 L2212.52 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    bestEpSc    = -100.0;\n",
    "    statesBest  = zeros( size( X_0, 1 ), T )\n",
    "    actionsBest = zeros( T );\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/(episodes-1)\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        s_l = 0.0\n",
    "        # while s_l == 0\n",
    "        \n",
    "            X     = X_0\n",
    "            qLast = get_Q( select_X_vector( X ), 0.0 )\n",
    "\n",
    "            ##### Double Q-Learning ###########################################\n",
    "\n",
    "            for k = 1:T\n",
    "\n",
    "                # 1. Choose action\n",
    "                if rand() < epsilon\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                else\n",
    "\n",
    "                    # A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                \n",
    "                    A = learned_action_for_state_fuzzy( Q_kdTree, G, V, qLast; k = vNN )\n",
    "                    if (A == 1000.0) || (A == 0.0) # Indicates no values in this region\n",
    "                        if rand() < EXPrand \n",
    "                            A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                        else\n",
    "                            A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                # 2. Cache last state\n",
    "                qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "                # 3. Generate the next stae\n",
    "                Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "                # 4. Collect reward R( s, a, s' )\n",
    "                R_t = cartpole_reward( Xp )\n",
    "\n",
    "                # 5. Get the optimal action at the next state\n",
    "                a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "                # 6. Compute the value at the next state\n",
    "\n",
    "                V_tp1_opt = query_value_fuzzy( \n",
    "                    Q_kdTree, G, V, \n",
    "                    get_Q( \n",
    "                        select_X_vector( Xp ), \n",
    "                        a_tp1_opt \n",
    "                    ); \n",
    "                    k = vNN \n",
    "                )\n",
    "                if isnan( V_tp1_opt )\n",
    "                    V_tp1_opt = 0.0\n",
    "                end\n",
    "\n",
    "\n",
    "                # 7. Blend the value back into nearest points\n",
    "\n",
    "                idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "                nNear      = size( idxs, 1 )\n",
    "                for i = 1:nNear\n",
    "                    j    = idxs[i]\n",
    "                    if !isnan( wgts[i] ) \n",
    "\n",
    "                        # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                        VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                states[:,k] = Xp\n",
    "                actions[k]  = A\n",
    "\n",
    "                X = Xp\n",
    "            end\n",
    "\n",
    "            s_l    = vertical_score_s( states, aMargin, ts )\n",
    "            \n",
    "        # end\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if s_l > bestEpSc\n",
    "            bestEpSc    = s_l\n",
    "            statesBest  = copy( states  )\n",
    "            actionsBest = copy( actions )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        # if useElig && (s_l > s_Totl/(1.0*l)) && (s_l > 0.0) \n",
    "        # if useElig && (s_l > 0.0) \n",
    "        if useElig \n",
    "            \n",
    "            # if s_l == 0.0\n",
    "            #     states  = copy( bestXs )\n",
    "            #     actions = copy( bestAs )\n",
    "            # end\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "            # println(\"SWAP\")\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    ##### Learning Rate Schedule ##########################################\n",
    "    alpha *= beta\n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709555b9-2598-4281-a634-c7b0681277d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Method 2 Performance, Average Vertical Duration [s]\n",
    "Each score is the best average score of the last two epochs: 32 epochs of 64 episodes each, Q-function swap after every episode \n",
    "\n",
    "### TD Tuning\n",
    "\n",
    "$\\gamma = 1.00$  \n",
    "\n",
    "| Param                |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|----------------------|------| ------- | ------- | ------- | ------- | ------- |------| ----- |\n",
    "| $$\\alpha = 0.99$$    |&nbsp;| 0.251   | 0.198   | 0.146   | 0.147   | 0.210   |&nbsp;| 0.190 |\n",
    "| $$\\alpha = 0.75$$    |&nbsp;| 0.179   | 0.185   | 0.239   | 0.179   | 0.175   |&nbsp;| 0.191 |\n",
    "| $$\\alpha = 0.50$$    |&nbsp;| 0.204   | 0.100   | 0.238   | 0.158   | 0.139   |&nbsp;| 0.168 |\n",
    "| $$\\alpha = 0.25$$    |&nbsp;| 0.294   | 0.170   | 0.107   | 0.223   | 0.147   |&nbsp;| 0.188 |\n",
    "| $$\\alpha = 0.125$$   |&nbsp;| 0.187   | 0.254   | 0.177   | 0.163   | 0.204   |&nbsp;| 0.197 |  \n",
    "| $$\\alpha = 0.0625$$  |&nbsp;| 0.113   | 0.241   | 0.353   | 0.134   | 0.749   |&nbsp;| 0.318 |\n",
    "| $$\\alpha = 0.03125$$ |&nbsp;| 0.231   | 0.322   | 0.018   | 0.098   | 0.000   |&nbsp;| 0.134 |\n",
    "| $$\\alpha = 0.02344$$ |&nbsp;| 1.289   | 0.119   | 0.380   | 0.168   | 0.086   |&nbsp;| 0.408 |\n",
    "| $$\\alpha = \\mathbf{0.02148}$$ |&nbsp;| 0.498   | 0.813   | 0.286   | 7.130   | 0.281   |&nbsp;| **1.802** |\n",
    "| $$\\alpha = 0.01953$$ |&nbsp;| 0.234   | 0.113   | 0.445   | 0.119   | 1.637   |&nbsp;| 0.510 |\n",
    "| $$\\alpha = 0.01758$$ |&nbsp;| 0.175   | 0.249   | 0.217   | 0.047   | 1.006   |&nbsp;| 0.339 |\n",
    "| $$\\alpha = 0.01563$$ |&nbsp;| 0.281   | 1.371   | 0.066   | 0.037   | 0.751   |&nbsp;| 0.501 |\n",
    "| $$\\alpha = 0.00782$$ |&nbsp;| 0.133   | 0.241   | 0.149   | 0.493   | 0.146   |&nbsp;| 0.232 |\n",
    "| $$\\alpha = 0.00391$$ |&nbsp;| 0.037   | 0.626   | 1.000   | 0.525   | 0.139   |&nbsp;| 0.465 |\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "### $\\gamma$ Tuning\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "\n",
    "| Param                 |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "| :-------------------- |------| ------- | ------- | ------- | ------- | ------- |------| ----- |\n",
    "| $$\\gamma = 0.999$$    |&nbsp;| 0.925   | 0.247   | 0.145   | 0.364   | 3.038   |&nbsp;| 0.944 |\n",
    "| $$\\gamma = 0.99$$     |&nbsp;| 0.011   | 0.448   | 0.453   | 0.915   | 0.013   |&nbsp;| 0.368 |\n",
    "| $$\\gamma = 0.85$$     |&nbsp;| 0.314   | 2.778   | 0.275   | 1.183   | 0.079   |&nbsp;| 0.926 |\n",
    "| $$\\gamma = 0.80$$     |&nbsp;| 0.082   | 0.033   | 0.173   | 0.251   | 1.741   |&nbsp;| 0.456 |\n",
    "| $$\\gamma = 0.75$$     |&nbsp;| 0.283   | 0.239   | 2.223   | 0.264   | 0.753   |&nbsp;| 0.752 |\n",
    "| $$\\gamma = 0.50$$     |&nbsp;| 0.167   | 0.289   | 0.474   | 0.266   | 0.230   |&nbsp;| 0.285 |\n",
    "\n",
    " \n",
    "### Double-Q Tuning, Swap Evey N Episodes  \n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "Epochs = 32\n",
    "\n",
    "| Param                 |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|-----------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| $$\\%\\ \\ 2$$           |&nbsp;|  0.570  | 0.132   | 1.053   | 0.731   | 0.900   |&nbsp;| 0.677 |\n",
    "| $$\\%\\ \\ 4$$           |&nbsp;|  1.313  | 0.087   | 2.282   | 0.417   | 0.409   |&nbsp;| 0.901 |\n",
    "| $$\\%\\ \\ 8$$           |&nbsp;|  0.097  | 0.040   | 0.621   | 0.030   | 0.608   |&nbsp;| 0.279 |\n",
    "| $$\\%16$$              |&nbsp;|  0.260  | 0.219   | 0.054   | 0.407   | 0.845   |&nbsp;| 0.357 |\n",
    "| $$\\%32$$              |&nbsp;|  0.674  | 0.130   | 0.301   | 0.286   | 0.313   |&nbsp;| 0.341 |\n",
    "| $$\\%\\mathbf{64}$$     |&nbsp;| 15.261  | 2.072   | 0.380   | 0.056   | 0.727   |&nbsp;| **3.699** |\n",
    "  \n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "Episodes = 128  \n",
    "Epochs = 16  \n",
    "\n",
    "| Param            |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| $$\\%\\ \\ \\ \\ 4$$  |&nbsp;|  1.333  | 0.117   | 0.138   | 0.430   | 0.149   |&nbsp;| 0.433 |\n",
    "| $$\\%\\ \\ 64$$     |&nbsp;|  0.166  | 0.110   | 0.240   | 1.615   | 0.049   |&nbsp;| 0.436 |\n",
    "| $$\\%128$$        |&nbsp;|  2.700  | 0.228   | 0.222   | 0.183   | 0.002   |&nbsp;| 0.667 |\n",
    "\n",
    "  \n",
    "### Trace Tuning\n",
    "\n",
    "This is not a Sutton and Barto eligibility trace.  Instead, I look for $N_\\text{peak}$ peaks in the value history of the episode, and apply the learning rule in reverse order from the peak through $N_\\text{step}$ previous timesteps, with a $\\lambda$ decay each step. This is neither classical nor rigorous, and if it does not work, then I will switch to one of the classic $Q(\\lambda)$ methods found in Sutton and Barto.\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "$\\lambda = 0.95$  \n",
    "Peaks = 16  \n",
    "Episodes = 64  \n",
    "Swap = \\%64  \n",
    "Epochs = 32  \n",
    "\n",
    "\n",
    "| Param                  |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|------------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| Steps: &nbsp; &nbsp; 4 |&nbsp;| 0.418   | 0.098   | 0.231   | 0.080   | 0.571   |&nbsp;| 0.280 |\n",
    "| Steps: &nbsp; 16       |&nbsp;| 0.540   | 0.365   | 1.629   | 0.215   | 0.470   |&nbsp;| 0.644 |\n",
    "| Steps: &nbsp; 64       |&nbsp;| 1.197   | 0.410   | 1.187   | 1.017   | 0.975   |&nbsp;| 0.957 |\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "$\\lambda = 0.99$  \n",
    "Peaks = 32  \n",
    "Episodes = 64  \n",
    "Swap = \\%64  \n",
    "Epochs = 32  \n",
    "\n",
    "Variations\n",
    "* Only trace non-zero uptime episodes, Result: Many more zero score episodes and no improvement\n",
    "* Only trace episodes with above-average uptime, Result: Many more zero score episodes and no improvement\n",
    "* Re-run the episode until there is non-zero uptime, Result: Extremely slow and no improvement in average uptime  \n",
    "\n",
    "| Param                  |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|------------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| Steps: &nbsp; 64       |&nbsp;| 0.265   |  1.204  | 6.919   | 1.575   |  3.940  |&nbsp;| 2.781 |\n",
    "| Steps: &nbsp; 96       |&nbsp;| 0.212   | 12.012  | 0.213   | 0.195   | 13.896  |&nbsp;| 5.306 |\n",
    "| **Steps: 128**         |&nbsp;| 0.065   | 17.540  | 0.493   | 0.325   | 15.345  |&nbsp;| **6.754** |\n",
    "| Steps: 192             |&nbsp;| 0.271   |  0.127  | 0.220   | 0.299   |  0.600  |&nbsp;| 0.303 |\n",
    "| Steps: 256             |&nbsp;| 0.958   |  2.014  | 0.947   | 0.433   |  0.045  |&nbsp;| 0.879 |\n",
    "| Steps: 512             |&nbsp;| 1.487   |  0.343  | 0.159   | 1.057   |  0.640  |&nbsp;| 0.737 |  \n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "$\\lambda = 0.99$  \n",
    "Steps = 128  \n",
    "Episodes = 64  \n",
    "Swap = \\%64  \n",
    "Epochs = 32  \n",
    "\n",
    "| Param                  |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|------------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| Peaks: &nbsp; &nbsp; 2 |&nbsp;|  0.635  | 5.336   | 0.198   |  0.069  | 0.624   |&nbsp;|       |\n",
    "| Peaks: &nbsp; &nbsp; 4 |&nbsp;|  0.086  | 0.270   | 0.286   |  0.704  | 0.122   |&nbsp;|       |\n",
    "| Peaks: &nbsp; &nbsp; 8 |&nbsp;| 17.591  | 0.446   | 0.334   |  0.317  | 1.206   |&nbsp;| 3.979 |\n",
    "| Peaks: &nbsp; 16       |&nbsp;|  0.449  | 6.393   | 0.763   | 11.826  | 0.089   |&nbsp;|       |\n",
    "| Peaks: &nbsp; 64       |&nbsp;|  0.455  | 0.910   | 1.000   |  0.555  | 0.891   |&nbsp;|       |\n",
    "| Peaks: 128             |&nbsp;|  0.354  | 0.242   | 1.780   |  0.393  | 0.166   |&nbsp;|       |\n",
    "\n",
    "\n",
    "### Value Estimation Tuning\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "$\\lambda = 0.99$  \n",
    "Peaks =  32  \n",
    "Steps = 128 \n",
    "Episodes = 64  \n",
    "Swap = \\%64  \n",
    "Epochs = 32 \n",
    "\n",
    "| Param 1   | Param 2     |&nbsp;| Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |&nbsp;| Mean  |\n",
    "|-----------|-------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| Inputs: 2 | Outputs: 1  |      | 1.172   | 0.413   |  0.057  | 0.130   | 0.092   |      |       | \n",
    "| Inputs: 2 | Outputs: 2  |      | 1.327   | 0.258   | 12.772  | 0.361   | 0.321   |      |       |\n",
    "| Inputs: 3 | Outputs: 1  |      | 0.365   | 0.575   |  0.033  | 0.046   | 0.415   |      |       | \n",
    "| Inputs: 3 | Outputs: 2  |      | 0.279   | 1.335   |  0.438  | 1.413   | 0.121   |      |       | \n",
    "| Inputs: 3 | Outputs: 3  |      | 0.415   | 0.352   |  0.195  | 0.884   | 1.048   |      |       | \n",
    "| Inputs: 4 | Outputs: 2  |      | 0.083   | 1.845   |  0.437  | 0.418   | 3.486   |      |       | \n",
    "| Inputs: 4 | Outputs: 3  |      | 0.273   | 0.566   |  0.266  | 0.174   | 0.487   |      |       | \n",
    "| Inputs: 4 | Outputs: 4  |      | 0.620   | 0.145   |  1.528  | 0.418   | 0.130   |      |       | \n",
    "| Inputs: 5 | Outputs: 1  |      | 0.203   | 0.406   |  0.281  | 1.045   | 1.341   |      |       | \n",
    "\n",
    "### Learning Rate Decay\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "$\\lambda = 0.99$  \n",
    "Peaks =  32  \n",
    "Steps = 128  \n",
    "Episodes = 64  \n",
    "Swap = \\%64  \n",
    "Epochs = 32  \n",
    "Inputs = 4  \n",
    "Outputs = 1  \n",
    "\n",
    "| Param                  |&nbsp;| Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |&nbsp;| Mean  |\n",
    "|------------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| $$\\beta = 0.999$$      |      | 1.347   | 0.185   | 11.403  | 0.890   |  0.333  |      | 2.832 | \n",
    "| $$\\beta = 0.99\\ $$     |      | 0.482   | 0.089   |  1.839  | 8.804   |  0.144  |      | 2.272 | \n",
    "| $$\\beta = 0.95\\ $$     |      | 0.470   | 1.620   |  1.122  | 5.594   |  0.951  |      | 1.951 | \n",
    "| $$\\beta = 0.925 $$     |      | 0.143   | 4.728   |  2.583  | 0.170   | 17.117  |      | 4.948 | \n",
    "| $$\\beta = 0.913 $$     |      | 0.734   | 0.464   |  0.036  | 1.491   |  0.421  |      |       | \n",
    "| $$\\beta = 0.90\\ $$     |      | 0.500   | 4.234   |  5.158  | 1.656   |  5.795  |      | 3.469 | \n",
    "| $$\\beta = 0.85\\ $$     |      | 0.348   | 2.692   |  0.711  | 0.566   |  1.614  |      | 1.186 | \n",
    "| $$\\beta = 0.80\\ $$     |      | 4.467   | 4.096   |  2.152  | 0.767   |  0.328  |      | 2.362 | \n",
    "| $$\\beta = 0.75\\ $$     |      | 0.731   | 0.098   |  0.176  | 0.355   |  0.000  |      |       | \n",
    "| $$\\beta = 0.70\\ $$     |      | 0.313   | 0.916   |  1.234  | 0.378   |  0.820  |      |       | \n",
    "\n",
    "### `!!!` IMPLEMENTATION CHECK `!!!`\n",
    "\n",
    "#### Action Selection\n",
    "\n",
    "### Blend: Best Episode\n",
    "\n",
    "$\\beta = 0.07$:  \n",
    "$\\beta = 0.15$: 0.244\n",
    "\n",
    "| Method      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n",
    "| ----------- | ------- | ------- | ------- | ------- | ------- | ---- |\n",
    "| Blend (Epi) |         |         |         |         |         |      |\n",
    "| Blend (Epo) |         |         |         |         |         |      |\n",
    "| TD          |         |         |         |         |         |      |\n",
    "| TD  + ????? |         |         |         |         |         |      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Process(`\u001b[4mplay\u001b[24m \u001b[4m-nq\u001b[24m \u001b[4m-t\u001b[24m \u001b[4malsa\u001b[24m \u001b[4msynth\u001b[24m \u001b[4m3\u001b[24m \u001b[4msine\u001b[24m \u001b[4m300\u001b[24m`, ProcessExited(0))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(`play -nq -t alsa synth 3 sine 300`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b5ade7-5f94-43b1-837f-85ccdd6b5c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
