{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.02148 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 # 0.00782 # 0.00391\n",
    "gamma    = 1.00 \n",
    "swapDiv  = 128\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes = 128 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   =  16 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "beta   = 0.15\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = false\n",
    "N_peaks =  40\n",
    "N_steps = 200\n",
    "lambda  =   0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.17, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.12999999999999998, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.7300000000000004, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.6300000000000003, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.3300000000000001, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.46000000000000024, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.38000000000000017, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.5600000000000003, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.18000000000000002, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.8800000000000006, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.17, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.20000000000000004, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.16, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.1993750000000001\n",
      "\n",
      "Epoch 2, Best Score: 1.270000000000001\n",
      "Training Iteration 4 score: 0.6500000000000004, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.12999999999999998, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.10999999999999999, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.15, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.2700000000000001, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.21000000000000005, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.22000000000000006, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.3100000000000001, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.21000000000000005, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.36000000000000015, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.17, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.4000000000000002, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 1.300000000000001, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.34000000000000014, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.38000000000000017, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.20000000000000004, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.5800000000000003, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.8700000000000006, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.6600000000000004, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.3000000000000001, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 1.430000000000001, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.36000000000000015, epsilon: 0.00390625\n",
      "Average Score: 0.3837500000000001\n",
      "\n",
      "Epoch 3, Best Score: 1.6100000000000012\n",
      "Training Iteration 4 score: 0.4100000000000002, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.5700000000000003, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.5100000000000002, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.2700000000000001, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.6400000000000003, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.8500000000000005, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.10999999999999999, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 1.2100000000000009, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.4200000000000002, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.35000000000000014, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 1.1700000000000008, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.5100000000000002, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.9400000000000006, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 1.1500000000000008, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.7200000000000004, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 1.5800000000000012, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.09, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 1.1900000000000008, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.6700000000000004, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.20000000000000004, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.20000000000000004, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.08, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.5500000000000003, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 1.0600000000000007, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.9800000000000006, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 2.5599999999999894, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.3100000000000001, epsilon: 0.00390625\n",
      "Average Score: 0.426015625\n",
      "\n",
      "Epoch 4, Best Score: 3.2199999999999753\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.3300000000000001, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.45000000000000023, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.036406250000000015\n",
      "\n",
      "Epoch 5, Best Score: 3.2199999999999753\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.15, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.21000000000000005, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.23000000000000007, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.15, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.5200000000000002, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.11999999999999998, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.16, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.11999999999999998, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.09, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.7500000000000004, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.3100000000000001, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.15, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.13999999999999999, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.08, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.8800000000000006, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.16, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.25000000000000006, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.3200000000000001, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.10999999999999999, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.05, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.5200000000000002, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.7900000000000005, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.12999999999999998, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.3000000000000001, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.060000000000000005, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.9600000000000006, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.45000000000000023, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.3000000000000001, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 1.0700000000000007, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.22000000000000006, epsilon: 0.00390625\n",
      "Average Score: 0.40710937500000016\n",
      "\n",
      "Epoch 6, Best Score: 3.2199999999999753\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 7, Best Score: 3.2199999999999753\n",
      "Training Iteration 4 score: 0.18000000000000002, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.5400000000000003, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 1.0300000000000007, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.7600000000000005, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.6300000000000003, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.03, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.4300000000000002, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.22000000000000006, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.09, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.47000000000000025, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.3000000000000001, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.12999999999999998, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.7600000000000005, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.26000000000000006, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.47000000000000025, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.19000000000000003, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.47000000000000025, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.5000000000000002, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.08, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.45000000000000023, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.5600000000000003, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.4300000000000002, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.48000000000000026, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.6400000000000003, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.15, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.2900000000000001, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.8800000000000006, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.3100000000000001, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.2971875000000004\n",
      "\n",
      "Epoch 8, Best Score: 3.2199999999999753\n",
      "Training Iteration 4 score: 0.4100000000000002, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.2900000000000001, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.2700000000000001, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.49000000000000027, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.6900000000000004, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.19000000000000003, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.49000000000000027, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.5300000000000002, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.21000000000000005, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.4000000000000002, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.38000000000000017, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.34000000000000014, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.3900000000000002, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.11999999999999998, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.6400000000000003, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.5900000000000003, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.4200000000000002, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.2700000000000001, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.34000000000000014, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.7600000000000005, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.3200000000000001, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.26000000000000006, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.48000000000000026, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.49000000000000027, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.2900000000000001, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.36000000000000015, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.4400000000000002, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.8900000000000006, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.4400000000000002, epsilon: 0.00390625\n",
      "Average Score: 0.3454687500000001\n",
      "\n",
      "Epoch 9, Best Score: 3.2199999999999753\n",
      "Training Iteration 4 score: 0.18000000000000002, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.3000000000000001, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.36000000000000015, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.16, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.16, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.25000000000000006, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.5700000000000003, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.36000000000000015, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.5300000000000002, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.23000000000000007, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.5100000000000002, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.5300000000000002, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 2.299999999999995, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.6100000000000003, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.3100000000000001, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.35000000000000014, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.12999999999999998, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.09999999999999999, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.15, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.11999999999999998, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.15, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 4.719999999999944, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.3900000000000002, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 4.049999999999958, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 1.490000000000001, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 2.020000000000001, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.20000000000000004, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 1.1600000000000008, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.4300000000000002, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.08, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.25000000000000006, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.15, epsilon: 0.00390625\n",
      "Average Score: 0.5436718749999992\n",
      "\n",
      "Epoch 10, Best Score: 4.719999999999944\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.3300000000000001, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.7000000000000004, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.10999999999999999, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 15.879999999999706, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 20.380000000000386, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.6292187499999967\n",
      "\n",
      "Epoch 11, Best Score: 20.380000000000386\n",
      "Training Iteration 4 score: 1.460000000000001, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.9600000000000006, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 1.0100000000000007, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.2700000000000001, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.3900000000000002, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.48000000000000026, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.9500000000000006, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.9900000000000007, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 1.370000000000001, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.8900000000000006, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.45000000000000023, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.6300000000000003, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 1.1300000000000008, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 1.340000000000001, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 1.7400000000000013, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 1.2000000000000008, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.4300000000000002, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 1.350000000000001, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 1.370000000000001, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.6200000000000003, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 2.6099999999999883, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.7300000000000004, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 2.899999999999982, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.6000000000000003, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.8200000000000005, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 1.2200000000000009, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 5.779999999999921, epsilon: 0.00390625\n",
      "Average Score: 1.1471874999999951\n",
      "\n",
      "Epoch 12, Best Score: 20.380000000000386\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 1.400000000000001, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 7.899999999999876, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 8.819999999999856, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.48000000000000026, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 1.2100000000000009, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 20.01000000000033, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 23.6700000000009, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 23.310000000000844, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 29.380000000001793, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 27.550000000001507, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.38000000000000017, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 26.070000000001276, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 29.29000000000178, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 27.970000000001573, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 23.92000000000094, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 25.21000000000114, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 27.230000000001457, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 18.950000000000163, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 29.190000000001763, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 29.530000000001817, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 25.07000000000112, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 12.456015625000584\n",
      "\n",
      "Epoch 13, Best Score: 31.120000000002065\n",
      "Training Iteration 4 score: 0.2800000000000001, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.7500000000000004, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.48000000000000026, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.34000000000000014, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.5400000000000003, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.5100000000000002, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.49000000000000027, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.49000000000000027, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.09, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.2800000000000001, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.4200000000000002, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.23000000000000007, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.09999999999999999, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.22000000000000006, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.22000000000000006, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.4200000000000002, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.10999999999999999, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.4200000000000002, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.09, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.18000000000000002, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.7100000000000004, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.08, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.2800000000000001, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.4100000000000002, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.3200000000000001, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.4300000000000002, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.2900000000000001, epsilon: 0.00390625\n",
      "Average Score: 0.28789062499999996\n",
      "\n",
      "Epoch 14, Best Score: 31.120000000002065\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 15, Best Score: 31.120000000002065\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 16, Best Score: 31.120000000002065\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.0017968750000000005\n",
      "Saved a trained Q-table with size (76032,), After 25.41715316772461 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip820\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip820)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip821\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip820)\" d=\"\n",
       "M138.959 1486.45 L2352.76 1486.45 L2352.76 47.2441 L138.959 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip822\">\n",
       "    <rect x=\"138\" y=\"47\" width=\"2215\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip822)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  480.079,1486.45 480.079,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip822)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  897.776,1486.45 897.776,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip822)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1315.47,1486.45 1315.47,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip822)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1733.17,1486.45 1733.17,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip822)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2150.87,1486.45 2150.87,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip820)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  138.959,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip820)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  480.079,1486.45 480.079,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip820)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  897.776,1486.45 897.776,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip820)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1315.47,1486.45 1315.47,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip820)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1733.17,1486.45 1733.17,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip820)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2150.87,1486.45 2150.87,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip820)\" d=\"M484.327 1530.21 Q487.683 1530.93 489.558 1533.2 Q491.456 1535.47 491.456 1538.8 Q491.456 1543.92 487.938 1546.72 Q484.419 1549.52 477.938 1549.52 Q475.762 1549.52 473.447 1549.08 Q471.155 1548.66 468.702 1547.81 L468.702 1543.29 Q470.646 1544.43 472.961 1545.01 Q475.276 1545.58 477.799 1545.58 Q482.197 1545.58 484.489 1543.85 Q486.804 1542.11 486.804 1538.8 Q486.804 1535.75 484.651 1534.03 Q482.521 1532.3 478.702 1532.3 L474.674 1532.3 L474.674 1528.45 L478.887 1528.45 Q482.336 1528.45 484.165 1527.09 Q485.993 1525.7 485.993 1523.11 Q485.993 1520.45 484.095 1519.03 Q482.22 1517.6 478.702 1517.6 Q476.78 1517.6 474.581 1518.01 Q472.382 1518.43 469.743 1519.31 L469.743 1515.14 Q472.405 1514.4 474.72 1514.03 Q477.058 1513.66 479.118 1513.66 Q484.442 1513.66 487.544 1516.09 Q490.646 1518.5 490.646 1522.62 Q490.646 1525.49 489.003 1527.48 Q487.359 1529.45 484.327 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip820)\" d=\"M898.182 1529.7 Q895.033 1529.7 893.182 1531.86 Q891.353 1534.01 891.353 1537.76 Q891.353 1541.49 893.182 1543.66 Q895.033 1545.82 898.182 1545.82 Q901.33 1545.82 903.158 1543.66 Q905.01 1541.49 905.01 1537.76 Q905.01 1534.01 903.158 1531.86 Q901.33 1529.7 898.182 1529.7 M907.464 1515.05 L907.464 1519.31 Q905.705 1518.48 903.899 1518.04 Q902.117 1517.6 900.357 1517.6 Q895.728 1517.6 893.274 1520.72 Q890.844 1523.85 890.496 1530.17 Q891.862 1528.15 893.922 1527.09 Q895.982 1526 898.459 1526 Q903.668 1526 906.677 1529.17 Q909.709 1532.32 909.709 1537.76 Q909.709 1543.08 906.561 1546.3 Q903.413 1549.52 898.182 1549.52 Q892.186 1549.52 889.015 1544.94 Q885.844 1540.33 885.844 1531.6 Q885.844 1523.41 889.733 1518.55 Q893.621 1513.66 900.172 1513.66 Q901.932 1513.66 903.714 1514.01 Q905.519 1514.36 907.464 1515.05 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip820)\" d=\"M1305.77 1548.13 L1305.77 1543.87 Q1307.53 1544.7 1309.34 1545.14 Q1311.15 1545.58 1312.88 1545.58 Q1317.51 1545.58 1319.94 1542.48 Q1322.4 1539.36 1322.74 1533.01 Q1321.4 1535.01 1319.34 1536.07 Q1317.28 1537.13 1314.78 1537.13 Q1309.59 1537.13 1306.56 1534.01 Q1303.55 1530.86 1303.55 1525.42 Q1303.55 1520.1 1306.7 1516.88 Q1309.85 1513.66 1315.08 1513.66 Q1321.08 1513.66 1324.22 1518.27 Q1327.4 1522.85 1327.4 1531.6 Q1327.4 1539.77 1323.51 1544.66 Q1319.64 1549.52 1313.09 1549.52 Q1311.33 1549.52 1309.52 1549.17 Q1307.72 1548.82 1305.77 1548.13 M1315.08 1533.48 Q1318.23 1533.48 1320.06 1531.32 Q1321.91 1529.17 1321.91 1525.42 Q1321.91 1521.7 1320.06 1519.54 Q1318.23 1517.37 1315.08 1517.37 Q1311.93 1517.37 1310.08 1519.54 Q1308.25 1521.7 1308.25 1525.42 Q1308.25 1529.17 1310.08 1531.32 Q1311.93 1533.48 1315.08 1533.48 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip820)\" d=\"M1708.66 1544.91 L1716.3 1544.91 L1716.3 1518.55 L1707.99 1520.21 L1707.99 1515.95 L1716.25 1514.29 L1720.93 1514.29 L1720.93 1544.91 L1728.56 1544.91 L1728.56 1548.85 L1708.66 1548.85 L1708.66 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip820)\" d=\"M1742.04 1544.91 L1758.36 1544.91 L1758.36 1548.85 L1736.41 1548.85 L1736.41 1544.91 Q1739.07 1542.16 1743.66 1537.53 Q1748.26 1532.88 1749.44 1531.53 Q1751.69 1529.01 1752.57 1527.27 Q1753.47 1525.51 1753.47 1523.82 Q1753.47 1521.07 1751.53 1519.33 Q1749.61 1517.6 1746.5 1517.6 Q1744.31 1517.6 1741.85 1518.36 Q1739.42 1519.13 1736.64 1520.68 L1736.64 1515.95 Q1739.47 1514.82 1741.92 1514.24 Q1744.38 1513.66 1746.41 1513.66 Q1751.78 1513.66 1754.98 1516.35 Q1758.17 1519.03 1758.17 1523.52 Q1758.17 1525.65 1757.36 1527.57 Q1756.57 1529.47 1754.47 1532.07 Q1753.89 1532.74 1750.79 1535.95 Q1747.69 1539.15 1742.04 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip820)\" d=\"M2126.05 1544.91 L2133.69 1544.91 L2133.69 1518.55 L2125.38 1520.21 L2125.38 1515.95 L2133.65 1514.29 L2138.32 1514.29 L2138.32 1544.91 L2145.96 1544.91 L2145.96 1548.85 L2126.05 1548.85 L2126.05 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip820)\" d=\"M2155.45 1514.29 L2173.81 1514.29 L2173.81 1518.22 L2159.73 1518.22 L2159.73 1526.7 Q2160.75 1526.35 2161.77 1526.19 Q2162.79 1526 2163.81 1526 Q2169.6 1526 2172.98 1529.17 Q2176.35 1532.34 2176.35 1537.76 Q2176.35 1543.34 2172.88 1546.44 Q2169.41 1549.52 2163.09 1549.52 Q2160.92 1549.52 2158.65 1549.15 Q2156.4 1548.78 2153.99 1548.04 L2153.99 1543.34 Q2156.08 1544.47 2158.3 1545.03 Q2160.52 1545.58 2163 1545.58 Q2167 1545.58 2169.34 1543.48 Q2171.68 1541.37 2171.68 1537.76 Q2171.68 1534.15 2169.34 1532.04 Q2167 1529.94 2163 1529.94 Q2161.12 1529.94 2159.25 1530.35 Q2157.4 1530.77 2155.45 1531.65 L2155.45 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip822)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  138.959,1445.72 2352.76,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip822)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  138.959,1227.71 2352.76,1227.71 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip822)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  138.959,1009.7 2352.76,1009.7 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip822)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  138.959,791.699 2352.76,791.699 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip822)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  138.959,573.694 2352.76,573.694 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip822)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  138.959,355.689 2352.76,355.689 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip822)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  138.959,137.683 2352.76,137.683 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip820)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  138.959,1486.45 138.959,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip820)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  138.959,1445.72 157.857,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip820)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  138.959,1227.71 157.857,1227.71 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip820)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  138.959,1009.7 157.857,1009.7 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip820)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  138.959,791.699 157.857,791.699 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip820)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  138.959,573.694 157.857,573.694 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip820)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  138.959,355.689 157.857,355.689 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip820)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  138.959,137.683 157.857,137.683 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip820)\" d=\"M91.0151 1431.51 Q87.404 1431.51 85.5753 1435.08 Q83.7697 1438.62 83.7697 1445.75 Q83.7697 1452.86 85.5753 1456.42 Q87.404 1459.96 91.0151 1459.96 Q94.6493 1459.96 96.4548 1456.42 Q98.2835 1452.86 98.2835 1445.75 Q98.2835 1438.62 96.4548 1435.08 Q94.6493 1431.51 91.0151 1431.51 M91.0151 1427.81 Q96.8252 1427.81 99.8808 1432.42 Q102.959 1437 102.959 1445.75 Q102.959 1454.48 99.8808 1459.08 Q96.8252 1463.67 91.0151 1463.67 Q85.2049 1463.67 82.1262 1459.08 Q79.0707 1454.48 79.0707 1445.75 Q79.0707 1437 82.1262 1432.42 Q85.2049 1427.81 91.0151 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip820)\" d=\"M86.6401 1241.06 L102.959 1241.06 L102.959 1244.99 L81.0151 1244.99 L81.0151 1241.06 Q83.6771 1238.3 88.2604 1233.67 Q92.8669 1229.02 94.0475 1227.68 Q96.2928 1225.15 97.1724 1223.42 Q98.0752 1221.66 98.0752 1219.97 Q98.0752 1217.21 96.1308 1215.48 Q94.2095 1213.74 91.1077 1213.74 Q88.9086 1213.74 86.4549 1214.5 Q84.0244 1215.27 81.2466 1216.82 L81.2466 1212.1 Q84.0707 1210.96 86.5243 1210.38 Q88.978 1209.81 91.0151 1209.81 Q96.3854 1209.81 99.5798 1212.49 Q102.774 1215.18 102.774 1219.67 Q102.774 1221.8 101.964 1223.72 Q101.177 1225.62 99.0706 1228.21 Q98.4919 1228.88 95.39 1232.1 Q92.2882 1235.29 86.6401 1241.06 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip820)\" d=\"M93.3762 996.499 L81.5707 1014.95 L93.3762 1014.95 L93.3762 996.499 M92.1493 992.425 L98.0289 992.425 L98.0289 1014.95 L102.959 1014.95 L102.959 1018.84 L98.0289 1018.84 L98.0289 1026.98 L93.3762 1026.98 L93.3762 1018.84 L77.7744 1018.84 L77.7744 1014.32 L92.1493 992.425 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip820)\" d=\"M91.4317 789.836 Q88.2836 789.836 86.4318 791.989 Q84.6031 794.142 84.6031 797.892 Q84.6031 801.618 86.4318 803.794 Q88.2836 805.947 91.4317 805.947 Q94.5799 805.947 96.4085 803.794 Q98.2604 801.618 98.2604 797.892 Q98.2604 794.142 96.4085 791.989 Q94.5799 789.836 91.4317 789.836 M100.714 775.183 L100.714 779.443 Q98.9548 778.609 97.1493 778.169 Q95.3669 777.73 93.6076 777.73 Q88.978 777.73 86.5243 780.855 Q84.0938 783.98 83.7466 790.299 Q85.1123 788.285 87.1725 787.22 Q89.2327 786.132 91.7095 786.132 Q96.9178 786.132 99.927 789.304 Q102.959 792.452 102.959 797.892 Q102.959 803.216 99.8113 806.433 Q96.6632 809.651 91.4317 809.651 Q85.4364 809.651 82.2651 805.067 Q79.0938 800.461 79.0938 791.734 Q79.0938 783.54 82.9827 778.679 Q86.8716 773.794 93.4225 773.794 Q95.1817 773.794 96.9641 774.142 Q98.7696 774.489 100.714 775.183 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip820)\" d=\"M91.1077 574.562 Q87.7743 574.562 85.8531 576.344 Q83.9549 578.127 83.9549 581.252 Q83.9549 584.377 85.8531 586.159 Q87.7743 587.942 91.1077 587.942 Q94.441 587.942 96.3623 586.159 Q98.2835 584.354 98.2835 581.252 Q98.2835 578.127 96.3623 576.344 Q94.4641 574.562 91.1077 574.562 M86.4318 572.571 Q83.4225 571.831 81.7327 569.77 Q80.066 567.71 80.066 564.747 Q80.066 560.604 83.0058 558.196 Q85.9688 555.789 91.1077 555.789 Q96.2697 555.789 99.2095 558.196 Q102.149 560.604 102.149 564.747 Q102.149 567.71 100.459 569.77 Q98.7928 571.831 95.8067 572.571 Q99.1863 573.358 101.061 575.65 Q102.959 577.942 102.959 581.252 Q102.959 586.275 99.8808 588.96 Q96.8252 591.645 91.1077 591.645 Q85.3901 591.645 82.3114 588.96 Q79.2559 586.275 79.2559 581.252 Q79.2559 577.942 81.154 575.65 Q83.0521 573.358 86.4318 572.571 M84.7188 565.187 Q84.7188 567.872 86.3855 569.377 Q88.0753 570.882 91.1077 570.882 Q94.1169 570.882 95.8067 569.377 Q97.5197 567.872 97.5197 565.187 Q97.5197 562.502 95.8067 560.997 Q94.1169 559.493 91.1077 559.493 Q88.0753 559.493 86.3855 560.997 Q84.7188 562.502 84.7188 565.187 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip820)\" d=\"M51.6634 369.033 L59.3023 369.033 L59.3023 342.668 L50.9921 344.335 L50.9921 340.075 L59.256 338.409 L63.9319 338.409 L63.9319 369.033 L71.5707 369.033 L71.5707 372.969 L51.6634 372.969 L51.6634 369.033 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip820)\" d=\"M91.0151 341.487 Q87.404 341.487 85.5753 345.052 Q83.7697 348.594 83.7697 355.723 Q83.7697 362.83 85.5753 366.395 Q87.404 369.936 91.0151 369.936 Q94.6493 369.936 96.4548 366.395 Q98.2835 362.83 98.2835 355.723 Q98.2835 348.594 96.4548 345.052 Q94.6493 341.487 91.0151 341.487 M91.0151 337.784 Q96.8252 337.784 99.8808 342.39 Q102.959 346.973 102.959 355.723 Q102.959 364.45 99.8808 369.057 Q96.8252 373.64 91.0151 373.64 Q85.2049 373.64 82.1262 369.057 Q79.0707 364.45 79.0707 355.723 Q79.0707 346.973 82.1262 342.39 Q85.2049 337.784 91.0151 337.784 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip820)\" d=\"M53.2606 151.028 L60.8995 151.028 L60.8995 124.662 L52.5893 126.329 L52.5893 122.07 L60.8532 120.403 L65.5291 120.403 L65.5291 151.028 L73.1679 151.028 L73.1679 154.963 L53.2606 154.963 L53.2606 151.028 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip820)\" d=\"M86.6401 151.028 L102.959 151.028 L102.959 154.963 L81.0151 154.963 L81.0151 151.028 Q83.6771 148.273 88.2604 143.644 Q92.8669 138.991 94.0475 137.648 Q96.2928 135.125 97.1724 133.389 Q98.0752 131.63 98.0752 129.94 Q98.0752 127.186 96.1308 125.449 Q94.2095 123.713 91.1077 123.713 Q88.9086 123.713 86.4549 124.477 Q84.0244 125.241 81.2466 126.792 L81.2466 122.07 Q84.0707 120.936 86.5243 120.357 Q88.978 119.778 91.0151 119.778 Q96.3854 119.778 99.5798 122.463 Q102.774 125.149 102.774 129.639 Q102.774 131.769 101.964 133.69 Q101.177 135.588 99.0706 138.181 Q98.4919 138.852 95.39 142.07 Q92.2882 145.264 86.6401 151.028 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip822)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  201.614,1423.98 340.847,1403.89 480.079,1399.28 619.312,1441.75 758.544,1401.34 897.776,1445.72 1037.01,1413.32 1176.24,1408.06 1315.47,1386.45 1454.71,1377.13 \n",
       "  1593.94,1320.67 1733.17,87.9763 1872.4,1414.33 2011.64,1445.72 2150.87,1445.72 2290.1,1445.52 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip820)\" d=\"\n",
       "M2005.15 198.898 L2278.96 198.898 L2278.96 95.2176 L2005.15 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip820)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2005.15,198.898 2278.96,198.898 2278.96,95.2176 2005.15,95.2176 2005.15,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip820)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2029.75,147.058 2177.34,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip820)\" d=\"M2215.78 166.745 Q2213.97 171.375 2212.26 172.787 Q2210.55 174.199 2207.68 174.199 L2204.27 174.199 L2204.27 170.634 L2206.77 170.634 Q2208.53 170.634 2209.5 169.8 Q2210.48 168.967 2211.66 165.865 L2212.42 163.921 L2201.93 138.412 L2206.45 138.412 L2214.55 158.689 L2222.65 138.412 L2227.17 138.412 L2215.78 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip820)\" d=\"M2234.46 160.402 L2242.1 160.402 L2242.1 134.037 L2233.79 135.703 L2233.79 131.444 L2242.05 129.778 L2246.73 129.778 L2246.73 160.402 L2254.36 160.402 L2254.36 164.338 L2234.46 164.338 L2234.46 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/episodes\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        X  = X_0\n",
    "        \n",
    "        ##### Double Q-Learning ###########################################\n",
    "\n",
    "        for k = 1:T\n",
    "\n",
    "            # 1. Choose action\n",
    "            if rand() < epsilon\n",
    "                if rand() < EXPrand \n",
    "                    A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                else\n",
    "                    A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                end\n",
    "            else\n",
    "\n",
    "                A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                if A == 1000.0 # Indicates no values in this region\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "\n",
    "            # 2. Cache last state\n",
    "            qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "            # 3. Generate the next stae\n",
    "            Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "            # 4. Collect reward R( s, a, s' )\n",
    "            R_t = cartpole_reward( Xp )\n",
    "\n",
    "            # 5. Get the optimal action at the next state\n",
    "            a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "            # 6. Compute the value at the next state\n",
    "\n",
    "            V_tp1_opt = query_value_fuzzy( \n",
    "                Q_kdTree, G, V, \n",
    "                get_Q( \n",
    "                    select_X_vector( Xp ), \n",
    "                    a_tp1_opt \n",
    "                ); \n",
    "                k = vNN \n",
    "            )\n",
    "            if isnan( V_tp1_opt )\n",
    "                V_tp1_opt = 0.0\n",
    "            end\n",
    "\n",
    "\n",
    "            # 7. Blend the value back into nearest points\n",
    "\n",
    "            idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "            nNear      = size( idxs, 1 )\n",
    "            for i = 1:nNear\n",
    "                j    = idxs[i]\n",
    "                if !isnan( wgts[i] ) \n",
    "\n",
    "                    # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                    VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "                    \n",
    "                end\n",
    "            end\n",
    "\n",
    "            states[:,k] = Xp\n",
    "            actions[k]  = A\n",
    "\n",
    "            X = Xp\n",
    "        end\n",
    "\n",
    "        s_l    = vertical_score_s( states, aMargin, ts )\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        if useElig\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "            # println(\"SWAP\")\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709555b9-2598-4281-a634-c7b0681277d0",
   "metadata": {},
   "source": [
    "# Method 2 Performance, Average Vertical Duration [s]\n",
    "Each score is the best average score of the last two epochs: 32 epochs of 64 episodes each, Q-function swap after every episode \n",
    "\n",
    "### TD Tuning\n",
    "\n",
    "$\\gamma = 1.00$  \n",
    "\n",
    "| Param                |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|----------------------|------| ------- | ------- | ------- | ------- | ------- |------| ----- |\n",
    "| $$\\alpha = 0.99$$    |&nbsp;| 0.251   | 0.198   | 0.146   | 0.147   | 0.210   |&nbsp;| 0.190 |\n",
    "| $$\\alpha = 0.75$$    |&nbsp;| 0.179   | 0.185   | 0.239   | 0.179   | 0.175   |&nbsp;| 0.191 |\n",
    "| $$\\alpha = 0.50$$    |&nbsp;| 0.204   | 0.100   | 0.238   | 0.158   | 0.139   |&nbsp;| 0.168 |\n",
    "| $$\\alpha = 0.25$$    |&nbsp;| 0.294   | 0.170   | 0.107   | 0.223   | 0.147   |&nbsp;| 0.188 |\n",
    "| $$\\alpha = 0.125$$   |&nbsp;| 0.187   | 0.254   | 0.177   | 0.163   | 0.204   |&nbsp;| 0.197 |  \n",
    "| $$\\alpha = 0.0625$$  |&nbsp;| 0.113   | 0.241   | 0.353   | 0.134   | 0.749   |&nbsp;| 0.318 |\n",
    "| $$\\alpha = 0.03125$$ |&nbsp;| 0.231   | 0.322   | 0.018   | 0.098   | 0.000   |&nbsp;| 0.134 |\n",
    "| $$\\alpha = 0.02344$$ |&nbsp;| 1.289   | 0.119   | 0.380   | 0.168   | 0.086   |&nbsp;| 0.408 |\n",
    "| $$\\alpha = \\mathbf{0.02148}$$ |&nbsp;| 0.498   | 0.813   | 0.286   | 7.130   | 0.281   |&nbsp;| **1.802** |\n",
    "| $$\\alpha = 0.01953$$ |&nbsp;| 0.234   | 0.113   | 0.445   | 0.119   | 1.637   |&nbsp;| 0.510 |\n",
    "| $$\\alpha = 0.01758$$ |&nbsp;| 0.175   | 0.249   | 0.217   | 0.047   | 1.006   |&nbsp;| 0.339 |\n",
    "| $$\\alpha = 0.01563$$ |&nbsp;| 0.281   | 1.371   | 0.066   | 0.037   | 0.751   |&nbsp;| 0.501 |\n",
    "| $$\\alpha = 0.00782$$ |&nbsp;| 0.133   | 0.241   | 0.149   | 0.493   | 0.146   |&nbsp;| 0.232 |\n",
    "| $$\\alpha = 0.00391$$ |&nbsp;| 0.037   | 0.626   | 1.000   | 0.525   | 0.139   |&nbsp;| 0.465 |\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "### $\\gamma$ Tuning\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "\n",
    "| Param                 |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "| :-------------------- |------| ------- | ------- | ------- | ------- | ------- |------| ----- |\n",
    "| $$\\gamma = 0.999$$    |&nbsp;| 0.925   | 0.247   | 0.145   | 0.364   | 3.038   |&nbsp;| 0.944 |\n",
    "| $$\\gamma = 0.99$$     |&nbsp;| 0.011   | 0.448   | 0.453   | 0.915   | 0.013   |&nbsp;| 0.368 |\n",
    "| $$\\gamma = 0.85$$     |&nbsp;| 0.314   | 2.778   | 0.275   | 1.183   | 0.079   |&nbsp;| 0.926 |\n",
    "| $$\\gamma = 0.80$$     |&nbsp;| 0.082   | 0.033   | 0.173   | 0.251   | 1.741   |&nbsp;| 0.456 |\n",
    "| $$\\gamma = 0.75$$     |&nbsp;| 0.283   | 0.239   | 2.223   | 0.264   | 0.753   |&nbsp;| 0.752 |\n",
    "| $$\\gamma = 0.50$$     |&nbsp;| 0.167   | 0.289   | 0.474   | 0.266   | 0.230   |&nbsp;| 0.285 |\n",
    "\n",
    " \n",
    "### Double-Q Tuning, Swap Evey N Episodes\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "Epochs = 32\n",
    "\n",
    "| Param                 |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|-----------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| $$\\%\\ \\ 2$$           |&nbsp;|  0.570  | 0.132   | 1.053   | 0.731   | 0.900   |&nbsp;| 0.677 |\n",
    "| $$\\%\\ \\ 4$$           |&nbsp;|  1.313  | 0.087   | 2.282   | 0.417   | 0.409   |&nbsp;| 0.901 |\n",
    "| $$\\%\\ \\ 8$$           |&nbsp;|  0.097  | 0.040   | 0.621   | 0.030   | 0.608   |&nbsp;| 0.279 |\n",
    "| $$\\%16$$              |&nbsp;|  0.260  | 0.219   | 0.054   | 0.407   | 0.845   |&nbsp;| 0.357 |\n",
    "| $$\\%32$$              |&nbsp;|  0.674  | 0.130   | 0.301   | 0.286   | 0.313   |&nbsp;| 0.341 |\n",
    "| $$\\%\\mathbf{64}$$     |&nbsp;| 15.261  | 2.072   | 0.380   | 0.056   | 0.727   |&nbsp;| **3.699** |\n",
    "  \n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "Episodes = 128  \n",
    "Epochs = 16  \n",
    "\n",
    "| Param            |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| $$\\%\\ \\ \\ \\ 4$$  |&nbsp;|  1.333  | 0.117   | 0.138   | 0.430   | 0.149   |&nbsp;| 0.433 |\n",
    "| $$\\%\\ \\ 64$$     |&nbsp;|  0.166  | 0.110   | 0.240   | 1.615   | 0.049   |&nbsp;| 0.436 |\n",
    "| $$\\%128$$        |&nbsp;|  2.700  | 0.228   | 0.222   | 0.183   | 0.002   |&nbsp;| 0.667 |\n",
    "\n",
    "  \n",
    "### Trace Tuning\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "$\\lambda = 0.95$  \n",
    "Episodes = 64  \n",
    "Swap = \\%64  \n",
    "Epochs = 32  \n",
    "\n",
    "\n",
    "| Param           |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|-----------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| Steps: &nbsp; 4 |      |         |         |         |         |         |      |       |\n",
    "| Steps: 16       |      |         |         |         |         |         |      |       |\n",
    "| Steps: 64       |      |         |         |         |         |         |      |       |\n",
    "\n",
    "\n",
    "### Blend: Best Episode\n",
    "\n",
    "$\\beta = 0.07$:  \n",
    "$\\beta = 0.15$: 0.244\n",
    "\n",
    "| Method      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n",
    "| ----------- | ------- | ------- | ------- | ------- | ------- | ---- |\n",
    "| Blend (Epi) |         |         |         |         |         |      |\n",
    "| Blend (Epo) |         |         |         |         |         |      |\n",
    "| TD          |         |         |         |         |         |      |\n",
    "| TD  + ????? |         |         |         |         |         |      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Process(`\u001b[4mplay\u001b[24m \u001b[4m-nq\u001b[24m \u001b[4m-t\u001b[24m \u001b[4malsa\u001b[24m \u001b[4msynth\u001b[24m \u001b[4m3\u001b[24m \u001b[4msine\u001b[24m \u001b[4m300\u001b[24m`, ProcessExited(0))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(`play -nq -t alsa synth 3 sine 300`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b5ade7-5f94-43b1-837f-85ccdd6b5c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
