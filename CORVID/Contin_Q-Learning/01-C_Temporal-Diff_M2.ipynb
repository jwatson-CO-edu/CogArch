{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.02148 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 # 0.00782 # 0.00391\n",
    "beta     = 0.95\n",
    "gamma    = 1.00 \n",
    "swapDiv  = 64\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes = 64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   = 32 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = true\n",
    "N_peaks =  32\n",
    "N_steps = 128\n",
    "lambda  =   0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.17, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.18000000000000002, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.3100000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.21000000000000005, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.13999999999999999, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.4000000000000002, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.2900000000000001, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.19000000000000003, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.17, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.21734375000000017\n",
      "\n",
      "Epoch 2, Best Score: 1.300000000000001\n",
      "Training Iteration 4 score: 1.1400000000000008, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.21000000000000005, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.5100000000000002, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.15, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.3100000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.09999999999999999, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.2900000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.3100000000000001, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.5800000000000003, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.3200000000000001, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.8600000000000005, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.34000000000000014, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.18000000000000002, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.3178124999999999\n",
      "\n",
      "Epoch 3, Best Score: 3.1299999999999772\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 4, Best Score: 3.1299999999999772\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.09, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.3900000000000002, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.35000000000000014, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.7600000000000005, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.1850000000000001\n",
      "\n",
      "Epoch 5, Best Score: 3.1299999999999772\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 6, Best Score: 3.1299999999999772\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.2800000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.20000000000000004, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.03609375000000001\n",
      "\n",
      "Epoch 7, Best Score: 3.1299999999999772\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.24000000000000007, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.010156250000000002\n",
      "\n",
      "Epoch 8, Best Score: 3.1299999999999772\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.3100000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.49000000000000027, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.5800000000000003, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 1.260000000000001, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.12421875000000006\n",
      "\n",
      "Epoch 9, Best Score: 3.1299999999999772\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 10, Best Score: 3.1299999999999772\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.6300000000000003, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.12109374999999961\n",
      "\n",
      "Epoch 11, Best Score: 3.4099999999999713\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 12, Best Score: 3.4099999999999713\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.3300000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 12.84999999999977, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 19.240000000000208, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 20.100000000000342, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 2.4999999999999907, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 19.32000000000022, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.22000000000000006, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 26.92000000000141, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 25.160000000001133, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 22.71000000000075, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 25.830000000001238, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 14.839999999999728, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 28.830000000001707, epsilon: 8.881784197001252e-16\n",
      "Average Score: 13.914375000000504\n",
      "\n",
      "Epoch 13, Best Score: 33.22000000000196\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.17, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.3000000000000001, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.5200000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.04468750000000002\n",
      "\n",
      "Epoch 14, Best Score: 33.22000000000196\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.9300000000000006, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.7700000000000005, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.37000000000000016, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 5.219999999999933, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.6400000000000003, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.3200000000000001, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.34000000000000014, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.26000000000000006, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.3300000000000001, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 7.349999999999888, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.25000000000000006, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.9100000000000006, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.5800000000000003, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.2800000000000001, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.774374999999993\n",
      "\n",
      "Epoch 15, Best Score: 33.22000000000196\n",
      "Training Iteration 4 score: 0.37000000000000016, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 1.0800000000000007, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.17328125\n",
      "\n",
      "Epoch 16, Best Score: 33.22000000000196\n",
      "Training Iteration 4 score: 0.25000000000000006, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.18000000000000002, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.17, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 2.0799999999999996, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.3200000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.26000000000000006, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.3300000000000001, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.18000000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.7300000000000004, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 3.989999999999959, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.21000000000000005, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.7400000000000004, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.24000000000000007, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.25000000000000006, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.20000000000000004, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 1.4434375000000195\n",
      "\n",
      "Epoch 17, Best Score: 33.22000000000196\n",
      "Training Iteration 4 score: 0.49000000000000027, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.11999999999999998, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.9600000000000006, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.3000000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.2900000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.8300000000000005, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.25000000000000006, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.5200000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.7700000000000005, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 1.2400000000000009, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 1.400000000000001, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 1.390000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 2.0500000000000003, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.7381249999999991\n",
      "\n",
      "Epoch 18, Best Score: 33.22000000000196\n",
      "Training Iteration 4 score: 0.26000000000000006, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.3300000000000001, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.05203125000000002\n",
      "\n",
      "Epoch 19, Best Score: 33.22000000000196\n",
      "Training Iteration 4 score: 0.26000000000000006, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.3100000000000001, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.45000000000000023, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.22000000000000006, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.05, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.20000000000000004, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.26000000000000006, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.6000000000000003, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.24000000000000007, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.10999999999999999, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.09999999999999999, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.16, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.2300000000000001\n",
      "\n",
      "Epoch 20, Best Score: 33.22000000000196\n",
      "Training Iteration 4 score: 1.7500000000000013, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.13999999999999999, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 1.460000000000001, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.5300000000000002, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.13999999999999999, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.9600000000000006, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 1.0300000000000007, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.330000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 1.490000000000001, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.9500000000000006, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 1.7300000000000013, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.16, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 1.2400000000000009, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 1.7900000000000014, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 2.07, epsilon: 8.881784197001252e-16\n",
      "Average Score: 1.1907812499999961\n",
      "\n",
      "Epoch 21, Best Score: 33.22000000000196\n",
      "Training Iteration 4 score: 0.5900000000000003, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.6500000000000004, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.48000000000000026, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.026875000000000013\n",
      "\n",
      "Epoch 22, Best Score: 33.22000000000196\n",
      "Training Iteration 4 score: 1.0200000000000007, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.35000000000000014, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.20000000000000004, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.21000000000000005, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.6800000000000004, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.9800000000000006, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.19000000000000003, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.8600000000000005, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.6000000000000003, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.17, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.25000000000000006, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.5400000000000003, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.15, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.16, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.16, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.8268749999999998\n",
      "\n",
      "Epoch 23, Best Score: 33.22000000000196\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.11999999999999998, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.19000000000000003, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.2700000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.19000000000000003, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.15, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.2700000000000001, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.3200000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.3100000000000001, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.3100000000000001, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.23000000000000007, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.2800000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.9600000000000006, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.24000000000000007, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.2703125000000001\n",
      "\n",
      "Epoch 24, Best Score: 33.22000000000196\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.5900000000000003, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 2.5099999999999905, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.09, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.6400000000000003, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 1.1400000000000008, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 3.139999999999977, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 3.329999999999973, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 6.159999999999913, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.7804687499999974\n",
      "\n",
      "Epoch 25, Best Score: 33.22000000000196\n",
      "Training Iteration 4 score: 0.5500000000000003, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.34000000000000014, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.23000000000000007, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.22000000000000006, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.7200000000000004, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.48000000000000026, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.6600000000000004, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.46000000000000024, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.46000000000000024, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.20765625000000013\n",
      "\n",
      "Epoch 26, Best Score: 33.22000000000196\n",
      "Training Iteration 4 score: 0.5300000000000002, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.3200000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.18000000000000002, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.7200000000000004, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.09203125000000006\n",
      "\n",
      "Epoch 27, Best Score: 33.22000000000196\n",
      "Training Iteration 4 score: 0.38000000000000017, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 1.0600000000000007, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.4300000000000002, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.8700000000000006, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.2700000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.2900000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.16, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.46000000000000024, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.37000000000000016, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.2700000000000001, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.46000000000000024, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.36218750000000005\n",
      "\n",
      "Epoch 28, Best Score: 33.22000000000196\n",
      "Training Iteration 4 score: 0.37000000000000016, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.07, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.5300000000000002, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.9900000000000007, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.5000000000000002, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 1.5800000000000012, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.26000000000000006, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.7900000000000005, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.38000000000000017, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.37703125000000015\n",
      "\n",
      "Epoch 29, Best Score: 33.22000000000196\n",
      "Training Iteration 4 score: 0.3900000000000002, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.8200000000000005, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.20000000000000004, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.36000000000000015, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.36000000000000015, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 1.330000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.36000000000000015, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.3200000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.5700000000000003, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 1.1300000000000008, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.21000000000000005, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.31593750000000026\n",
      "\n",
      "Epoch 30, Best Score: 33.22000000000196\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.34000000000000014, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.5400000000000003, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.3300000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.36000000000000015, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.3300000000000001, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.5300000000000002, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.6700000000000004, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.11468750000000005\n",
      "\n",
      "Epoch 31, Best Score: 33.22000000000196\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.9300000000000006, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.8100000000000005, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.3200000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.9400000000000006, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.8500000000000005, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.24000000000000007, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.10999999999999999, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.6600000000000004, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.20312500000000006\n",
      "\n",
      "Epoch 32, Best Score: 33.22000000000196\n",
      "Training Iteration 4 score: 0.9400000000000006, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.8800000000000006, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.4000000000000002, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.4300000000000002, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.9700000000000006, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.9600000000000006, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 1.122031250000014\n",
      "Saved a trained Q-table with size (76032,), After 13.834672133127848 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip050\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip050)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip051\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip050)\" d=\"\n",
       "M184.191 1486.45 L2352.76 1486.45 L2352.76 47.2441 L184.191 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip052\">\n",
       "    <rect x=\"184\" y=\"47\" width=\"2170\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip052)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  509.541,1486.45 509.541,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip052)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  839.512,1486.45 839.512,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip052)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1169.48,1486.45 1169.48,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip052)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1499.45,1486.45 1499.45,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip052)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1829.42,1486.45 1829.42,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip052)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2159.39,1486.45 2159.39,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  509.541,1486.45 509.541,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  839.512,1486.45 839.512,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1169.48,1486.45 1169.48,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1499.45,1486.45 1499.45,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1829.42,1486.45 1829.42,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2159.39,1486.45 2159.39,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip050)\" d=\"M499.819 1514.29 L518.176 1514.29 L518.176 1518.22 L504.102 1518.22 L504.102 1526.7 Q505.12 1526.35 506.139 1526.19 Q507.157 1526 508.176 1526 Q513.963 1526 517.342 1529.17 Q520.722 1532.34 520.722 1537.76 Q520.722 1543.34 517.25 1546.44 Q513.778 1549.52 507.458 1549.52 Q505.282 1549.52 503.014 1549.15 Q500.768 1548.78 498.361 1548.04 L498.361 1543.34 Q500.444 1544.47 502.666 1545.03 Q504.889 1545.58 507.366 1545.58 Q511.37 1545.58 513.708 1543.48 Q516.046 1541.37 516.046 1537.76 Q516.046 1534.15 513.708 1532.04 Q511.37 1529.94 507.366 1529.94 Q505.491 1529.94 503.616 1530.35 Q501.764 1530.77 499.819 1531.65 L499.819 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M814.199 1544.91 L821.838 1544.91 L821.838 1518.55 L813.528 1520.21 L813.528 1515.95 L821.792 1514.29 L826.468 1514.29 L826.468 1544.91 L834.107 1544.91 L834.107 1548.85 L814.199 1548.85 L814.199 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M853.551 1517.37 Q849.94 1517.37 848.111 1520.93 Q846.306 1524.47 846.306 1531.6 Q846.306 1538.71 848.111 1542.27 Q849.94 1545.82 853.551 1545.82 Q857.185 1545.82 858.991 1542.27 Q860.82 1538.71 860.82 1531.6 Q860.82 1524.47 858.991 1520.93 Q857.185 1517.37 853.551 1517.37 M853.551 1513.66 Q859.361 1513.66 862.417 1518.27 Q865.495 1522.85 865.495 1531.6 Q865.495 1540.33 862.417 1544.94 Q859.361 1549.52 853.551 1549.52 Q847.741 1549.52 844.662 1544.94 Q841.607 1540.33 841.607 1531.6 Q841.607 1522.85 844.662 1518.27 Q847.741 1513.66 853.551 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M1144.67 1544.91 L1152.31 1544.91 L1152.31 1518.55 L1144 1520.21 L1144 1515.95 L1152.26 1514.29 L1156.94 1514.29 L1156.94 1544.91 L1164.57 1544.91 L1164.57 1548.85 L1144.67 1548.85 L1144.67 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M1174.07 1514.29 L1192.42 1514.29 L1192.42 1518.22 L1178.35 1518.22 L1178.35 1526.7 Q1179.37 1526.35 1180.38 1526.19 Q1181.4 1526 1182.42 1526 Q1188.21 1526 1191.59 1529.17 Q1194.97 1532.34 1194.97 1537.76 Q1194.97 1543.34 1191.5 1546.44 Q1188.02 1549.52 1181.7 1549.52 Q1179.53 1549.52 1177.26 1549.15 Q1175.01 1548.78 1172.61 1548.04 L1172.61 1543.34 Q1174.69 1544.47 1176.91 1545.03 Q1179.13 1545.58 1181.61 1545.58 Q1185.62 1545.58 1187.95 1543.48 Q1190.29 1541.37 1190.29 1537.76 Q1190.29 1534.15 1187.95 1532.04 Q1185.62 1529.94 1181.61 1529.94 Q1179.74 1529.94 1177.86 1530.35 Q1176.01 1530.77 1174.07 1531.65 L1174.07 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M1478.23 1544.91 L1494.55 1544.91 L1494.55 1548.85 L1472.6 1548.85 L1472.6 1544.91 Q1475.26 1542.16 1479.85 1537.53 Q1484.45 1532.88 1485.63 1531.53 Q1487.88 1529.01 1488.76 1527.27 Q1489.66 1525.51 1489.66 1523.82 Q1489.66 1521.07 1487.72 1519.33 Q1485.8 1517.6 1482.69 1517.6 Q1480.49 1517.6 1478.04 1518.36 Q1475.61 1519.13 1472.83 1520.68 L1472.83 1515.95 Q1475.66 1514.82 1478.11 1514.24 Q1480.56 1513.66 1482.6 1513.66 Q1487.97 1513.66 1491.17 1516.35 Q1494.36 1519.03 1494.36 1523.52 Q1494.36 1525.65 1493.55 1527.57 Q1492.76 1529.47 1490.66 1532.07 Q1490.08 1532.74 1486.98 1535.95 Q1483.87 1539.15 1478.23 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M1514.36 1517.37 Q1510.75 1517.37 1508.92 1520.93 Q1507.11 1524.47 1507.11 1531.6 Q1507.11 1538.71 1508.92 1542.27 Q1510.75 1545.82 1514.36 1545.82 Q1517.99 1545.82 1519.8 1542.27 Q1521.63 1538.71 1521.63 1531.6 Q1521.63 1524.47 1519.8 1520.93 Q1517.99 1517.37 1514.36 1517.37 M1514.36 1513.66 Q1520.17 1513.66 1523.23 1518.27 Q1526.3 1522.85 1526.3 1531.6 Q1526.3 1540.33 1523.23 1544.94 Q1520.17 1549.52 1514.36 1549.52 Q1508.55 1549.52 1505.47 1544.94 Q1502.42 1540.33 1502.42 1531.6 Q1502.42 1522.85 1505.47 1518.27 Q1508.55 1513.66 1514.36 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M1808.69 1544.91 L1825.01 1544.91 L1825.01 1548.85 L1803.07 1548.85 L1803.07 1544.91 Q1805.73 1542.16 1810.31 1537.53 Q1814.92 1532.88 1816.1 1531.53 Q1818.35 1529.01 1819.23 1527.27 Q1820.13 1525.51 1820.13 1523.82 Q1820.13 1521.07 1818.18 1519.33 Q1816.26 1517.6 1813.16 1517.6 Q1810.96 1517.6 1808.51 1518.36 Q1806.08 1519.13 1803.3 1520.68 L1803.3 1515.95 Q1806.12 1514.82 1808.58 1514.24 Q1811.03 1513.66 1813.07 1513.66 Q1818.44 1513.66 1821.63 1516.35 Q1824.83 1519.03 1824.83 1523.52 Q1824.83 1525.65 1824.02 1527.57 Q1823.23 1529.47 1821.12 1532.07 Q1820.55 1532.74 1817.44 1535.95 Q1814.34 1539.15 1808.69 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M1834.87 1514.29 L1853.23 1514.29 L1853.23 1518.22 L1839.16 1518.22 L1839.16 1526.7 Q1840.18 1526.35 1841.19 1526.19 Q1842.21 1526 1843.23 1526 Q1849.02 1526 1852.4 1529.17 Q1855.78 1532.34 1855.78 1537.76 Q1855.78 1543.34 1852.3 1546.44 Q1848.83 1549.52 1842.51 1549.52 Q1840.34 1549.52 1838.07 1549.15 Q1835.82 1548.78 1833.42 1548.04 L1833.42 1543.34 Q1835.5 1544.47 1837.72 1545.03 Q1839.94 1545.58 1842.42 1545.58 Q1846.43 1545.58 1848.76 1543.48 Q1851.1 1541.37 1851.1 1537.76 Q1851.1 1534.15 1848.76 1532.04 Q1846.43 1529.94 1842.42 1529.94 Q1840.55 1529.94 1838.67 1530.35 Q1836.82 1530.77 1834.87 1531.65 L1834.87 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M2148.24 1530.21 Q2151.59 1530.93 2153.47 1533.2 Q2155.37 1535.47 2155.37 1538.8 Q2155.37 1543.92 2151.85 1546.72 Q2148.33 1549.52 2141.85 1549.52 Q2139.67 1549.52 2137.36 1549.08 Q2135.06 1548.66 2132.61 1547.81 L2132.61 1543.29 Q2134.56 1544.43 2136.87 1545.01 Q2139.19 1545.58 2141.71 1545.58 Q2146.11 1545.58 2148.4 1543.85 Q2150.71 1542.11 2150.71 1538.8 Q2150.71 1535.75 2148.56 1534.03 Q2146.43 1532.3 2142.61 1532.3 L2138.58 1532.3 L2138.58 1528.45 L2142.8 1528.45 Q2146.25 1528.45 2148.07 1527.09 Q2149.9 1525.7 2149.9 1523.11 Q2149.9 1520.45 2148 1519.03 Q2146.13 1517.6 2142.61 1517.6 Q2140.69 1517.6 2138.49 1518.01 Q2136.29 1518.43 2133.65 1519.31 L2133.65 1515.14 Q2136.31 1514.4 2138.63 1514.03 Q2140.97 1513.66 2143.03 1513.66 Q2148.35 1513.66 2151.45 1516.09 Q2154.56 1518.5 2154.56 1522.62 Q2154.56 1525.49 2152.91 1527.48 Q2151.27 1529.45 2148.24 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M2174.23 1517.37 Q2170.62 1517.37 2168.79 1520.93 Q2166.99 1524.47 2166.99 1531.6 Q2166.99 1538.71 2168.79 1542.27 Q2170.62 1545.82 2174.23 1545.82 Q2177.87 1545.82 2179.67 1542.27 Q2181.5 1538.71 2181.5 1531.6 Q2181.5 1524.47 2179.67 1520.93 Q2177.87 1517.37 2174.23 1517.37 M2174.23 1513.66 Q2180.04 1513.66 2183.1 1518.27 Q2186.18 1522.85 2186.18 1531.6 Q2186.18 1540.33 2183.1 1544.94 Q2180.04 1549.52 2174.23 1549.52 Q2168.42 1549.52 2165.34 1544.94 Q2162.29 1540.33 2162.29 1531.6 Q2162.29 1522.85 2165.34 1518.27 Q2168.42 1513.66 2174.23 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip052)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,1445.72 2352.76,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip052)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,1201.77 2352.76,1201.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip052)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,957.825 2352.76,957.825 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip052)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,713.879 2352.76,713.879 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip052)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,469.934 2352.76,469.934 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip052)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,225.988 2352.76,225.988 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,1486.45 184.191,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,1445.72 203.088,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,1201.77 203.088,1201.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,957.825 203.088,957.825 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,713.879 203.088,713.879 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,469.934 203.088,469.934 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,225.988 203.088,225.988 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip050)\" d=\"M91.0151 1431.51 Q87.404 1431.51 85.5753 1435.08 Q83.7697 1438.62 83.7697 1445.75 Q83.7697 1452.86 85.5753 1456.42 Q87.404 1459.96 91.0151 1459.96 Q94.6493 1459.96 96.4548 1456.42 Q98.2835 1452.86 98.2835 1445.75 Q98.2835 1438.62 96.4548 1435.08 Q94.6493 1431.51 91.0151 1431.51 M91.0151 1427.81 Q96.8252 1427.81 99.8808 1432.42 Q102.959 1437 102.959 1445.75 Q102.959 1454.48 99.8808 1459.08 Q96.8252 1463.67 91.0151 1463.67 Q85.2049 1463.67 82.1262 1459.08 Q79.0707 1454.48 79.0707 1445.75 Q79.0707 1437 82.1262 1432.42 Q85.2049 1427.81 91.0151 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M111.177 1457.12 L116.061 1457.12 L116.061 1463 L111.177 1463 L111.177 1457.12 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M136.246 1431.51 Q132.635 1431.51 130.807 1435.08 Q129.001 1438.62 129.001 1445.75 Q129.001 1452.86 130.807 1456.42 Q132.635 1459.96 136.246 1459.96 Q139.881 1459.96 141.686 1456.42 Q143.515 1452.86 143.515 1445.75 Q143.515 1438.62 141.686 1435.08 Q139.881 1431.51 136.246 1431.51 M136.246 1427.81 Q142.056 1427.81 145.112 1432.42 Q148.191 1437 148.191 1445.75 Q148.191 1454.48 145.112 1459.08 Q142.056 1463.67 136.246 1463.67 Q130.436 1463.67 127.357 1459.08 Q124.302 1454.48 124.302 1445.75 Q124.302 1437 127.357 1432.42 Q130.436 1427.81 136.246 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M86.0382 1215.12 L102.358 1215.12 L102.358 1219.05 L80.4133 1219.05 L80.4133 1215.12 Q83.0753 1212.36 87.6586 1207.73 Q92.2651 1203.08 93.4456 1201.74 Q95.691 1199.21 96.5706 1197.48 Q97.4734 1195.72 97.4734 1194.03 Q97.4734 1191.27 95.5289 1189.54 Q93.6076 1187.8 90.5058 1187.8 Q88.3067 1187.8 85.8531 1188.56 Q83.4225 1189.33 80.6447 1190.88 L80.6447 1186.16 Q83.4688 1185.02 85.9225 1184.44 Q88.3762 1183.87 90.4132 1183.87 Q95.7836 1183.87 98.978 1186.55 Q102.172 1189.24 102.172 1193.73 Q102.172 1195.86 101.362 1197.78 Q100.575 1199.68 98.4687 1202.27 Q97.89 1202.94 94.7882 1206.16 Q91.6864 1209.35 86.0382 1215.12 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M112.172 1213.17 L117.057 1213.17 L117.057 1219.05 L112.172 1219.05 L112.172 1213.17 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M127.288 1184.49 L145.644 1184.49 L145.644 1188.43 L131.57 1188.43 L131.57 1196.9 Q132.589 1196.55 133.607 1196.39 Q134.626 1196.2 135.644 1196.2 Q141.431 1196.2 144.811 1199.37 Q148.191 1202.55 148.191 1207.96 Q148.191 1213.54 144.718 1216.64 Q141.246 1219.72 134.927 1219.72 Q132.751 1219.72 130.482 1219.35 Q128.237 1218.98 125.83 1218.24 L125.83 1213.54 Q127.913 1214.68 130.135 1215.23 Q132.357 1215.79 134.834 1215.79 Q138.839 1215.79 141.177 1213.68 Q143.515 1211.57 143.515 1207.96 Q143.515 1204.35 141.177 1202.24 Q138.839 1200.14 134.834 1200.14 Q132.959 1200.14 131.084 1200.55 Q129.232 1200.97 127.288 1201.85 L127.288 1184.49 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M81.0614 940.545 L99.4178 940.545 L99.4178 944.48 L85.3438 944.48 L85.3438 952.952 Q86.3623 952.605 87.3808 952.443 Q88.3993 952.258 89.4178 952.258 Q95.2049 952.258 98.5845 955.429 Q101.964 958.6 101.964 964.017 Q101.964 969.596 98.4919 972.697 Q95.0197 975.776 88.7003 975.776 Q86.5243 975.776 84.2558 975.406 Q82.0105 975.035 79.6031 974.295 L79.6031 969.596 Q81.6864 970.73 83.9086 971.285 Q86.1308 971.841 88.6077 971.841 Q92.6123 971.841 94.9502 969.734 Q97.2882 967.628 97.2882 964.017 Q97.2882 960.406 94.9502 958.299 Q92.6123 956.193 88.6077 956.193 Q86.7327 956.193 84.8577 956.61 Q83.0058 957.026 81.0614 957.906 L81.0614 940.545 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M111.177 969.225 L116.061 969.225 L116.061 975.105 L111.177 975.105 L111.177 969.225 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M136.246 943.623 Q132.635 943.623 130.807 947.188 Q129.001 950.73 129.001 957.86 Q129.001 964.966 130.807 968.531 Q132.635 972.072 136.246 972.072 Q139.881 972.072 141.686 968.531 Q143.515 964.966 143.515 957.86 Q143.515 950.73 141.686 947.188 Q139.881 943.623 136.246 943.623 M136.246 939.92 Q142.056 939.92 145.112 944.526 Q148.191 949.11 148.191 957.86 Q148.191 966.586 145.112 971.193 Q142.056 975.776 136.246 975.776 Q130.436 975.776 127.357 971.193 Q124.302 966.586 124.302 957.86 Q124.302 949.11 127.357 944.526 Q130.436 939.92 136.246 939.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M80.8299 696.599 L103.052 696.599 L103.052 698.59 L90.5058 731.159 L85.6216 731.159 L97.4271 700.534 L80.8299 700.534 L80.8299 696.599 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M112.172 725.28 L117.057 725.28 L117.057 731.159 L112.172 731.159 L112.172 725.28 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M127.288 696.599 L145.644 696.599 L145.644 700.534 L131.57 700.534 L131.57 709.007 Q132.589 708.659 133.607 708.497 Q134.626 708.312 135.644 708.312 Q141.431 708.312 144.811 711.484 Q148.191 714.655 148.191 720.071 Q148.191 725.65 144.718 728.752 Q141.246 731.831 134.927 731.831 Q132.751 731.831 130.482 731.46 Q128.237 731.09 125.83 730.349 L125.83 725.65 Q127.913 726.784 130.135 727.34 Q132.357 727.895 134.834 727.895 Q138.839 727.895 141.177 725.789 Q143.515 723.683 143.515 720.071 Q143.515 716.46 141.177 714.354 Q138.839 712.247 134.834 712.247 Q132.959 712.247 131.084 712.664 Q129.232 713.081 127.288 713.96 L127.288 696.599 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M51.6634 483.279 L59.3023 483.279 L59.3023 456.913 L50.9921 458.58 L50.9921 454.321 L59.256 452.654 L63.9319 452.654 L63.9319 483.279 L71.5707 483.279 L71.5707 487.214 L51.6634 487.214 L51.6634 483.279 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M91.0151 455.733 Q87.404 455.733 85.5753 459.297 Q83.7697 462.839 83.7697 469.969 Q83.7697 477.075 85.5753 480.64 Q87.404 484.181 91.0151 484.181 Q94.6493 484.181 96.4548 480.64 Q98.2835 477.075 98.2835 469.969 Q98.2835 462.839 96.4548 459.297 Q94.6493 455.733 91.0151 455.733 M91.0151 452.029 Q96.8252 452.029 99.8808 456.635 Q102.959 461.219 102.959 469.969 Q102.959 478.695 99.8808 483.302 Q96.8252 487.885 91.0151 487.885 Q85.2049 487.885 82.1262 483.302 Q79.0707 478.695 79.0707 469.969 Q79.0707 461.219 82.1262 456.635 Q85.2049 452.029 91.0151 452.029 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M111.177 481.334 L116.061 481.334 L116.061 487.214 L111.177 487.214 L111.177 481.334 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M136.246 455.733 Q132.635 455.733 130.807 459.297 Q129.001 462.839 129.001 469.969 Q129.001 477.075 130.807 480.64 Q132.635 484.181 136.246 484.181 Q139.881 484.181 141.686 480.64 Q143.515 477.075 143.515 469.969 Q143.515 462.839 141.686 459.297 Q139.881 455.733 136.246 455.733 M136.246 452.029 Q142.056 452.029 145.112 456.635 Q148.191 461.219 148.191 469.969 Q148.191 478.695 145.112 483.302 Q142.056 487.885 136.246 487.885 Q130.436 487.885 127.357 483.302 Q124.302 478.695 124.302 469.969 Q124.302 461.219 127.357 456.635 Q130.436 452.029 136.246 452.029 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M52.6588 239.333 L60.2976 239.333 L60.2976 212.968 L51.9875 214.634 L51.9875 210.375 L60.2513 208.708 L64.9272 208.708 L64.9272 239.333 L72.5661 239.333 L72.5661 243.268 L52.6588 243.268 L52.6588 239.333 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M86.0382 239.333 L102.358 239.333 L102.358 243.268 L80.4133 243.268 L80.4133 239.333 Q83.0753 236.579 87.6586 231.949 Q92.2651 227.296 93.4456 225.954 Q95.691 223.431 96.5706 221.694 Q97.4734 219.935 97.4734 218.245 Q97.4734 215.491 95.5289 213.755 Q93.6076 212.019 90.5058 212.019 Q88.3067 212.019 85.8531 212.782 Q83.4225 213.546 80.6447 215.097 L80.6447 210.375 Q83.4688 209.241 85.9225 208.662 Q88.3762 208.083 90.4132 208.083 Q95.7836 208.083 98.978 210.769 Q102.172 213.454 102.172 217.944 Q102.172 220.074 101.362 221.995 Q100.575 223.894 98.4687 226.486 Q97.89 227.157 94.7882 230.375 Q91.6864 233.569 86.0382 239.333 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M112.172 237.389 L117.057 237.389 L117.057 243.268 L112.172 243.268 L112.172 237.389 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M127.288 208.708 L145.644 208.708 L145.644 212.644 L131.57 212.644 L131.57 221.116 Q132.589 220.769 133.607 220.607 Q134.626 220.421 135.644 220.421 Q141.431 220.421 144.811 223.593 Q148.191 226.764 148.191 232.181 Q148.191 237.759 144.718 240.861 Q141.246 243.94 134.927 243.94 Q132.751 243.94 130.482 243.569 Q128.237 243.199 125.83 242.458 L125.83 237.759 Q127.913 238.893 130.135 239.449 Q132.357 240.005 134.834 240.005 Q138.839 240.005 141.177 237.898 Q143.515 235.792 143.515 232.181 Q143.515 228.569 141.177 226.463 Q138.839 224.356 134.834 224.356 Q132.959 224.356 131.084 224.773 Q129.232 225.19 127.288 226.069 L127.288 208.708 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip052)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  245.565,1424.51 311.559,1414.7 377.553,1445.72 443.547,1427.66 509.541,1445.72 575.536,1442.19 641.53,1444.72 707.524,1433.59 773.518,1445.72 839.512,1433.9 \n",
       "  905.506,1445.72 971.5,87.9763 1037.49,1441.36 1103.49,1370.15 1169.48,1428.81 1235.48,1304.87 1301.47,1373.69 1367.46,1440.64 1433.46,1423.27 1499.45,1329.52 \n",
       "  1565.45,1443.09 1631.44,1365.03 1697.43,1419.34 1763.43,1369.56 1829.42,1425.45 1895.42,1436.74 1961.41,1410.37 2027.41,1408.93 2093.4,1414.89 2159.39,1434.52 \n",
       "  2225.39,1425.9 2291.38,1336.23 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip050)\" d=\"\n",
       "M1987.09 198.898 L2280.47 198.898 L2280.47 95.2176 L1987.09 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1987.09,198.898 2280.47,198.898 2280.47,95.2176 1987.09,95.2176 1987.09,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2011.18,147.058 2155.75,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip050)\" d=\"M2193.69 166.745 Q2191.89 171.375 2190.17 172.787 Q2188.46 174.199 2185.59 174.199 L2182.19 174.199 L2182.19 170.634 L2184.69 170.634 Q2186.45 170.634 2187.42 169.8 Q2188.39 168.967 2189.57 165.865 L2190.34 163.921 L2179.85 138.412 L2184.36 138.412 L2192.47 158.689 L2200.57 138.412 L2205.08 138.412 L2193.69 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M2212.37 160.402 L2220.01 160.402 L2220.01 134.037 L2211.7 135.703 L2211.7 131.444 L2219.97 129.778 L2224.64 129.778 L2224.64 160.402 L2232.28 160.402 L2232.28 164.338 L2212.37 164.338 L2212.37 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    bestEpSc    = -100.0;\n",
    "    statesBest  = zeros( size( X_0, 1 ), T )\n",
    "    actionsBest = zeros( T );\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/(episodes-1)\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        s_l = 0.0\n",
    "        # while s_l == 0\n",
    "        \n",
    "            X  = X_0\n",
    "\n",
    "            ##### Double Q-Learning ###########################################\n",
    "\n",
    "            for k = 1:T\n",
    "\n",
    "                # 1. Choose action\n",
    "                if rand() < epsilon\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                else\n",
    "\n",
    "                    A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                    if A == 1000.0 # Indicates no values in this region\n",
    "                        if rand() < EXPrand \n",
    "                            A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                        else\n",
    "                            A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                # 2. Cache last state\n",
    "                qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "                # 3. Generate the next stae\n",
    "                Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "                # 4. Collect reward R( s, a, s' )\n",
    "                R_t = cartpole_reward( Xp )\n",
    "\n",
    "                # 5. Get the optimal action at the next state\n",
    "                a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "                # 6. Compute the value at the next state\n",
    "\n",
    "                V_tp1_opt = query_value_fuzzy( \n",
    "                    Q_kdTree, G, V, \n",
    "                    get_Q( \n",
    "                        select_X_vector( Xp ), \n",
    "                        a_tp1_opt \n",
    "                    ); \n",
    "                    k = vNN \n",
    "                )\n",
    "                if isnan( V_tp1_opt )\n",
    "                    V_tp1_opt = 0.0\n",
    "                end\n",
    "\n",
    "\n",
    "                # 7. Blend the value back into nearest points\n",
    "\n",
    "                idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "                nNear      = size( idxs, 1 )\n",
    "                for i = 1:nNear\n",
    "                    j    = idxs[i]\n",
    "                    if !isnan( wgts[i] ) \n",
    "\n",
    "                        # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                        VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                states[:,k] = Xp\n",
    "                actions[k]  = A\n",
    "\n",
    "                X = Xp\n",
    "            end\n",
    "\n",
    "            s_l    = vertical_score_s( states, aMargin, ts )\n",
    "            \n",
    "        # end\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if s_l > bestEpSc\n",
    "            bestEpSc    = s_l\n",
    "            statesBest  = copy( states  )\n",
    "            actionsBest = copy( actions )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        # if useElig && (s_l > s_Totl/(1.0*l)) && (s_l > 0.0) \n",
    "        # if useElig && (s_l > 0.0) \n",
    "        if useElig \n",
    "            \n",
    "            # if s_l == 0.0\n",
    "            #     states  = copy( bestXs )\n",
    "            #     actions = copy( bestAs )\n",
    "            # end\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "            # println(\"SWAP\")\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    ##### Learning Rate Schedule ##########################################\n",
    "    alpha *= beta\n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709555b9-2598-4281-a634-c7b0681277d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Method 2 Performance, Average Vertical Duration [s]\n",
    "Each score is the best average score of the last two epochs: 32 epochs of 64 episodes each, Q-function swap after every episode \n",
    "\n",
    "### TD Tuning\n",
    "\n",
    "$\\gamma = 1.00$  \n",
    "\n",
    "| Param                |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|----------------------|------| ------- | ------- | ------- | ------- | ------- |------| ----- |\n",
    "| $$\\alpha = 0.99$$    |&nbsp;| 0.251   | 0.198   | 0.146   | 0.147   | 0.210   |&nbsp;| 0.190 |\n",
    "| $$\\alpha = 0.75$$    |&nbsp;| 0.179   | 0.185   | 0.239   | 0.179   | 0.175   |&nbsp;| 0.191 |\n",
    "| $$\\alpha = 0.50$$    |&nbsp;| 0.204   | 0.100   | 0.238   | 0.158   | 0.139   |&nbsp;| 0.168 |\n",
    "| $$\\alpha = 0.25$$    |&nbsp;| 0.294   | 0.170   | 0.107   | 0.223   | 0.147   |&nbsp;| 0.188 |\n",
    "| $$\\alpha = 0.125$$   |&nbsp;| 0.187   | 0.254   | 0.177   | 0.163   | 0.204   |&nbsp;| 0.197 |  \n",
    "| $$\\alpha = 0.0625$$  |&nbsp;| 0.113   | 0.241   | 0.353   | 0.134   | 0.749   |&nbsp;| 0.318 |\n",
    "| $$\\alpha = 0.03125$$ |&nbsp;| 0.231   | 0.322   | 0.018   | 0.098   | 0.000   |&nbsp;| 0.134 |\n",
    "| $$\\alpha = 0.02344$$ |&nbsp;| 1.289   | 0.119   | 0.380   | 0.168   | 0.086   |&nbsp;| 0.408 |\n",
    "| $$\\alpha = \\mathbf{0.02148}$$ |&nbsp;| 0.498   | 0.813   | 0.286   | 7.130   | 0.281   |&nbsp;| **1.802** |\n",
    "| $$\\alpha = 0.01953$$ |&nbsp;| 0.234   | 0.113   | 0.445   | 0.119   | 1.637   |&nbsp;| 0.510 |\n",
    "| $$\\alpha = 0.01758$$ |&nbsp;| 0.175   | 0.249   | 0.217   | 0.047   | 1.006   |&nbsp;| 0.339 |\n",
    "| $$\\alpha = 0.01563$$ |&nbsp;| 0.281   | 1.371   | 0.066   | 0.037   | 0.751   |&nbsp;| 0.501 |\n",
    "| $$\\alpha = 0.00782$$ |&nbsp;| 0.133   | 0.241   | 0.149   | 0.493   | 0.146   |&nbsp;| 0.232 |\n",
    "| $$\\alpha = 0.00391$$ |&nbsp;| 0.037   | 0.626   | 1.000   | 0.525   | 0.139   |&nbsp;| 0.465 |\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "### $\\gamma$ Tuning\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "\n",
    "| Param                 |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "| :-------------------- |------| ------- | ------- | ------- | ------- | ------- |------| ----- |\n",
    "| $$\\gamma = 0.999$$    |&nbsp;| 0.925   | 0.247   | 0.145   | 0.364   | 3.038   |&nbsp;| 0.944 |\n",
    "| $$\\gamma = 0.99$$     |&nbsp;| 0.011   | 0.448   | 0.453   | 0.915   | 0.013   |&nbsp;| 0.368 |\n",
    "| $$\\gamma = 0.85$$     |&nbsp;| 0.314   | 2.778   | 0.275   | 1.183   | 0.079   |&nbsp;| 0.926 |\n",
    "| $$\\gamma = 0.80$$     |&nbsp;| 0.082   | 0.033   | 0.173   | 0.251   | 1.741   |&nbsp;| 0.456 |\n",
    "| $$\\gamma = 0.75$$     |&nbsp;| 0.283   | 0.239   | 2.223   | 0.264   | 0.753   |&nbsp;| 0.752 |\n",
    "| $$\\gamma = 0.50$$     |&nbsp;| 0.167   | 0.289   | 0.474   | 0.266   | 0.230   |&nbsp;| 0.285 |\n",
    "\n",
    " \n",
    "### Double-Q Tuning, Swap Evey N Episodes  \n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "Epochs = 32\n",
    "\n",
    "| Param                 |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|-----------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| $$\\%\\ \\ 2$$           |&nbsp;|  0.570  | 0.132   | 1.053   | 0.731   | 0.900   |&nbsp;| 0.677 |\n",
    "| $$\\%\\ \\ 4$$           |&nbsp;|  1.313  | 0.087   | 2.282   | 0.417   | 0.409   |&nbsp;| 0.901 |\n",
    "| $$\\%\\ \\ 8$$           |&nbsp;|  0.097  | 0.040   | 0.621   | 0.030   | 0.608   |&nbsp;| 0.279 |\n",
    "| $$\\%16$$              |&nbsp;|  0.260  | 0.219   | 0.054   | 0.407   | 0.845   |&nbsp;| 0.357 |\n",
    "| $$\\%32$$              |&nbsp;|  0.674  | 0.130   | 0.301   | 0.286   | 0.313   |&nbsp;| 0.341 |\n",
    "| $$\\%\\mathbf{64}$$     |&nbsp;| 15.261  | 2.072   | 0.380   | 0.056   | 0.727   |&nbsp;| **3.699** |\n",
    "  \n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "Episodes = 128  \n",
    "Epochs = 16  \n",
    "\n",
    "| Param            |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| $$\\%\\ \\ \\ \\ 4$$  |&nbsp;|  1.333  | 0.117   | 0.138   | 0.430   | 0.149   |&nbsp;| 0.433 |\n",
    "| $$\\%\\ \\ 64$$     |&nbsp;|  0.166  | 0.110   | 0.240   | 1.615   | 0.049   |&nbsp;| 0.436 |\n",
    "| $$\\%128$$        |&nbsp;|  2.700  | 0.228   | 0.222   | 0.183   | 0.002   |&nbsp;| 0.667 |\n",
    "\n",
    "  \n",
    "### Trace Tuning\n",
    "\n",
    "This is not a Sutton and Barto eligibility trace.  Instead, I look for $N_\\text{peak}$ peaks in the value history of the episode, and apply the learning rule in reverse order from the peak through $N_\\text{step}$ previous timesteps, with a $\\lambda$ decay each step. This is neither classical nor rigorous, and if it does not work, then I will switch to one of the classic $Q(\\lambda)$ methods found in Sutton and Barto.\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "$\\lambda = 0.95$  \n",
    "Peaks = 16  \n",
    "Episodes = 64  \n",
    "Swap = \\%64  \n",
    "Epochs = 32  \n",
    "\n",
    "\n",
    "| Param                  |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|------------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| Steps: &nbsp; &nbsp; 4 |&nbsp;| 0.418   | 0.098   | 0.231   | 0.080   | 0.571   |&nbsp;| 0.280 |\n",
    "| Steps: &nbsp; 16       |&nbsp;| 0.540   | 0.365   | 1.629   | 0.215   | 0.470   |&nbsp;| 0.644 |\n",
    "| Steps: &nbsp; 64       |&nbsp;| 1.197   | 0.410   | 1.187   | 1.017   | 0.975   |&nbsp;| 0.957 |\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "$\\lambda = 0.99$  \n",
    "Peaks = 32  \n",
    "Episodes = 64  \n",
    "Swap = \\%64  \n",
    "Epochs = 32  \n",
    "\n",
    "Variations\n",
    "* Only trace non-zero uptime episodes, Result: Many more zero score episodes and no improvement\n",
    "* Only trace episodes with above-average uptime, Result: Many more zero score episodes and no improvement\n",
    "* Re-run the episode until there is non-zero uptime, Result: Extremely slow and no improvement in average uptime  \n",
    "\n",
    "| Param                  |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|------------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| Steps: &nbsp; 64       |&nbsp;| 0.265   |  1.204  | 6.919   | 1.575   |  3.940  |&nbsp;| 2.781 |\n",
    "| Steps: &nbsp; 96       |&nbsp;| 0.212   | 12.012  | 0.213   | 0.195   | 13.896  |&nbsp;| 5.306 |\n",
    "| **Steps: 128**         |&nbsp;| 0.065   | 17.540  | 0.493   | 0.325   | 15.345  |&nbsp;| **6.754** |\n",
    "| Steps: 192             |&nbsp;| 0.271   |  0.127  | 0.220   | 0.299   |  0.600  |&nbsp;| 0.303 |\n",
    "| Steps: 256             |&nbsp;| 0.958   |  2.014  | 0.947   | 0.433   |  0.045  |&nbsp;| 0.879 |\n",
    "| Steps: 512             |&nbsp;| 1.487   |  0.343  | 0.159   | 1.057   |  0.640  |&nbsp;| 0.737 |  \n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "$\\lambda = 0.99$  \n",
    "Steps = 128  \n",
    "Episodes = 64  \n",
    "Swap = \\%64  \n",
    "Epochs = 32  \n",
    "\n",
    "| Param                  |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|------------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| Peaks: &nbsp; &nbsp; 2 |&nbsp;|  0.635  | 5.336   | 0.198   |  0.069  | 0.624   |&nbsp;|       |\n",
    "| Peaks: &nbsp; &nbsp; 4 |&nbsp;|  0.086  | 0.270   | 0.286   |  0.704  | 0.122   |&nbsp;|       |\n",
    "| Peaks: &nbsp; &nbsp; 8 |&nbsp;| 17.591  | 0.446   | 0.334   |  0.317  | 1.206   |&nbsp;| 3.979 |\n",
    "| Peaks: &nbsp; 16       |&nbsp;|  0.449  | 6.393   | 0.763   | 11.826  | 0.089   |&nbsp;|       |\n",
    "| Peaks: &nbsp; 64       |&nbsp;|  0.455  | 0.910   | 1.000   |  0.555  | 0.891   |&nbsp;|       |\n",
    "| Peaks: 128             |&nbsp;|  0.354  | 0.242   | 1.780   |  0.393  | 0.166   |&nbsp;|       |\n",
    "\n",
    "\n",
    "### Value Estimation Tuning\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "$\\lambda = 0.99$  \n",
    "Peaks =  32  \n",
    "Steps = 128 \n",
    "Episodes = 64  \n",
    "Swap = \\%64  \n",
    "Epochs = 32 \n",
    "\n",
    "| Param 1   | Param 2     |&nbsp;| Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |&nbsp;| Mean  |\n",
    "|-----------|-------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| Inputs: 2 | Outputs: 1  |      | 1.172   | 0.413   |  0.057  | 0.130   | 0.092   |      |       | \n",
    "| Inputs: 2 | Outputs: 2  |      | 1.327   | 0.258   | 12.772  | 0.361   | 0.321   |      |       |\n",
    "| Inputs: 3 | Outputs: 1  |      | 0.365   | 0.575   |  0.033  | 0.046   | 0.415   |      |       | \n",
    "| Inputs: 3 | Outputs: 2  |      | 0.279   | 1.335   |  0.438  | 1.413   | 0.121   |      |       | \n",
    "| Inputs: 3 | Outputs: 3  |      | 0.415   | 0.352   |  0.195  | 0.884   | 1.048   |      |       | \n",
    "| Inputs: 4 | Outputs: 2  |      | 0.083   | 1.845   |  0.437  | 0.418   | 3.486   |      |       | \n",
    "| Inputs: 4 | Outputs: 3  |      | 0.273   | 0.566   |  0.266  | 0.174   | 0.487   |      |       | \n",
    "| Inputs: 4 | Outputs: 4  |      | 0.620   | 0.145   |  1.528  | 0.418   | 0.130   |      |       | \n",
    "| Inputs: 5 | Outputs: 1  |      | 0.203   | 0.406   |  0.281  | 1.045   | 1.341   |      |       | \n",
    "\n",
    "### Learning Rate Decay\n",
    "\n",
    "$\\alpha = \\mathbf{0.02148}$  \n",
    "$\\gamma = \\mathbf{1.00}$  \n",
    "$\\lambda = 0.99$  \n",
    "Peaks =  32  \n",
    "Steps = 128  \n",
    "Episodes = 64  \n",
    "Swap = \\%64  \n",
    "Epochs = 32  \n",
    "Inputs = 4  \n",
    "Outputs = 1  \n",
    "\n",
    "| Param                  |      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |      | Mean  |\n",
    "|------------------------|------|---------|---------|---------|---------|---------|------|-------|\n",
    "| $$\\beta = 0.999$$      |      | 1.347   | 0.185   | 11.403  |         |         |      |       | \n",
    "| $$\\beta = 0.99\\ $$     |      | 0.482   | 0.089   |  1.839  |         |         |      |       | \n",
    "| $$\\beta = 0.95\\ $$     |      | 0.470   | 1.620   |  1.122  |         |         |      |       | \n",
    "| $$\\beta = 0.90\\ $$     |      |         |         |         |         |         |      |       | \n",
    "| $$\\beta = 0.80\\ $$     |      |         |         |         |         |         |      |       | \n",
    "| $$\\beta = 0.70\\ $$     |      |         |         |         |         |         |      |       | \n",
    "\n",
    "### `!!!` IMPLEMENTATION CHECK `!!!`\n",
    "\n",
    "### Blend: Best Episode\n",
    "\n",
    "$\\beta = 0.07$:  \n",
    "$\\beta = 0.15$: 0.244\n",
    "\n",
    "| Method      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n",
    "| ----------- | ------- | ------- | ------- | ------- | ------- | ---- |\n",
    "| Blend (Epi) |         |         |         |         |         |      |\n",
    "| Blend (Epo) |         |         |         |         |         |      |\n",
    "| TD          |         |         |         |         |         |      |\n",
    "| TD  + ????? |         |         |         |         |         |      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Process(`\u001b[4mplay\u001b[24m \u001b[4m-nq\u001b[24m \u001b[4m-t\u001b[24m \u001b[4malsa\u001b[24m \u001b[4msynth\u001b[24m \u001b[4m3\u001b[24m \u001b[4msine\u001b[24m \u001b[4m300\u001b[24m`, ProcessExited(0))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(`play -nq -t alsa synth 3 sine 300`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b5ade7-5f94-43b1-837f-85ccdd6b5c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
