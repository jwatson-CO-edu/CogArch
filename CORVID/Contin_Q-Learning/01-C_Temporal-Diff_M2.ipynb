{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.01953 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 \n",
    "gamma    = 1.00 \n",
    "swapDiv  = 1\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes =  64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   =  32 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "beta   = 0.15\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = false\n",
    "N_peaks =  40\n",
    "N_steps = 200\n",
    "lambda  =   0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.26000000000000006, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.36000000000000015, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.11999999999999998, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.09, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.4200000000000002, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.25000000000000006, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.5500000000000003, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.3300000000000001, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.21000000000000005, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.1514062500000001\n",
      "\n",
      "Epoch 2, Best Score: 1.320000000000001\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.9300000000000006, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.6100000000000003, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.13999999999999999, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.37000000000000016, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.48000000000000026, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 1.480000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.09999999999999999, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.35000000000000014, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.10999999999999999, epsilon: 0.0078125\n",
      "Average Score: 0.14390625000000007\n",
      "\n",
      "Epoch 3, Best Score: 1.480000000000001\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.19000000000000003, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.4200000000000002, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.2900000000000001, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.4200000000000002, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.1807812500000001\n",
      "\n",
      "Epoch 4, Best Score: 1.480000000000001\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.2156250000000001\n",
      "\n",
      "Epoch 5, Best Score: 1.480000000000001\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.21156250000000013\n",
      "\n",
      "Epoch 6, Best Score: 1.8800000000000014\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.21109375000000002\n",
      "\n",
      "Epoch 7, Best Score: 2.289999999999995\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.17, epsilon: 0.0078125\n",
      "Average Score: 0.1678125000000001\n",
      "\n",
      "Epoch 8, Best Score: 2.289999999999995\n",
      "Training Iteration 4 score: 1.5900000000000012, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.8400000000000005, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 1.0300000000000007, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.19000000000000003, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.9700000000000006, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.7800000000000005, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.8600000000000005, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.18000000000000002, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.8100000000000005, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.8700000000000006, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 1.480000000000001, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.46000000000000024, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.20000000000000004, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.12999999999999998, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.7200000000000004, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.8600000000000005, epsilon: 0.0078125\n",
      "Average Score: 0.6360937500000003\n",
      "\n",
      "Epoch 9, Best Score: 2.289999999999995\n",
      "Training Iteration 4 score: 0.5600000000000003, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.17, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.9700000000000006, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.7600000000000005, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 1.0800000000000007, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.17, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 1.460000000000001, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.3200000000000001, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 1.0200000000000007, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.9000000000000006, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.8700000000000006, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 1.0000000000000007, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 1.500000000000001, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.8200000000000005, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.24000000000000007, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.19000000000000003, epsilon: 0.0078125\n",
      "Average Score: 0.5807812500000004\n",
      "\n",
      "Epoch 10, Best Score: 2.3699999999999934\n",
      "Training Iteration 4 score: 1.0400000000000007, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.21000000000000005, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.7500000000000004, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.9800000000000006, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.19000000000000003, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.38000000000000017, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.7600000000000005, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.9900000000000007, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.9500000000000006, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.8600000000000005, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.8700000000000006, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 1.2100000000000009, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.21000000000000005, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.8200000000000005, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.7500000000000004, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.8700000000000006, epsilon: 0.0078125\n",
      "Average Score: 0.9400000000000025\n",
      "\n",
      "Epoch 11, Best Score: 18.81000000000014\n",
      "Training Iteration 4 score: 0.19000000000000003, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.21000000000000005, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.9200000000000006, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.19000000000000003, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 1.8200000000000014, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.8800000000000006, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.8900000000000006, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 15.559999999999713, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.5600000000000003, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.22000000000000006, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.21000000000000005, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.7800000000000005, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.8200000000000005, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.8600000000000005, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.9800000000000006, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.8000000000000005, epsilon: 0.0078125\n",
      "Average Score: 0.8057812499999956\n",
      "\n",
      "Epoch 12, Best Score: 18.81000000000014\n",
      "Training Iteration 4 score: 0.38000000000000017, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.24000000000000007, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 1.460000000000001, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.21000000000000005, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.8400000000000005, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 2.339999999999994, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.21000000000000005, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.17, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 1.0200000000000007, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.46000000000000024, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 16.74999999999982, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.8300000000000005, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.9200000000000006, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.20000000000000004, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.8200000000000005, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.2700000000000001, epsilon: 0.0078125\n",
      "Average Score: 1.0785937499999967\n",
      "\n",
      "Epoch 13, Best Score: 18.81000000000014\n",
      "Training Iteration 4 score: 1.290000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.6100000000000003, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.34000000000000014, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.19000000000000003, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.6200000000000003, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 15.149999999999721, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.18000000000000002, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.8600000000000005, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.7700000000000005, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 2.3099999999999947, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.7600000000000005, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.9100000000000006, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.8100000000000005, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.8700000000000006, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.8600000000000005, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.7600000000000005, epsilon: 0.0078125\n",
      "Average Score: 0.9074999999999983\n",
      "\n",
      "Epoch 14, Best Score: 19.040000000000177\n",
      "Training Iteration 4 score: 0.2700000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 1.1400000000000008, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 1.0400000000000007, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.7500000000000004, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 1.2000000000000008, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.13999999999999999, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 1.0100000000000007, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.18000000000000002, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.8200000000000005, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.16, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.17, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.25000000000000006, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.9200000000000006, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.8300000000000005, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.7700000000000005, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.7900000000000005, epsilon: 0.0078125\n",
      "Average Score: 0.43562500000000015\n",
      "\n",
      "Epoch 15, Best Score: 19.040000000000177\n",
      "Training Iteration 4 score: 0.9300000000000006, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 1.0900000000000007, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.34000000000000014, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.25000000000000006, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.6200000000000003, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.9500000000000006, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.19000000000000003, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.9400000000000006, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.6800000000000004, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.8200000000000005, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.6700000000000004, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.7900000000000005, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.20000000000000004, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.3200000000000001, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.8100000000000005, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.7700000000000005, epsilon: 0.0078125\n",
      "Average Score: 0.7151562499999966\n",
      "\n",
      "Epoch 16, Best Score: 19.040000000000177\n",
      "Training Iteration 4 score: 0.8600000000000005, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 5.279999999999932, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.15, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.18000000000000002, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.8800000000000006, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.18000000000000002, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.8600000000000005, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.8700000000000006, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.7300000000000004, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.25000000000000006, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.4300000000000002, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.8200000000000005, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 1.0700000000000007, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.8000000000000005, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.9200000000000006, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.7600000000000005, epsilon: 0.0078125\n",
      "Average Score: 0.5471874999999993\n",
      "\n",
      "Epoch 17, Best Score: 19.040000000000177\n",
      "Training Iteration 4 score: 0.37000000000000016, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.24000000000000007, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.20000000000000004, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.6300000000000003, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 1.0500000000000007, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.9300000000000006, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.8400000000000005, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.19000000000000003, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.6500000000000004, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 1.1600000000000008, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.21000000000000005, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.8000000000000005, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.8200000000000005, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 1.470000000000001, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.8700000000000006, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.8500000000000005, epsilon: 0.0078125\n",
      "Average Score: 0.8639062499999982\n",
      "\n",
      "Epoch 18, Best Score: 19.040000000000177\n",
      "Training Iteration 4 score: 0.26000000000000006, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.17, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.8200000000000005, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.3300000000000001, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 1.2000000000000008, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.21000000000000005, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 1.0000000000000007, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.17, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 1.1400000000000008, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 1.370000000000001, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 1.5900000000000012, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.9000000000000006, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.8700000000000006, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.8600000000000005, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 1.0800000000000007, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.4100000000000002, epsilon: 0.0078125\n",
      "Average Score: 0.48218750000000044\n",
      "\n",
      "Epoch 19, Best Score: 19.040000000000177\n",
      "Training Iteration 4 score: 1.2500000000000009, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.15, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 1.0300000000000007, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.9200000000000006, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 1.9300000000000015, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 1.6700000000000013, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 1.310000000000001, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.8400000000000005, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.9200000000000006, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.9300000000000006, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.8600000000000005, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.4400000000000002, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 2.1299999999999986, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 1.1500000000000008, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.8200000000000005, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.7800000000000005, epsilon: 0.0078125\n",
      "Average Score: 0.5326562500000003\n",
      "\n",
      "Epoch 20, Best Score: 19.040000000000177\n",
      "Training Iteration 4 score: 0.2900000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 1.300000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.6700000000000004, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.8700000000000006, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.9300000000000006, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.9900000000000007, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.13999999999999999, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.6200000000000003, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.23000000000000007, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.8000000000000005, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 1.1100000000000008, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.8600000000000005, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.7400000000000004, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.4200000000000002, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.5500000000000003, epsilon: 0.0078125\n",
      "Average Score: 0.3660937500000002\n",
      "\n",
      "Epoch 21, Best Score: 19.040000000000177\n",
      "Training Iteration 4 score: 0.2900000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.9000000000000006, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.6500000000000004, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.6900000000000004, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.7300000000000004, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.2700000000000001, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.19000000000000003, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.26000000000000006, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.4100000000000002, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.2900000000000001, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.05, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.16, epsilon: 0.0078125\n",
      "Average Score: 0.2864062500000002\n",
      "\n",
      "Epoch 22, Best Score: 19.040000000000177\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.37000000000000016, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.3300000000000001, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.35000000000000014, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.6400000000000003, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 1.280000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.45000000000000023, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 1.2500000000000009, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.9400000000000006, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 1.2000000000000008, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.3000000000000001, epsilon: 0.0078125\n",
      "Average Score: 0.30062500000000014\n",
      "\n",
      "Epoch 23, Best Score: 19.040000000000177\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.15, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.23000000000000007, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 1.370000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.5300000000000002, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.23000000000000007, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.4100000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.2843750000000001\n",
      "\n",
      "Epoch 24, Best Score: 19.040000000000177\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.27359374999999986\n",
      "\n",
      "Epoch 25, Best Score: 19.040000000000177\n",
      "Training Iteration 4 score: 0.4300000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.8500000000000005, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.12031250000000007\n",
      "\n",
      "Epoch 26, Best Score: 19.040000000000177\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.4200000000000002, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.17, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.8900000000000006, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.21156250000000004\n",
      "\n",
      "Epoch 27, Best Score: 19.040000000000177\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 10.329999999999824, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 12.519999999999778, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 32.590000000002085, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.3200000000000001, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 1.9534375000000592\n",
      "\n",
      "Epoch 28, Best Score: 32.590000000002085\n",
      "Training Iteration 4 score: 0.5100000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.6500000000000004, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.48000000000000026, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.5600000000000003, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.5700000000000003, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.5200000000000002, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.5500000000000003, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.6100000000000003, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.7800000000000005, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.2700000000000001, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.7300000000000004, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.4000000000000002, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.48000000000000026, epsilon: 0.0078125\n",
      "Average Score: 0.27859375000000014\n",
      "\n",
      "Epoch 29, Best Score: 32.590000000002085\n",
      "Training Iteration 4 score: 0.3900000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 1.6200000000000012, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 1.5100000000000011, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 1.0000000000000007, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.3900000000000002, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.5500000000000003, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.5000000000000002, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 1.1800000000000008, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 2.429999999999992, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 1.340000000000001, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 4.89999999999994, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.2700000000000001, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 17.699999999999967, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.6800000000000004, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 3.7299999999999645, epsilon: 0.0078125\n",
      "Average Score: 1.670781250000007\n",
      "\n",
      "Epoch 30, Best Score: 32.590000000002085\n",
      "Training Iteration 4 score: 0.7300000000000004, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.7700000000000005, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.45000000000000023, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 1.0000000000000007, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.4000000000000002, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 1.410000000000001, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.3300000000000001, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 2.439999999999992, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.9500000000000006, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.8387499999999966\n",
      "\n",
      "Epoch 31, Best Score: 32.590000000002085\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 11.329999999999803, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 7.379999999999887, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 4.319999999999952, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.49000000000000027, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.4100000000000002, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.23000000000000007, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 1.2300000000000009, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.49000000000000027, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 2.159999999999998, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 1.6368749999999828\n",
      "\n",
      "Epoch 32, Best Score: 32.590000000002085\n",
      "Training Iteration 4 score: 1.1100000000000008, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.9000000000000006, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.11999999999999998, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 1.350000000000001, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.25000000000000006, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.4100000000000002, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.9700000000000006, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.3100000000000001, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.7300000000000004, epsilon: 0.0078125\n",
      "Average Score: 1.015468749999992\n",
      "Saved a trained Q-table with size (76032,), After 12.085770881175995 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip200\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip200)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip201\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip200)\" d=\"\n",
       "M155.765 1486.45 L2352.76 1486.45 L2352.76 47.2441 L155.765 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip202\">\n",
       "    <rect x=\"155\" y=\"47\" width=\"2198\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  485.38,1486.45 485.38,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  819.676,1486.45 819.676,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1153.97,1486.45 1153.97,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1488.27,1486.45 1488.27,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1822.56,1486.45 1822.56,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2156.86,1486.45 2156.86,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  155.765,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  485.38,1486.45 485.38,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  819.676,1486.45 819.676,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1153.97,1486.45 1153.97,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1488.27,1486.45 1488.27,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1822.56,1486.45 1822.56,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2156.86,1486.45 2156.86,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip200)\" d=\"M475.658 1514.29 L494.015 1514.29 L494.015 1518.22 L479.941 1518.22 L479.941 1526.7 Q480.959 1526.35 481.978 1526.19 Q482.996 1526 484.015 1526 Q489.802 1526 493.181 1529.17 Q496.561 1532.34 496.561 1537.76 Q496.561 1543.34 493.089 1546.44 Q489.617 1549.52 483.297 1549.52 Q481.121 1549.52 478.853 1549.15 Q476.607 1548.78 474.2 1548.04 L474.2 1543.34 Q476.283 1544.47 478.505 1545.03 Q480.728 1545.58 483.205 1545.58 Q487.209 1545.58 489.547 1543.48 Q491.885 1541.37 491.885 1537.76 Q491.885 1534.15 489.547 1532.04 Q487.209 1529.94 483.205 1529.94 Q481.33 1529.94 479.455 1530.35 Q477.603 1530.77 475.658 1531.65 L475.658 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M794.364 1544.91 L802.003 1544.91 L802.003 1518.55 L793.692 1520.21 L793.692 1515.95 L801.956 1514.29 L806.632 1514.29 L806.632 1544.91 L814.271 1544.91 L814.271 1548.85 L794.364 1548.85 L794.364 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M833.715 1517.37 Q830.104 1517.37 828.276 1520.93 Q826.47 1524.47 826.47 1531.6 Q826.47 1538.71 828.276 1542.27 Q830.104 1545.82 833.715 1545.82 Q837.35 1545.82 839.155 1542.27 Q840.984 1538.71 840.984 1531.6 Q840.984 1524.47 839.155 1520.93 Q837.35 1517.37 833.715 1517.37 M833.715 1513.66 Q839.525 1513.66 842.581 1518.27 Q845.66 1522.85 845.66 1531.6 Q845.66 1540.33 842.581 1544.94 Q839.525 1549.52 833.715 1549.52 Q827.905 1549.52 824.826 1544.94 Q821.771 1540.33 821.771 1531.6 Q821.771 1522.85 824.826 1518.27 Q827.905 1513.66 833.715 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M1129.16 1544.91 L1136.8 1544.91 L1136.8 1518.55 L1128.49 1520.21 L1128.49 1515.95 L1136.75 1514.29 L1141.43 1514.29 L1141.43 1544.91 L1149.06 1544.91 L1149.06 1548.85 L1129.16 1548.85 L1129.16 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M1158.56 1514.29 L1176.91 1514.29 L1176.91 1518.22 L1162.84 1518.22 L1162.84 1526.7 Q1163.86 1526.35 1164.87 1526.19 Q1165.89 1526 1166.91 1526 Q1172.7 1526 1176.08 1529.17 Q1179.46 1532.34 1179.46 1537.76 Q1179.46 1543.34 1175.99 1546.44 Q1172.51 1549.52 1166.19 1549.52 Q1164.02 1549.52 1161.75 1549.15 Q1159.5 1548.78 1157.1 1548.04 L1157.1 1543.34 Q1159.18 1544.47 1161.4 1545.03 Q1163.62 1545.58 1166.1 1545.58 Q1170.11 1545.58 1172.44 1543.48 Q1174.78 1541.37 1174.78 1537.76 Q1174.78 1534.15 1172.44 1532.04 Q1170.11 1529.94 1166.1 1529.94 Q1164.23 1529.94 1162.35 1530.35 Q1160.5 1530.77 1158.56 1531.65 L1158.56 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M1467.04 1544.91 L1483.36 1544.91 L1483.36 1548.85 L1461.42 1548.85 L1461.42 1544.91 Q1464.08 1542.16 1468.66 1537.53 Q1473.27 1532.88 1474.45 1531.53 Q1476.69 1529.01 1477.57 1527.27 Q1478.48 1525.51 1478.48 1523.82 Q1478.48 1521.07 1476.53 1519.33 Q1474.61 1517.6 1471.51 1517.6 Q1469.31 1517.6 1466.86 1518.36 Q1464.42 1519.13 1461.65 1520.68 L1461.65 1515.95 Q1464.47 1514.82 1466.92 1514.24 Q1469.38 1513.66 1471.42 1513.66 Q1476.79 1513.66 1479.98 1516.35 Q1483.17 1519.03 1483.17 1523.52 Q1483.17 1525.65 1482.36 1527.57 Q1481.58 1529.47 1479.47 1532.07 Q1478.89 1532.74 1475.79 1535.95 Q1472.69 1539.15 1467.04 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M1503.17 1517.37 Q1499.56 1517.37 1497.73 1520.93 Q1495.93 1524.47 1495.93 1531.6 Q1495.93 1538.71 1497.73 1542.27 Q1499.56 1545.82 1503.17 1545.82 Q1506.81 1545.82 1508.61 1542.27 Q1510.44 1538.71 1510.44 1531.6 Q1510.44 1524.47 1508.61 1520.93 Q1506.81 1517.37 1503.17 1517.37 M1503.17 1513.66 Q1508.98 1513.66 1512.04 1518.27 Q1515.12 1522.85 1515.12 1531.6 Q1515.12 1540.33 1512.04 1544.94 Q1508.98 1549.52 1503.17 1549.52 Q1497.36 1549.52 1494.29 1544.94 Q1491.23 1540.33 1491.23 1531.6 Q1491.23 1522.85 1494.29 1518.27 Q1497.36 1513.66 1503.17 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M1801.83 1544.91 L1818.15 1544.91 L1818.15 1548.85 L1796.21 1548.85 L1796.21 1544.91 Q1798.87 1542.16 1803.45 1537.53 Q1808.06 1532.88 1809.24 1531.53 Q1811.49 1529.01 1812.37 1527.27 Q1813.27 1525.51 1813.27 1523.82 Q1813.27 1521.07 1811.32 1519.33 Q1809.4 1517.6 1806.3 1517.6 Q1804.1 1517.6 1801.65 1518.36 Q1799.22 1519.13 1796.44 1520.68 L1796.44 1515.95 Q1799.26 1514.82 1801.72 1514.24 Q1804.17 1513.66 1806.21 1513.66 Q1811.58 1513.66 1814.77 1516.35 Q1817.97 1519.03 1817.97 1523.52 Q1817.97 1525.65 1817.16 1527.57 Q1816.37 1529.47 1814.26 1532.07 Q1813.69 1532.74 1810.58 1535.95 Q1807.48 1539.15 1801.83 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M1828.01 1514.29 L1846.37 1514.29 L1846.37 1518.22 L1832.3 1518.22 L1832.3 1526.7 Q1833.32 1526.35 1834.33 1526.19 Q1835.35 1526 1836.37 1526 Q1842.16 1526 1845.54 1529.17 Q1848.92 1532.34 1848.92 1537.76 Q1848.92 1543.34 1845.44 1546.44 Q1841.97 1549.52 1835.65 1549.52 Q1833.48 1549.52 1831.21 1549.15 Q1828.96 1548.78 1826.56 1548.04 L1826.56 1543.34 Q1828.64 1544.47 1830.86 1545.03 Q1833.08 1545.58 1835.56 1545.58 Q1839.57 1545.58 1841.9 1543.48 Q1844.24 1541.37 1844.24 1537.76 Q1844.24 1534.15 1841.9 1532.04 Q1839.57 1529.94 1835.56 1529.94 Q1833.69 1529.94 1831.81 1530.35 Q1829.96 1530.77 1828.01 1531.65 L1828.01 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M2145.7 1530.21 Q2149.06 1530.93 2150.93 1533.2 Q2152.83 1535.47 2152.83 1538.8 Q2152.83 1543.92 2149.31 1546.72 Q2145.79 1549.52 2139.31 1549.52 Q2137.14 1549.52 2134.82 1549.08 Q2132.53 1548.66 2130.08 1547.81 L2130.08 1543.29 Q2132.02 1544.43 2134.34 1545.01 Q2136.65 1545.58 2139.17 1545.58 Q2143.57 1545.58 2145.86 1543.85 Q2148.18 1542.11 2148.18 1538.8 Q2148.18 1535.75 2146.03 1534.03 Q2143.9 1532.3 2140.08 1532.3 L2136.05 1532.3 L2136.05 1528.45 L2140.26 1528.45 Q2143.71 1528.45 2145.54 1527.09 Q2147.37 1525.7 2147.37 1523.11 Q2147.37 1520.45 2145.47 1519.03 Q2143.59 1517.6 2140.08 1517.6 Q2138.16 1517.6 2135.96 1518.01 Q2133.76 1518.43 2131.12 1519.31 L2131.12 1515.14 Q2133.78 1514.4 2136.09 1514.03 Q2138.43 1513.66 2140.49 1513.66 Q2145.82 1513.66 2148.92 1516.09 Q2152.02 1518.5 2152.02 1522.62 Q2152.02 1525.49 2150.38 1527.48 Q2148.73 1529.45 2145.7 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M2171.7 1517.37 Q2168.09 1517.37 2166.26 1520.93 Q2164.45 1524.47 2164.45 1531.6 Q2164.45 1538.71 2166.26 1542.27 Q2168.09 1545.82 2171.7 1545.82 Q2175.33 1545.82 2177.14 1542.27 Q2178.97 1538.71 2178.97 1531.6 Q2178.97 1524.47 2177.14 1520.93 Q2175.33 1517.37 2171.7 1517.37 M2171.7 1513.66 Q2177.51 1513.66 2180.56 1518.27 Q2183.64 1522.85 2183.64 1531.6 Q2183.64 1540.33 2180.56 1544.94 Q2177.51 1549.52 2171.7 1549.52 Q2165.89 1549.52 2162.81 1544.94 Q2159.75 1540.33 2159.75 1531.6 Q2159.75 1522.85 2162.81 1518.27 Q2165.89 1513.66 2171.7 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  155.765,1164.49 2352.76,1164.49 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  155.765,794.158 2352.76,794.158 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  155.765,423.824 2352.76,423.824 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  155.765,53.4889 2352.76,53.4889 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  155.765,1486.45 155.765,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  155.765,1164.49 174.663,1164.49 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  155.765,794.158 174.663,794.158 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  155.765,423.824 174.663,423.824 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  155.765,53.4889 174.663,53.4889 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip200)\" d=\"M63.5847 1150.29 Q59.9736 1150.29 58.1449 1153.86 Q56.3393 1157.4 56.3393 1164.53 Q56.3393 1171.63 58.1449 1175.2 Q59.9736 1178.74 63.5847 1178.74 Q67.2189 1178.74 69.0244 1175.2 Q70.8531 1171.63 70.8531 1164.53 Q70.8531 1157.4 69.0244 1153.86 Q67.2189 1150.29 63.5847 1150.29 M63.5847 1146.59 Q69.3948 1146.59 72.4503 1151.19 Q75.529 1155.78 75.529 1164.53 Q75.529 1173.25 72.4503 1177.86 Q69.3948 1182.44 63.5847 1182.44 Q57.7745 1182.44 54.6958 1177.86 Q51.6403 1173.25 51.6403 1164.53 Q51.6403 1155.78 54.6958 1151.19 Q57.7745 1146.59 63.5847 1146.59 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M83.7466 1175.89 L88.6308 1175.89 L88.6308 1181.77 L83.7466 1181.77 L83.7466 1175.89 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M98.8622 1147.21 L117.219 1147.21 L117.219 1151.15 L103.145 1151.15 L103.145 1159.62 Q104.163 1159.27 105.182 1159.11 Q106.2 1158.93 107.219 1158.93 Q113.006 1158.93 116.385 1162.1 Q119.765 1165.27 119.765 1170.68 Q119.765 1176.26 116.293 1179.37 Q112.82 1182.44 106.501 1182.44 Q104.325 1182.44 102.057 1182.07 Q99.8113 1181.7 97.4039 1180.96 L97.4039 1176.26 Q99.4872 1177.4 101.709 1177.95 Q103.932 1178.51 106.408 1178.51 Q110.413 1178.51 112.751 1176.4 Q115.089 1174.3 115.089 1170.68 Q115.089 1167.07 112.751 1164.97 Q110.413 1162.86 106.408 1162.86 Q104.534 1162.86 102.659 1163.28 Q100.807 1163.69 98.8622 1164.57 L98.8622 1147.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M53.3995 807.503 L61.0384 807.503 L61.0384 781.137 L52.7282 782.804 L52.7282 778.545 L60.9921 776.878 L65.668 776.878 L65.668 807.503 L73.3068 807.503 L73.3068 811.438 L53.3995 811.438 L53.3995 807.503 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M82.7512 805.559 L87.6354 805.559 L87.6354 811.438 L82.7512 811.438 L82.7512 805.559 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M107.821 779.957 Q104.209 779.957 102.381 783.522 Q100.575 787.063 100.575 794.193 Q100.575 801.299 102.381 804.864 Q104.209 808.406 107.821 808.406 Q111.455 808.406 113.26 804.864 Q115.089 801.299 115.089 794.193 Q115.089 787.063 113.26 783.522 Q111.455 779.957 107.821 779.957 M107.821 776.253 Q113.631 776.253 116.686 780.86 Q119.765 785.443 119.765 794.193 Q119.765 802.92 116.686 807.526 Q113.631 812.109 107.821 812.109 Q102.01 812.109 98.9317 807.526 Q95.8761 802.92 95.8761 794.193 Q95.8761 785.443 98.9317 780.86 Q102.01 776.253 107.821 776.253 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M54.3949 437.168 L62.0337 437.168 L62.0337 410.803 L53.7236 412.469 L53.7236 408.21 L61.9874 406.544 L66.6633 406.544 L66.6633 437.168 L74.3022 437.168 L74.3022 441.104 L54.3949 441.104 L54.3949 437.168 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M83.7466 435.224 L88.6308 435.224 L88.6308 441.104 L83.7466 441.104 L83.7466 435.224 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M98.8622 406.544 L117.219 406.544 L117.219 410.479 L103.145 410.479 L103.145 418.951 Q104.163 418.604 105.182 418.442 Q106.2 418.256 107.219 418.256 Q113.006 418.256 116.385 421.428 Q119.765 424.599 119.765 430.016 Q119.765 435.594 116.293 438.696 Q112.82 441.775 106.501 441.775 Q104.325 441.775 102.057 441.404 Q99.8113 441.034 97.4039 440.293 L97.4039 435.594 Q99.4872 436.729 101.709 437.284 Q103.932 437.84 106.408 437.84 Q110.413 437.84 112.751 435.733 Q115.089 433.627 115.089 430.016 Q115.089 426.405 112.751 424.298 Q110.413 422.192 106.408 422.192 Q104.534 422.192 102.659 422.608 Q100.807 423.025 98.8622 423.905 L98.8622 406.544 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M56.6171 66.8337 L72.9365 66.8337 L72.9365 70.7689 L50.9921 70.7689 L50.9921 66.8337 Q53.6541 64.0791 58.2375 59.4495 Q62.8439 54.7967 64.0245 53.4541 Q66.2698 50.931 67.1494 49.1949 Q68.0522 47.4357 68.0522 45.7458 Q68.0522 42.9912 66.1078 41.2551 Q64.1865 39.519 61.0847 39.519 Q58.8856 39.519 56.4319 40.2829 Q54.0014 41.0468 51.2236 42.5977 L51.2236 37.8755 Q54.0477 36.7413 56.5014 36.1626 Q58.955 35.5839 60.9921 35.5839 Q66.3624 35.5839 69.5568 38.269 Q72.7513 40.9542 72.7513 45.4449 Q72.7513 47.5745 71.9411 49.4958 Q71.1541 51.394 69.0476 53.9865 Q68.4689 54.6578 65.367 57.8754 Q62.2652 61.0698 56.6171 66.8337 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M82.7512 64.8893 L87.6354 64.8893 L87.6354 70.7689 L82.7512 70.7689 L82.7512 64.8893 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M107.821 39.2875 Q104.209 39.2875 102.381 42.8523 Q100.575 46.394 100.575 53.5236 Q100.575 60.63 102.381 64.1948 Q104.209 67.7365 107.821 67.7365 Q111.455 67.7365 113.26 64.1948 Q115.089 60.63 115.089 53.5236 Q115.089 46.394 113.26 42.8523 Q111.455 39.2875 107.821 39.2875 M107.821 35.5839 Q113.631 35.5839 116.686 40.1903 Q119.765 44.7736 119.765 53.5236 Q119.765 62.2504 116.686 66.8568 Q113.631 71.4402 107.821 71.4402 Q102.01 71.4402 98.9317 66.8568 Q95.8761 62.2504 95.8761 53.5236 Q95.8761 44.7736 98.9317 40.1903 Q102.01 35.5839 107.821 35.5839 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip202)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  217.944,1422.69 284.803,1428.24 351.662,1400.93 418.521,1375.12 485.38,1378.13 552.24,1378.48 619.099,1410.53 685.958,1063.69 752.817,1104.66 819.676,838.598 \n",
       "  886.535,938.01 953.394,735.946 1020.25,862.67 1087.11,1212.17 1153.97,1005.13 1220.83,1129.54 1287.69,894.959 1354.55,1177.69 1421.41,1140.31 1488.27,1263.67 \n",
       "  1555.13,1322.7 1621.99,1312.16 1688.84,1324.2 1755.7,1332.18 1822.56,1445.72 1889.42,1378.13 1956.28,87.9763 2023.14,1328.48 2090,297.331 2156.86,913.591 \n",
       "  2223.72,322.444 2290.58,782.701 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip200)\" d=\"\n",
       "M1982.98 198.898 L2279.52 198.898 L2279.52 95.2176 L1982.98 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1982.98,198.898 2279.52,198.898 2279.52,95.2176 1982.98,95.2176 1982.98,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2007.39,147.058 2153.86,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip200)\" d=\"M2192.11 166.745 Q2190.31 171.375 2188.59 172.787 Q2186.88 174.199 2184.01 174.199 L2180.61 174.199 L2180.61 170.634 L2183.11 170.634 Q2184.87 170.634 2185.84 169.8 Q2186.81 168.967 2187.99 165.865 L2188.76 163.921 L2178.27 138.412 L2182.78 138.412 L2190.89 158.689 L2198.99 138.412 L2203.5 138.412 L2192.11 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M2210.79 160.402 L2218.43 160.402 L2218.43 134.037 L2210.12 135.703 L2210.12 131.444 L2218.39 129.778 L2223.06 129.778 L2223.06 160.402 L2230.7 160.402 L2230.7 164.338 L2210.79 164.338 L2210.79 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/episodes\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        X  = X_0\n",
    "        \n",
    "        ##### Double Q-Learning ###########################################\n",
    "\n",
    "        for k = 1:T\n",
    "\n",
    "            # 1. Choose action\n",
    "            if rand() < epsilon\n",
    "                if rand() < EXPrand \n",
    "                    A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                else\n",
    "                    A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                end\n",
    "            else\n",
    "\n",
    "                A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                if A == 1000.0 # Indicates no values in this region\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "\n",
    "            # 2. Cache last state\n",
    "            qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "            # 3. Generate the next stae\n",
    "            Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "            # 4. Collect reward R( s, a, s' )\n",
    "            R_t = cartpole_reward( Xp )\n",
    "\n",
    "            # 5. Get the optimal action at the next state\n",
    "            a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "            # 6. Compute the value at the next state\n",
    "\n",
    "            V_tp1_opt = query_value_fuzzy( \n",
    "                Q_kdTree, G, V, \n",
    "                get_Q( \n",
    "                    select_X_vector( Xp ), \n",
    "                    a_tp1_opt \n",
    "                ); \n",
    "                k = vNN \n",
    "            )\n",
    "            if isnan( V_tp1_opt )\n",
    "                V_tp1_opt = 0.0\n",
    "            end\n",
    "\n",
    "\n",
    "            # 7. Blend the value back into nearest points\n",
    "\n",
    "            idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "            nNear      = size( idxs, 1 )\n",
    "            for i = 1:nNear\n",
    "                j    = idxs[i]\n",
    "                if !isnan( wgts[i] ) \n",
    "\n",
    "                    # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                    VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "                    \n",
    "                end\n",
    "            end\n",
    "\n",
    "            states[:,k] = Xp\n",
    "            actions[k]  = A\n",
    "\n",
    "            X = Xp\n",
    "        end\n",
    "\n",
    "        s_l    = vertical_score_s( states, aMargin, ts )\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        if useElig\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "            # println(\"SWAP\")\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709555b9-2598-4281-a634-c7b0681277d0",
   "metadata": {},
   "source": [
    "# Method 2 Performance, Average Vertical Duration [s]\n",
    "Each score is the best average score of the last two epochs: 32 epochs of 64 episodes each, Q-function swap after every episode \n",
    "\n",
    "### TD Tuning\n",
    "\n",
    "| Param                | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n",
    "| -------------------- | ------- | ------- | ------- | ------- | ------- | ---- |\n",
    "| $$\\alpha = 0.99$$    | 0.251   | 0.198   | 0.146   | 0.147   | 0.210   |      |\n",
    "| $$\\alpha = 0.75$$    | 0.179   | 0.185   | 0.239   | 0.179   | 0.175   |      |\n",
    "| $$\\alpha = 0.50$$    | 0.204   | 0.100   | 0.238   | 0.158   | 0.139   |      |\n",
    "| $$\\alpha = 0.25$$    | 0.294   | 0.170   | 0.107   | 0.223   | 0.147   |      |\n",
    "| $$\\alpha = 0.125$$   | 0.187   | 0.254   | 0.177   | 0.163   | 0.204   |      |  \n",
    "| $$\\alpha = 0.0625$$  | 0.113   | 0.241   | 0.353   | 0.134   | 0.749   |      |\n",
    "| $$\\alpha = 0.03125$$ | 0.231   | 0.322   | 0.018   | 0.098   | 0.000   |      |\n",
    "| $$\\alpha = 0.02344$$ | 1.289   | 0.119   | 0.380   | 0.168   | 0.086   |      |\n",
    "| $$\\alpha = 0.01953$$ | 0.234   | 0.113   | 0.445   | 0.119   | 1.637   |      |\n",
    "| $$\\alpha = 0.01563$$ |         |         |         |         |         |      |\n",
    " \n",
    "### Add gamma?\n",
    " \n",
    "### Double-Q Tuning, Swap Evey N Episodes\n",
    "$\\%\\ \\ 2$:  \n",
    "$\\%\\ \\ 4$:  \n",
    "$\\%\\ \\ 8$:  \n",
    "$\\%16$:  \n",
    "$\\%32$:  \n",
    "$\\%64$:  \n",
    "\n",
    "\n",
    "\n",
    "### Blend: Best Episode\n",
    "\n",
    "$\\beta = 0.07$:  \n",
    "$\\beta = 0.15$: 0.244\n",
    "\n",
    "| Method      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n",
    "| ----------- | ------- | ------- | ------- | ------- | ------- | ---- |\n",
    "| Blend (Epi) |         |         |         |         |         |      |\n",
    "| Blend (Epo) |         |         |         |         |         |      |\n",
    "| TD          |         |         |         |         |         |      |\n",
    "| TD  + ????? |         |         |         |         |         |      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
