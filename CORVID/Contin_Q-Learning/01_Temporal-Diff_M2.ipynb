{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    # if thetaDotN > maxThetaDot\n",
    "    #     R -= thetaDotN\n",
    "    # end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.15\n",
    "gamma    = 0.99 \n",
    "epsMin   = 0.05 # 0.05\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes =  64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   =  64 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0, Best Average: -100.0\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.36000000000000015, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.45000000000000023, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.2800000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.8400000000000005, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 2.010000000000001, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.5400000000000003, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 1.8800000000000014, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2717187499999995\n",
      "BLEND\n",
      "\n",
      "Epoch 2, Best Score: 3.9699999999999593, Best Average: 0.2717187499999995\n",
      "Training Iteration 4 score: 0.23000000000000007, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.25000000000000006, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.5000000000000002, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.19000000000000003, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.6800000000000004, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.34000000000000014, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.09, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.2800000000000001, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.5900000000000003, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.23000000000000007, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.6000000000000003, epsilon: 0.05703125000000056\n",
      "Average Score: 0.47374999999999545\n",
      "BLEND\n",
      "\n",
      "Epoch 3, Best Score: 11.189999999999806, Best Average: 0.47374999999999545\n",
      "Training Iteration 4 score: 0.09999999999999999, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.2800000000000001, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.11999999999999998, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.16, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.12999999999999998, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.9500000000000006, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.8900000000000006, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 1.1000000000000008, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 1.350000000000001, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.9000000000000006, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.3200000000000001, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.46000000000000024, epsilon: 0.05703125000000056\n",
      "Average Score: 0.3053124999999999\n",
      "\n",
      "Epoch 4, Best Score: 11.189999999999806, Best Average: 0.47374999999999545\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 1.340000000000001, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.04843750000000003\n",
      "\n",
      "Epoch 5, Best Score: 11.189999999999806, Best Average: 0.47374999999999545\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.5900000000000003, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.3000000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.7200000000000133\n",
      "BLEND\n",
      "\n",
      "Epoch 6, Best Score: 25.00000000000111, Best Average: 0.7200000000000133\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.2800000000000001, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.3200000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.8100000000000005, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.10999999999999999, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 1.8432812500000948\n",
      "BLEND\n",
      "\n",
      "Epoch 7, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.4300000000000002, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 2.809999999999984, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2785937499999993\n",
      "\n",
      "Epoch 8, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.5800000000000003, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 1.0800000000000007, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.22000000000000006, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.2700000000000001, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.4412500000000069\n",
      "\n",
      "Epoch 9, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 1.0200000000000007, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.9600000000000006, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2621874999999998\n",
      "\n",
      "Epoch 10, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.3200000000000001, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.01937500000000001\n",
      "\n",
      "Epoch 11, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.8100000000000005, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.2700000000000001, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.6400000000000003, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 1.2400000000000009, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.15156249999999996\n",
      "\n",
      "Epoch 12, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.8200000000000005, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.34000000000000014, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.4100000000000002, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 1.6800000000000013, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.8200000000000005, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.7500000000000004, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.5600000000000003, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.5900000000000003, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1868750000000001\n",
      "\n",
      "Epoch 13, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.20000000000000004, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.19000000000000003, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.3300000000000001, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.24000000000000007, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.6500000000000004, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.9100000000000006, epsilon: 0.05703125000000056\n",
      "Average Score: 0.13781250000000006\n",
      "\n",
      "Epoch 14, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.2700000000000001, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.4300000000000002, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.21000000000000005, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.34000000000000014, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.4300000000000002, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.45000000000000023, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.3200000000000001, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.11999999999999998, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 1.2400000000000009, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.3000000000000001, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.5600000000000003, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.16, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2431250000000001\n",
      "\n",
      "Epoch 15, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.21000000000000005, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.4300000000000002, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.34000000000000014, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.20000000000000004, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.12999999999999998, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.24000000000000007, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.5500000000000003, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.13999999999999999, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.2800000000000001, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.10999999999999999, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.13999999999999999, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.11999999999999998, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2618749999999996\n",
      "\n",
      "Epoch 16, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.22000000000000006, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.11999999999999998, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.7400000000000004, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.21000000000000005, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.13999999999999999, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.16, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.34000000000000014, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.04, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.11999999999999998, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.8100000000000005, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.07, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.23000000000000007, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.23000000000000007, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2109375000000001\n",
      "\n",
      "Epoch 17, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.4400000000000002, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.5700000000000003, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.5700000000000003, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.34000000000000014, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.13999999999999999, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.13999999999999999, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.15, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.05, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.36000000000000015, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.05, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.5000000000000002, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.060000000000000005, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.6400000000000003, epsilon: 0.05703125000000056\n",
      "Average Score: 0.19078125000000012\n",
      "\n",
      "Epoch 18, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.24000000000000007, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.22000000000000006, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.07, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 1.0700000000000007, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.35000000000000014, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.4300000000000002, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.08, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.4400000000000002, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.05, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.23000000000000007, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.4000000000000002, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.13999999999999999, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.15, epsilon: 0.05703125000000056\n",
      "Average Score: 0.19328125000000015\n",
      "\n",
      "Epoch 19, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.3000000000000001, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.3200000000000001, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.07, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.22000000000000006, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.3000000000000001, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.38000000000000017, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.7700000000000005, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.2800000000000001, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.2800000000000001, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.8600000000000005, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.21000000000000005, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2176562500000001\n",
      "\n",
      "Epoch 20, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.26000000000000006, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.34000000000000014, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.18000000000000002, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.2900000000000001, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.22000000000000006, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.35000000000000014, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.6000000000000003, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.07, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.15, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.19000000000000003, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.6300000000000003, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.23000000000000007, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2331250000000001\n",
      "\n",
      "Epoch 21, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.08, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.11999999999999998, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.26000000000000006, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.34000000000000014, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.07, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.15, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.11999999999999998, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.17, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.18000000000000002, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.12999999999999998, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.07, epsilon: 0.05703125000000056\n",
      "Average Score: 0.12046875000000005\n",
      "\n",
      "Epoch 22, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 1.0500000000000007, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.060000000000000005, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.47000000000000025, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.8200000000000005, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.17, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.22000000000000006, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.7200000000000004, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.060000000000000005, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.3200000000000001, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.22296875000000016\n",
      "\n",
      "Epoch 23, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 1.0300000000000007, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.05, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.5200000000000002, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.37000000000000016, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 1.1500000000000008, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.12999999999999998, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.13999999999999999, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.2800000000000001, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.09999999999999999, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.060000000000000005, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.3000000000000001, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1942187500000001\n",
      "\n",
      "Epoch 24, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.09999999999999999, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.16, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.18000000000000002, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.10999999999999999, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.9300000000000006, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.07, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.3200000000000001, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.10999999999999999, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.34000000000000014, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.19000000000000003, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.26000000000000006, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.20000000000000018\n",
      "\n",
      "Epoch 25, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.18000000000000002, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.5300000000000002, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.3300000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.3900000000000002, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.35000000000000014, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.2800000000000001, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.36000000000000015, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.25000000000000006, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.060000000000000005, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.24296875000000007\n",
      "\n",
      "Epoch 26, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.7100000000000004, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.38000000000000017, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.22000000000000006, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.5100000000000002, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.3200000000000001, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.15, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.20000000000000004, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.17906250000000007\n",
      "\n",
      "Epoch 27, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.3100000000000001, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.6200000000000003, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.16, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.05, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.21000000000000005, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.5200000000000002, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.09, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.18000000000000002, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.4100000000000002, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.2800000000000001, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.2700000000000001, epsilon: 0.05703125000000056\n",
      "Average Score: 0.19562500000000008\n",
      "\n",
      "Epoch 28, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 1.0100000000000007, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.5400000000000003, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.21000000000000005, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.3000000000000001, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.4200000000000002, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.3900000000000002, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.35000000000000014, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.7000000000000004, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.16, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.20000000000000004, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2584375000000001\n",
      "\n",
      "Epoch 29, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.36000000000000015, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.19000000000000003, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 1.2200000000000009, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.13999999999999999, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.19000000000000003, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.3300000000000001, epsilon: 0.05703125000000056\n",
      "Average Score: 0.21359375000000008\n",
      "\n",
      "Epoch 30, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.38000000000000017, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.07, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.13999999999999999, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.25000000000000006, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.17, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.24000000000000007, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.6200000000000003, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.25000000000000006, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.09999999999999999, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.20000000000000004, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.7100000000000004, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.18000000000000002, epsilon: 0.05703125000000056\n",
      "Average Score: 0.11359375000000003\n",
      "\n",
      "Epoch 31, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 1.0200000000000007, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.13999999999999999, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.18000000000000002, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.36000000000000015, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.18000000000000002, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.15, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.2800000000000001, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.2800000000000001, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.16, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.4400000000000002, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.5900000000000003, epsilon: 0.05703125000000056\n",
      "Average Score: 0.17453125000000005\n",
      "\n",
      "Epoch 32, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.34000000000000014, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.2900000000000001, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.21000000000000005, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.7600000000000005, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.35000000000000014, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.35000000000000014, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.4200000000000002, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.18000000000000002, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1776562500000001\n",
      "\n",
      "Epoch 33, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.6700000000000004, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.08, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.2900000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.20000000000000004, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.3200000000000001, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.6300000000000003, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.3100000000000001, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.16, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.08, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.25000000000000006, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.11999999999999998, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.49000000000000027, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 1.1200000000000008, epsilon: 0.05703125000000056\n",
      "Average Score: 0.15109375000000014\n",
      "\n",
      "Epoch 34, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.4100000000000002, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.5300000000000002, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 1.2200000000000009, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.7500000000000004, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.3000000000000001, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.3100000000000001, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.4100000000000002, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1643750000000001\n",
      "\n",
      "Epoch 35, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.21000000000000005, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.17, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.3900000000000002, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.5200000000000002, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.18000000000000002, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.24000000000000007, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.7500000000000004, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.3900000000000002, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.16, epsilon: 0.05703125000000056\n",
      "Average Score: 0.15187500000000007\n",
      "\n",
      "Epoch 36, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.20000000000000004, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.47000000000000025, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.18000000000000002, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.13999999999999999, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.09999999999999999, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.09, epsilon: 0.05703125000000056\n",
      "Average Score: 0.12687500000000004\n",
      "\n",
      "Epoch 37, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.6300000000000003, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.11999999999999998, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.7200000000000004, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.17, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.13999999999999999, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.20000000000000004, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.5200000000000002, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.24000000000000007, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.15, epsilon: 0.05703125000000056\n",
      "Average Score: 0.15015625000000007\n",
      "\n",
      "Epoch 38, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.4200000000000002, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.5700000000000003, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.22000000000000006, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.35000000000000014, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.09999999999999999, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.22000000000000006, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.5100000000000002, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.2800000000000001, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.3000000000000001, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.11999999999999998, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.6500000000000004, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.12999999999999998, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.5800000000000003, epsilon: 0.05703125000000056\n",
      "Average Score: 0.15625000000000006\n",
      "\n",
      "Epoch 39, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.4400000000000002, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.5600000000000003, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.35000000000000014, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.11999999999999998, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.3100000000000001, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.5100000000000002, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.6500000000000004, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.12999999999999998, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.21000000000000005, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.14656250000000012\n",
      "\n",
      "Epoch 40, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.22000000000000006, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.4100000000000002, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.5000000000000002, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.45000000000000023, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.3000000000000001, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.20000000000000004, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.6900000000000004, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.23000000000000007, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.38000000000000017, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.2900000000000001, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.8400000000000005, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1687500000000001\n",
      "\n",
      "Epoch 41, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.12999999999999998, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.4300000000000002, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.15, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.3300000000000001, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.18000000000000002, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.47000000000000025, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.36000000000000015, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.4400000000000002, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.21000000000000005, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.12999999999999998, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.5900000000000003, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.34000000000000014, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.5300000000000002, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.23000000000000007, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.2800000000000001, epsilon: 0.05703125000000056\n",
      "Average Score: 0.15515625000000005\n",
      "\n",
      "Epoch 42, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.45000000000000023, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.15, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.7000000000000004, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.20000000000000004, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.2800000000000001, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.21000000000000005, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.49000000000000027, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.38000000000000017, epsilon: 0.05703125000000056\n",
      "Average Score: 0.12828125000000007\n",
      "\n",
      "Epoch 43, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.3100000000000001, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.5000000000000002, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.13999999999999999, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.7800000000000005, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.2900000000000001, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.3100000000000001, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.24000000000000007, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.13999999999999999, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 1.430000000000001, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.6500000000000004, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.15, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.13999999999999999, epsilon: 0.05703125000000056\n",
      "Average Score: 0.21281250000000015\n",
      "\n",
      "Epoch 44, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.17, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.3200000000000001, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.12999999999999998, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.16, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.15, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.09, epsilon: 0.05703125000000056\n",
      "Average Score: 0.10328125000000003\n",
      "\n",
      "Epoch 45, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.6100000000000003, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.3200000000000001, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.35000000000000014, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.19000000000000003, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.8700000000000006, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.2900000000000001, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.34000000000000014, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.2700000000000001, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.2900000000000001, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.20000000000000004, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.17, epsilon: 0.05703125000000056\n",
      "Average Score: 0.18718750000000012\n",
      "\n",
      "Epoch 46, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.36000000000000015, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.45000000000000023, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.20000000000000004, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.34000000000000014, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.7100000000000004, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.12999999999999998, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.4400000000000002, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.47000000000000025, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.26000000000000006, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.18000000000000002, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.46000000000000024, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.17, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2071875000000001\n",
      "\n",
      "Epoch 47, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.6200000000000003, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.6300000000000003, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.3200000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.3200000000000001, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.8600000000000005, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.26000000000000006, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.22000000000000006, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.4200000000000002, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.2800000000000001, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.17640625000000007\n",
      "\n",
      "Epoch 48, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.34000000000000014, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.3000000000000001, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 1.0000000000000007, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.18000000000000002, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.22000000000000006, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.38000000000000017, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.11999999999999998, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.12999999999999998, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.37000000000000016, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.19000000000000003, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1696875000000001\n",
      "\n",
      "Epoch 49, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.13999999999999999, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.20000000000000004, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.2700000000000001, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.26000000000000006, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.6800000000000004, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.25000000000000006, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.34000000000000014, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.15, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.13999999999999999, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.3200000000000001, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.09999999999999999, epsilon: 0.05703125000000056\n",
      "Average Score: 0.18328125000000003\n",
      "\n",
      "Epoch 50, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.22000000000000006, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.22000000000000006, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.16, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.24000000000000007, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.3100000000000001, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.37000000000000016, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.22000000000000006, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.26000000000000006, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.26000000000000006, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.20000000000000004, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.15484375000000003\n",
      "\n",
      "Epoch 51, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.35000000000000014, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.3900000000000002, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.4300000000000002, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.11999999999999998, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.09, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.15, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.4300000000000002, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.3000000000000001, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.5700000000000003, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.18062500000000012\n",
      "\n",
      "Epoch 52, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.8900000000000006, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.36000000000000015, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.5500000000000003, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.7800000000000005, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.23000000000000007, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.6100000000000003, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.15, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.09999999999999999, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1528125000000001\n",
      "\n",
      "Epoch 53, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.37000000000000016, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.24000000000000007, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.15, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.22000000000000006, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.5600000000000003, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.4200000000000002, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.10999999999999999, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.09, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.8500000000000005, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.16843750000000007\n",
      "\n",
      "Epoch 54, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.8000000000000005, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.37000000000000016, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.7400000000000004, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.25000000000000006, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.2700000000000001, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.49000000000000027, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.19000000000000003, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.13999999999999999, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.12999999999999998, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.8900000000000006, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.18000000000000002, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1806250000000001\n",
      "\n",
      "Epoch 55, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.26000000000000006, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.15, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.3000000000000001, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.3200000000000001, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.21000000000000005, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.3300000000000001, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.5900000000000003, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.19000000000000003, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.5900000000000003, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.15, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.12515625000000005\n",
      "\n",
      "Epoch 56, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.11999999999999998, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.5100000000000002, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.12999999999999998, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.6300000000000003, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.18000000000000002, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.2900000000000001, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.13999999999999999, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.2800000000000001, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.20000000000000004, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.22000000000000006, epsilon: 0.05703125000000056\n",
      "Average Score: 0.12234375000000004\n",
      "\n",
      "Epoch 57, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.09999999999999999, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.37000000000000016, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.3200000000000001, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.6400000000000003, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.23000000000000007, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.20000000000000004, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.21000000000000005, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.11999999999999998, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.4100000000000002, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.11999999999999998, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.8100000000000005, epsilon: 0.05703125000000056\n",
      "Average Score: 0.21953125000000012\n",
      "\n",
      "Epoch 58, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.3100000000000001, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.7500000000000004, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.24000000000000007, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.3100000000000001, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.13999999999999999, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.3200000000000001, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.25000000000000006, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.34000000000000014, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.34000000000000014, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2168750000000001\n",
      "\n",
      "Epoch 59, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.17, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.22000000000000006, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.5300000000000002, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.9200000000000006, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.17, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.2800000000000001, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.19000000000000003, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.09, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.09999999999999999, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.18000000000000002, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.34000000000000014, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1715625000000001\n",
      "\n",
      "Epoch 60, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.20000000000000004, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.18000000000000002, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.26000000000000006, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 1.1400000000000008, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.37000000000000016, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.8500000000000005, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.22000000000000006, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.22000000000000006, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.25000000000000006, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 1.0600000000000007, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.5700000000000003, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.3200000000000001, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2271875000000001\n",
      "\n",
      "Epoch 61, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.12999999999999998, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.37000000000000016, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 1.490000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.23000000000000007, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.22000000000000006, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.21000000000000005, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.20000000000000004, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.6300000000000003, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.38000000000000017, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.3100000000000001, epsilon: 0.05703125000000056\n",
      "Average Score: 0.22656250000000017\n",
      "\n",
      "Epoch 62, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.22000000000000006, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.2800000000000001, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.20000000000000004, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.18000000000000002, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.13999999999999999, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 1.0000000000000007, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.09999999999999999, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.10015625000000003\n",
      "\n",
      "Epoch 63, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.25000000000000006, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.15, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.24000000000000007, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.4100000000000002, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.12999999999999998, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.16, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.15, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.2800000000000001, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.8500000000000005, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.24000000000000007, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.9000000000000006, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 1.0600000000000007, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.4100000000000002, epsilon: 0.05703125000000056\n",
      "Average Score: 0.20218750000000008\n",
      "\n",
      "Epoch 64, Best Score: 30.700000000002, Best Average: 1.8432812500000948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.23000000000000007, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.13999999999999999, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.21000000000000005, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.26000000000000006, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.09999999999999999, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.18000000000000002, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.19000000000000003, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.3300000000000001, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.10218750000000004\n",
      "Saved a trained Q-table with size (76032,), After 24.059444268544514 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip640\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip640)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip641\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip640)\" d=\"\n",
       "M156.112 1486.45 L2352.76 1486.45 L2352.76 47.2441 L156.112 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip642\">\n",
       "    <rect x=\"156\" y=\"47\" width=\"2198\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip642)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  185.388,1486.45 185.388,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip642)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  514.325,1486.45 514.325,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip642)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  843.262,1486.45 843.262,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip642)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1172.2,1486.45 1172.2,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip642)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1501.14,1486.45 1501.14,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip642)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1830.07,1486.45 1830.07,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip642)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2159.01,1486.45 2159.01,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip640)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip640)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  185.388,1486.45 185.388,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip640)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  514.325,1486.45 514.325,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip640)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  843.262,1486.45 843.262,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip640)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1172.2,1486.45 1172.2,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip640)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1501.14,1486.45 1501.14,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip640)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1830.07,1486.45 1830.07,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip640)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2159.01,1486.45 2159.01,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip640)\" d=\"M185.388 1517.37 Q181.776 1517.37 179.948 1520.93 Q178.142 1524.47 178.142 1531.6 Q178.142 1538.71 179.948 1542.27 Q181.776 1545.82 185.388 1545.82 Q189.022 1545.82 190.827 1542.27 Q192.656 1538.71 192.656 1531.6 Q192.656 1524.47 190.827 1520.93 Q189.022 1517.37 185.388 1517.37 M185.388 1513.66 Q191.198 1513.66 194.253 1518.27 Q197.332 1522.85 197.332 1531.6 Q197.332 1540.33 194.253 1544.94 Q191.198 1549.52 185.388 1549.52 Q179.577 1549.52 176.499 1544.94 Q173.443 1540.33 173.443 1531.6 Q173.443 1522.85 176.499 1518.27 Q179.577 1513.66 185.388 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip640)\" d=\"M489.013 1544.91 L496.651 1544.91 L496.651 1518.55 L488.341 1520.21 L488.341 1515.95 L496.605 1514.29 L501.281 1514.29 L501.281 1544.91 L508.92 1544.91 L508.92 1548.85 L489.013 1548.85 L489.013 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip640)\" d=\"M528.364 1517.37 Q524.753 1517.37 522.924 1520.93 Q521.119 1524.47 521.119 1531.6 Q521.119 1538.71 522.924 1542.27 Q524.753 1545.82 528.364 1545.82 Q531.998 1545.82 533.804 1542.27 Q535.633 1538.71 535.633 1531.6 Q535.633 1524.47 533.804 1520.93 Q531.998 1517.37 528.364 1517.37 M528.364 1513.66 Q534.174 1513.66 537.23 1518.27 Q540.309 1522.85 540.309 1531.6 Q540.309 1540.33 537.23 1544.94 Q534.174 1549.52 528.364 1549.52 Q522.554 1549.52 519.475 1544.94 Q516.42 1540.33 516.42 1531.6 Q516.42 1522.85 519.475 1518.27 Q522.554 1513.66 528.364 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip640)\" d=\"M822.036 1544.91 L838.355 1544.91 L838.355 1548.85 L816.411 1548.85 L816.411 1544.91 Q819.073 1542.16 823.656 1537.53 Q828.262 1532.88 829.443 1531.53 Q831.688 1529.01 832.568 1527.27 Q833.471 1525.51 833.471 1523.82 Q833.471 1521.07 831.526 1519.33 Q829.605 1517.6 826.503 1517.6 Q824.304 1517.6 821.85 1518.36 Q819.42 1519.13 816.642 1520.68 L816.642 1515.95 Q819.466 1514.82 821.92 1514.24 Q824.374 1513.66 826.411 1513.66 Q831.781 1513.66 834.975 1516.35 Q838.17 1519.03 838.17 1523.52 Q838.17 1525.65 837.36 1527.57 Q836.573 1529.47 834.466 1532.07 Q833.887 1532.74 830.786 1535.95 Q827.684 1539.15 822.036 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip640)\" d=\"M858.17 1517.37 Q854.559 1517.37 852.73 1520.93 Q850.924 1524.47 850.924 1531.6 Q850.924 1538.71 852.73 1542.27 Q854.559 1545.82 858.17 1545.82 Q861.804 1545.82 863.609 1542.27 Q865.438 1538.71 865.438 1531.6 Q865.438 1524.47 863.609 1520.93 Q861.804 1517.37 858.17 1517.37 M858.17 1513.66 Q863.98 1513.66 867.035 1518.27 Q870.114 1522.85 870.114 1531.6 Q870.114 1540.33 867.035 1544.94 Q863.98 1549.52 858.17 1549.52 Q852.359 1549.52 849.281 1544.94 Q846.225 1540.33 846.225 1531.6 Q846.225 1522.85 849.281 1518.27 Q852.359 1513.66 858.17 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip640)\" d=\"M1161.04 1530.21 Q1164.4 1530.93 1166.27 1533.2 Q1168.17 1535.47 1168.17 1538.8 Q1168.17 1543.92 1164.65 1546.72 Q1161.13 1549.52 1154.65 1549.52 Q1152.48 1549.52 1150.16 1549.08 Q1147.87 1548.66 1145.42 1547.81 L1145.42 1543.29 Q1147.36 1544.43 1149.68 1545.01 Q1151.99 1545.58 1154.51 1545.58 Q1158.91 1545.58 1161.2 1543.85 Q1163.52 1542.11 1163.52 1538.8 Q1163.52 1535.75 1161.37 1534.03 Q1159.24 1532.3 1155.42 1532.3 L1151.39 1532.3 L1151.39 1528.45 L1155.6 1528.45 Q1159.05 1528.45 1160.88 1527.09 Q1162.71 1525.7 1162.71 1523.11 Q1162.71 1520.45 1160.81 1519.03 Q1158.94 1517.6 1155.42 1517.6 Q1153.5 1517.6 1151.3 1518.01 Q1149.1 1518.43 1146.46 1519.31 L1146.46 1515.14 Q1149.12 1514.4 1151.44 1514.03 Q1153.77 1513.66 1155.83 1513.66 Q1161.16 1513.66 1164.26 1516.09 Q1167.36 1518.5 1167.36 1522.62 Q1167.36 1525.49 1165.72 1527.48 Q1164.07 1529.45 1161.04 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip640)\" d=\"M1187.04 1517.37 Q1183.43 1517.37 1181.6 1520.93 Q1179.79 1524.47 1179.79 1531.6 Q1179.79 1538.71 1181.6 1542.27 Q1183.43 1545.82 1187.04 1545.82 Q1190.67 1545.82 1192.48 1542.27 Q1194.31 1538.71 1194.31 1531.6 Q1194.31 1524.47 1192.48 1520.93 Q1190.67 1517.37 1187.04 1517.37 M1187.04 1513.66 Q1192.85 1513.66 1195.9 1518.27 Q1198.98 1522.85 1198.98 1531.6 Q1198.98 1540.33 1195.9 1544.94 Q1192.85 1549.52 1187.04 1549.52 Q1181.23 1549.52 1178.15 1544.94 Q1175.09 1540.33 1175.09 1531.6 Q1175.09 1522.85 1178.15 1518.27 Q1181.23 1513.66 1187.04 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip640)\" d=\"M1489.31 1518.36 L1477.5 1536.81 L1489.31 1536.81 L1489.31 1518.36 M1488.08 1514.29 L1493.96 1514.29 L1493.96 1536.81 L1498.89 1536.81 L1498.89 1540.7 L1493.96 1540.7 L1493.96 1548.85 L1489.31 1548.85 L1489.31 1540.7 L1473.71 1540.7 L1473.71 1536.19 L1488.08 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip640)\" d=\"M1516.62 1517.37 Q1513.01 1517.37 1511.18 1520.93 Q1509.38 1524.47 1509.38 1531.6 Q1509.38 1538.71 1511.18 1542.27 Q1513.01 1545.82 1516.62 1545.82 Q1520.26 1545.82 1522.06 1542.27 Q1523.89 1538.71 1523.89 1531.6 Q1523.89 1524.47 1522.06 1520.93 Q1520.26 1517.37 1516.62 1517.37 M1516.62 1513.66 Q1522.43 1513.66 1525.49 1518.27 Q1528.57 1522.85 1528.57 1531.6 Q1528.57 1540.33 1525.49 1544.94 Q1522.43 1549.52 1516.62 1549.52 Q1510.81 1549.52 1507.73 1544.94 Q1504.68 1540.33 1504.68 1531.6 Q1504.68 1522.85 1507.73 1518.27 Q1510.81 1513.66 1516.62 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip640)\" d=\"M1804.77 1514.29 L1823.13 1514.29 L1823.13 1518.22 L1809.06 1518.22 L1809.06 1526.7 Q1810.07 1526.35 1811.09 1526.19 Q1812.11 1526 1813.13 1526 Q1818.92 1526 1822.3 1529.17 Q1825.68 1532.34 1825.68 1537.76 Q1825.68 1543.34 1822.2 1546.44 Q1818.73 1549.52 1812.41 1549.52 Q1810.24 1549.52 1807.97 1549.15 Q1805.72 1548.78 1803.32 1548.04 L1803.32 1543.34 Q1805.4 1544.47 1807.62 1545.03 Q1809.84 1545.58 1812.32 1545.58 Q1816.32 1545.58 1818.66 1543.48 Q1821 1541.37 1821 1537.76 Q1821 1534.15 1818.66 1532.04 Q1816.32 1529.94 1812.32 1529.94 Q1810.44 1529.94 1808.57 1530.35 Q1806.72 1530.77 1804.77 1531.65 L1804.77 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip640)\" d=\"M1844.89 1517.37 Q1841.28 1517.37 1839.45 1520.93 Q1837.64 1524.47 1837.64 1531.6 Q1837.64 1538.71 1839.45 1542.27 Q1841.28 1545.82 1844.89 1545.82 Q1848.52 1545.82 1850.33 1542.27 Q1852.16 1538.71 1852.16 1531.6 Q1852.16 1524.47 1850.33 1520.93 Q1848.52 1517.37 1844.89 1517.37 M1844.89 1513.66 Q1850.7 1513.66 1853.75 1518.27 Q1856.83 1522.85 1856.83 1531.6 Q1856.83 1540.33 1853.75 1544.94 Q1850.7 1549.52 1844.89 1549.52 Q1839.08 1549.52 1836 1544.94 Q1832.94 1540.33 1832.94 1531.6 Q1832.94 1522.85 1836 1518.27 Q1839.08 1513.66 1844.89 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip640)\" d=\"M2144.42 1529.7 Q2141.27 1529.7 2139.42 1531.86 Q2137.59 1534.01 2137.59 1537.76 Q2137.59 1541.49 2139.42 1543.66 Q2141.27 1545.82 2144.42 1545.82 Q2147.57 1545.82 2149.39 1543.66 Q2151.25 1541.49 2151.25 1537.76 Q2151.25 1534.01 2149.39 1531.86 Q2147.57 1529.7 2144.42 1529.7 M2153.7 1515.05 L2153.7 1519.31 Q2151.94 1518.48 2150.13 1518.04 Q2148.35 1517.6 2146.59 1517.6 Q2141.96 1517.6 2139.51 1520.72 Q2137.08 1523.85 2136.73 1530.17 Q2138.1 1528.15 2140.16 1527.09 Q2142.22 1526 2144.69 1526 Q2149.9 1526 2152.91 1529.17 Q2155.94 1532.32 2155.94 1537.76 Q2155.94 1543.08 2152.8 1546.3 Q2149.65 1549.52 2144.42 1549.52 Q2138.42 1549.52 2135.25 1544.94 Q2132.08 1540.33 2132.08 1531.6 Q2132.08 1523.41 2135.97 1518.55 Q2139.86 1513.66 2146.41 1513.66 Q2148.17 1513.66 2149.95 1514.01 Q2151.75 1514.36 2153.7 1515.05 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip640)\" d=\"M2174 1517.37 Q2170.39 1517.37 2168.56 1520.93 Q2166.75 1524.47 2166.75 1531.6 Q2166.75 1538.71 2168.56 1542.27 Q2170.39 1545.82 2174 1545.82 Q2177.63 1545.82 2179.44 1542.27 Q2181.27 1538.71 2181.27 1531.6 Q2181.27 1524.47 2179.44 1520.93 Q2177.63 1517.37 2174 1517.37 M2174 1513.66 Q2179.81 1513.66 2182.87 1518.27 Q2185.94 1522.85 2185.94 1531.6 Q2185.94 1540.33 2182.87 1544.94 Q2179.81 1549.52 2174 1549.52 Q2168.19 1549.52 2165.11 1544.94 Q2162.06 1540.33 2162.06 1531.6 Q2162.06 1522.85 2165.11 1518.27 Q2168.19 1513.66 2174 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip642)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,1460.14 2352.76,1460.14 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip642)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,1087.93 2352.76,1087.93 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip642)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,715.726 2352.76,715.726 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip642)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,343.519 2352.76,343.519 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip640)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,1486.45 156.112,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip640)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,1460.14 175.01,1460.14 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip640)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,1087.93 175.01,1087.93 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip640)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,715.726 175.01,715.726 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip640)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,343.519 175.01,343.519 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip640)\" d=\"M62.9365 1445.94 Q59.3254 1445.94 57.4967 1449.5 Q55.6912 1453.04 55.6912 1460.17 Q55.6912 1467.28 57.4967 1470.84 Q59.3254 1474.39 62.9365 1474.39 Q66.5707 1474.39 68.3763 1470.84 Q70.205 1467.28 70.205 1460.17 Q70.205 1453.04 68.3763 1449.5 Q66.5707 1445.94 62.9365 1445.94 M62.9365 1442.23 Q68.7467 1442.23 71.8022 1446.84 Q74.8809 1451.42 74.8809 1460.17 Q74.8809 1468.9 71.8022 1473.51 Q68.7467 1478.09 62.9365 1478.09 Q57.1264 1478.09 54.0477 1473.51 Q50.9921 1468.9 50.9921 1460.17 Q50.9921 1451.42 54.0477 1446.84 Q57.1264 1442.23 62.9365 1442.23 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip640)\" d=\"M83.0984 1471.54 L87.9827 1471.54 L87.9827 1477.42 L83.0984 1477.42 L83.0984 1471.54 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip640)\" d=\"M108.168 1445.94 Q104.557 1445.94 102.728 1449.5 Q100.922 1453.04 100.922 1460.17 Q100.922 1467.28 102.728 1470.84 Q104.557 1474.39 108.168 1474.39 Q111.802 1474.39 113.608 1470.84 Q115.436 1467.28 115.436 1460.17 Q115.436 1453.04 113.608 1449.5 Q111.802 1445.94 108.168 1445.94 M108.168 1442.23 Q113.978 1442.23 117.033 1446.84 Q120.112 1451.42 120.112 1460.17 Q120.112 1468.9 117.033 1473.51 Q113.978 1478.09 108.168 1478.09 Q102.358 1478.09 99.2789 1473.51 Q96.2234 1468.9 96.2234 1460.17 Q96.2234 1451.42 99.2789 1446.84 Q102.358 1442.23 108.168 1442.23 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip640)\" d=\"M63.9319 1073.73 Q60.3208 1073.73 58.4921 1077.3 Q56.6865 1080.84 56.6865 1087.97 Q56.6865 1095.07 58.4921 1098.64 Q60.3208 1102.18 63.9319 1102.18 Q67.5661 1102.18 69.3717 1098.64 Q71.2004 1095.07 71.2004 1087.97 Q71.2004 1080.84 69.3717 1077.3 Q67.5661 1073.73 63.9319 1073.73 M63.9319 1070.03 Q69.742 1070.03 72.7976 1074.63 Q75.8763 1079.22 75.8763 1087.97 Q75.8763 1096.69 72.7976 1101.3 Q69.742 1105.88 63.9319 1105.88 Q58.1217 1105.88 55.043 1101.3 Q51.9875 1096.69 51.9875 1087.97 Q51.9875 1079.22 55.043 1074.63 Q58.1217 1070.03 63.9319 1070.03 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip640)\" d=\"M84.0938 1099.33 L88.978 1099.33 L88.978 1105.21 L84.0938 1105.21 L84.0938 1099.33 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip640)\" d=\"M99.2095 1070.65 L117.566 1070.65 L117.566 1074.59 L103.492 1074.59 L103.492 1083.06 Q104.51 1082.71 105.529 1082.55 Q106.547 1082.37 107.566 1082.37 Q113.353 1082.37 116.733 1085.54 Q120.112 1088.71 120.112 1094.12 Q120.112 1099.7 116.64 1102.8 Q113.168 1105.88 106.848 1105.88 Q104.672 1105.88 102.404 1105.51 Q100.159 1105.14 97.7511 1104.4 L97.7511 1099.7 Q99.8345 1100.84 102.057 1101.39 Q104.279 1101.95 106.756 1101.95 Q110.76 1101.95 113.098 1099.84 Q115.436 1097.74 115.436 1094.12 Q115.436 1090.51 113.098 1088.41 Q110.76 1086.3 106.756 1086.3 Q104.881 1086.3 103.006 1086.72 Q101.154 1087.13 99.2095 1088.01 L99.2095 1070.65 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip640)\" d=\"M53.7467 729.071 L61.3856 729.071 L61.3856 702.705 L53.0754 704.372 L53.0754 700.112 L61.3393 698.446 L66.0152 698.446 L66.0152 729.071 L73.654 729.071 L73.654 733.006 L53.7467 733.006 L53.7467 729.071 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip640)\" d=\"M83.0984 727.126 L87.9827 727.126 L87.9827 733.006 L83.0984 733.006 L83.0984 727.126 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip640)\" d=\"M108.168 701.524 Q104.557 701.524 102.728 705.089 Q100.922 708.631 100.922 715.76 Q100.922 722.867 102.728 726.432 Q104.557 729.973 108.168 729.973 Q111.802 729.973 113.608 726.432 Q115.436 722.867 115.436 715.76 Q115.436 708.631 113.608 705.089 Q111.802 701.524 108.168 701.524 M108.168 697.821 Q113.978 697.821 117.033 702.427 Q120.112 707.011 120.112 715.76 Q120.112 724.487 117.033 729.094 Q113.978 733.677 108.168 733.677 Q102.358 733.677 99.2789 729.094 Q96.2234 724.487 96.2234 715.76 Q96.2234 707.011 99.2789 702.427 Q102.358 697.821 108.168 697.821 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip640)\" d=\"M54.7421 356.864 L62.381 356.864 L62.381 330.499 L54.0708 332.165 L54.0708 327.906 L62.3347 326.239 L67.0106 326.239 L67.0106 356.864 L74.6494 356.864 L74.6494 360.799 L54.7421 360.799 L54.7421 356.864 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip640)\" d=\"M84.0938 354.92 L88.978 354.92 L88.978 360.799 L84.0938 360.799 L84.0938 354.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip640)\" d=\"M99.2095 326.239 L117.566 326.239 L117.566 330.174 L103.492 330.174 L103.492 338.647 Q104.51 338.299 105.529 338.137 Q106.547 337.952 107.566 337.952 Q113.353 337.952 116.733 341.123 Q120.112 344.295 120.112 349.711 Q120.112 355.29 116.64 358.392 Q113.168 361.471 106.848 361.471 Q104.672 361.471 102.404 361.1 Q100.159 360.73 97.7511 359.989 L97.7511 355.29 Q99.8345 356.424 102.057 356.98 Q104.279 357.535 106.756 357.535 Q110.76 357.535 113.098 355.429 Q115.436 353.322 115.436 349.711 Q115.436 346.1 113.098 343.994 Q110.76 341.887 106.756 341.887 Q104.881 341.887 103.006 342.304 Q101.154 342.721 99.2095 343.6 L99.2095 326.239 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip642)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  218.281,1257.87 251.175,1107.47 284.069,1232.86 316.963,1424.08 349.856,924.161 382.75,87.9763 415.644,1252.75 448.537,1131.67 481.431,1264.96 514.325,1445.72 \n",
       "  547.219,1347.31 580.112,1321.03 613.006,1357.55 645.9,1279.15 678.794,1265.2 711.687,1303.11 744.581,1318.12 777.475,1316.26 810.369,1298.11 843.262,1286.6 \n",
       "  876.156,1370.46 909.05,1294.16 941.944,1315.56 974.837,1311.26 1007.73,1279.27 1040.62,1326.84 1073.52,1314.51 1106.41,1267.75 1139.31,1301.14 1172.2,1375.58 \n",
       "  1205.09,1330.22 1237.99,1327.89 1270.88,1347.66 1303.77,1337.78 1336.67,1347.08 1369.56,1365.69 1402.46,1348.36 1435.35,1343.82 1468.24,1351.04 1501.14,1334.52 \n",
       "  1534.03,1344.64 1566.92,1364.64 1599.82,1301.72 1632.71,1383.25 1665.61,1320.79 1698.5,1305.91 1731.39,1328.82 1764.29,1333.82 1797.18,1323.7 1830.07,1344.87 \n",
       "  1862.97,1325.68 1895.86,1346.38 1928.76,1334.75 1961.65,1325.68 1994.54,1366.97 2027.44,1369.06 2060.33,1296.72 2093.22,1298.69 2126.12,1332.43 2159.01,1291.02 \n",
       "  2191.91,1291.48 2224.8,1385.58 2257.69,1309.63 2290.59,1384.07 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip640)\" d=\"\n",
       "M1983.03 198.898 L2279.53 198.898 L2279.53 95.2176 L1983.03 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip640)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1983.03,198.898 2279.53,198.898 2279.53,95.2176 1983.03,95.2176 1983.03,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip640)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2007.44,147.058 2153.88,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip640)\" d=\"M2192.13 166.745 Q2190.33 171.375 2188.61 172.787 Q2186.9 174.199 2184.03 174.199 L2180.63 174.199 L2180.63 170.634 L2183.13 170.634 Q2184.89 170.634 2185.86 169.8 Q2186.83 168.967 2188.01 165.865 L2188.78 163.921 L2178.29 138.412 L2182.8 138.412 L2190.91 158.689 L2199.01 138.412 L2203.52 138.412 L2192.13 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip640)\" d=\"M2210.81 160.402 L2218.45 160.402 L2218.45 134.037 L2210.14 135.703 L2210.14 131.444 L2218.41 129.778 L2223.08 129.778 L2223.08 160.402 L2230.72 160.402 L2230.72 164.338 L2210.81 164.338 L2210.81 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/episodes\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        X  = X_0\n",
    "\n",
    "        for k = 1:T\n",
    "\n",
    "            # 1. Choose action\n",
    "            if rand() < epsilon\n",
    "                if rand() < EXPrand \n",
    "                    A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                else\n",
    "                    A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                end\n",
    "            else\n",
    "\n",
    "                A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                if A == 1000.0 # Indicates no values in this region\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "\n",
    "            # 2. Cache last state\n",
    "            qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "            # 3. Generate the next stae\n",
    "            Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "            # 4. Collect reward R( s, a, s' )\n",
    "            R_t = cartpole_reward( Xp )\n",
    "\n",
    "            # 5. Get the optimal action at the next state\n",
    "            a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "            # 6. Compute the value at the next state\n",
    "\n",
    "            V_tp1_opt = query_value_fuzzy( \n",
    "                Q_kdTree, G, V, \n",
    "                get_Q( \n",
    "                    select_X_vector( Xp ), \n",
    "                    a_tp1_opt \n",
    "                ); \n",
    "                k = vNN \n",
    "            )\n",
    "            if isnan( V_tp1_opt )\n",
    "                V_tp1_opt = 0.0\n",
    "            end\n",
    "\n",
    "\n",
    "            # 7. Blend the value back into nearest points\n",
    "\n",
    "            idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "            nNear      = size( idxs, 1 )\n",
    "            for i = 1:nNear\n",
    "                j    = idxs[i]\n",
    "                if !isnan( wgts[i] ) \n",
    "\n",
    "                    # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                    VS[j] = VS[j] + alpha*( R_t + V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "                    \n",
    "                end\n",
    "            end\n",
    "\n",
    "            states[:,k] = Xp\n",
    "            actions[k]  = A\n",
    "\n",
    "            X = Xp\n",
    "        end\n",
    "\n",
    "        s_l    = vertical_score_s( states, aMargin, ts )\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "\n",
    "        # Swap Q-functions for Double Q-Learning\n",
    "        vSwp = copy( VS   )\n",
    "        VS   = copy( V    )\n",
    "        V    = copy( vSwp )\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "    \n",
    "    if (s_Avg > bestAvg) && true\n",
    "        println( \"BLEND\" )\n",
    "        bestAvg = s_Avg\n",
    "        vBAv    = copy( V ) # Try a blend of both next\n",
    "        vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V )\n",
    "    end\n",
    "    \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c593da-dc6b-4658-a102-7988776030cd",
   "metadata": {},
   "source": [
    "# Method 2 Performance, Longest Vertical Duration [s]\n",
    "Each score is the best run out of an entire training period: 64 epochs of 64 episodes each, Q-function swap after every episode  \n",
    "* Plain: 2.12\n",
    "* Blended: 3.14, 33.15\n",
    "* TD: 28.24, 17.57\n",
    "* TD, Blended:25.21, 30.70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
