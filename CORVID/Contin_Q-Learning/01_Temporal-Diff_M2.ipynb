{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.01953 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 \n",
    "gamma    = 0.99 \n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes =  64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   =  64 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "beta   = 0.15\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = false\n",
    "N_peaks =  40\n",
    "N_steps = 200\n",
    "lambda  =   0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.20000000000000004, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.3100000000000001, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.18000000000000002, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.5800000000000003, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 1.2400000000000009, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.5800000000000003, epsilon: 0.0078125\n",
      "Average Score: 0.27187500000000026\n",
      "\n",
      "Epoch 2, Best Score: 1.390000000000001\n",
      "Training Iteration 4 score: 0.07, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.18000000000000002, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.24000000000000007, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.20000000000000004, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.35000000000000014, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.11234375000000005\n",
      "\n",
      "Epoch 3, Best Score: 1.390000000000001\n",
      "Training Iteration 4 score: 0.12999999999999998, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.13999999999999999, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.16, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.5600000000000003, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.8400000000000005, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.20000000000000004, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.47000000000000025, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.3300000000000001, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.6200000000000003, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.18000000000000002, epsilon: 0.0078125\n",
      "Average Score: 0.13453125000000005\n",
      "\n",
      "Epoch 4, Best Score: 1.390000000000001\n",
      "Training Iteration 4 score: 0.47000000000000025, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.3000000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.45000000000000023, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.3200000000000001, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.23000000000000007, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.08, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.26000000000000006, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.17, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.17, epsilon: 0.0078125\n",
      "Average Score: 0.17125000000000012\n",
      "\n",
      "Epoch 5, Best Score: 1.390000000000001\n",
      "Training Iteration 4 score: 0.3200000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.18000000000000002, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 1.6300000000000012, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.26000000000000006, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.08, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.15, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.15, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.16, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.34000000000000014, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 1.2100000000000009, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.9600000000000006, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.4400000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 26.450000000001335, epsilon: 0.0078125\n",
      "Average Score: 0.7864062500000208\n",
      "\n",
      "Epoch 6, Best Score: 26.450000000001335\n",
      "Training Iteration 4 score: 0.7100000000000004, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.2700000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.36000000000000015, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.35000000000000014, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.23000000000000007, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.16, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.6700000000000004, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.5200000000000002, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.2800000000000001, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.3300000000000001, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.9700000000000006, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.35500000000000004\n",
      "\n",
      "Epoch 7, Best Score: 26.450000000001335\n",
      "Training Iteration 4 score: 1.270000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 2.7399999999999856, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.8700000000000006, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.2700000000000001, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.11999999999999998, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.2700000000000001, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.07, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.15, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.23656249999999987\n",
      "\n",
      "Epoch 8, Best Score: 26.450000000001335\n",
      "Training Iteration 4 score: 0.17, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.6300000000000003, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.5600000000000003, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.5200000000000002, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.36000000000000015, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.2046875000000001\n",
      "\n",
      "Epoch 9, Best Score: 26.450000000001335\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.4000000000000002, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 1.1500000000000008, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.18000000000000002, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.8200000000000005, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.35000000000000014, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.6200000000000003, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.47000000000000025, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.6765625000000073\n",
      "\n",
      "Epoch 10, Best Score: 26.450000000001335\n",
      "Training Iteration 4 score: 0.22000000000000006, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.26000000000000006, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.25000000000000006, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.13999999999999999, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.7400000000000004, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.36000000000000015, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.5200000000000002, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 6.529999999999905, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.6400000000000003, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.7700000000000005, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.48000000000000026, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 1.0000000000000007, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.47000000000000025, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.8551562499999946\n",
      "\n",
      "Epoch 11, Best Score: 26.450000000001335\n",
      "Training Iteration 4 score: 0.21000000000000005, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.10999999999999999, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.4400000000000002, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.2800000000000001, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.12999999999999998, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.09, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.4300000000000002, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.07, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.12999999999999998, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 1.1400000000000008, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.48000000000000026, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.36000000000000015, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.3900000000000002, epsilon: 0.0078125\n",
      "Average Score: 0.2500000000000001\n",
      "\n",
      "Epoch 12, Best Score: 26.450000000001335\n",
      "Training Iteration 4 score: 0.7900000000000005, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.7000000000000004, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.8000000000000005, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.9500000000000006, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.45000000000000023, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.3900000000000002, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.6200000000000003, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.18000000000000002, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.08, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.08, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.3200000000000001, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.1795312500000001\n",
      "\n",
      "Epoch 13, Best Score: 26.450000000001335\n",
      "Training Iteration 4 score: 0.26000000000000006, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.17, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.6900000000000004, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.34000000000000014, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.17, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.2800000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.2800000000000001, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.17, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 34.22000000000176, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.3200000000000001, epsilon: 0.0078125\n",
      "Average Score: 0.6634375000000277\n",
      "\n",
      "Epoch 14, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.48000000000000026, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.45000000000000023, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 1.420000000000001, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.12999999999999998, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.21000000000000005, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.2900000000000001, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.25000000000000006, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 1.1400000000000008, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 1.1400000000000008, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.08, epsilon: 0.0078125\n",
      "Average Score: 0.2034375000000001\n",
      "\n",
      "Epoch 15, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 1.0800000000000007, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.09, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.9800000000000006, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.4000000000000002, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.36000000000000015, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.6100000000000003, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.21000000000000005, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.7000000000000004, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.16, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.07, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.4100000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.4300000000000002, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.34000000000000014, epsilon: 0.0078125\n",
      "Average Score: 2.059843750000063\n",
      "\n",
      "Epoch 16, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.18000000000000002, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.10999999999999999, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.24000000000000007, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.5800000000000003, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.35000000000000014, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.17, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.3100000000000001, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.22000000000000006, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.21765625000000005\n",
      "\n",
      "Epoch 17, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.36000000000000015, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.13999999999999999, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.49000000000000027, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.2700000000000001, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.2900000000000001, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.4300000000000002, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.46000000000000024, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.21000000000000005, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.5700000000000003, epsilon: 0.0078125\n",
      "Average Score: 0.1979687500000001\n",
      "\n",
      "Epoch 18, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.8000000000000005, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 2.5199999999999902, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 5.799999999999921, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.11999999999999998, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.8800000000000006, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 1.360000000000001, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 1.350000000000001, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 1.5200000000000011, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 1.2000000000000008, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 1.9000000000000015, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 1.5400000000000011, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.6315624999999986\n",
      "\n",
      "Epoch 19, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.25000000000000006, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.2700000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 1.9700000000000015, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 2.2299999999999964, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.9000000000000006, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.5700000000000003, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.5200000000000002, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 4.539999999999948, epsilon: 0.0078125\n",
      "Average Score: 0.639218749999998\n",
      "\n",
      "Epoch 20, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.17, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.3300000000000001, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 2.5199999999999902, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 1.2648437500000214\n",
      "\n",
      "Epoch 21, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.4000000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.6000000000000003, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.5100000000000002, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.46000000000000024, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.8900000000000006, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.4200000000000002, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.17750000000000005\n",
      "\n",
      "Epoch 22, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.00875\n",
      "\n",
      "Epoch 23, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 24, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 5.909999999999918, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.6400000000000003, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.38000000000000017, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 1.9000000000000015, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 1.7100000000000013, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.07, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.5400000000000003, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 1.6700000000000013, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.36000000000000015, epsilon: 0.0078125\n",
      "Average Score: 0.4576562499999986\n",
      "\n",
      "Epoch 25, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.09999999999999999, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.13999999999999999, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.2700000000000001, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.35000000000000014, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.7200000000000004, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.9500000000000006, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.4200000000000002, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.25000000000000006, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.1882812500000001\n",
      "\n",
      "Epoch 26, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.2700000000000001, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.6400000000000003, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.9400000000000006, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.09468750000000005\n",
      "\n",
      "Epoch 27, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.5900000000000003, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.08109374999999994\n",
      "\n",
      "Epoch 28, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.3900000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 1.500000000000001, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 3.2199999999999753, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 4.329999999999952, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 2.809999999999984, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.7800000000000005, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.6100000000000003, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.9300000000000006, epsilon: 0.0078125\n",
      "Average Score: 0.40015624999999866\n",
      "\n",
      "Epoch 29, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.3100000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.6700000000000004, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.19000000000000003, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.22000000000000006, epsilon: 0.0078125\n",
      "Average Score: 0.04578125000000002\n",
      "\n",
      "Epoch 30, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.5400000000000003, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.5000000000000002, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.6100000000000003, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.31078124999999596\n",
      "\n",
      "Epoch 31, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.37000000000000016, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.3000000000000001, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.5500000000000003, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.07187500000000004\n",
      "\n",
      "Epoch 32, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 33, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.010781250000000006\n",
      "\n",
      "Epoch 34, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.014687500000000004\n",
      "\n",
      "Epoch 35, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.7500000000000004, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.3100000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.07750000000000004\n",
      "\n",
      "Epoch 36, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.3000000000000001, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.3200000000000001, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.06500000000000003\n",
      "\n",
      "Epoch 37, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.23000000000000007, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.04187500000000001\n",
      "\n",
      "Epoch 38, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.049062500000000016\n",
      "\n",
      "Epoch 39, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.24000000000000007, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.025156250000000012\n",
      "\n",
      "Epoch 40, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.24000000000000007, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.37000000000000016, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.15, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.3100000000000001, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.46000000000000024, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.6400000000000003, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.2900000000000001, epsilon: 0.0078125\n",
      "Average Score: 0.6189062499999979\n",
      "\n",
      "Epoch 41, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.9000000000000006, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 30.140000000001912, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 2.249999999999996, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.9800000000000006, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.6400000000000003, epsilon: 0.0078125\n",
      "Average Score: 1.3110937500000501\n",
      "\n",
      "Epoch 42, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.2900000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.3100000000000001, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.19000000000000003, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.23000000000000007, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 1.5300000000000011, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.17, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.8400000000000005, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.6100000000000003, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 1.0600000000000007, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.5700000000000003, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.13999999999999999, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.5500000000000003, epsilon: 0.0078125\n",
      "Average Score: 0.7640625000000149\n",
      "\n",
      "Epoch 43, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.8000000000000005, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.6500000000000004, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.26000000000000006, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.5182812499999991\n",
      "\n",
      "Epoch 44, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.20000000000000004, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.08546875000000004\n",
      "\n",
      "Epoch 45, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.2700000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.20000000000000004, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.38000000000000017, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.45000000000000023, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.20000000000000004, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.21000000000000005, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.17, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.24000000000000007, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.21000000000000005, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.18000000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.4200000000000002, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.1560937500000001\n",
      "\n",
      "Epoch 46, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.22000000000000006, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.17, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.5900000000000003, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.5700000000000003, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.5500000000000003, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.7800000000000005, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.4000000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.17, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.3100000000000001, epsilon: 0.0078125\n",
      "Average Score: 0.2831250000000002\n",
      "\n",
      "Epoch 47, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.20000000000000004, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.4300000000000002, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.18000000000000002, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.17109375000000007\n",
      "\n",
      "Epoch 48, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.18000000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.37000000000000016, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.20000000000000004, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.08, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.3300000000000001, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.17, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.21000000000000005, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.12218750000000003\n",
      "\n",
      "Epoch 49, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.16, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.19000000000000003, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.19000000000000003, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.17, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.18000000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.16, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.17, epsilon: 0.0078125\n",
      "Average Score: 0.085\n",
      "\n",
      "Epoch 50, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.09999999999999999, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.013437500000000003\n",
      "\n",
      "Epoch 51, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.04515625000000002\n",
      "\n",
      "Epoch 52, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.48000000000000026, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.007500000000000004\n",
      "\n",
      "Epoch 53, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.9900000000000007, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.06500000000000003\n",
      "\n",
      "Epoch 54, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.5500000000000003, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.3300000000000001, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.5300000000000002, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.7100000000000004, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.12999999999999998, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.12999999999999998, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.23000000000000007, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.2900000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.13999999999999999, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.25109375000000017\n",
      "\n",
      "Epoch 55, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.3000000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.35000000000000014, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.48000000000000026, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 2.5935937500000716\n",
      "\n",
      "Epoch 56, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.5700000000000003, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.10999999999999999, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.15531250000000008\n",
      "\n",
      "Epoch 57, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.23000000000000007, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.3100000000000001, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.4000000000000002, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.5700000000000003, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.46000000000000024, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.09156250000000005\n",
      "\n",
      "Epoch 58, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.7200000000000004, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.4100000000000002, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.36000000000000015, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.10187500000000006\n",
      "\n",
      "Epoch 59, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.4100000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.047812500000000036\n",
      "\n",
      "Epoch 60, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.8800000000000006, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.14390624999999996\n",
      "\n",
      "Epoch 61, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.8900000000000006, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 1.0400000000000007, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.8400000000000005, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.8200000000000005, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 1.450000000000001, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.12999999999999998, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 1.2000000000000008, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 1.8100000000000014, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.5100000000000002, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.36000000000000015, epsilon: 0.0078125\n",
      "Average Score: 1.0034375000000215\n",
      "\n",
      "Epoch 62, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.45000000000000023, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.26000000000000006, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.24000000000000007, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.18000000000000002, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.7900000000000005, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.13999999999999999, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.6000000000000003, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.18000000000000002, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.3300000000000001, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.20000000000000004, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.5100000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.5000000000000002, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.7399999999999979\n",
      "\n",
      "Epoch 63, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.3100000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.10999999999999999, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.07, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.3900000000000002, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.5900000000000003, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.4100000000000002, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.7800000000000005, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.7000000000000004, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.3100000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.35000000000000014, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.4000000000000002, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.3900000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.38000000000000017, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.35000000000000014, epsilon: 0.0078125\n",
      "Average Score: 0.2626562500000002\n",
      "\n",
      "Epoch 64, Best Score: 34.22000000000176\n",
      "Training Iteration 4 score: 0.6800000000000004, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.3200000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.48000000000000026, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.4400000000000002, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.5700000000000003, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.09999999999999999, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.19000000000000003, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 1.270000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.35000000000000014, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.46000000000000024, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.36000000000000015, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.5400000000000003, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.08, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.3200000000000001, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.17, epsilon: 0.0078125\n",
      "Average Score: 0.2676562500000002\n",
      "Saved a trained Q-table with size (76032,), After 22.58722528616587 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip220\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip220)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip221\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip220)\" d=\"\n",
       "M156.112 1486.45 L2352.76 1486.45 L2352.76 47.2441 L156.112 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip222\">\n",
       "    <rect x=\"156\" y=\"47\" width=\"2198\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip222)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  185.388,1486.45 185.388,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip222)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  514.325,1486.45 514.325,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip222)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  843.262,1486.45 843.262,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip222)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1172.2,1486.45 1172.2,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip222)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1501.14,1486.45 1501.14,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip222)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1830.07,1486.45 1830.07,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip222)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2159.01,1486.45 2159.01,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip220)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip220)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  185.388,1486.45 185.388,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip220)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  514.325,1486.45 514.325,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip220)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  843.262,1486.45 843.262,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip220)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1172.2,1486.45 1172.2,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip220)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1501.14,1486.45 1501.14,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip220)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1830.07,1486.45 1830.07,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip220)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2159.01,1486.45 2159.01,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip220)\" d=\"M185.388 1517.37 Q181.776 1517.37 179.948 1520.93 Q178.142 1524.47 178.142 1531.6 Q178.142 1538.71 179.948 1542.27 Q181.776 1545.82 185.388 1545.82 Q189.022 1545.82 190.827 1542.27 Q192.656 1538.71 192.656 1531.6 Q192.656 1524.47 190.827 1520.93 Q189.022 1517.37 185.388 1517.37 M185.388 1513.66 Q191.198 1513.66 194.253 1518.27 Q197.332 1522.85 197.332 1531.6 Q197.332 1540.33 194.253 1544.94 Q191.198 1549.52 185.388 1549.52 Q179.577 1549.52 176.499 1544.94 Q173.443 1540.33 173.443 1531.6 Q173.443 1522.85 176.499 1518.27 Q179.577 1513.66 185.388 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M489.013 1544.91 L496.651 1544.91 L496.651 1518.55 L488.341 1520.21 L488.341 1515.95 L496.605 1514.29 L501.281 1514.29 L501.281 1544.91 L508.92 1544.91 L508.92 1548.85 L489.013 1548.85 L489.013 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M528.364 1517.37 Q524.753 1517.37 522.924 1520.93 Q521.119 1524.47 521.119 1531.6 Q521.119 1538.71 522.924 1542.27 Q524.753 1545.82 528.364 1545.82 Q531.998 1545.82 533.804 1542.27 Q535.633 1538.71 535.633 1531.6 Q535.633 1524.47 533.804 1520.93 Q531.998 1517.37 528.364 1517.37 M528.364 1513.66 Q534.174 1513.66 537.23 1518.27 Q540.309 1522.85 540.309 1531.6 Q540.309 1540.33 537.23 1544.94 Q534.174 1549.52 528.364 1549.52 Q522.554 1549.52 519.475 1544.94 Q516.42 1540.33 516.42 1531.6 Q516.42 1522.85 519.475 1518.27 Q522.554 1513.66 528.364 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M822.036 1544.91 L838.355 1544.91 L838.355 1548.85 L816.411 1548.85 L816.411 1544.91 Q819.073 1542.16 823.656 1537.53 Q828.262 1532.88 829.443 1531.53 Q831.688 1529.01 832.568 1527.27 Q833.471 1525.51 833.471 1523.82 Q833.471 1521.07 831.526 1519.33 Q829.605 1517.6 826.503 1517.6 Q824.304 1517.6 821.85 1518.36 Q819.42 1519.13 816.642 1520.68 L816.642 1515.95 Q819.466 1514.82 821.92 1514.24 Q824.374 1513.66 826.411 1513.66 Q831.781 1513.66 834.975 1516.35 Q838.17 1519.03 838.17 1523.52 Q838.17 1525.65 837.36 1527.57 Q836.573 1529.47 834.466 1532.07 Q833.887 1532.74 830.786 1535.95 Q827.684 1539.15 822.036 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M858.17 1517.37 Q854.559 1517.37 852.73 1520.93 Q850.924 1524.47 850.924 1531.6 Q850.924 1538.71 852.73 1542.27 Q854.559 1545.82 858.17 1545.82 Q861.804 1545.82 863.609 1542.27 Q865.438 1538.71 865.438 1531.6 Q865.438 1524.47 863.609 1520.93 Q861.804 1517.37 858.17 1517.37 M858.17 1513.66 Q863.98 1513.66 867.035 1518.27 Q870.114 1522.85 870.114 1531.6 Q870.114 1540.33 867.035 1544.94 Q863.98 1549.52 858.17 1549.52 Q852.359 1549.52 849.281 1544.94 Q846.225 1540.33 846.225 1531.6 Q846.225 1522.85 849.281 1518.27 Q852.359 1513.66 858.17 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M1161.04 1530.21 Q1164.4 1530.93 1166.27 1533.2 Q1168.17 1535.47 1168.17 1538.8 Q1168.17 1543.92 1164.65 1546.72 Q1161.13 1549.52 1154.65 1549.52 Q1152.48 1549.52 1150.16 1549.08 Q1147.87 1548.66 1145.42 1547.81 L1145.42 1543.29 Q1147.36 1544.43 1149.68 1545.01 Q1151.99 1545.58 1154.51 1545.58 Q1158.91 1545.58 1161.2 1543.85 Q1163.52 1542.11 1163.52 1538.8 Q1163.52 1535.75 1161.37 1534.03 Q1159.24 1532.3 1155.42 1532.3 L1151.39 1532.3 L1151.39 1528.45 L1155.6 1528.45 Q1159.05 1528.45 1160.88 1527.09 Q1162.71 1525.7 1162.71 1523.11 Q1162.71 1520.45 1160.81 1519.03 Q1158.94 1517.6 1155.42 1517.6 Q1153.5 1517.6 1151.3 1518.01 Q1149.1 1518.43 1146.46 1519.31 L1146.46 1515.14 Q1149.12 1514.4 1151.44 1514.03 Q1153.77 1513.66 1155.83 1513.66 Q1161.16 1513.66 1164.26 1516.09 Q1167.36 1518.5 1167.36 1522.62 Q1167.36 1525.49 1165.72 1527.48 Q1164.07 1529.45 1161.04 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M1187.04 1517.37 Q1183.43 1517.37 1181.6 1520.93 Q1179.79 1524.47 1179.79 1531.6 Q1179.79 1538.71 1181.6 1542.27 Q1183.43 1545.82 1187.04 1545.82 Q1190.67 1545.82 1192.48 1542.27 Q1194.31 1538.71 1194.31 1531.6 Q1194.31 1524.47 1192.48 1520.93 Q1190.67 1517.37 1187.04 1517.37 M1187.04 1513.66 Q1192.85 1513.66 1195.9 1518.27 Q1198.98 1522.85 1198.98 1531.6 Q1198.98 1540.33 1195.9 1544.94 Q1192.85 1549.52 1187.04 1549.52 Q1181.23 1549.52 1178.15 1544.94 Q1175.09 1540.33 1175.09 1531.6 Q1175.09 1522.85 1178.15 1518.27 Q1181.23 1513.66 1187.04 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M1489.31 1518.36 L1477.5 1536.81 L1489.31 1536.81 L1489.31 1518.36 M1488.08 1514.29 L1493.96 1514.29 L1493.96 1536.81 L1498.89 1536.81 L1498.89 1540.7 L1493.96 1540.7 L1493.96 1548.85 L1489.31 1548.85 L1489.31 1540.7 L1473.71 1540.7 L1473.71 1536.19 L1488.08 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M1516.62 1517.37 Q1513.01 1517.37 1511.18 1520.93 Q1509.38 1524.47 1509.38 1531.6 Q1509.38 1538.71 1511.18 1542.27 Q1513.01 1545.82 1516.62 1545.82 Q1520.26 1545.82 1522.06 1542.27 Q1523.89 1538.71 1523.89 1531.6 Q1523.89 1524.47 1522.06 1520.93 Q1520.26 1517.37 1516.62 1517.37 M1516.62 1513.66 Q1522.43 1513.66 1525.49 1518.27 Q1528.57 1522.85 1528.57 1531.6 Q1528.57 1540.33 1525.49 1544.94 Q1522.43 1549.52 1516.62 1549.52 Q1510.81 1549.52 1507.73 1544.94 Q1504.68 1540.33 1504.68 1531.6 Q1504.68 1522.85 1507.73 1518.27 Q1510.81 1513.66 1516.62 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M1804.77 1514.29 L1823.13 1514.29 L1823.13 1518.22 L1809.06 1518.22 L1809.06 1526.7 Q1810.07 1526.35 1811.09 1526.19 Q1812.11 1526 1813.13 1526 Q1818.92 1526 1822.3 1529.17 Q1825.68 1532.34 1825.68 1537.76 Q1825.68 1543.34 1822.2 1546.44 Q1818.73 1549.52 1812.41 1549.52 Q1810.24 1549.52 1807.97 1549.15 Q1805.72 1548.78 1803.32 1548.04 L1803.32 1543.34 Q1805.4 1544.47 1807.62 1545.03 Q1809.84 1545.58 1812.32 1545.58 Q1816.32 1545.58 1818.66 1543.48 Q1821 1541.37 1821 1537.76 Q1821 1534.15 1818.66 1532.04 Q1816.32 1529.94 1812.32 1529.94 Q1810.44 1529.94 1808.57 1530.35 Q1806.72 1530.77 1804.77 1531.65 L1804.77 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M1844.89 1517.37 Q1841.28 1517.37 1839.45 1520.93 Q1837.64 1524.47 1837.64 1531.6 Q1837.64 1538.71 1839.45 1542.27 Q1841.28 1545.82 1844.89 1545.82 Q1848.52 1545.82 1850.33 1542.27 Q1852.16 1538.71 1852.16 1531.6 Q1852.16 1524.47 1850.33 1520.93 Q1848.52 1517.37 1844.89 1517.37 M1844.89 1513.66 Q1850.7 1513.66 1853.75 1518.27 Q1856.83 1522.85 1856.83 1531.6 Q1856.83 1540.33 1853.75 1544.94 Q1850.7 1549.52 1844.89 1549.52 Q1839.08 1549.52 1836 1544.94 Q1832.94 1540.33 1832.94 1531.6 Q1832.94 1522.85 1836 1518.27 Q1839.08 1513.66 1844.89 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M2144.42 1529.7 Q2141.27 1529.7 2139.42 1531.86 Q2137.59 1534.01 2137.59 1537.76 Q2137.59 1541.49 2139.42 1543.66 Q2141.27 1545.82 2144.42 1545.82 Q2147.57 1545.82 2149.39 1543.66 Q2151.25 1541.49 2151.25 1537.76 Q2151.25 1534.01 2149.39 1531.86 Q2147.57 1529.7 2144.42 1529.7 M2153.7 1515.05 L2153.7 1519.31 Q2151.94 1518.48 2150.13 1518.04 Q2148.35 1517.6 2146.59 1517.6 Q2141.96 1517.6 2139.51 1520.72 Q2137.08 1523.85 2136.73 1530.17 Q2138.1 1528.15 2140.16 1527.09 Q2142.22 1526 2144.69 1526 Q2149.9 1526 2152.91 1529.17 Q2155.94 1532.32 2155.94 1537.76 Q2155.94 1543.08 2152.8 1546.3 Q2149.65 1549.52 2144.42 1549.52 Q2138.42 1549.52 2135.25 1544.94 Q2132.08 1540.33 2132.08 1531.6 Q2132.08 1523.41 2135.97 1518.55 Q2139.86 1513.66 2146.41 1513.66 Q2148.17 1513.66 2149.95 1514.01 Q2151.75 1514.36 2153.7 1515.05 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M2174 1517.37 Q2170.39 1517.37 2168.56 1520.93 Q2166.75 1524.47 2166.75 1531.6 Q2166.75 1538.71 2168.56 1542.27 Q2170.39 1545.82 2174 1545.82 Q2177.63 1545.82 2179.44 1542.27 Q2181.27 1538.71 2181.27 1531.6 Q2181.27 1524.47 2179.44 1520.93 Q2177.63 1517.37 2174 1517.37 M2174 1513.66 Q2179.81 1513.66 2182.87 1518.27 Q2185.94 1522.85 2185.94 1531.6 Q2185.94 1540.33 2182.87 1544.94 Q2179.81 1549.52 2174 1549.52 Q2168.19 1549.52 2165.11 1544.94 Q2162.06 1540.33 2162.06 1531.6 Q2162.06 1522.85 2165.11 1518.27 Q2168.19 1513.66 2174 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip222)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,1445.72 2352.76,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip222)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,1183.97 2352.76,1183.97 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip222)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,922.218 2352.76,922.218 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip222)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,660.47 2352.76,660.47 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip222)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,398.721 2352.76,398.721 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip222)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,136.972 2352.76,136.972 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip220)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,1486.45 156.112,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip220)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,1445.72 175.01,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip220)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,1183.97 175.01,1183.97 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip220)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,922.218 175.01,922.218 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip220)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,660.47 175.01,660.47 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip220)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,398.721 175.01,398.721 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip220)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,136.972 175.01,136.972 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip220)\" d=\"M62.9365 1431.51 Q59.3254 1431.51 57.4967 1435.08 Q55.6912 1438.62 55.6912 1445.75 Q55.6912 1452.86 57.4967 1456.42 Q59.3254 1459.96 62.9365 1459.96 Q66.5707 1459.96 68.3763 1456.42 Q70.205 1452.86 70.205 1445.75 Q70.205 1438.62 68.3763 1435.08 Q66.5707 1431.51 62.9365 1431.51 M62.9365 1427.81 Q68.7467 1427.81 71.8022 1432.42 Q74.8809 1437 74.8809 1445.75 Q74.8809 1454.48 71.8022 1459.08 Q68.7467 1463.67 62.9365 1463.67 Q57.1264 1463.67 54.0477 1459.08 Q50.9921 1454.48 50.9921 1445.75 Q50.9921 1437 54.0477 1432.42 Q57.1264 1427.81 62.9365 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M83.0984 1457.12 L87.9827 1457.12 L87.9827 1463 L83.0984 1463 L83.0984 1457.12 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M108.168 1431.51 Q104.557 1431.51 102.728 1435.08 Q100.922 1438.62 100.922 1445.75 Q100.922 1452.86 102.728 1456.42 Q104.557 1459.96 108.168 1459.96 Q111.802 1459.96 113.608 1456.42 Q115.436 1452.86 115.436 1445.75 Q115.436 1438.62 113.608 1435.08 Q111.802 1431.51 108.168 1431.51 M108.168 1427.81 Q113.978 1427.81 117.033 1432.42 Q120.112 1437 120.112 1445.75 Q120.112 1454.48 117.033 1459.08 Q113.978 1463.67 108.168 1463.67 Q102.358 1463.67 99.2789 1459.08 Q96.2234 1454.48 96.2234 1445.75 Q96.2234 1437 99.2789 1432.42 Q102.358 1427.81 108.168 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M63.9319 1169.77 Q60.3208 1169.77 58.4921 1173.33 Q56.6865 1176.87 56.6865 1184 Q56.6865 1191.11 58.4921 1194.67 Q60.3208 1198.21 63.9319 1198.21 Q67.5661 1198.21 69.3717 1194.67 Q71.2004 1191.11 71.2004 1184 Q71.2004 1176.87 69.3717 1173.33 Q67.5661 1169.77 63.9319 1169.77 M63.9319 1166.06 Q69.742 1166.06 72.7976 1170.67 Q75.8763 1175.25 75.8763 1184 Q75.8763 1192.73 72.7976 1197.34 Q69.742 1201.92 63.9319 1201.92 Q58.1217 1201.92 55.043 1197.34 Q51.9875 1192.73 51.9875 1184 Q51.9875 1175.25 55.043 1170.67 Q58.1217 1166.06 63.9319 1166.06 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M84.0938 1195.37 L88.978 1195.37 L88.978 1201.25 L84.0938 1201.25 L84.0938 1195.37 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M99.2095 1166.69 L117.566 1166.69 L117.566 1170.62 L103.492 1170.62 L103.492 1179.09 Q104.51 1178.75 105.529 1178.59 Q106.547 1178.4 107.566 1178.4 Q113.353 1178.4 116.733 1181.57 Q120.112 1184.74 120.112 1190.16 Q120.112 1195.74 116.64 1198.84 Q113.168 1201.92 106.848 1201.92 Q104.672 1201.92 102.404 1201.55 Q100.159 1201.18 97.7511 1200.44 L97.7511 1195.74 Q99.8345 1196.87 102.057 1197.43 Q104.279 1197.98 106.756 1197.98 Q110.76 1197.98 113.098 1195.88 Q115.436 1193.77 115.436 1190.16 Q115.436 1186.55 113.098 1184.44 Q110.76 1182.34 106.756 1182.34 Q104.881 1182.34 103.006 1182.75 Q101.154 1183.17 99.2095 1184.05 L99.2095 1166.69 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M53.7467 935.563 L61.3856 935.563 L61.3856 909.198 L53.0754 910.864 L53.0754 906.605 L61.3393 904.938 L66.0152 904.938 L66.0152 935.563 L73.654 935.563 L73.654 939.498 L53.7467 939.498 L53.7467 935.563 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M83.0984 933.619 L87.9827 933.619 L87.9827 939.498 L83.0984 939.498 L83.0984 933.619 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M108.168 908.017 Q104.557 908.017 102.728 911.582 Q100.922 915.123 100.922 922.253 Q100.922 929.36 102.728 932.924 Q104.557 936.466 108.168 936.466 Q111.802 936.466 113.608 932.924 Q115.436 929.36 115.436 922.253 Q115.436 915.123 113.608 911.582 Q111.802 908.017 108.168 908.017 M108.168 904.313 Q113.978 904.313 117.033 908.92 Q120.112 913.503 120.112 922.253 Q120.112 930.98 117.033 935.586 Q113.978 940.17 108.168 940.17 Q102.358 940.17 99.2789 935.586 Q96.2234 930.98 96.2234 922.253 Q96.2234 913.503 99.2789 908.92 Q102.358 904.313 108.168 904.313 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M54.7421 673.815 L62.381 673.815 L62.381 647.449 L54.0708 649.116 L54.0708 644.856 L62.3347 643.19 L67.0106 643.19 L67.0106 673.815 L74.6494 673.815 L74.6494 677.75 L54.7421 677.75 L54.7421 673.815 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M84.0938 671.87 L88.978 671.87 L88.978 677.75 L84.0938 677.75 L84.0938 671.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M99.2095 643.19 L117.566 643.19 L117.566 647.125 L103.492 647.125 L103.492 655.597 Q104.51 655.25 105.529 655.088 Q106.547 654.903 107.566 654.903 Q113.353 654.903 116.733 658.074 Q120.112 661.245 120.112 666.662 Q120.112 672.24 116.64 675.342 Q113.168 678.421 106.848 678.421 Q104.672 678.421 102.404 678.051 Q100.159 677.68 97.7511 676.94 L97.7511 672.24 Q99.8345 673.375 102.057 673.93 Q104.279 674.486 106.756 674.486 Q110.76 674.486 113.098 672.379 Q115.436 670.273 115.436 666.662 Q115.436 663.051 113.098 660.944 Q110.76 658.838 106.756 658.838 Q104.881 658.838 103.006 659.254 Q101.154 659.671 99.2095 660.551 L99.2095 643.19 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M56.9643 412.066 L73.2837 412.066 L73.2837 416.001 L51.3393 416.001 L51.3393 412.066 Q54.0014 409.311 58.5847 404.682 Q63.1911 400.029 64.3717 398.686 Q66.617 396.163 67.4967 394.427 Q68.3994 392.668 68.3994 390.978 Q68.3994 388.223 66.455 386.487 Q64.5337 384.751 61.4319 384.751 Q59.2328 384.751 56.7791 385.515 Q54.3486 386.279 51.5708 387.83 L51.5708 383.108 Q54.3949 381.973 56.8486 381.395 Q59.3023 380.816 61.3393 380.816 Q66.7096 380.816 69.9041 383.501 Q73.0985 386.186 73.0985 390.677 Q73.0985 392.807 72.2883 394.728 Q71.5013 396.626 69.3948 399.219 Q68.8161 399.89 65.7143 403.108 Q62.6124 406.302 56.9643 412.066 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M83.0984 410.121 L87.9827 410.121 L87.9827 416.001 L83.0984 416.001 L83.0984 410.121 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M108.168 384.52 Q104.557 384.52 102.728 388.085 Q100.922 391.626 100.922 398.756 Q100.922 405.862 102.728 409.427 Q104.557 412.969 108.168 412.969 Q111.802 412.969 113.608 409.427 Q115.436 405.862 115.436 398.756 Q115.436 391.626 113.608 388.085 Q111.802 384.52 108.168 384.52 M108.168 380.816 Q113.978 380.816 117.033 385.422 Q120.112 390.006 120.112 398.756 Q120.112 407.483 117.033 412.089 Q113.978 416.672 108.168 416.672 Q102.358 416.672 99.2789 412.089 Q96.2234 407.483 96.2234 398.756 Q96.2234 390.006 99.2789 385.422 Q102.358 380.816 108.168 380.816 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M57.9597 150.317 L74.279 150.317 L74.279 154.252 L52.3347 154.252 L52.3347 150.317 Q54.9967 147.563 59.58 142.933 Q64.1865 138.28 65.367 136.938 Q67.6124 134.414 68.492 132.678 Q69.3948 130.919 69.3948 129.229 Q69.3948 126.475 67.4504 124.739 Q65.5291 123.003 62.4272 123.003 Q60.2282 123.003 57.7745 123.766 Q55.344 124.53 52.5662 126.081 L52.5662 121.359 Q55.3903 120.225 57.8439 119.646 Q60.2976 119.067 62.3347 119.067 Q67.705 119.067 70.8994 121.753 Q74.0939 124.438 74.0939 128.928 Q74.0939 131.058 73.2837 132.979 Q72.4966 134.877 70.3902 137.47 Q69.8115 138.141 66.7096 141.359 Q63.6078 144.553 57.9597 150.317 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M84.0938 148.373 L88.978 148.373 L88.978 154.252 L84.0938 154.252 L84.0938 148.373 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M99.2095 119.692 L117.566 119.692 L117.566 123.628 L103.492 123.628 L103.492 132.1 Q104.51 131.752 105.529 131.59 Q106.547 131.405 107.566 131.405 Q113.353 131.405 116.733 134.577 Q120.112 137.748 120.112 143.164 Q120.112 148.743 116.64 151.845 Q113.168 154.924 106.848 154.924 Q104.672 154.924 102.404 154.553 Q100.159 154.183 97.7511 153.442 L97.7511 148.743 Q99.8345 149.877 102.057 150.433 Q104.279 150.988 106.756 150.988 Q110.76 150.988 113.098 148.882 Q115.436 146.776 115.436 143.164 Q115.436 139.553 113.098 137.447 Q110.76 135.34 106.756 135.34 Q104.881 135.34 103.006 135.757 Q101.154 136.174 99.2095 137.053 L99.2095 119.692 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip222)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  218.281,1303.39 251.175,1386.9 284.069,1375.29 316.963,1356.07 349.856,1034.03 382.75,1259.87 415.644,1321.88 448.537,1338.56 481.431,1091.54 514.325,998.044 \n",
       "  547.219,1314.84 580.112,1351.73 613.006,1098.41 645.9,1339.22 678.794,367.393 711.687,1331.77 744.581,1342.08 777.475,1115.09 810.369,1111.09 843.262,783.573 \n",
       "  876.156,1352.79 909.05,1441.14 941.944,1445.72 974.837,1206.13 1007.73,1347.15 1040.62,1396.15 1073.52,1403.26 1106.41,1236.23 1139.31,1421.75 1172.2,1283.02 \n",
       "  1205.09,1408.09 1237.99,1445.72 1270.88,1440.07 1303.77,1438.03 1336.67,1405.14 1369.56,1411.69 1402.46,1423.79 1435.35,1420.03 1468.24,1432.55 1501.14,1121.72 \n",
       "  1534.03,759.362 1566.92,1045.73 1599.82,1174.4 1632.71,1400.97 1665.61,1364 1698.5,1297.5 1731.39,1356.15 1764.29,1381.75 1797.18,1401.22 1830.07,1438.68 \n",
       "  1862.97,1422.08 1895.86,1441.79 1928.76,1411.69 1961.65,1314.27 1994.54,87.9763 2027.44,1364.41 2060.33,1397.78 2093.22,1392.38 2126.12,1420.69 2159.01,1370.38 \n",
       "  2191.91,920.419 2224.8,1058.33 2257.69,1308.22 2290.59,1305.6 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip220)\" d=\"\n",
       "M1983.03 198.898 L2279.53 198.898 L2279.53 95.2176 L1983.03 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip220)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1983.03,198.898 2279.53,198.898 2279.53,95.2176 1983.03,95.2176 1983.03,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip220)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2007.44,147.058 2153.88,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip220)\" d=\"M2192.13 166.745 Q2190.33 171.375 2188.61 172.787 Q2186.9 174.199 2184.03 174.199 L2180.63 174.199 L2180.63 170.634 L2183.13 170.634 Q2184.89 170.634 2185.86 169.8 Q2186.83 168.967 2188.01 165.865 L2188.78 163.921 L2178.29 138.412 L2182.8 138.412 L2190.91 158.689 L2199.01 138.412 L2203.52 138.412 L2192.13 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip220)\" d=\"M2210.81 160.402 L2218.45 160.402 L2218.45 134.037 L2210.14 135.703 L2210.14 131.444 L2218.41 129.778 L2223.08 129.778 L2223.08 160.402 L2230.72 160.402 L2230.72 164.338 L2210.81 164.338 L2210.81 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/episodes\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        X  = X_0\n",
    "        \n",
    "        ##### Double Q-Learning ###########################################\n",
    "\n",
    "        for k = 1:T\n",
    "\n",
    "            # 1. Choose action\n",
    "            if rand() < epsilon\n",
    "                if rand() < EXPrand \n",
    "                    A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                else\n",
    "                    A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                end\n",
    "            else\n",
    "\n",
    "                A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                if A == 1000.0 # Indicates no values in this region\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "\n",
    "            # 2. Cache last state\n",
    "            qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "            # 3. Generate the next stae\n",
    "            Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "            # 4. Collect reward R( s, a, s' )\n",
    "            R_t = cartpole_reward( Xp )\n",
    "\n",
    "            # 5. Get the optimal action at the next state\n",
    "            a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "            # 6. Compute the value at the next state\n",
    "\n",
    "            V_tp1_opt = query_value_fuzzy( \n",
    "                Q_kdTree, G, V, \n",
    "                get_Q( \n",
    "                    select_X_vector( Xp ), \n",
    "                    a_tp1_opt \n",
    "                ); \n",
    "                k = vNN \n",
    "            )\n",
    "            if isnan( V_tp1_opt )\n",
    "                V_tp1_opt = 0.0\n",
    "            end\n",
    "\n",
    "\n",
    "            # 7. Blend the value back into nearest points\n",
    "\n",
    "            idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "            nNear      = size( idxs, 1 )\n",
    "            for i = 1:nNear\n",
    "                j    = idxs[i]\n",
    "                if !isnan( wgts[i] ) \n",
    "\n",
    "                    # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                    VS[j] = VS[j] + alpha*( R_t + V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "                    \n",
    "                end\n",
    "            end\n",
    "\n",
    "            states[:,k] = Xp\n",
    "            actions[k]  = A\n",
    "\n",
    "            X = Xp\n",
    "        end\n",
    "\n",
    "        s_l    = vertical_score_s( states, aMargin, ts )\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        if useElig\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "\n",
    "        # Swap Q-functions for Double Q-Learning\n",
    "        vSwp = copy( VS   )\n",
    "        VS   = copy( V    )\n",
    "        V    = copy( vSwp )\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709555b9-2598-4281-a634-c7b0681277d0",
   "metadata": {},
   "source": [
    "# Method 2 Performance, Average Vertical Duration [s]\n",
    "Each score is the best average score of the last two epochs: 64 epochs of 64 episodes each, Q-function swap after every episode \n",
    "\n",
    "### TD Tuning\n",
    "\n",
    "$\\alpha = 0.99$: 0.238  \n",
    "$\\alpha = 0.75$: 0.257  \n",
    "$\\alpha = 0.50$: 0.191   \n",
    "$\\alpha = 0.25$: 0.170  \n",
    "$\\alpha = 0.125$: 0.290  \n",
    "$\\alpha = 0.0625$: 0.208, but fantastic performance in the middle of training  \n",
    "$\\alpha = 0.03125$: 0.978  \n",
    "$\\alpha = 0.02344$: 2.567  \n",
    "$\\alpha = 0.01953$: 0.268  \n",
    "$\\alpha = 0.015625$: 0.095  \n",
    " \n",
    "### Add gamma?\n",
    " \n",
    "### Double-Q Tuning, Swap Evey N Episodes\n",
    "$\\%\\ \\ 2$:  \n",
    "$\\%\\ \\ 4$:  \n",
    "$\\%\\ \\ 8$:  \n",
    "$\\%16$:  \n",
    "$\\%32$:  \n",
    "$\\%64$:  \n",
    "\n",
    "\n",
    "\n",
    "### Blend: Best Episode\n",
    "\n",
    "$\\beta = 0.07$:  \n",
    "$\\beta = 0.15$: 0.244\n",
    "\n",
    "| Method      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n",
    "| ----------- | ------- | ------- | ------- | ------- | ------- | ---- |\n",
    "| Blend (Epi) |         |         |         |         |         |      |\n",
    "| Blend (Epo) |         |         |         |         |         |      |\n",
    "| TD          |         |         |         |         |         |      |\n",
    "| TD  + ????? |         |         |         |         |         |      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
