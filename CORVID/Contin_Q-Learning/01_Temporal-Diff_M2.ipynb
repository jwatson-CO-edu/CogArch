{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    # if thetaDotN > maxThetaDot\n",
    "    #     R -= thetaDotN\n",
    "    # end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.15\n",
    "gamma    = 0.99 \n",
    "epsMin   = 0.05 # 0.05\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes =  64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   =  64 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0, Best Average: -100.0\n",
      "Training Iteration 4 score: 0.7200000000000004, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.21000000000000005, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.5600000000000003, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.7500000000000004, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.13999999999999999, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 1.0700000000000007, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 1.0400000000000007, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.15, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.21000000000000005, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.16, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 7.779999999999879, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.36328124999999817\n",
      "BLEND\n",
      "\n",
      "Epoch 2, Best Score: 7.779999999999879, Best Average: 0.36328124999999817\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.7500000000000004, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.34000000000000014, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 1.1000000000000008, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 2.4199999999999924, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.5300000000000002, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.4200000000000002, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.6900000000000004, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.36000000000000015, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.4100000000000002, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.4400000000000002, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2854687499999999\n",
      "\n",
      "Epoch 3, Best Score: 7.779999999999879, Best Average: 0.36328124999999817\n",
      "Training Iteration 4 score: 0.38000000000000017, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 1.0300000000000007, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.17, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.22000000000000006, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 1.460000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.12999999999999998, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 1.8600000000000014, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 1.0100000000000007, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.8200000000000005, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.7800000000000005, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 1.1500000000000008, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.3300000000000001, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.24343750000000017\n",
      "\n",
      "Epoch 4, Best Score: 7.779999999999879, Best Average: 0.36328124999999817\n",
      "Training Iteration 4 score: 0.20000000000000004, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.26000000000000006, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.20000000000000004, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.3100000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.19000000000000003, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.3100000000000001, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.21000000000000005, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.5800000000000003, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.3900000000000002, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.5200000000000002, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 2.0000000000000013, epsilon: 0.05703125000000056\n",
      "Average Score: 0.4564062499999971\n",
      "BLEND\n",
      "\n",
      "Epoch 5, Best Score: 16.709999999999813, Best Average: 0.4564062499999971\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.6700000000000004, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.22000000000000006, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.35000000000000014, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.5400000000000003, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.4100000000000002, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.4100000000000002, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 1.6000000000000012, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 2.0799999999999996, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.060000000000000005, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 2.109999999999999, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 1.2100000000000009, epsilon: 0.05703125000000056\n",
      "Average Score: 1.6645312500000489\n",
      "BLEND\n",
      "\n",
      "Epoch 6, Best Score: 33.5300000000019, Best Average: 1.6645312500000489\n",
      "Training Iteration 4 score: 0.4100000000000002, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.2800000000000001, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.5700000000000003, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 1.6200000000000012, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.6900000000000004, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.19000000000000003, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.3100000000000001, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.47000000000000025, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.2800000000000001, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.8000000000000005, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.4200000000000002, epsilon: 0.05703125000000056\n",
      "Average Score: 1.1371875000000424\n",
      "\n",
      "Epoch 7, Best Score: 33.5300000000019, Best Average: 1.6645312500000489\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.7700000000000005, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.09, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.20000000000000004, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.5100000000000002, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.18000000000000002, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.7200000000000004, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 2.0400000000000005, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 1.280000000000001, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 30.030000000001895, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 1.6000000000000012, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.5800000000000003, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.8090625000000298\n",
      "\n",
      "Epoch 8, Best Score: 33.5300000000019, Best Average: 1.6645312500000489\n",
      "Training Iteration 4 score: 0.22000000000000006, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.09999999999999999, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.20000000000000004, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.5800000000000003, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.2800000000000001, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.20000000000000004, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.47000000000000025, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.16531250000000014\n",
      "\n",
      "Epoch 9, Best Score: 33.5300000000019, Best Average: 1.6645312500000489\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 1.470000000000001, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.7100000000000004, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.3900000000000002, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.2700000000000001, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.5900000000000003, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 1.0300000000000007, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.8300000000000005, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.8842187500000122\n",
      "\n",
      "Epoch 10, Best Score: 33.5300000000019, Best Average: 1.6645312500000489\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.4000000000000002, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.34000000000000014, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.045156250000000016\n",
      "\n",
      "Epoch 11, Best Score: 33.5300000000019, Best Average: 1.6645312500000489\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.2900000000000001, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.49000000000000027, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.23000000000000007, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.05437500000000003\n",
      "\n",
      "Epoch 12, Best Score: 33.5300000000019, Best Average: 1.6645312500000489\n",
      "Training Iteration 4 score: 22.240000000000677, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 10.569999999999819, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 12.38999999999978, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.2800000000000001, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 1.1500000000000008, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 1.2518750000000092\n",
      "\n",
      "Epoch 13, Best Score: 33.5300000000019, Best Average: 1.6645312500000489\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.8000000000000005, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 1.1600000000000008, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.06234375000000004\n",
      "\n",
      "Epoch 14, Best Score: 33.5300000000019, Best Average: 1.6645312500000489\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.24000000000000007, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.035156250000000014\n",
      "\n",
      "Epoch 15, Best Score: 33.5300000000019, Best Average: 1.6645312500000489\n",
      "Training Iteration 4 score: 0.2900000000000001, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.5300000000000002, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.2900000000000001, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 1.0100000000000007, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.17953125000000006\n",
      "\n",
      "Epoch 16, Best Score: 33.5300000000019, Best Average: 1.6645312500000489\n",
      "Training Iteration 4 score: 0.4300000000000002, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 1.2300000000000009, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.3100000000000001, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.7000000000000004, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.35000000000000014, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.10999999999999999, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.3773437499999971\n",
      "\n",
      "Epoch 17, Best Score: 33.5300000000019, Best Average: 1.6645312500000489\n",
      "Training Iteration 4 score: 0.3900000000000002, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.5800000000000003, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.026250000000000013\n",
      "\n",
      "Epoch 18, Best Score: 33.5300000000019, Best Average: 1.6645312500000489\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 28.510000000001657, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 22.97000000000079, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.26000000000000006, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.3200000000000001, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.6100000000000003, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.26000000000000006, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.23000000000000007, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.6900000000000004, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.19000000000000003, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.2900000000000001, epsilon: 0.05703125000000056\n",
      "Average Score: 1.7498437500000654\n",
      "BLEND\n",
      "\n",
      "Epoch 19, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.23000000000000007, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.10999999999999999, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.20000000000000004, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.34000000000000014, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.9500000000000006, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 2.399999999999993, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.23000000000000007, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.13999999999999999, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.23000000000000007, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2212499999999996\n",
      "\n",
      "Epoch 20, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.6700000000000004, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.2900000000000001, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.3200000000000001, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.09, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.17984374999999989\n",
      "\n",
      "Epoch 21, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.46000000000000024, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.9600000000000006, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.3100000000000001, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.24000000000000007, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.3900000000000002, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.09999999999999999, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.20000000000000004, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2181249999999991\n",
      "\n",
      "Epoch 22, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.5300000000000002, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.19000000000000003, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.11999999999999998, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.15, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.6000000000000003, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.3000000000000001, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.8800000000000006, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 1.1500000000000008, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.26515625000000004\n",
      "\n",
      "Epoch 23, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.3000000000000001, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.20000000000000004, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.11999999999999998, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.10999999999999999, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.5700000000000003, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.38000000000000017, epsilon: 0.05703125000000056\n",
      "Average Score: 0.14468750000000008\n",
      "\n",
      "Epoch 24, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.2900000000000001, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.16, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.6000000000000003, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.5300000000000002, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.13999999999999999, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.6700000000000004, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 1.1100000000000008, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.4200000000000002, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.20000000000000004, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.15, epsilon: 0.05703125000000056\n",
      "Average Score: 0.18890625000000008\n",
      "\n",
      "Epoch 25, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.22000000000000006, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.24000000000000007, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.22000000000000006, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.15, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.3000000000000001, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.10281250000000003\n",
      "\n",
      "Epoch 26, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.7600000000000005, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.12999999999999998, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.22000000000000006, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.37000000000000016, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.23000000000000007, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.3100000000000001, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.5100000000000002, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.16468750000000007\n",
      "\n",
      "Epoch 27, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.09999999999999999, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.3200000000000001, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.26000000000000006, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.10999999999999999, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.10999999999999999, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.2900000000000001, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.10999999999999999, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.5700000000000003, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.16, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.9700000000000006, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.25000000000000006, epsilon: 0.05703125000000056\n",
      "Average Score: 0.12156250000000006\n",
      "\n",
      "Epoch 28, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.2900000000000001, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.7200000000000004, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.34000000000000014, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.9100000000000006, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.36000000000000015, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.3100000000000001, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.36000000000000015, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.3100000000000001, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.18328125000000006\n",
      "\n",
      "Epoch 29, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.5100000000000002, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.11999999999999998, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.20000000000000004, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 1.430000000000001, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.35000000000000014, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.11999999999999998, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.16000000000000003\n",
      "\n",
      "Epoch 30, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.09, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.36000000000000015, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.13999999999999999, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.12999999999999998, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.22000000000000006, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.09, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.45000000000000023, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.9000000000000006, epsilon: 0.05703125000000056\n",
      "Average Score: 0.13671875000000006\n",
      "\n",
      "Epoch 31, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.6900000000000004, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.17, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.36000000000000015, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.21000000000000005, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.08, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.07, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.3100000000000001, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.16, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.8700000000000006, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.2900000000000001, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.21000000000000005, epsilon: 0.05703125000000056\n",
      "Average Score: 0.24234375000000016\n",
      "\n",
      "Epoch 32, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.3100000000000001, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.8900000000000006, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.09, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.26000000000000006, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 1.2000000000000008, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 1.7500000000000013, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.10999999999999999, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.19390625000000014\n",
      "\n",
      "Epoch 33, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.09, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 1.0900000000000007, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.15, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.23000000000000007, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.2700000000000001, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.11999999999999998, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.08, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.12999999999999998, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.26046875\n",
      "\n",
      "Epoch 34, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.48000000000000026, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.20000000000000004, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.09999999999999999, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.2700000000000001, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.11999999999999998, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.3000000000000001, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.19000000000000003, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.6000000000000003, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.36000000000000015, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.7300000000000004, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.14093750000000005\n",
      "\n",
      "Epoch 35, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.22000000000000006, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.7500000000000004, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.6500000000000004, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.34000000000000014, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.8200000000000005, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.4300000000000002, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.4100000000000002, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.07, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.15, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.17578125000000008\n",
      "\n",
      "Epoch 36, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.23000000000000007, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.09999999999999999, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.5900000000000003, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.6600000000000004, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.24000000000000007, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.10999999999999999, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.3000000000000001, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.13265625000000003\n",
      "\n",
      "Epoch 37, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.4200000000000002, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.21000000000000005, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.09999999999999999, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.15, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.17, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.13999999999999999, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.060000000000000005, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.08, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.2700000000000001, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.07, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.13999999999999999, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.18000000000000002, epsilon: 0.05703125000000056\n",
      "Average Score: 0.13359375000000004\n",
      "\n",
      "Epoch 38, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.5800000000000003, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.3900000000000002, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.49000000000000027, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.09999999999999999, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.17, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.2900000000000001, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.5000000000000002, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.34000000000000014, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.18000000000000002, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.09, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.49000000000000027, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.4300000000000002, epsilon: 0.05703125000000056\n",
      "Average Score: 0.17718750000000005\n",
      "\n",
      "Epoch 39, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.17, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.20000000000000004, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.12999999999999998, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.13999999999999999, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.12999999999999998, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.15, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.14578125000000008\n",
      "\n",
      "Epoch 40, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.09999999999999999, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.6400000000000003, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.17, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.5600000000000003, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.09, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.060000000000000005, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.060000000000000005, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.34000000000000014, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.14875000000000005\n",
      "\n",
      "Epoch 41, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.3300000000000001, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.09999999999999999, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.01, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.3300000000000001, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.12156250000000005\n",
      "\n",
      "Epoch 42, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.08, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.15, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.18000000000000002, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.22000000000000006, epsilon: 0.05703125000000056\n",
      "Average Score: 0.14187500000000008\n",
      "\n",
      "Epoch 43, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.4000000000000002, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.8400000000000005, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.3000000000000001, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.24000000000000007, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.060000000000000005, epsilon: 0.05703125000000056\n",
      "Average Score: 0.14843750000000008\n",
      "\n",
      "Epoch 44, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.07703125000000004\n",
      "\n",
      "Epoch 45, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.24000000000000007, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.08, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.22000000000000006, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.08, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.15390624999999997\n",
      "\n",
      "Epoch 46, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.21000000000000005, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 1.8600000000000014, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.22000000000000006, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1373437500000001\n",
      "\n",
      "Epoch 47, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.22000000000000006, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.3200000000000001, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.06593750000000002\n",
      "\n",
      "Epoch 48, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.7500000000000004, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.2700000000000001, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.8100000000000005, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.10968750000000005\n",
      "\n",
      "Epoch 49, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.8500000000000005, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.22000000000000006, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.17, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.12578125000000004\n",
      "\n",
      "Epoch 50, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.17, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.12578125000000007\n",
      "\n",
      "Epoch 51, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.15, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.07, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.15, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.08890625000000005\n",
      "\n",
      "Epoch 52, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.45000000000000023, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.5900000000000003, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 1.1300000000000008, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.6500000000000004, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.6400000000000003, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.13578125000000005\n",
      "\n",
      "Epoch 53, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.17, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.38000000000000017, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.08468750000000001\n",
      "\n",
      "Epoch 54, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.09999999999999999, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.22000000000000006, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.9400000000000006, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.13999999999999999, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.6200000000000003, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.14031250000000006\n",
      "\n",
      "Epoch 55, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.14718750000000008\n",
      "\n",
      "Epoch 56, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.2700000000000001, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.22000000000000006, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.10453125000000005\n",
      "\n",
      "Epoch 57, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.17, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.2700000000000001, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.19000000000000003, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.7800000000000005, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.35000000000000014, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.09671875000000005\n",
      "\n",
      "Epoch 58, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.23000000000000007, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.18000000000000002, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.09421875000000006\n",
      "\n",
      "Epoch 59, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.4300000000000002, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.49000000000000027, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.9000000000000006, epsilon: 0.05703125000000056\n",
      "Average Score: 0.13906250000000006\n",
      "\n",
      "Epoch 60, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.16, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.5800000000000003, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.15, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.4100000000000002, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.19000000000000003, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.22000000000000006, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.24000000000000007, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.12203125000000005\n",
      "\n",
      "Epoch 61, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.47000000000000025, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.12531250000000005\n",
      "\n",
      "Epoch 62, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.25000000000000006, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.3000000000000001, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.9800000000000006, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.2800000000000001, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.2700000000000001, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.12937500000000007\n",
      "\n",
      "Epoch 63, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.4200000000000002, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.06531250000000002\n",
      "\n",
      "Epoch 64, Best Score: 33.5300000000019, Best Average: 1.7498437500000654\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.5600000000000003, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.09, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.17, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.4300000000000002, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.47000000000000025, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.08359375000000004\n",
      "Saved a trained Q-table with size (76032,), After 23.371283467610677 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip630\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip630)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip631\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip630)\" d=\"\n",
       "M156.112 1486.45 L2352.76 1486.45 L2352.76 47.2441 L156.112 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip632\">\n",
       "    <rect x=\"156\" y=\"47\" width=\"2198\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip632)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  185.388,1486.45 185.388,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip632)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  514.325,1486.45 514.325,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip632)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  843.262,1486.45 843.262,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip632)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1172.2,1486.45 1172.2,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip632)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1501.14,1486.45 1501.14,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip632)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1830.07,1486.45 1830.07,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip632)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2159.01,1486.45 2159.01,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  185.388,1486.45 185.388,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  514.325,1486.45 514.325,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  843.262,1486.45 843.262,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1172.2,1486.45 1172.2,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1501.14,1486.45 1501.14,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1830.07,1486.45 1830.07,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2159.01,1486.45 2159.01,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip630)\" d=\"M185.388 1517.37 Q181.776 1517.37 179.948 1520.93 Q178.142 1524.47 178.142 1531.6 Q178.142 1538.71 179.948 1542.27 Q181.776 1545.82 185.388 1545.82 Q189.022 1545.82 190.827 1542.27 Q192.656 1538.71 192.656 1531.6 Q192.656 1524.47 190.827 1520.93 Q189.022 1517.37 185.388 1517.37 M185.388 1513.66 Q191.198 1513.66 194.253 1518.27 Q197.332 1522.85 197.332 1531.6 Q197.332 1540.33 194.253 1544.94 Q191.198 1549.52 185.388 1549.52 Q179.577 1549.52 176.499 1544.94 Q173.443 1540.33 173.443 1531.6 Q173.443 1522.85 176.499 1518.27 Q179.577 1513.66 185.388 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M489.013 1544.91 L496.651 1544.91 L496.651 1518.55 L488.341 1520.21 L488.341 1515.95 L496.605 1514.29 L501.281 1514.29 L501.281 1544.91 L508.92 1544.91 L508.92 1548.85 L489.013 1548.85 L489.013 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M528.364 1517.37 Q524.753 1517.37 522.924 1520.93 Q521.119 1524.47 521.119 1531.6 Q521.119 1538.71 522.924 1542.27 Q524.753 1545.82 528.364 1545.82 Q531.998 1545.82 533.804 1542.27 Q535.633 1538.71 535.633 1531.6 Q535.633 1524.47 533.804 1520.93 Q531.998 1517.37 528.364 1517.37 M528.364 1513.66 Q534.174 1513.66 537.23 1518.27 Q540.309 1522.85 540.309 1531.6 Q540.309 1540.33 537.23 1544.94 Q534.174 1549.52 528.364 1549.52 Q522.554 1549.52 519.475 1544.94 Q516.42 1540.33 516.42 1531.6 Q516.42 1522.85 519.475 1518.27 Q522.554 1513.66 528.364 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M822.036 1544.91 L838.355 1544.91 L838.355 1548.85 L816.411 1548.85 L816.411 1544.91 Q819.073 1542.16 823.656 1537.53 Q828.262 1532.88 829.443 1531.53 Q831.688 1529.01 832.568 1527.27 Q833.471 1525.51 833.471 1523.82 Q833.471 1521.07 831.526 1519.33 Q829.605 1517.6 826.503 1517.6 Q824.304 1517.6 821.85 1518.36 Q819.42 1519.13 816.642 1520.68 L816.642 1515.95 Q819.466 1514.82 821.92 1514.24 Q824.374 1513.66 826.411 1513.66 Q831.781 1513.66 834.975 1516.35 Q838.17 1519.03 838.17 1523.52 Q838.17 1525.65 837.36 1527.57 Q836.573 1529.47 834.466 1532.07 Q833.887 1532.74 830.786 1535.95 Q827.684 1539.15 822.036 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M858.17 1517.37 Q854.559 1517.37 852.73 1520.93 Q850.924 1524.47 850.924 1531.6 Q850.924 1538.71 852.73 1542.27 Q854.559 1545.82 858.17 1545.82 Q861.804 1545.82 863.609 1542.27 Q865.438 1538.71 865.438 1531.6 Q865.438 1524.47 863.609 1520.93 Q861.804 1517.37 858.17 1517.37 M858.17 1513.66 Q863.98 1513.66 867.035 1518.27 Q870.114 1522.85 870.114 1531.6 Q870.114 1540.33 867.035 1544.94 Q863.98 1549.52 858.17 1549.52 Q852.359 1549.52 849.281 1544.94 Q846.225 1540.33 846.225 1531.6 Q846.225 1522.85 849.281 1518.27 Q852.359 1513.66 858.17 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M1161.04 1530.21 Q1164.4 1530.93 1166.27 1533.2 Q1168.17 1535.47 1168.17 1538.8 Q1168.17 1543.92 1164.65 1546.72 Q1161.13 1549.52 1154.65 1549.52 Q1152.48 1549.52 1150.16 1549.08 Q1147.87 1548.66 1145.42 1547.81 L1145.42 1543.29 Q1147.36 1544.43 1149.68 1545.01 Q1151.99 1545.58 1154.51 1545.58 Q1158.91 1545.58 1161.2 1543.85 Q1163.52 1542.11 1163.52 1538.8 Q1163.52 1535.75 1161.37 1534.03 Q1159.24 1532.3 1155.42 1532.3 L1151.39 1532.3 L1151.39 1528.45 L1155.6 1528.45 Q1159.05 1528.45 1160.88 1527.09 Q1162.71 1525.7 1162.71 1523.11 Q1162.71 1520.45 1160.81 1519.03 Q1158.94 1517.6 1155.42 1517.6 Q1153.5 1517.6 1151.3 1518.01 Q1149.1 1518.43 1146.46 1519.31 L1146.46 1515.14 Q1149.12 1514.4 1151.44 1514.03 Q1153.77 1513.66 1155.83 1513.66 Q1161.16 1513.66 1164.26 1516.09 Q1167.36 1518.5 1167.36 1522.62 Q1167.36 1525.49 1165.72 1527.48 Q1164.07 1529.45 1161.04 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M1187.04 1517.37 Q1183.43 1517.37 1181.6 1520.93 Q1179.79 1524.47 1179.79 1531.6 Q1179.79 1538.71 1181.6 1542.27 Q1183.43 1545.82 1187.04 1545.82 Q1190.67 1545.82 1192.48 1542.27 Q1194.31 1538.71 1194.31 1531.6 Q1194.31 1524.47 1192.48 1520.93 Q1190.67 1517.37 1187.04 1517.37 M1187.04 1513.66 Q1192.85 1513.66 1195.9 1518.27 Q1198.98 1522.85 1198.98 1531.6 Q1198.98 1540.33 1195.9 1544.94 Q1192.85 1549.52 1187.04 1549.52 Q1181.23 1549.52 1178.15 1544.94 Q1175.09 1540.33 1175.09 1531.6 Q1175.09 1522.85 1178.15 1518.27 Q1181.23 1513.66 1187.04 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M1489.31 1518.36 L1477.5 1536.81 L1489.31 1536.81 L1489.31 1518.36 M1488.08 1514.29 L1493.96 1514.29 L1493.96 1536.81 L1498.89 1536.81 L1498.89 1540.7 L1493.96 1540.7 L1493.96 1548.85 L1489.31 1548.85 L1489.31 1540.7 L1473.71 1540.7 L1473.71 1536.19 L1488.08 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M1516.62 1517.37 Q1513.01 1517.37 1511.18 1520.93 Q1509.38 1524.47 1509.38 1531.6 Q1509.38 1538.71 1511.18 1542.27 Q1513.01 1545.82 1516.62 1545.82 Q1520.26 1545.82 1522.06 1542.27 Q1523.89 1538.71 1523.89 1531.6 Q1523.89 1524.47 1522.06 1520.93 Q1520.26 1517.37 1516.62 1517.37 M1516.62 1513.66 Q1522.43 1513.66 1525.49 1518.27 Q1528.57 1522.85 1528.57 1531.6 Q1528.57 1540.33 1525.49 1544.94 Q1522.43 1549.52 1516.62 1549.52 Q1510.81 1549.52 1507.73 1544.94 Q1504.68 1540.33 1504.68 1531.6 Q1504.68 1522.85 1507.73 1518.27 Q1510.81 1513.66 1516.62 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M1804.77 1514.29 L1823.13 1514.29 L1823.13 1518.22 L1809.06 1518.22 L1809.06 1526.7 Q1810.07 1526.35 1811.09 1526.19 Q1812.11 1526 1813.13 1526 Q1818.92 1526 1822.3 1529.17 Q1825.68 1532.34 1825.68 1537.76 Q1825.68 1543.34 1822.2 1546.44 Q1818.73 1549.52 1812.41 1549.52 Q1810.24 1549.52 1807.97 1549.15 Q1805.72 1548.78 1803.32 1548.04 L1803.32 1543.34 Q1805.4 1544.47 1807.62 1545.03 Q1809.84 1545.58 1812.32 1545.58 Q1816.32 1545.58 1818.66 1543.48 Q1821 1541.37 1821 1537.76 Q1821 1534.15 1818.66 1532.04 Q1816.32 1529.94 1812.32 1529.94 Q1810.44 1529.94 1808.57 1530.35 Q1806.72 1530.77 1804.77 1531.65 L1804.77 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M1844.89 1517.37 Q1841.28 1517.37 1839.45 1520.93 Q1837.64 1524.47 1837.64 1531.6 Q1837.64 1538.71 1839.45 1542.27 Q1841.28 1545.82 1844.89 1545.82 Q1848.52 1545.82 1850.33 1542.27 Q1852.16 1538.71 1852.16 1531.6 Q1852.16 1524.47 1850.33 1520.93 Q1848.52 1517.37 1844.89 1517.37 M1844.89 1513.66 Q1850.7 1513.66 1853.75 1518.27 Q1856.83 1522.85 1856.83 1531.6 Q1856.83 1540.33 1853.75 1544.94 Q1850.7 1549.52 1844.89 1549.52 Q1839.08 1549.52 1836 1544.94 Q1832.94 1540.33 1832.94 1531.6 Q1832.94 1522.85 1836 1518.27 Q1839.08 1513.66 1844.89 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M2144.42 1529.7 Q2141.27 1529.7 2139.42 1531.86 Q2137.59 1534.01 2137.59 1537.76 Q2137.59 1541.49 2139.42 1543.66 Q2141.27 1545.82 2144.42 1545.82 Q2147.57 1545.82 2149.39 1543.66 Q2151.25 1541.49 2151.25 1537.76 Q2151.25 1534.01 2149.39 1531.86 Q2147.57 1529.7 2144.42 1529.7 M2153.7 1515.05 L2153.7 1519.31 Q2151.94 1518.48 2150.13 1518.04 Q2148.35 1517.6 2146.59 1517.6 Q2141.96 1517.6 2139.51 1520.72 Q2137.08 1523.85 2136.73 1530.17 Q2138.1 1528.15 2140.16 1527.09 Q2142.22 1526 2144.69 1526 Q2149.9 1526 2152.91 1529.17 Q2155.94 1532.32 2155.94 1537.76 Q2155.94 1543.08 2152.8 1546.3 Q2149.65 1549.52 2144.42 1549.52 Q2138.42 1549.52 2135.25 1544.94 Q2132.08 1540.33 2132.08 1531.6 Q2132.08 1523.41 2135.97 1518.55 Q2139.86 1513.66 2146.41 1513.66 Q2148.17 1513.66 2149.95 1514.01 Q2151.75 1514.36 2153.7 1515.05 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M2174 1517.37 Q2170.39 1517.37 2168.56 1520.93 Q2166.75 1524.47 2166.75 1531.6 Q2166.75 1538.71 2168.56 1542.27 Q2170.39 1545.82 2174 1545.82 Q2177.63 1545.82 2179.44 1542.27 Q2181.27 1538.71 2181.27 1531.6 Q2181.27 1524.47 2179.44 1520.93 Q2177.63 1517.37 2174 1517.37 M2174 1513.66 Q2179.81 1513.66 2182.87 1518.27 Q2185.94 1522.85 2185.94 1531.6 Q2185.94 1540.33 2182.87 1544.94 Q2179.81 1549.52 2174 1549.52 Q2168.19 1549.52 2165.11 1544.94 Q2162.06 1540.33 2162.06 1531.6 Q2162.06 1522.85 2165.11 1518.27 Q2168.19 1513.66 2174 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip632)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,1466.39 2352.76,1466.39 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip632)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,1072.53 2352.76,1072.53 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip632)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,678.656 2352.76,678.656 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip632)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,284.788 2352.76,284.788 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,1486.45 156.112,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,1466.39 175.01,1466.39 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,1072.53 175.01,1072.53 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,678.656 175.01,678.656 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,284.788 175.01,284.788 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip630)\" d=\"M62.9365 1452.19 Q59.3254 1452.19 57.4967 1455.76 Q55.6912 1459.3 55.6912 1466.43 Q55.6912 1473.53 57.4967 1477.1 Q59.3254 1480.64 62.9365 1480.64 Q66.5707 1480.64 68.3763 1477.1 Q70.205 1473.53 70.205 1466.43 Q70.205 1459.3 68.3763 1455.76 Q66.5707 1452.19 62.9365 1452.19 M62.9365 1448.49 Q68.7467 1448.49 71.8022 1453.1 Q74.8809 1457.68 74.8809 1466.43 Q74.8809 1475.16 71.8022 1479.76 Q68.7467 1484.35 62.9365 1484.35 Q57.1264 1484.35 54.0477 1479.76 Q50.9921 1475.16 50.9921 1466.43 Q50.9921 1457.68 54.0477 1453.1 Q57.1264 1448.49 62.9365 1448.49 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M83.0984 1477.79 L87.9827 1477.79 L87.9827 1483.67 L83.0984 1483.67 L83.0984 1477.79 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M108.168 1452.19 Q104.557 1452.19 102.728 1455.76 Q100.922 1459.3 100.922 1466.43 Q100.922 1473.53 102.728 1477.1 Q104.557 1480.64 108.168 1480.64 Q111.802 1480.64 113.608 1477.1 Q115.436 1473.53 115.436 1466.43 Q115.436 1459.3 113.608 1455.76 Q111.802 1452.19 108.168 1452.19 M108.168 1448.49 Q113.978 1448.49 117.033 1453.1 Q120.112 1457.68 120.112 1466.43 Q120.112 1475.16 117.033 1479.76 Q113.978 1484.35 108.168 1484.35 Q102.358 1484.35 99.2789 1479.76 Q96.2234 1475.16 96.2234 1466.43 Q96.2234 1457.68 99.2789 1453.1 Q102.358 1448.49 108.168 1448.49 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M63.9319 1058.32 Q60.3208 1058.32 58.4921 1061.89 Q56.6865 1065.43 56.6865 1072.56 Q56.6865 1079.67 58.4921 1083.23 Q60.3208 1086.77 63.9319 1086.77 Q67.5661 1086.77 69.3717 1083.23 Q71.2004 1079.67 71.2004 1072.56 Q71.2004 1065.43 69.3717 1061.89 Q67.5661 1058.32 63.9319 1058.32 M63.9319 1054.62 Q69.742 1054.62 72.7976 1059.23 Q75.8763 1063.81 75.8763 1072.56 Q75.8763 1081.29 72.7976 1085.89 Q69.742 1090.48 63.9319 1090.48 Q58.1217 1090.48 55.043 1085.89 Q51.9875 1081.29 51.9875 1072.56 Q51.9875 1063.81 55.043 1059.23 Q58.1217 1054.62 63.9319 1054.62 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M84.0938 1083.93 L88.978 1083.93 L88.978 1089.81 L84.0938 1089.81 L84.0938 1083.93 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M99.2095 1055.25 L117.566 1055.25 L117.566 1059.18 L103.492 1059.18 L103.492 1067.65 Q104.51 1067.31 105.529 1067.14 Q106.547 1066.96 107.566 1066.96 Q113.353 1066.96 116.733 1070.13 Q120.112 1073.3 120.112 1078.72 Q120.112 1084.3 116.64 1087.4 Q113.168 1090.48 106.848 1090.48 Q104.672 1090.48 102.404 1090.11 Q100.159 1089.74 97.7511 1088.99 L97.7511 1084.3 Q99.8345 1085.43 102.057 1085.99 Q104.279 1086.54 106.756 1086.54 Q110.76 1086.54 113.098 1084.43 Q115.436 1082.33 115.436 1078.72 Q115.436 1075.11 113.098 1073 Q110.76 1070.89 106.756 1070.89 Q104.881 1070.89 103.006 1071.31 Q101.154 1071.73 99.2095 1072.61 L99.2095 1055.25 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M53.7467 692.001 L61.3856 692.001 L61.3856 665.636 L53.0754 667.302 L53.0754 663.043 L61.3393 661.376 L66.0152 661.376 L66.0152 692.001 L73.654 692.001 L73.654 695.936 L53.7467 695.936 L53.7467 692.001 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M83.0984 690.057 L87.9827 690.057 L87.9827 695.936 L83.0984 695.936 L83.0984 690.057 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M108.168 664.455 Q104.557 664.455 102.728 668.02 Q100.922 671.561 100.922 678.691 Q100.922 685.797 102.728 689.362 Q104.557 692.904 108.168 692.904 Q111.802 692.904 113.608 689.362 Q115.436 685.797 115.436 678.691 Q115.436 671.561 113.608 668.02 Q111.802 664.455 108.168 664.455 M108.168 660.751 Q113.978 660.751 117.033 665.358 Q120.112 669.941 120.112 678.691 Q120.112 687.418 117.033 692.024 Q113.978 696.608 108.168 696.608 Q102.358 696.608 99.2789 692.024 Q96.2234 687.418 96.2234 678.691 Q96.2234 669.941 99.2789 665.358 Q102.358 660.751 108.168 660.751 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M54.7421 298.132 L62.381 298.132 L62.381 271.767 L54.0708 273.433 L54.0708 269.174 L62.3347 267.508 L67.0106 267.508 L67.0106 298.132 L74.6494 298.132 L74.6494 302.068 L54.7421 302.068 L54.7421 298.132 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M84.0938 296.188 L88.978 296.188 L88.978 302.068 L84.0938 302.068 L84.0938 296.188 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M99.2095 267.508 L117.566 267.508 L117.566 271.443 L103.492 271.443 L103.492 279.915 Q104.51 279.568 105.529 279.406 Q106.547 279.22 107.566 279.22 Q113.353 279.22 116.733 282.392 Q120.112 285.563 120.112 290.98 Q120.112 296.558 116.64 299.66 Q113.168 302.739 106.848 302.739 Q104.672 302.739 102.404 302.368 Q100.159 301.998 97.7511 301.257 L97.7511 296.558 Q99.8345 297.693 102.057 298.248 Q104.279 298.804 106.756 298.804 Q110.76 298.804 113.098 296.697 Q115.436 294.591 115.436 290.98 Q115.436 287.369 113.098 285.262 Q110.76 283.156 106.756 283.156 Q104.881 283.156 103.006 283.572 Q101.154 283.989 99.2095 284.869 L99.2095 267.508 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip632)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  218.281,1180.22 251.175,1241.52 284.069,1274.63 316.963,1106.87 349.856,155.18 382.75,570.589 415.644,829.065 448.537,1336.17 481.431,769.862 514.325,1430.82 \n",
       "  547.219,1423.56 580.112,480.245 613.006,1417.28 645.9,1438.7 678.794,1324.97 711.687,1169.15 744.581,1445.72 777.475,87.9763 810.369,1292.11 843.262,1324.72 \n",
       "  876.156,1294.57 909.05,1257.52 941.944,1352.42 974.837,1317.59 1007.73,1385.4 1040.62,1336.66 1073.52,1370.63 1106.41,1322.02 1139.31,1340.36 1172.2,1358.7 \n",
       "  1205.09,1275.49 1237.99,1313.65 1270.88,1261.21 1303.77,1355.37 1336.67,1327.92 1369.56,1361.9 1402.46,1361.16 1435.35,1326.82 1468.24,1351.56 1501.14,1349.22 \n",
       "  1534.03,1370.63 1566.92,1354.63 1599.82,1349.46 1632.71,1405.71 1665.61,1345.16 1698.5,1358.2 1731.39,1414.45 1764.29,1379.99 1797.18,1367.31 1830.07,1367.31 \n",
       "  1862.97,1396.36 1895.86,1359.43 1928.76,1399.68 1961.65,1355.86 1994.54,1350.45 2027.44,1384.05 2060.33,1390.2 2093.22,1392.17 2126.12,1356.85 2159.01,1370.27 \n",
       "  2191.91,1367.68 2224.8,1364.48 2257.69,1414.94 2290.59,1400.54 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip630)\" d=\"\n",
       "M1983.03 198.898 L2279.53 198.898 L2279.53 95.2176 L1983.03 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1983.03,198.898 2279.53,198.898 2279.53,95.2176 1983.03,95.2176 1983.03,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip630)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2007.44,147.058 2153.88,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip630)\" d=\"M2192.13 166.745 Q2190.33 171.375 2188.61 172.787 Q2186.9 174.199 2184.03 174.199 L2180.63 174.199 L2180.63 170.634 L2183.13 170.634 Q2184.89 170.634 2185.86 169.8 Q2186.83 168.967 2188.01 165.865 L2188.78 163.921 L2178.29 138.412 L2182.8 138.412 L2190.91 158.689 L2199.01 138.412 L2203.52 138.412 L2192.13 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M2210.81 160.402 L2218.45 160.402 L2218.45 134.037 L2210.14 135.703 L2210.14 131.444 L2218.41 129.778 L2223.08 129.778 L2223.08 160.402 L2230.72 160.402 L2230.72 164.338 L2210.81 164.338 L2210.81 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/episodes\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        X  = X_0\n",
    "\n",
    "        for k = 1:T\n",
    "\n",
    "            # 1. Choose action\n",
    "            if rand() < epsilon\n",
    "                if rand() < EXPrand \n",
    "                    A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                else\n",
    "                    A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                end\n",
    "            else\n",
    "\n",
    "                A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                if A == 1000.0 # Indicates no values in this region\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "\n",
    "            # 2. Cache last state\n",
    "            qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "            # 3. Generate the next stae\n",
    "            Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "            # 4. Collect reward R( s, a, s' )\n",
    "            R_t = cartpole_reward( Xp )\n",
    "\n",
    "            # 5. Get the optimal action at the next state\n",
    "            a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "            # 6. Compute the value at the next state\n",
    "\n",
    "            V_tp1_opt = query_value_fuzzy( \n",
    "                Q_kdTree, G, V, \n",
    "                get_Q( \n",
    "                    select_X_vector( Xp ), \n",
    "                    a_tp1_opt \n",
    "                ); \n",
    "                k = vNN \n",
    "            )\n",
    "            if isnan( V_tp1_opt )\n",
    "                V_tp1_opt = 0.0\n",
    "            end\n",
    "\n",
    "\n",
    "            # 7. Blend the value back into nearest points\n",
    "\n",
    "            idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "            nNear      = size( idxs, 1 )\n",
    "            for i = 1:nNear\n",
    "                j    = idxs[i]\n",
    "                if !isnan( wgts[i] ) \n",
    "\n",
    "                    # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                    VS[j] = VS[j] + alpha*( R_t + V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "                    \n",
    "                end\n",
    "            end\n",
    "\n",
    "            states[:,k] = Xp\n",
    "            actions[k]  = A\n",
    "\n",
    "            X = Xp\n",
    "        end\n",
    "\n",
    "        s_l    = vertical_score_s( states, aMargin, ts )\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "\n",
    "        # Swap Q-functions for Double Q-Learning\n",
    "        vSwp = copy( VS   )\n",
    "        VS   = copy( V    )\n",
    "        V    = copy( vSwp )\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "    \n",
    "    if (s_Avg > bestAvg) && true\n",
    "        println( \"BLEND\" )\n",
    "        bestAvg = s_Avg\n",
    "        vBAv    = copy( V ) # Try a blend of both next\n",
    "        vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V )\n",
    "    end\n",
    "    \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c593da-dc6b-4658-a102-7988776030cd",
   "metadata": {},
   "source": [
    "# Method 2 Performance, Longest Vertical Duration [s]\n",
    "Each score is the best run out of an entire training period: 64 epochs of 64 episodes each, Q-function swap after every episode.\n",
    "The average over all episodes is much lower, typically less than 1s. This test is only to find settings to apply to follow-on measures to increase overall performance, such as eligibility traces.\n",
    "* Plain: 2.12\n",
    "* Blended: 3.14, 33.15, 2.61, 3.45\n",
    "* TD: 28.24, 17.57, 34.31, 34.32\n",
    "* TD, Blended:25.21, 30.70, 24.22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9defcf2b-31cb-4f1f-b0bc-829ced9549eb",
   "metadata": {},
   "source": [
    "# Method 2 Performance, Longest Vertical Duration [s]\n",
    "Each score is the best run out of an entire training period: 64 epochs of 64 episodes each, Q-function swap after every episode  \n",
    "* Plain: 2.12\n",
    "* Blended: 3.14, 33.15, 2.61, 3.45\n",
    "* TD: 28.24, 17.57, 34.31, 34.32\n",
    "* TD, Blended:25.21, 30.70, 24.22, 33.53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
