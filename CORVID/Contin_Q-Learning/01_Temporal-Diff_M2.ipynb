{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    # if thetaDotN > maxThetaDot\n",
    "    #     R -= thetaDotN\n",
    "    # end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.15\n",
    "gamma    = 0.99 \n",
    "epsMin   = 0.05 # 0.05\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes =  64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   =  64 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0, Best Average: -100.0\n",
      "Training Iteration 4 score: 0.09, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.3900000000000002, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.8500000000000005, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.08375000000000005\n",
      "BLEND\n",
      "\n",
      "Epoch 2, Best Score: 1.2100000000000009, Best Average: 0.08375000000000005\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.12999999999999998, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.09625000000000006\n",
      "BLEND\n",
      "\n",
      "Epoch 3, Best Score: 1.2100000000000009, Best Average: 0.09625000000000006\n",
      "Training Iteration 4 score: 0.12999999999999998, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.5100000000000002, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.6300000000000003, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.7700000000000005, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.09, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.6900000000000004, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.07750000000000003\n",
      "\n",
      "Epoch 4, Best Score: 1.2100000000000009, Best Average: 0.09625000000000006\n",
      "Training Iteration 4 score: 0.22000000000000006, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.3900000000000002, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.46000000000000024, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.3300000000000001, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.8800000000000006, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.9200000000000006, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.5100000000000002, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.26703124999999966\n",
      "BLEND\n",
      "\n",
      "Epoch 5, Best Score: 3.429999999999971, Best Average: 0.26703124999999966\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 1.2500000000000009, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.06125000000000004\n",
      "\n",
      "Epoch 6, Best Score: 3.429999999999971, Best Average: 0.26703124999999966\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.37000000000000016, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.37000000000000016, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 1.470000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.9400000000000006, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1604687500000001\n",
      "\n",
      "Epoch 7, Best Score: 3.429999999999971, Best Average: 0.26703124999999966\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.06609375000000003\n",
      "\n",
      "Epoch 8, Best Score: 3.429999999999971, Best Average: 0.26703124999999966\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.09999999999999999, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.2700000000000001, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.37000000000000016, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.5900000000000003, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.20000000000000004, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.22000000000000006, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.26000000000000006, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.5223437499999966\n",
      "BLEND\n",
      "\n",
      "Epoch 9, Best Score: 10.779999999999815, Best Average: 0.5223437499999966\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.5200000000000002, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 1.260000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 1.1700000000000008, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.09999999999999999, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.6300000000000003, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.46000000000000024, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.30421875000000004\n",
      "\n",
      "Epoch 10, Best Score: 10.779999999999815, Best Average: 0.5223437499999966\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.4653124999999999\n",
      "\n",
      "Epoch 11, Best Score: 10.779999999999815, Best Average: 0.5223437499999966\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.29593749999999985\n",
      "\n",
      "Epoch 12, Best Score: 10.779999999999815, Best Average: 0.5223437499999966\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.8439062499999969\n",
      "BLEND\n",
      "\n",
      "Epoch 13, Best Score: 10.779999999999815, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.8117187499999975\n",
      "\n",
      "Epoch 14, Best Score: 10.779999999999815, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.5300000000000002, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.5900000000000003, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.5000000000000002, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.22000000000000006, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.9400000000000006, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.4000000000000002, epsilon: 0.05703125000000056\n",
      "Average Score: 0.7459374999999955\n",
      "\n",
      "Epoch 15, Best Score: 10.779999999999815, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.20000000000000004, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.3900000000000002, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.8000000000000005, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.20000000000000004, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.4000000000000002, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.2700000000000001, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.6800000000000004, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.21000000000000005, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.3923437499999997\n",
      "\n",
      "Epoch 16, Best Score: 10.779999999999815, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.5100000000000002, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.36000000000000015, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.6800000000000004, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.7000000000000004, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.3100000000000001, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.20890625000000013\n",
      "\n",
      "Epoch 17, Best Score: 10.779999999999815, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.8300000000000005, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.9200000000000006, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.7800000000000005, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.5300000000000002, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 1.0900000000000007, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 1.2200000000000009, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.36000000000000015, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 1.1800000000000008, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.33312500000000017\n",
      "\n",
      "Epoch 18, Best Score: 10.779999999999815, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.36000000000000015, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.3100000000000001, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 3.0199999999999796, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 1.8500000000000014, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.2700000000000001, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.6500000000000004, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.3000000000000001, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.6700000000000004, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.5200000000000002, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.24000000000000007, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.5300000000000002, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.12999999999999998, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.5500000000000003, epsilon: 0.05703125000000056\n",
      "Average Score: 0.6332812500000135\n",
      "\n",
      "Epoch 19, Best Score: 23.510000000000876, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.22000000000000006, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 1.7700000000000014, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.5900000000000003, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.09, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.35000000000000014, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.7071875000000156\n",
      "\n",
      "Epoch 20, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.08359375000000004\n",
      "\n",
      "Epoch 21, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.13999999999999999, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.13999999999999999, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.09765625000000004\n",
      "\n",
      "Epoch 22, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.17, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.3900000000000002, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.8000000000000005, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.35000000000000014, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.23000000000000007, epsilon: 0.05703125000000056\n",
      "Average Score: 0.14656249999999982\n",
      "\n",
      "Epoch 23, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.5500000000000003, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.18000000000000002, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.11999999999999998, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.10999999999999999, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.11999999999999998, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.12999999999999998, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.16, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 1.1000000000000008, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.36000000000000015, epsilon: 0.05703125000000056\n",
      "Average Score: 0.11875000000000006\n",
      "\n",
      "Epoch 24, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.4300000000000002, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.12999999999999998, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.2900000000000001, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.22000000000000006, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.47000000000000025, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.12999999999999998, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.4100000000000002, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.09999999999999999, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.12999999999999998, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.09999999999999999, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1776562500000001\n",
      "\n",
      "Epoch 25, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.5100000000000002, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 2.429999999999992, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.11999999999999998, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.12999999999999998, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.3300000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.09999999999999999, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.12999999999999998, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.09, epsilon: 0.05703125000000056\n",
      "Average Score: 0.24937499999999987\n",
      "\n",
      "Epoch 26, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.5700000000000003, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.20000000000000004, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 1.1400000000000008, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.6500000000000004, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.4100000000000002, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.13999999999999999, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.3200000000000001, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.2900000000000001, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.6700000000000004, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.38000000000000017, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.16, epsilon: 0.05703125000000056\n",
      "Average Score: 0.23953125000000017\n",
      "\n",
      "Epoch 27, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.16, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.20000000000000004, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.10999999999999999, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.26000000000000006, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.21000000000000005, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.3000000000000001, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.19000000000000003, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.34000000000000014, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.15, epsilon: 0.05703125000000056\n",
      "Average Score: 0.16421875000000005\n",
      "\n",
      "Epoch 28, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.6000000000000003, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.20000000000000004, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.11999999999999998, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.36000000000000015, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.34000000000000014, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.5400000000000003, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.25000000000000006, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.17, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1868750000000001\n",
      "\n",
      "Epoch 29, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.12999999999999998, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.3100000000000001, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.11999999999999998, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.36000000000000015, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.16, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.6500000000000004, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.11999999999999998, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.13999999999999999, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.18000000000000002, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1951562500000001\n",
      "\n",
      "Epoch 30, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.4100000000000002, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.5300000000000002, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.13999999999999999, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.10999999999999999, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.23000000000000007, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.6200000000000003, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.11999999999999998, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.11999999999999998, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.18000000000000002, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.09999999999999999, epsilon: 0.05703125000000056\n",
      "Average Score: 0.22203125000000012\n",
      "\n",
      "Epoch 31, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.21000000000000005, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.19000000000000003, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.07, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.08, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.38000000000000017, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.08, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.21000000000000005, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.2700000000000001, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.25000000000000006, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.5800000000000003, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.45000000000000023, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.6200000000000003, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.2900000000000001, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.12999999999999998, epsilon: 0.05703125000000056\n",
      "Average Score: 0.20109375000000015\n",
      "\n",
      "Epoch 32, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.15, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.12999999999999998, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.8800000000000006, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.8800000000000006, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.10999999999999999, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.12999999999999998, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.24000000000000007, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.2800000000000001, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.25000000000000006, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.11999999999999998, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.5200000000000002, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.3100000000000001, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2081250000000001\n",
      "\n",
      "Epoch 33, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.11999999999999998, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.5000000000000002, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.5700000000000003, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.4000000000000002, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.18000000000000002, epsilon: 0.05703125000000056\n",
      "Average Score: 0.17437500000000006\n",
      "\n",
      "Epoch 34, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.5200000000000002, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.6300000000000003, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.24000000000000007, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.22000000000000006, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.20000000000000004, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.4200000000000002, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.16, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.18000000000000002, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.22875000000000015\n",
      "\n",
      "Epoch 35, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.22000000000000006, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.21000000000000005, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.09999999999999999, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.3200000000000001, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.7500000000000004, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.38000000000000017, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.13999999999999999, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.24000000000000007, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.10999999999999999, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.3000000000000001, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.3200000000000001, epsilon: 0.05703125000000056\n",
      "Average Score: 0.20703125000000008\n",
      "\n",
      "Epoch 36, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.13999999999999999, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.36000000000000015, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.19000000000000003, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.15, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.11999999999999998, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 1.0100000000000007, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.11999999999999998, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.12999999999999998, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.2800000000000001, epsilon: 0.05703125000000056\n",
      "Average Score: 0.24671875000000013\n",
      "\n",
      "Epoch 37, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.2900000000000001, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.36000000000000015, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.11999999999999998, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.18000000000000002, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.09999999999999999, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.24000000000000007, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.23000000000000007, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.12999999999999998, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.22000000000000006, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.13999999999999999, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.10999999999999999, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2003125000000001\n",
      "\n",
      "Epoch 38, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.13999999999999999, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.24000000000000007, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.3100000000000001, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.5600000000000003, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.2900000000000001, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.09999999999999999, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.25000000000000006, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.5200000000000002, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.23546875000000012\n",
      "\n",
      "Epoch 39, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.49000000000000027, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.34000000000000014, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.24000000000000007, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.34000000000000014, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.13999999999999999, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.23000000000000007, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.3100000000000001, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.10999999999999999, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.16, epsilon: 0.05703125000000056\n",
      "Average Score: 0.19421875000000005\n",
      "\n",
      "Epoch 40, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.16, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.6100000000000003, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.19000000000000003, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.35000000000000014, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.18000000000000002, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 2.3599999999999937, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.18000000000000002, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.47000000000000025, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.3000000000000001, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.3100000000000001, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.09999999999999999, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.23656249999999998\n",
      "\n",
      "Epoch 41, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.2700000000000001, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.36000000000000015, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.3100000000000001, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.2700000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.16, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.35000000000000014, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.11999999999999998, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.3100000000000001, epsilon: 0.05703125000000056\n",
      "Average Score: 0.18718750000000006\n",
      "\n",
      "Epoch 42, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.10999999999999999, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.4100000000000002, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.11999999999999998, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.21000000000000005, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.18000000000000002, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.17, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 1.2400000000000009, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.19000000000000003, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.22000000000000006, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.12999999999999998, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.09999999999999999, epsilon: 0.05703125000000056\n",
      "Average Score: 0.17671875000000004\n",
      "\n",
      "Epoch 43, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.18000000000000002, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.2700000000000001, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.3100000000000001, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.2900000000000001, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.7500000000000004, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.24000000000000007, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.10999999999999999, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.22000000000000006, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.17, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.11999999999999998, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.17, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.11999999999999998, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.4400000000000002, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.22234375000000003\n",
      "\n",
      "Epoch 44, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.12999999999999998, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.09999999999999999, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.13999999999999999, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.13999999999999999, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.2700000000000001, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.3200000000000001, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.12999999999999998, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.26000000000000006, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.13999999999999999, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.4100000000000002, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.21000000000000005, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.4000000000000002, epsilon: 0.05703125000000056\n",
      "Average Score: 0.14453125000000006\n",
      "\n",
      "Epoch 45, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.25000000000000006, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.17, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.20000000000000004, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.3000000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.08, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.09, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.11999999999999998, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.3000000000000001, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.10999999999999999, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.19000000000000003, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.8800000000000006, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.22000000000000006, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.07, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1846875000000001\n",
      "\n",
      "Epoch 46, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.13999999999999999, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.23000000000000007, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.2700000000000001, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.060000000000000005, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.10999999999999999, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.20000000000000004, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.23000000000000007, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.23000000000000007, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.09999999999999999, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.15, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.36000000000000015, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.6300000000000003, epsilon: 0.05703125000000056\n",
      "Average Score: 0.16921875000000006\n",
      "\n",
      "Epoch 47, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.22000000000000006, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.20000000000000004, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.46000000000000024, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 1.1500000000000008, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.3300000000000001, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.20000000000000004, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.19000000000000003, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.48000000000000026, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.19000000000000003, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.8500000000000005, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.3300000000000001, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.13999999999999999, epsilon: 0.05703125000000056\n",
      "Average Score: 0.20421875000000006\n",
      "\n",
      "Epoch 48, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.25000000000000006, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 1.0700000000000007, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.17, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.6700000000000004, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.21000000000000005, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.12999999999999998, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.6100000000000003, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.18000000000000002, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.13999999999999999, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.2700000000000001, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.5900000000000003, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.4000000000000002, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.13999999999999999, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2829687500000002\n",
      "\n",
      "Epoch 49, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.6100000000000003, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.2900000000000001, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.25000000000000006, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.19000000000000003, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.19000000000000003, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.4300000000000002, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.16, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.36000000000000015, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.26000000000000006, epsilon: 0.05703125000000056\n",
      "Average Score: 0.18765625000000008\n",
      "\n",
      "Epoch 50, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.11999999999999998, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.18000000000000002, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.5100000000000002, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.11999999999999998, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.36000000000000015, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.07, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.09999999999999999, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.18000000000000002, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.2900000000000001, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1981250000000001\n",
      "\n",
      "Epoch 51, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.13999999999999999, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.20000000000000004, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.3300000000000001, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.12999999999999998, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.15, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.18000000000000002, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.2800000000000001, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.15, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.13999999999999999, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.15, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.8000000000000005, epsilon: 0.05703125000000056\n",
      "Average Score: 0.24703125000000017\n",
      "\n",
      "Epoch 52, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.3000000000000001, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.17, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.15, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.19000000000000003, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.10999999999999999, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.12999999999999998, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.19000000000000003, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.45000000000000023, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.9100000000000006, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.21000000000000005, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.10999999999999999, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.25000000000000006, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.19687500000000008\n",
      "\n",
      "Epoch 53, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 1.260000000000001, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 1.1600000000000008, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.21000000000000005, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.20000000000000004, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.23000000000000007, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.9300000000000006, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.2800000000000001, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.7200000000000004, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.23000000000000007, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.09999999999999999, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.09, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2245312500000001\n",
      "\n",
      "Epoch 54, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.17, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.5900000000000003, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 1.0900000000000007, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.5400000000000003, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.03, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.10999999999999999, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.5000000000000002, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.16, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.12999999999999998, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.16, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.26000000000000006, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.09999999999999999, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.05, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2240625000000001\n",
      "\n",
      "Epoch 55, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.17, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.19000000000000003, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.18000000000000002, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.10999999999999999, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.10999999999999999, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.15, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.060000000000000005, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.5300000000000002, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.16, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.17, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.38000000000000017, epsilon: 0.05703125000000056\n",
      "Average Score: 0.21968750000000012\n",
      "\n",
      "Epoch 56, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.24000000000000007, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.24000000000000007, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.2900000000000001, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.09999999999999999, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.12999999999999998, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.09, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.2700000000000001, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.10999999999999999, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.21000000000000005, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.17, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.17, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.25000000000000006, epsilon: 0.05703125000000056\n",
      "Average Score: 0.16671875000000005\n",
      "\n",
      "Epoch 57, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.12999999999999998, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.36000000000000015, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.19000000000000003, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.13999999999999999, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.10999999999999999, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.4400000000000002, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.3200000000000001, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.3100000000000001, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.11999999999999998, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.11999999999999998, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.48000000000000026, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2142187500000001\n",
      "\n",
      "Epoch 58, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.11999999999999998, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.20000000000000004, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 1.2300000000000009, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.5400000000000003, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.10999999999999999, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.17, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.25000000000000006, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.2700000000000001, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.10999999999999999, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.23000000000000007, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.19000000000000003, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.5200000000000002, epsilon: 0.05703125000000056\n",
      "Average Score: 0.21234375000000005\n",
      "\n",
      "Epoch 59, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.13999999999999999, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.12999999999999998, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.15, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.22000000000000006, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.17, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.16, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.4000000000000002, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.15, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.20000000000000004, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.20000000000000004, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.2900000000000001, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.20000000000000004, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.5200000000000002, epsilon: 0.05703125000000056\n",
      "Average Score: 0.23765625\n",
      "\n",
      "Epoch 60, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.2900000000000001, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.18000000000000002, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.3100000000000001, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.12999999999999998, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.8000000000000005, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.25000000000000006, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.6500000000000004, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.22000000000000006, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.10999999999999999, epsilon: 0.05703125000000056\n",
      "Average Score: 0.22468750000000012\n",
      "\n",
      "Epoch 61, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.45000000000000023, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.26000000000000006, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.11999999999999998, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.2700000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.17, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.17, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.10999999999999999, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.18000000000000002, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.12999999999999998, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.12999999999999998, epsilon: 0.05703125000000056\n",
      "Average Score: 0.18937500000000015\n",
      "\n",
      "Epoch 62, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.3000000000000001, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.13999999999999999, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.2800000000000001, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.13999999999999999, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.3000000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.09, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.21000000000000005, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.26000000000000006, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.7200000000000004, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.35000000000000014, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.19062500000000007\n",
      "\n",
      "Epoch 63, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.2900000000000001, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.12999999999999998, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.18000000000000002, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.09999999999999999, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.7100000000000004, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.13999999999999999, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.6600000000000004, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.11999999999999998, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.23000000000000007, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.11999999999999998, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.2800000000000001, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.4300000000000002, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.18828125000000004\n",
      "\n",
      "Epoch 64, Best Score: 24.220000000000987, Best Average: 0.8439062499999969\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.16, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.11999999999999998, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.8600000000000005, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.16, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.2700000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.6500000000000004, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.11999999999999998, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.19000000000000003, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.25000000000000006, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.13999999999999999, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.11999999999999998, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.05, epsilon: 0.05703125000000056\n",
      "Average Score: 0.22109375000000012\n",
      "Saved a trained Q-table with size (76032,), After 24.389225399494173 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip510\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip510)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip511\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip510)\" d=\"\n",
       "M156.598 1486.45 L2352.76 1486.45 L2352.76 47.2441 L156.598 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip512\">\n",
       "    <rect x=\"156\" y=\"47\" width=\"2197\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  185.867,1486.45 185.867,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  514.732,1486.45 514.732,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  843.596,1486.45 843.596,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1172.46,1486.45 1172.46,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1501.33,1486.45 1501.33,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1830.19,1486.45 1830.19,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2159.05,1486.45 2159.05,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  185.867,1486.45 185.867,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  514.732,1486.45 514.732,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  843.596,1486.45 843.596,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1172.46,1486.45 1172.46,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1501.33,1486.45 1501.33,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1830.19,1486.45 1830.19,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2159.05,1486.45 2159.05,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip510)\" d=\"M185.867 1517.37 Q182.256 1517.37 180.427 1520.93 Q178.622 1524.47 178.622 1531.6 Q178.622 1538.71 180.427 1542.27 Q182.256 1545.82 185.867 1545.82 Q189.501 1545.82 191.307 1542.27 Q193.136 1538.71 193.136 1531.6 Q193.136 1524.47 191.307 1520.93 Q189.501 1517.37 185.867 1517.37 M185.867 1513.66 Q191.677 1513.66 194.733 1518.27 Q197.812 1522.85 197.812 1531.6 Q197.812 1540.33 194.733 1544.94 Q191.677 1549.52 185.867 1549.52 Q180.057 1549.52 176.978 1544.94 Q173.923 1540.33 173.923 1531.6 Q173.923 1522.85 176.978 1518.27 Q180.057 1513.66 185.867 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M489.419 1544.91 L497.058 1544.91 L497.058 1518.55 L488.748 1520.21 L488.748 1515.95 L497.012 1514.29 L501.688 1514.29 L501.688 1544.91 L509.327 1544.91 L509.327 1548.85 L489.419 1548.85 L489.419 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M528.771 1517.37 Q525.16 1517.37 523.331 1520.93 Q521.526 1524.47 521.526 1531.6 Q521.526 1538.71 523.331 1542.27 Q525.16 1545.82 528.771 1545.82 Q532.405 1545.82 534.211 1542.27 Q536.04 1538.71 536.04 1531.6 Q536.04 1524.47 534.211 1520.93 Q532.405 1517.37 528.771 1517.37 M528.771 1513.66 Q534.581 1513.66 537.637 1518.27 Q540.715 1522.85 540.715 1531.6 Q540.715 1540.33 537.637 1544.94 Q534.581 1549.52 528.771 1549.52 Q522.961 1549.52 519.882 1544.94 Q516.827 1540.33 516.827 1531.6 Q516.827 1522.85 519.882 1518.27 Q522.961 1513.66 528.771 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M822.37 1544.91 L838.689 1544.91 L838.689 1548.85 L816.745 1548.85 L816.745 1544.91 Q819.407 1542.16 823.99 1537.53 Q828.596 1532.88 829.777 1531.53 Q832.022 1529.01 832.902 1527.27 Q833.805 1525.51 833.805 1523.82 Q833.805 1521.07 831.86 1519.33 Q829.939 1517.6 826.837 1517.6 Q824.638 1517.6 822.184 1518.36 Q819.754 1519.13 816.976 1520.68 L816.976 1515.95 Q819.8 1514.82 822.254 1514.24 Q824.708 1513.66 826.745 1513.66 Q832.115 1513.66 835.309 1516.35 Q838.504 1519.03 838.504 1523.52 Q838.504 1525.65 837.694 1527.57 Q836.907 1529.47 834.8 1532.07 Q834.221 1532.74 831.12 1535.95 Q828.018 1539.15 822.37 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M858.504 1517.37 Q854.893 1517.37 853.064 1520.93 Q851.258 1524.47 851.258 1531.6 Q851.258 1538.71 853.064 1542.27 Q854.893 1545.82 858.504 1545.82 Q862.138 1545.82 863.943 1542.27 Q865.772 1538.71 865.772 1531.6 Q865.772 1524.47 863.943 1520.93 Q862.138 1517.37 858.504 1517.37 M858.504 1513.66 Q864.314 1513.66 867.369 1518.27 Q870.448 1522.85 870.448 1531.6 Q870.448 1540.33 867.369 1544.94 Q864.314 1549.52 858.504 1549.52 Q852.694 1549.52 849.615 1544.94 Q846.559 1540.33 846.559 1531.6 Q846.559 1522.85 849.615 1518.27 Q852.694 1513.66 858.504 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1161.3 1530.21 Q1164.66 1530.93 1166.54 1533.2 Q1168.43 1535.47 1168.43 1538.8 Q1168.43 1543.92 1164.91 1546.72 Q1161.4 1549.52 1154.91 1549.52 Q1152.74 1549.52 1150.42 1549.08 Q1148.13 1548.66 1145.68 1547.81 L1145.68 1543.29 Q1147.62 1544.43 1149.94 1545.01 Q1152.25 1545.58 1154.78 1545.58 Q1159.17 1545.58 1161.47 1543.85 Q1163.78 1542.11 1163.78 1538.8 Q1163.78 1535.75 1161.63 1534.03 Q1159.5 1532.3 1155.68 1532.3 L1151.65 1532.3 L1151.65 1528.45 L1155.86 1528.45 Q1159.31 1528.45 1161.14 1527.09 Q1162.97 1525.7 1162.97 1523.11 Q1162.97 1520.45 1161.07 1519.03 Q1159.2 1517.6 1155.68 1517.6 Q1153.76 1517.6 1151.56 1518.01 Q1149.36 1518.43 1146.72 1519.31 L1146.72 1515.14 Q1149.38 1514.4 1151.7 1514.03 Q1154.04 1513.66 1156.1 1513.66 Q1161.42 1513.66 1164.52 1516.09 Q1167.62 1518.5 1167.62 1522.62 Q1167.62 1525.49 1165.98 1527.48 Q1164.34 1529.45 1161.3 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1187.3 1517.37 Q1183.69 1517.37 1181.86 1520.93 Q1180.05 1524.47 1180.05 1531.6 Q1180.05 1538.71 1181.86 1542.27 Q1183.69 1545.82 1187.3 1545.82 Q1190.93 1545.82 1192.74 1542.27 Q1194.57 1538.71 1194.57 1531.6 Q1194.57 1524.47 1192.74 1520.93 Q1190.93 1517.37 1187.3 1517.37 M1187.3 1513.66 Q1193.11 1513.66 1196.16 1518.27 Q1199.24 1522.85 1199.24 1531.6 Q1199.24 1540.33 1196.16 1544.94 Q1193.11 1549.52 1187.3 1549.52 Q1181.49 1549.52 1178.41 1544.94 Q1175.35 1540.33 1175.35 1531.6 Q1175.35 1522.85 1178.41 1518.27 Q1181.49 1513.66 1187.3 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1489.5 1518.36 L1477.69 1536.81 L1489.5 1536.81 L1489.5 1518.36 M1488.27 1514.29 L1494.15 1514.29 L1494.15 1536.81 L1499.08 1536.81 L1499.08 1540.7 L1494.15 1540.7 L1494.15 1548.85 L1489.5 1548.85 L1489.5 1540.7 L1473.9 1540.7 L1473.9 1536.19 L1488.27 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1516.81 1517.37 Q1513.2 1517.37 1511.37 1520.93 Q1509.57 1524.47 1509.57 1531.6 Q1509.57 1538.71 1511.37 1542.27 Q1513.2 1545.82 1516.81 1545.82 Q1520.45 1545.82 1522.25 1542.27 Q1524.08 1538.71 1524.08 1531.6 Q1524.08 1524.47 1522.25 1520.93 Q1520.45 1517.37 1516.81 1517.37 M1516.81 1513.66 Q1522.62 1513.66 1525.68 1518.27 Q1528.76 1522.85 1528.76 1531.6 Q1528.76 1540.33 1525.68 1544.94 Q1522.62 1549.52 1516.81 1549.52 Q1511 1549.52 1507.92 1544.94 Q1504.87 1540.33 1504.87 1531.6 Q1504.87 1522.85 1507.92 1518.27 Q1511 1513.66 1516.81 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1804.89 1514.29 L1823.25 1514.29 L1823.25 1518.22 L1809.17 1518.22 L1809.17 1526.7 Q1810.19 1526.35 1811.21 1526.19 Q1812.23 1526 1813.25 1526 Q1819.03 1526 1822.41 1529.17 Q1825.79 1532.34 1825.79 1537.76 Q1825.79 1543.34 1822.32 1546.44 Q1818.85 1549.52 1812.53 1549.52 Q1810.35 1549.52 1808.08 1549.15 Q1805.84 1548.78 1803.43 1548.04 L1803.43 1543.34 Q1805.51 1544.47 1807.74 1545.03 Q1809.96 1545.58 1812.44 1545.58 Q1816.44 1545.58 1818.78 1543.48 Q1821.12 1541.37 1821.12 1537.76 Q1821.12 1534.15 1818.78 1532.04 Q1816.44 1529.94 1812.44 1529.94 Q1810.56 1529.94 1808.69 1530.35 Q1806.83 1530.77 1804.89 1531.65 L1804.89 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1845 1517.37 Q1841.39 1517.37 1839.57 1520.93 Q1837.76 1524.47 1837.76 1531.6 Q1837.76 1538.71 1839.57 1542.27 Q1841.39 1545.82 1845 1545.82 Q1848.64 1545.82 1850.44 1542.27 Q1852.27 1538.71 1852.27 1531.6 Q1852.27 1524.47 1850.44 1520.93 Q1848.64 1517.37 1845 1517.37 M1845 1513.66 Q1850.81 1513.66 1853.87 1518.27 Q1856.95 1522.85 1856.95 1531.6 Q1856.95 1540.33 1853.87 1544.94 Q1850.81 1549.52 1845 1549.52 Q1839.19 1549.52 1836.12 1544.94 Q1833.06 1540.33 1833.06 1531.6 Q1833.06 1522.85 1836.12 1518.27 Q1839.19 1513.66 1845 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M2144.46 1529.7 Q2141.31 1529.7 2139.46 1531.86 Q2137.63 1534.01 2137.63 1537.76 Q2137.63 1541.49 2139.46 1543.66 Q2141.31 1545.82 2144.46 1545.82 Q2147.61 1545.82 2149.44 1543.66 Q2151.29 1541.49 2151.29 1537.76 Q2151.29 1534.01 2149.44 1531.86 Q2147.61 1529.7 2144.46 1529.7 M2153.74 1515.05 L2153.74 1519.31 Q2151.98 1518.48 2150.18 1518.04 Q2148.4 1517.6 2146.64 1517.6 Q2142.01 1517.6 2139.55 1520.72 Q2137.12 1523.85 2136.77 1530.17 Q2138.14 1528.15 2140.2 1527.09 Q2142.26 1526 2144.74 1526 Q2149.95 1526 2152.96 1529.17 Q2155.99 1532.32 2155.99 1537.76 Q2155.99 1543.08 2152.84 1546.3 Q2149.69 1549.52 2144.46 1549.52 Q2138.46 1549.52 2135.29 1544.94 Q2132.12 1540.33 2132.12 1531.6 Q2132.12 1523.41 2136.01 1518.55 Q2139.9 1513.66 2146.45 1513.66 Q2148.21 1513.66 2149.99 1514.01 Q2151.8 1514.36 2153.74 1515.05 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M2174.04 1517.37 Q2170.43 1517.37 2168.6 1520.93 Q2166.8 1524.47 2166.8 1531.6 Q2166.8 1538.71 2168.6 1542.27 Q2170.43 1545.82 2174.04 1545.82 Q2177.68 1545.82 2179.48 1542.27 Q2181.31 1538.71 2181.31 1531.6 Q2181.31 1524.47 2179.48 1520.93 Q2177.68 1517.37 2174.04 1517.37 M2174.04 1513.66 Q2179.85 1513.66 2182.91 1518.27 Q2185.99 1522.85 2185.99 1531.6 Q2185.99 1540.33 2182.91 1544.94 Q2179.85 1549.52 2174.04 1549.52 Q2168.23 1549.52 2165.15 1544.94 Q2162.1 1540.33 2162.1 1531.6 Q2162.1 1522.85 2165.15 1518.27 Q2168.23 1513.66 2174.04 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,1205.01 2352.76,1205.01 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,858.058 2352.76,858.058 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,511.101 2352.76,511.101 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,164.144 2352.76,164.144 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1486.45 156.598,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1205.01 175.496,1205.01 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,858.058 175.496,858.058 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,511.101 175.496,511.101 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,164.144 175.496,164.144 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip510)\" d=\"M65.0198 1190.81 Q61.4087 1190.81 59.58 1194.38 Q57.7745 1197.92 57.7745 1205.05 Q57.7745 1212.16 59.58 1215.72 Q61.4087 1219.26 65.0198 1219.26 Q68.6541 1219.26 70.4596 1215.72 Q72.2883 1212.16 72.2883 1205.05 Q72.2883 1197.92 70.4596 1194.38 Q68.6541 1190.81 65.0198 1190.81 M65.0198 1187.11 Q70.83 1187.11 73.8855 1191.72 Q76.9642 1196.3 76.9642 1205.05 Q76.9642 1213.78 73.8855 1218.38 Q70.83 1222.97 65.0198 1222.97 Q59.2097 1222.97 56.131 1218.38 Q53.0754 1213.78 53.0754 1205.05 Q53.0754 1196.3 56.131 1191.72 Q59.2097 1187.11 65.0198 1187.11 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M85.1818 1216.41 L90.066 1216.41 L90.066 1222.29 L85.1818 1222.29 L85.1818 1216.41 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M104.279 1218.36 L120.598 1218.36 L120.598 1222.29 L98.6539 1222.29 L98.6539 1218.36 Q101.316 1215.6 105.899 1210.98 Q110.506 1206.32 111.686 1204.98 Q113.932 1202.46 114.811 1200.72 Q115.714 1198.96 115.714 1197.27 Q115.714 1194.52 113.77 1192.78 Q111.848 1191.04 108.746 1191.04 Q106.547 1191.04 104.094 1191.81 Q101.663 1192.57 98.8854 1194.12 L98.8854 1189.4 Q101.709 1188.27 104.163 1187.69 Q106.617 1187.11 108.654 1187.11 Q114.024 1187.11 117.219 1189.79 Q120.413 1192.48 120.413 1196.97 Q120.413 1199.1 119.603 1201.02 Q118.816 1202.92 116.709 1205.51 Q116.131 1206.18 113.029 1209.4 Q109.927 1212.6 104.279 1218.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M62.9365 843.856 Q59.3254 843.856 57.4967 847.421 Q55.6912 850.963 55.6912 858.092 Q55.6912 865.199 57.4967 868.764 Q59.3254 872.305 62.9365 872.305 Q66.5707 872.305 68.3763 868.764 Q70.205 865.199 70.205 858.092 Q70.205 850.963 68.3763 847.421 Q66.5707 843.856 62.9365 843.856 M62.9365 840.153 Q68.7467 840.153 71.8022 844.759 Q74.8809 849.342 74.8809 858.092 Q74.8809 866.819 71.8022 871.426 Q68.7467 876.009 62.9365 876.009 Q57.1264 876.009 54.0477 871.426 Q50.9921 866.819 50.9921 858.092 Q50.9921 849.342 54.0477 844.759 Q57.1264 840.153 62.9365 840.153 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M83.0984 869.458 L87.9827 869.458 L87.9827 875.338 L83.0984 875.338 L83.0984 869.458 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M111.015 844.852 L99.2095 863.301 L111.015 863.301 L111.015 844.852 M109.788 840.778 L115.668 840.778 L115.668 863.301 L120.598 863.301 L120.598 867.19 L115.668 867.19 L115.668 875.338 L111.015 875.338 L111.015 867.19 L95.4132 867.19 L95.4132 862.676 L109.788 840.778 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M63.2606 496.9 Q59.6495 496.9 57.8208 500.464 Q56.0152 504.006 56.0152 511.136 Q56.0152 518.242 57.8208 521.807 Q59.6495 525.349 63.2606 525.349 Q66.8948 525.349 68.7004 521.807 Q70.5291 518.242 70.5291 511.136 Q70.5291 504.006 68.7004 500.464 Q66.8948 496.9 63.2606 496.9 M63.2606 493.196 Q69.0707 493.196 72.1263 497.802 Q75.205 502.386 75.205 511.136 Q75.205 519.862 72.1263 524.469 Q69.0707 529.052 63.2606 529.052 Q57.4504 529.052 54.3717 524.469 Q51.3162 519.862 51.3162 511.136 Q51.3162 502.386 54.3717 497.802 Q57.4504 493.196 63.2606 493.196 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M83.4225 522.501 L88.3067 522.501 L88.3067 528.381 L83.4225 528.381 L83.4225 522.501 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M109.071 509.237 Q105.922 509.237 104.071 511.39 Q102.242 513.543 102.242 517.293 Q102.242 521.02 104.071 523.196 Q105.922 525.349 109.071 525.349 Q112.219 525.349 114.047 523.196 Q115.899 521.02 115.899 517.293 Q115.899 513.543 114.047 511.39 Q112.219 509.237 109.071 509.237 M118.353 494.585 L118.353 498.844 Q116.594 498.011 114.788 497.571 Q113.006 497.131 111.246 497.131 Q106.617 497.131 104.163 500.256 Q101.733 503.381 101.385 509.7 Q102.751 507.687 104.811 506.622 Q106.871 505.534 109.348 505.534 Q114.557 505.534 117.566 508.705 Q120.598 511.853 120.598 517.293 Q120.598 522.617 117.45 525.835 Q114.302 529.052 109.071 529.052 Q103.075 529.052 99.9039 524.469 Q96.7326 519.862 96.7326 511.136 Q96.7326 502.941 100.621 498.08 Q104.51 493.196 111.061 493.196 Q112.82 493.196 114.603 493.543 Q116.408 493.89 118.353 494.585 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M63.5152 149.943 Q59.9041 149.943 58.0754 153.508 Q56.2699 157.049 56.2699 164.179 Q56.2699 171.285 58.0754 174.85 Q59.9041 178.392 63.5152 178.392 Q67.1494 178.392 68.955 174.85 Q70.7837 171.285 70.7837 164.179 Q70.7837 157.049 68.955 153.508 Q67.1494 149.943 63.5152 149.943 M63.5152 146.239 Q69.3254 146.239 72.3809 150.846 Q75.4596 155.429 75.4596 164.179 Q75.4596 172.906 72.3809 177.512 Q69.3254 182.095 63.5152 182.095 Q57.7051 182.095 54.6264 177.512 Q51.5708 172.906 51.5708 164.179 Q51.5708 155.429 54.6264 150.846 Q57.7051 146.239 63.5152 146.239 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M83.6771 175.545 L88.5614 175.545 L88.5614 181.424 L83.6771 181.424 L83.6771 175.545 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M108.746 165.012 Q105.413 165.012 103.492 166.795 Q101.594 168.577 101.594 171.702 Q101.594 174.827 103.492 176.609 Q105.413 178.392 108.746 178.392 Q112.08 178.392 114.001 176.609 Q115.922 174.804 115.922 171.702 Q115.922 168.577 114.001 166.795 Q112.103 165.012 108.746 165.012 M104.071 163.021 Q101.061 162.281 99.3715 160.221 Q97.7048 158.16 97.7048 155.197 Q97.7048 151.054 100.645 148.647 Q103.608 146.239 108.746 146.239 Q113.908 146.239 116.848 148.647 Q119.788 151.054 119.788 155.197 Q119.788 158.16 118.098 160.221 Q116.432 162.281 113.445 163.021 Q116.825 163.808 118.7 166.1 Q120.598 168.392 120.598 171.702 Q120.598 176.725 117.52 179.41 Q114.464 182.095 108.746 182.095 Q103.029 182.095 99.9502 179.41 Q96.8947 176.725 96.8947 171.702 Q96.8947 168.392 98.7928 166.1 Q100.691 163.808 104.071 163.021 M102.358 155.637 Q102.358 158.322 104.024 159.827 Q105.714 161.332 108.746 161.332 Q111.756 161.332 113.445 159.827 Q115.158 158.322 115.158 155.637 Q115.158 152.952 113.445 151.447 Q111.756 149.943 108.746 149.943 Q105.714 149.943 104.024 151.447 Q102.358 152.952 102.358 155.637 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip512)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  218.754,1406.68 251.64,1385 284.527,1417.53 317.413,1088.73 350.299,1445.72 383.186,1273.59 416.072,1437.31 448.959,645.818 481.845,1024.22 514.732,744.755 \n",
       "  547.618,1038.58 580.505,87.9763 613.391,143.815 646.278,257.931 679.164,871.34 712.051,1189.56 744.937,974.071 777.823,453.365 810.71,325.154 843.596,1406.95 \n",
       "  876.483,1382.56 909.369,1297.72 942.256,1345.97 975.142,1243.78 1008.03,1119.36 1040.92,1136.44 1073.8,1267.09 1106.69,1227.78 1139.57,1213.42 1172.46,1166.79 \n",
       "  1205.35,1203.12 1238.23,1190.92 1271.12,1249.47 1304.01,1155.14 1336.89,1192.82 1369.78,1123.97 1402.67,1204.47 1435.55,1143.48 1468.44,1215.04 1501.33,1141.59 \n",
       "  1534.21,1227.24 1567.1,1245.4 1599.98,1166.25 1632.87,1301.24 1665.76,1231.58 1698.64,1258.41 1731.53,1197.7 1764.42,1061.08 1797.3,1226.43 1830.19,1208.27 \n",
       "  1863.08,1123.43 1895.96,1210.44 1928.85,1162.46 1961.74,1163.27 1994.62,1170.86 2027.51,1262.75 2060.4,1180.35 2093.28,1183.6 2126.17,1139.69 2159.05,1162.19 \n",
       "  2191.94,1223.45 2224.83,1221.28 2257.71,1225.34 2290.6,1168.42 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip510)\" d=\"\n",
       "M1983.1 198.898 L2279.55 198.898 L2279.55 95.2176 L1983.1 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1983.1,198.898 2279.55,198.898 2279.55,95.2176 1983.1,95.2176 1983.1,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2007.5,147.058 2153.92,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip510)\" d=\"M2192.16 166.745 Q2190.35 171.375 2188.64 172.787 Q2186.93 174.199 2184.06 174.199 L2180.65 174.199 L2180.65 170.634 L2183.15 170.634 Q2184.91 170.634 2185.89 169.8 Q2186.86 168.967 2188.04 165.865 L2188.8 163.921 L2178.32 138.412 L2182.83 138.412 L2190.93 158.689 L2199.03 138.412 L2203.55 138.412 L2192.16 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M2210.84 160.402 L2218.48 160.402 L2218.48 134.037 L2210.17 135.703 L2210.17 131.444 L2218.43 129.778 L2223.11 129.778 L2223.11 160.402 L2230.75 160.402 L2230.75 164.338 L2210.84 164.338 L2210.84 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/episodes\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        X  = X_0\n",
    "\n",
    "        for k = 1:T\n",
    "\n",
    "            # 1. Choose action\n",
    "            if rand() < epsilon\n",
    "                if rand() < EXPrand \n",
    "                    A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                else\n",
    "                    A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                end\n",
    "            else\n",
    "\n",
    "                A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                if A == 1000.0 # Indicates no values in this region\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "\n",
    "            # 2. Cache last state\n",
    "            qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "            # 3. Generate the next stae\n",
    "            Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "            # 4. Collect reward R( s, a, s' )\n",
    "            R_t = cartpole_reward( Xp )\n",
    "\n",
    "            # 5. Get the optimal action at the next state\n",
    "            a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "            # 6. Compute the value at the next state\n",
    "\n",
    "            V_tp1_opt = query_value_fuzzy( \n",
    "                Q_kdTree, G, V, \n",
    "                get_Q( \n",
    "                    select_X_vector( Xp ), \n",
    "                    a_tp1_opt \n",
    "                ); \n",
    "                k = vNN \n",
    "            )\n",
    "            if isnan( V_tp1_opt )\n",
    "                V_tp1_opt = 0.0\n",
    "            end\n",
    "\n",
    "\n",
    "            # 7. Blend the value back into nearest points\n",
    "\n",
    "            idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "            nNear      = size( idxs, 1 )\n",
    "            for i = 1:nNear\n",
    "                j    = idxs[i]\n",
    "                if !isnan( wgts[i] ) \n",
    "\n",
    "                    # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                    VS[j] = VS[j] + alpha*( R_t + V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "                    \n",
    "                end\n",
    "            end\n",
    "\n",
    "            states[:,k] = Xp\n",
    "            actions[k]  = A\n",
    "\n",
    "            X = Xp\n",
    "        end\n",
    "\n",
    "        s_l    = vertical_score_s( states, aMargin, ts )\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "\n",
    "        # Swap Q-functions for Double Q-Learning\n",
    "        vSwp = copy( VS   )\n",
    "        VS   = copy( V    )\n",
    "        V    = copy( vSwp )\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "    \n",
    "    if (s_Avg > bestAvg) && true\n",
    "        println( \"BLEND\" )\n",
    "        bestAvg = s_Avg\n",
    "        vBAv    = copy( V ) # Try a blend of both next\n",
    "        vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V )\n",
    "    end\n",
    "    \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c593da-dc6b-4658-a102-7988776030cd",
   "metadata": {},
   "source": [
    "# Method 2 Performance, Longest Vertical Duration [s]\n",
    "Each score is the best run out of an entire training period: 64 epochs of 64 episodes each, Q-function swap after every episode  \n",
    "* Plain: 2.12\n",
    "* Blended: 3.14, 33.15, 2.61\n",
    "* TD: 28.24, 17.57, 34.31\n",
    "* TD, Blended:25.21, 30.70, 24.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
