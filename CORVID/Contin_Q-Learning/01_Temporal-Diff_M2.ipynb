{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.99 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125\n",
    "gamma    = 0.99 \n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes =  64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   =  64 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "beta   = 0.15\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = false\n",
    "N_peaks =  40\n",
    "N_steps = 200\n",
    "lambda  =   0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.6700000000000004, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.5200000000000002, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.11999999999999998, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.34000000000000014, epsilon: 0.0078125\n",
      "Average Score: 0.08546875000000004\n",
      "\n",
      "Epoch 2, Best Score: 1.9600000000000015\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.6800000000000004, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.17, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 2.020000000000001, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.45000000000000023, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.17, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.12999999999999998, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.3200000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.5100000000000002, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.21000000000000005, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.34000000000000014, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.18000000000000002, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.25000000000000006, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.17, epsilon: 0.0078125\n",
      "Average Score: 0.30968750000000034\n",
      "\n",
      "Epoch 3, Best Score: 2.020000000000001\n",
      "Training Iteration 4 score: 0.47000000000000025, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.36000000000000015, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.5700000000000003, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 1.450000000000001, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.3000000000000001, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.38000000000000017, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 1.0600000000000007, epsilon: 0.0078125\n",
      "Average Score: 0.290937499999999\n",
      "\n",
      "Epoch 4, Best Score: 5.639999999999924\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 1.1100000000000008, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.04812500000000002\n",
      "\n",
      "Epoch 5, Best Score: 5.639999999999924\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 1.0700000000000007, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.2800000000000001, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.025937500000000013\n",
      "\n",
      "Epoch 6, Best Score: 5.639999999999924\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.12999999999999998, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.39296874999999376\n",
      "\n",
      "Epoch 7, Best Score: 11.649999999999796\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.06937499999999938\n",
      "\n",
      "Epoch 8, Best Score: 11.649999999999796\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 1.330000000000001, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.48000000000000026, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.4717187500000131\n",
      "\n",
      "Epoch 9, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.10999999999999999, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.4000000000000002, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.36000000000000015, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.12999999999999998, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.1364062500000001\n",
      "\n",
      "Epoch 10, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.3900000000000002, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.15, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.4300000000000002, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.16, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.17, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.19000000000000003, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.13999999999999999, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.2900000000000001, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.16953125000000008\n",
      "\n",
      "Epoch 11, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.6700000000000004, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.24000000000000007, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.11999999999999998, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.11999999999999998, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.6700000000000004, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.19000000000000003, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.26000000000000006, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.08, epsilon: 0.0078125\n",
      "Average Score: 0.18234375000000008\n",
      "\n",
      "Epoch 12, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.20000000000000004, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.45000000000000023, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 1.390000000000001, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.20000000000000004, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.34000000000000014, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 1.350000000000001, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.3300000000000001, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 1.2400000000000009, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.21250000000000008\n",
      "\n",
      "Epoch 13, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.26000000000000006, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.4300000000000002, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.5100000000000002, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.19000000000000003, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.7800000000000005, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.26000000000000006, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.21000000000000005, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.21234375000000016\n",
      "\n",
      "Epoch 14, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.12999999999999998, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.16, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.13999999999999999, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.17, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.3200000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.6900000000000004, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.4400000000000002, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.4000000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.24796875000000015\n",
      "\n",
      "Epoch 15, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.3200000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.3000000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.08, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.46000000000000024, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.3000000000000001, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.17234375000000005\n",
      "\n",
      "Epoch 16, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.21000000000000005, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.5100000000000002, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.16, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.1781250000000001\n",
      "\n",
      "Epoch 17, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.18000000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.2800000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.19000000000000003, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.05, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.5300000000000002, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.08, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.060000000000000005, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.3000000000000001, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.16078125000000007\n",
      "\n",
      "Epoch 18, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.9900000000000007, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.16, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.2900000000000001, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.17, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.19000000000000003, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.17, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.07, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.2700000000000001, epsilon: 0.0078125\n",
      "Average Score: 0.21265625000000016\n",
      "\n",
      "Epoch 19, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.05, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.3900000000000002, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.09999999999999999, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.24000000000000007, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 1.1100000000000008, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.9500000000000006, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.05, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.24109375000000013\n",
      "\n",
      "Epoch 20, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.060000000000000005, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.3300000000000001, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.5100000000000002, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.6600000000000004, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.16, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.05, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.07, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.060000000000000005, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.4400000000000002, epsilon: 0.0078125\n",
      "Average Score: 0.25296875000000013\n",
      "\n",
      "Epoch 21, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.3300000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.9200000000000006, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.24000000000000007, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.25000000000000006, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.15, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.12999999999999998, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.5700000000000003, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.22000000000000006, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.19296875000000013\n",
      "\n",
      "Epoch 22, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.09999999999999999, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.07, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.060000000000000005, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.3300000000000001, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.7800000000000005, epsilon: 0.0078125\n",
      "Average Score: 0.1673437500000001\n",
      "\n",
      "Epoch 23, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.18000000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.12999999999999998, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.08, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.20000000000000004, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.21000000000000005, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.15, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.5000000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.23875000000000016\n",
      "\n",
      "Epoch 24, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.37000000000000016, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 1.5900000000000012, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.07, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 1.370000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.10999999999999999, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.2800000000000001, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.13999999999999999, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.16, epsilon: 0.0078125\n",
      "Average Score: 0.2576562500000002\n",
      "\n",
      "Epoch 25, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.3100000000000001, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.38000000000000017, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.18000000000000002, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.09, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.5800000000000003, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.7000000000000004, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.21000000000000005, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.16046875000000008\n",
      "\n",
      "Epoch 26, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.08, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.37000000000000016, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.24000000000000007, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.7800000000000005, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.5700000000000003, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.4100000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.14984375000000008\n",
      "\n",
      "Epoch 27, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.22000000000000006, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.08, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.3100000000000001, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 1.0100000000000007, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.16, epsilon: 0.0078125\n",
      "Average Score: 0.1767187500000001\n",
      "\n",
      "Epoch 28, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.19000000000000003, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.01, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.13999999999999999, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.20000000000000004, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.18000000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.36000000000000015, epsilon: 0.0078125\n",
      "Average Score: 0.15734375000000006\n",
      "\n",
      "Epoch 29, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 2.2299999999999964, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 1.1000000000000008, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.37000000000000016, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.22000000000000006, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.2800000000000001, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.08, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.21000000000000005, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.4300000000000002, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.26671875\n",
      "\n",
      "Epoch 30, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.09, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 1.0100000000000007, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.2900000000000001, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.23000000000000007, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.34000000000000014, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.2700000000000001, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.1860937500000001\n",
      "\n",
      "Epoch 31, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.10999999999999999, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.24000000000000007, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.47000000000000025, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.08, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.6800000000000004, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.47000000000000025, epsilon: 0.0078125\n",
      "Average Score: 0.20218750000000013\n",
      "\n",
      "Epoch 32, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.6200000000000003, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.08, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.46000000000000024, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.16, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.6100000000000003, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.24000000000000007, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.7700000000000005, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.9600000000000006, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.15, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.48000000000000026, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.21296875000000015\n",
      "\n",
      "Epoch 33, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.4400000000000002, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.6300000000000003, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.8900000000000006, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.36000000000000015, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.10999999999999999, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.34000000000000014, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.060000000000000005, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.2900000000000001, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.18953125000000012\n",
      "\n",
      "Epoch 34, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.2700000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.38000000000000017, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.07, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.18000000000000002, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.3900000000000002, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.7300000000000004, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.08, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.5100000000000002, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.09, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.5500000000000003, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.24984375000000011\n",
      "\n",
      "Epoch 35, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.3000000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.12999999999999998, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.3200000000000001, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.3200000000000001, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.6800000000000004, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.060000000000000005, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.19375000000000006\n",
      "\n",
      "Epoch 36, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.15, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.6700000000000004, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.8400000000000005, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.22000000000000006, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.12999999999999998, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.20000000000000004, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.36000000000000015, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.20000000000000004, epsilon: 0.0078125\n",
      "Average Score: 0.19578125000000007\n",
      "\n",
      "Epoch 37, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.8800000000000006, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.5400000000000003, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.09999999999999999, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.21000000000000005, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.21937500000000013\n",
      "\n",
      "Epoch 38, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.22000000000000006, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.18000000000000002, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.6500000000000004, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.21000000000000005, epsilon: 0.0078125\n",
      "Average Score: 0.1926562500000001\n",
      "\n",
      "Epoch 39, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.47000000000000025, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.3200000000000001, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.19000000000000003, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.38000000000000017, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.8600000000000005, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.37000000000000016, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.20000000000000004, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.2700000000000001, epsilon: 0.0078125\n",
      "Average Score: 0.16703125000000008\n",
      "\n",
      "Epoch 40, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.3300000000000001, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.2900000000000001, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.5300000000000002, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.4000000000000002, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.10999999999999999, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.18328125000000012\n",
      "\n",
      "Epoch 41, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.3900000000000002, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 1.1600000000000008, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.2700000000000001, epsilon: 0.0078125\n",
      "Average Score: 0.19687500000000013\n",
      "\n",
      "Epoch 42, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.5200000000000002, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.7400000000000004, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.07, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.18000000000000002, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.18156250000000007\n",
      "\n",
      "Epoch 43, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.25000000000000006, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.23000000000000007, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.09, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.20000000000000004, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.20000000000000004, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.3028125\n",
      "\n",
      "Epoch 44, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.8100000000000005, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.2900000000000001, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.4000000000000002, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.20000000000000004, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.13999999999999999, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.16, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.48000000000000026, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.8900000000000006, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.23187500000000014\n",
      "\n",
      "Epoch 45, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.15, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.4200000000000002, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.25000000000000006, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.15, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.09999999999999999, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.17703125000000008\n",
      "\n",
      "Epoch 46, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.2900000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.26000000000000006, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.3300000000000001, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.23000000000000007, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.3200000000000001, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.16843750000000007\n",
      "\n",
      "Epoch 47, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.7100000000000004, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.2900000000000001, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.5800000000000003, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.4000000000000002, epsilon: 0.0078125\n",
      "Average Score: 0.22046875000000016\n",
      "\n",
      "Epoch 48, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.5700000000000003, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.4200000000000002, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.20000000000000004, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.23000000000000007, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.8400000000000005, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.4200000000000002, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.07, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 1.430000000000001, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.21000000000000005, epsilon: 0.0078125\n",
      "Average Score: 0.23031250000000014\n",
      "\n",
      "Epoch 49, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.47000000000000025, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.3200000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.23000000000000007, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.38000000000000017, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.09, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.22406250000000016\n",
      "\n",
      "Epoch 50, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.7000000000000004, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.09999999999999999, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.07, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.22000000000000006, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.6300000000000003, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.22000000000000006, epsilon: 0.0078125\n",
      "Average Score: 0.1718750000000001\n",
      "\n",
      "Epoch 51, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.20000000000000004, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.12999999999999998, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.19000000000000003, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.4300000000000002, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.47000000000000025, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.24000000000000007, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.2800000000000001, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.5300000000000002, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.24000000000000007, epsilon: 0.0078125\n",
      "Average Score: 0.15625000000000008\n",
      "\n",
      "Epoch 52, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.22000000000000006, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.16, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.20000000000000004, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.08, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.23000000000000007, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.20000000000000004, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.08, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.203125\n",
      "\n",
      "Epoch 53, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.2700000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.19000000000000003, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.46000000000000024, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.5200000000000002, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 1.0600000000000007, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.38000000000000017, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.9400000000000006, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.17, epsilon: 0.0078125\n",
      "Average Score: 0.20750000000000013\n",
      "\n",
      "Epoch 54, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.3100000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.3900000000000002, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 1.260000000000001, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.09999999999999999, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.060000000000000005, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.20000000000000004, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.5700000000000003, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.9800000000000006, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.16171875000000008\n",
      "\n",
      "Epoch 55, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.2800000000000001, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.5100000000000002, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.9300000000000006, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.5700000000000003, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.8600000000000005, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.21000000000000005, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.18328125000000015\n",
      "\n",
      "Epoch 56, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.37000000000000016, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.15, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.18000000000000002, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.10999999999999999, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.3100000000000001, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.22718750000000018\n",
      "\n",
      "Epoch 57, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.25000000000000006, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.3200000000000001, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.6700000000000004, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.09, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.38000000000000017, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.4100000000000002, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 1.0000000000000007, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.4200000000000002, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.2618750000000001\n",
      "\n",
      "Epoch 58, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.5000000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.17, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.4200000000000002, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.3100000000000001, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.37000000000000016, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.3100000000000001, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.20765625000000013\n",
      "\n",
      "Epoch 59, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.3000000000000001, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.5200000000000002, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.2700000000000001, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.5300000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.21000000000000005, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.2126562500000001\n",
      "\n",
      "Epoch 60, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.2800000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.05, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.47000000000000025, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.26000000000000006, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.46000000000000024, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.2645312500000001\n",
      "\n",
      "Epoch 61, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.24000000000000007, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.5800000000000003, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.6800000000000004, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.17, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.2900000000000001, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.15, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.2700000000000001, epsilon: 0.0078125\n",
      "Average Score: 0.20796875000000006\n",
      "\n",
      "Epoch 62, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.3100000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.7800000000000005, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.22000000000000006, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.20000000000000004, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.4100000000000002, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.09, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.07, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.02, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.3200000000000001, epsilon: 0.0078125\n",
      "Average Score: 0.21015625000000007\n",
      "\n",
      "Epoch 63, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.15, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 1.1200000000000008, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.4100000000000002, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.5500000000000003, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.5000000000000002, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.15, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.38000000000000017, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.19000000000000003, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.23796875000000015\n",
      "\n",
      "Epoch 64, Best Score: 23.260000000000836\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.34000000000000014, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.5800000000000003, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.37000000000000016, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.5100000000000002, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.37000000000000016, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.19000000000000003, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.4100000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.09999999999999999, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.17593750000000005\n",
      "Saved a trained Q-table with size (76032,), After 24.76560831864675 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip080\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip080)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip081\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip080)\" d=\"\n",
       "M156.598 1486.45 L2352.76 1486.45 L2352.76 47.2441 L156.598 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip082\">\n",
       "    <rect x=\"156\" y=\"47\" width=\"2197\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  185.867,1486.45 185.867,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  514.732,1486.45 514.732,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  843.596,1486.45 843.596,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1172.46,1486.45 1172.46,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1501.33,1486.45 1501.33,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1830.19,1486.45 1830.19,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2159.05,1486.45 2159.05,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  185.867,1486.45 185.867,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  514.732,1486.45 514.732,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  843.596,1486.45 843.596,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1172.46,1486.45 1172.46,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1501.33,1486.45 1501.33,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1830.19,1486.45 1830.19,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2159.05,1486.45 2159.05,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip080)\" d=\"M185.867 1517.37 Q182.256 1517.37 180.427 1520.93 Q178.622 1524.47 178.622 1531.6 Q178.622 1538.71 180.427 1542.27 Q182.256 1545.82 185.867 1545.82 Q189.501 1545.82 191.307 1542.27 Q193.136 1538.71 193.136 1531.6 Q193.136 1524.47 191.307 1520.93 Q189.501 1517.37 185.867 1517.37 M185.867 1513.66 Q191.677 1513.66 194.733 1518.27 Q197.812 1522.85 197.812 1531.6 Q197.812 1540.33 194.733 1544.94 Q191.677 1549.52 185.867 1549.52 Q180.057 1549.52 176.978 1544.94 Q173.923 1540.33 173.923 1531.6 Q173.923 1522.85 176.978 1518.27 Q180.057 1513.66 185.867 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M489.419 1544.91 L497.058 1544.91 L497.058 1518.55 L488.748 1520.21 L488.748 1515.95 L497.012 1514.29 L501.688 1514.29 L501.688 1544.91 L509.327 1544.91 L509.327 1548.85 L489.419 1548.85 L489.419 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M528.771 1517.37 Q525.16 1517.37 523.331 1520.93 Q521.526 1524.47 521.526 1531.6 Q521.526 1538.71 523.331 1542.27 Q525.16 1545.82 528.771 1545.82 Q532.405 1545.82 534.211 1542.27 Q536.04 1538.71 536.04 1531.6 Q536.04 1524.47 534.211 1520.93 Q532.405 1517.37 528.771 1517.37 M528.771 1513.66 Q534.581 1513.66 537.637 1518.27 Q540.715 1522.85 540.715 1531.6 Q540.715 1540.33 537.637 1544.94 Q534.581 1549.52 528.771 1549.52 Q522.961 1549.52 519.882 1544.94 Q516.827 1540.33 516.827 1531.6 Q516.827 1522.85 519.882 1518.27 Q522.961 1513.66 528.771 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M822.37 1544.91 L838.689 1544.91 L838.689 1548.85 L816.745 1548.85 L816.745 1544.91 Q819.407 1542.16 823.99 1537.53 Q828.596 1532.88 829.777 1531.53 Q832.022 1529.01 832.902 1527.27 Q833.805 1525.51 833.805 1523.82 Q833.805 1521.07 831.86 1519.33 Q829.939 1517.6 826.837 1517.6 Q824.638 1517.6 822.184 1518.36 Q819.754 1519.13 816.976 1520.68 L816.976 1515.95 Q819.8 1514.82 822.254 1514.24 Q824.708 1513.66 826.745 1513.66 Q832.115 1513.66 835.309 1516.35 Q838.504 1519.03 838.504 1523.52 Q838.504 1525.65 837.694 1527.57 Q836.907 1529.47 834.8 1532.07 Q834.221 1532.74 831.12 1535.95 Q828.018 1539.15 822.37 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M858.504 1517.37 Q854.893 1517.37 853.064 1520.93 Q851.258 1524.47 851.258 1531.6 Q851.258 1538.71 853.064 1542.27 Q854.893 1545.82 858.504 1545.82 Q862.138 1545.82 863.943 1542.27 Q865.772 1538.71 865.772 1531.6 Q865.772 1524.47 863.943 1520.93 Q862.138 1517.37 858.504 1517.37 M858.504 1513.66 Q864.314 1513.66 867.369 1518.27 Q870.448 1522.85 870.448 1531.6 Q870.448 1540.33 867.369 1544.94 Q864.314 1549.52 858.504 1549.52 Q852.694 1549.52 849.615 1544.94 Q846.559 1540.33 846.559 1531.6 Q846.559 1522.85 849.615 1518.27 Q852.694 1513.66 858.504 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M1161.3 1530.21 Q1164.66 1530.93 1166.54 1533.2 Q1168.43 1535.47 1168.43 1538.8 Q1168.43 1543.92 1164.91 1546.72 Q1161.4 1549.52 1154.91 1549.52 Q1152.74 1549.52 1150.42 1549.08 Q1148.13 1548.66 1145.68 1547.81 L1145.68 1543.29 Q1147.62 1544.43 1149.94 1545.01 Q1152.25 1545.58 1154.78 1545.58 Q1159.17 1545.58 1161.47 1543.85 Q1163.78 1542.11 1163.78 1538.8 Q1163.78 1535.75 1161.63 1534.03 Q1159.5 1532.3 1155.68 1532.3 L1151.65 1532.3 L1151.65 1528.45 L1155.86 1528.45 Q1159.31 1528.45 1161.14 1527.09 Q1162.97 1525.7 1162.97 1523.11 Q1162.97 1520.45 1161.07 1519.03 Q1159.2 1517.6 1155.68 1517.6 Q1153.76 1517.6 1151.56 1518.01 Q1149.36 1518.43 1146.72 1519.31 L1146.72 1515.14 Q1149.38 1514.4 1151.7 1514.03 Q1154.04 1513.66 1156.1 1513.66 Q1161.42 1513.66 1164.52 1516.09 Q1167.62 1518.5 1167.62 1522.62 Q1167.62 1525.49 1165.98 1527.48 Q1164.34 1529.45 1161.3 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M1187.3 1517.37 Q1183.69 1517.37 1181.86 1520.93 Q1180.05 1524.47 1180.05 1531.6 Q1180.05 1538.71 1181.86 1542.27 Q1183.69 1545.82 1187.3 1545.82 Q1190.93 1545.82 1192.74 1542.27 Q1194.57 1538.71 1194.57 1531.6 Q1194.57 1524.47 1192.74 1520.93 Q1190.93 1517.37 1187.3 1517.37 M1187.3 1513.66 Q1193.11 1513.66 1196.16 1518.27 Q1199.24 1522.85 1199.24 1531.6 Q1199.24 1540.33 1196.16 1544.94 Q1193.11 1549.52 1187.3 1549.52 Q1181.49 1549.52 1178.41 1544.94 Q1175.35 1540.33 1175.35 1531.6 Q1175.35 1522.85 1178.41 1518.27 Q1181.49 1513.66 1187.3 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M1489.5 1518.36 L1477.69 1536.81 L1489.5 1536.81 L1489.5 1518.36 M1488.27 1514.29 L1494.15 1514.29 L1494.15 1536.81 L1499.08 1536.81 L1499.08 1540.7 L1494.15 1540.7 L1494.15 1548.85 L1489.5 1548.85 L1489.5 1540.7 L1473.9 1540.7 L1473.9 1536.19 L1488.27 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M1516.81 1517.37 Q1513.2 1517.37 1511.37 1520.93 Q1509.57 1524.47 1509.57 1531.6 Q1509.57 1538.71 1511.37 1542.27 Q1513.2 1545.82 1516.81 1545.82 Q1520.45 1545.82 1522.25 1542.27 Q1524.08 1538.71 1524.08 1531.6 Q1524.08 1524.47 1522.25 1520.93 Q1520.45 1517.37 1516.81 1517.37 M1516.81 1513.66 Q1522.62 1513.66 1525.68 1518.27 Q1528.76 1522.85 1528.76 1531.6 Q1528.76 1540.33 1525.68 1544.94 Q1522.62 1549.52 1516.81 1549.52 Q1511 1549.52 1507.92 1544.94 Q1504.87 1540.33 1504.87 1531.6 Q1504.87 1522.85 1507.92 1518.27 Q1511 1513.66 1516.81 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M1804.89 1514.29 L1823.25 1514.29 L1823.25 1518.22 L1809.17 1518.22 L1809.17 1526.7 Q1810.19 1526.35 1811.21 1526.19 Q1812.23 1526 1813.25 1526 Q1819.03 1526 1822.41 1529.17 Q1825.79 1532.34 1825.79 1537.76 Q1825.79 1543.34 1822.32 1546.44 Q1818.85 1549.52 1812.53 1549.52 Q1810.35 1549.52 1808.08 1549.15 Q1805.84 1548.78 1803.43 1548.04 L1803.43 1543.34 Q1805.51 1544.47 1807.74 1545.03 Q1809.96 1545.58 1812.44 1545.58 Q1816.44 1545.58 1818.78 1543.48 Q1821.12 1541.37 1821.12 1537.76 Q1821.12 1534.15 1818.78 1532.04 Q1816.44 1529.94 1812.44 1529.94 Q1810.56 1529.94 1808.69 1530.35 Q1806.83 1530.77 1804.89 1531.65 L1804.89 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M1845 1517.37 Q1841.39 1517.37 1839.57 1520.93 Q1837.76 1524.47 1837.76 1531.6 Q1837.76 1538.71 1839.57 1542.27 Q1841.39 1545.82 1845 1545.82 Q1848.64 1545.82 1850.44 1542.27 Q1852.27 1538.71 1852.27 1531.6 Q1852.27 1524.47 1850.44 1520.93 Q1848.64 1517.37 1845 1517.37 M1845 1513.66 Q1850.81 1513.66 1853.87 1518.27 Q1856.95 1522.85 1856.95 1531.6 Q1856.95 1540.33 1853.87 1544.94 Q1850.81 1549.52 1845 1549.52 Q1839.19 1549.52 1836.12 1544.94 Q1833.06 1540.33 1833.06 1531.6 Q1833.06 1522.85 1836.12 1518.27 Q1839.19 1513.66 1845 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M2144.46 1529.7 Q2141.31 1529.7 2139.46 1531.86 Q2137.63 1534.01 2137.63 1537.76 Q2137.63 1541.49 2139.46 1543.66 Q2141.31 1545.82 2144.46 1545.82 Q2147.61 1545.82 2149.44 1543.66 Q2151.29 1541.49 2151.29 1537.76 Q2151.29 1534.01 2149.44 1531.86 Q2147.61 1529.7 2144.46 1529.7 M2153.74 1515.05 L2153.74 1519.31 Q2151.98 1518.48 2150.18 1518.04 Q2148.4 1517.6 2146.64 1517.6 Q2142.01 1517.6 2139.55 1520.72 Q2137.12 1523.85 2136.77 1530.17 Q2138.14 1528.15 2140.2 1527.09 Q2142.26 1526 2144.74 1526 Q2149.95 1526 2152.96 1529.17 Q2155.99 1532.32 2155.99 1537.76 Q2155.99 1543.08 2152.84 1546.3 Q2149.69 1549.52 2144.46 1549.52 Q2138.46 1549.52 2135.29 1544.94 Q2132.12 1540.33 2132.12 1531.6 Q2132.12 1523.41 2136.01 1518.55 Q2139.9 1513.66 2146.45 1513.66 Q2148.21 1513.66 2149.99 1514.01 Q2151.8 1514.36 2153.74 1515.05 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M2174.04 1517.37 Q2170.43 1517.37 2168.6 1520.93 Q2166.8 1524.47 2166.8 1531.6 Q2166.8 1538.71 2168.6 1542.27 Q2170.43 1545.82 2174.04 1545.82 Q2177.68 1545.82 2179.48 1542.27 Q2181.31 1538.71 2181.31 1531.6 Q2181.31 1524.47 2179.48 1520.93 Q2177.68 1517.37 2174.04 1517.37 M2174.04 1513.66 Q2179.85 1513.66 2182.91 1518.27 Q2185.99 1522.85 2185.99 1531.6 Q2185.99 1540.33 2182.91 1544.94 Q2179.85 1549.52 2174.04 1549.52 Q2168.23 1549.52 2165.15 1544.94 Q2162.1 1540.33 2162.1 1531.6 Q2162.1 1522.85 2165.15 1518.27 Q2168.23 1513.66 2174.04 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,1220.14 2352.76,1220.14 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,915.564 2352.76,915.564 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,610.989 2352.76,610.989 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,306.414 2352.76,306.414 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1486.45 156.598,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1220.14 175.496,1220.14 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,915.564 175.496,915.564 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,610.989 175.496,610.989 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,306.414 175.496,306.414 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip080)\" d=\"M64.6495 1205.94 Q61.0384 1205.94 59.2097 1209.5 Q57.4041 1213.04 57.4041 1220.17 Q57.4041 1227.28 59.2097 1230.85 Q61.0384 1234.39 64.6495 1234.39 Q68.2837 1234.39 70.0892 1230.85 Q71.9179 1227.28 71.9179 1220.17 Q71.9179 1213.04 70.0892 1209.5 Q68.2837 1205.94 64.6495 1205.94 M64.6495 1202.23 Q70.4596 1202.23 73.5152 1206.84 Q76.5938 1211.42 76.5938 1220.17 Q76.5938 1228.9 73.5152 1233.51 Q70.4596 1238.09 64.6495 1238.09 Q58.8393 1238.09 55.7606 1233.51 Q52.7051 1228.9 52.7051 1220.17 Q52.7051 1211.42 55.7606 1206.84 Q58.8393 1202.23 64.6495 1202.23 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M84.8114 1231.54 L89.6956 1231.54 L89.6956 1237.42 L84.8114 1237.42 L84.8114 1231.54 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M100.691 1233.48 L108.33 1233.48 L108.33 1207.12 L100.02 1208.79 L100.02 1204.53 L108.283 1202.86 L112.959 1202.86 L112.959 1233.48 L120.598 1233.48 L120.598 1237.42 L100.691 1237.42 L100.691 1233.48 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M65.0198 901.363 Q61.4087 901.363 59.58 904.928 Q57.7745 908.47 57.7745 915.599 Q57.7745 922.706 59.58 926.27 Q61.4087 929.812 65.0198 929.812 Q68.6541 929.812 70.4596 926.27 Q72.2883 922.706 72.2883 915.599 Q72.2883 908.47 70.4596 904.928 Q68.6541 901.363 65.0198 901.363 M65.0198 897.659 Q70.83 897.659 73.8855 902.266 Q76.9642 906.849 76.9642 915.599 Q76.9642 924.326 73.8855 928.932 Q70.83 933.516 65.0198 933.516 Q59.2097 933.516 56.131 928.932 Q53.0754 924.326 53.0754 915.599 Q53.0754 906.849 56.131 902.266 Q59.2097 897.659 65.0198 897.659 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M85.1818 926.965 L90.066 926.965 L90.066 932.844 L85.1818 932.844 L85.1818 926.965 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M104.279 928.909 L120.598 928.909 L120.598 932.844 L98.6539 932.844 L98.6539 928.909 Q101.316 926.155 105.899 921.525 Q110.506 916.872 111.686 915.53 Q113.932 913.007 114.811 911.27 Q115.714 909.511 115.714 907.821 Q115.714 905.067 113.77 903.331 Q111.848 901.595 108.746 901.595 Q106.547 901.595 104.094 902.358 Q101.663 903.122 98.8854 904.673 L98.8854 899.951 Q101.709 898.817 104.163 898.238 Q106.617 897.659 108.654 897.659 Q114.024 897.659 117.219 900.345 Q120.413 903.03 120.413 907.52 Q120.413 909.65 119.603 911.571 Q118.816 913.469 116.709 916.062 Q116.131 916.733 113.029 919.951 Q109.927 923.145 104.279 928.909 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M64.0708 596.788 Q60.4597 596.788 58.631 600.353 Q56.8254 603.894 56.8254 611.024 Q56.8254 618.13 58.631 621.695 Q60.4597 625.237 64.0708 625.237 Q67.705 625.237 69.5105 621.695 Q71.3392 618.13 71.3392 611.024 Q71.3392 603.894 69.5105 600.353 Q67.705 596.788 64.0708 596.788 M64.0708 593.084 Q69.8809 593.084 72.9365 597.691 Q76.0151 602.274 76.0151 611.024 Q76.0151 619.751 72.9365 624.357 Q69.8809 628.94 64.0708 628.94 Q58.2606 628.94 55.1819 624.357 Q52.1264 619.751 52.1264 611.024 Q52.1264 602.274 55.1819 597.691 Q58.2606 593.084 64.0708 593.084 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M84.2327 622.39 L89.1169 622.39 L89.1169 628.269 L84.2327 628.269 L84.2327 622.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M113.469 609.635 Q116.825 610.353 118.7 612.621 Q120.598 614.89 120.598 618.223 Q120.598 623.339 117.08 626.139 Q113.561 628.94 107.08 628.94 Q104.904 628.94 102.589 628.501 Q100.297 628.084 97.8437 627.227 L97.8437 622.714 Q99.7882 623.848 102.103 624.427 Q104.418 625.005 106.941 625.005 Q111.339 625.005 113.631 623.269 Q115.945 621.533 115.945 618.223 Q115.945 615.167 113.793 613.454 Q111.663 611.718 107.844 611.718 L103.816 611.718 L103.816 607.876 L108.029 607.876 Q111.478 607.876 113.307 606.51 Q115.135 605.121 115.135 602.529 Q115.135 599.866 113.237 598.454 Q111.362 597.019 107.844 597.019 Q105.922 597.019 103.723 597.436 Q101.524 597.853 98.8854 598.732 L98.8854 594.566 Q101.547 593.825 103.862 593.454 Q106.2 593.084 108.26 593.084 Q113.584 593.084 116.686 595.515 Q119.788 597.922 119.788 602.042 Q119.788 604.913 118.145 606.903 Q116.501 608.871 113.469 609.635 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M62.9365 292.213 Q59.3254 292.213 57.4967 295.777 Q55.6912 299.319 55.6912 306.449 Q55.6912 313.555 57.4967 317.12 Q59.3254 320.661 62.9365 320.661 Q66.5707 320.661 68.3763 317.12 Q70.205 313.555 70.205 306.449 Q70.205 299.319 68.3763 295.777 Q66.5707 292.213 62.9365 292.213 M62.9365 288.509 Q68.7467 288.509 71.8022 293.115 Q74.8809 297.699 74.8809 306.449 Q74.8809 315.175 71.8022 319.782 Q68.7467 324.365 62.9365 324.365 Q57.1264 324.365 54.0477 319.782 Q50.9921 315.175 50.9921 306.449 Q50.9921 297.699 54.0477 293.115 Q57.1264 288.509 62.9365 288.509 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M83.0984 317.814 L87.9827 317.814 L87.9827 323.694 L83.0984 323.694 L83.0984 317.814 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M111.015 293.208 L99.2095 311.657 L111.015 311.657 L111.015 293.208 M109.788 289.134 L115.668 289.134 L115.668 311.657 L120.598 311.657 L120.598 315.546 L115.668 315.546 L115.668 323.694 L111.015 323.694 L111.015 315.546 L95.4132 315.546 L95.4132 311.032 L109.788 289.134 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip082)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  218.754,1264.4 251.64,581.483 284.527,638.591 317.413,1378.14 350.299,1445.72 383.186,327.829 416.072,1313.42 448.959,87.9763 481.845,1109.26 514.732,1008.36 \n",
       "  547.618,969.341 580.505,877.492 613.391,877.968 646.278,769.463 679.164,999.798 712.051,982.19 744.937,1035.01 777.823,877.017 810.71,790.403 843.596,754.235 \n",
       "  876.483,936.98 909.369,1015.03 942.256,797.541 975.142,739.958 1008.03,1035.97 1040.92,1068.33 1073.8,986.473 1106.69,1045.48 1139.57,712.356 1172.46,957.919 \n",
       "  1205.35,908.902 1238.23,876.065 1271.12,947.45 1304.01,763.753 1336.89,934.6 1369.78,928.414 1402.67,856.553 1435.55,937.932 1468.44,1015.98 1501.33,966.486 \n",
       "  1534.21,925.082 1567.1,971.72 1599.98,602.423 1632.87,818.481 1665.76,985.522 1698.64,1011.7 1731.53,853.222 1764.42,823.24 1797.3,842.276 1830.19,1001.23 \n",
       "  1863.08,1048.82 1895.96,906.046 1928.85,892.721 1961.74,1032.16 1994.62,966.486 2027.51,832.758 2060.4,727.108 2093.28,892.245 2126.17,877.017 2159.05,719.018 \n",
       "  2191.94,891.294 2224.83,884.631 2257.71,799.921 2290.6,988.853 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip080)\" d=\"\n",
       "M1983.1 198.898 L2279.55 198.898 L2279.55 95.2176 L1983.1 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1983.1,198.898 2279.55,198.898 2279.55,95.2176 1983.1,95.2176 1983.1,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2007.5,147.058 2153.92,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip080)\" d=\"M2192.16 166.745 Q2190.35 171.375 2188.64 172.787 Q2186.93 174.199 2184.06 174.199 L2180.65 174.199 L2180.65 170.634 L2183.15 170.634 Q2184.91 170.634 2185.89 169.8 Q2186.86 168.967 2188.04 165.865 L2188.8 163.921 L2178.32 138.412 L2182.83 138.412 L2190.93 158.689 L2199.03 138.412 L2203.55 138.412 L2192.16 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M2210.84 160.402 L2218.48 160.402 L2218.48 134.037 L2210.17 135.703 L2210.17 131.444 L2218.43 129.778 L2223.11 129.778 L2223.11 160.402 L2230.75 160.402 L2230.75 164.338 L2210.84 164.338 L2210.84 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/episodes\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        X  = X_0\n",
    "        \n",
    "        ##### Double Q-Learning ###########################################\n",
    "\n",
    "        for k = 1:T\n",
    "\n",
    "            # 1. Choose action\n",
    "            if rand() < epsilon\n",
    "                if rand() < EXPrand \n",
    "                    A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                else\n",
    "                    A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                end\n",
    "            else\n",
    "\n",
    "                A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                if A == 1000.0 # Indicates no values in this region\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "\n",
    "            # 2. Cache last state\n",
    "            qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "            # 3. Generate the next stae\n",
    "            Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "            # 4. Collect reward R( s, a, s' )\n",
    "            R_t = cartpole_reward( Xp )\n",
    "\n",
    "            # 5. Get the optimal action at the next state\n",
    "            a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "            # 6. Compute the value at the next state\n",
    "\n",
    "            V_tp1_opt = query_value_fuzzy( \n",
    "                Q_kdTree, G, V, \n",
    "                get_Q( \n",
    "                    select_X_vector( Xp ), \n",
    "                    a_tp1_opt \n",
    "                ); \n",
    "                k = vNN \n",
    "            )\n",
    "            if isnan( V_tp1_opt )\n",
    "                V_tp1_opt = 0.0\n",
    "            end\n",
    "\n",
    "\n",
    "            # 7. Blend the value back into nearest points\n",
    "\n",
    "            idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "            nNear      = size( idxs, 1 )\n",
    "            for i = 1:nNear\n",
    "                j    = idxs[i]\n",
    "                if !isnan( wgts[i] ) \n",
    "\n",
    "                    # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                    VS[j] = VS[j] + alpha*( R_t + V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "                    \n",
    "                end\n",
    "            end\n",
    "\n",
    "            states[:,k] = Xp\n",
    "            actions[k]  = A\n",
    "\n",
    "            X = Xp\n",
    "        end\n",
    "\n",
    "        s_l    = vertical_score_s( states, aMargin, ts )\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        if useElig\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "\n",
    "        # Swap Q-functions for Double Q-Learning\n",
    "        vSwp = copy( VS   )\n",
    "        VS   = copy( V    )\n",
    "        V    = copy( vSwp )\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709555b9-2598-4281-a634-c7b0681277d0",
   "metadata": {},
   "source": [
    "# Method 2 Performance, Average Vertical Duration [s]\n",
    "Each score is the best run out of an entire training period: 64 epochs of 64 episodes each, Q-function swap after every episode \n",
    "\n",
    "### TD Tuning\n",
    "$\\alpha = 0.03125$:  \n",
    "$\\alpha = 0.0625$:  \n",
    "$\\alpha = 0.125$:  \n",
    "$\\alpha = 0.25$:  \n",
    "$\\alpha = 0.50$:  \n",
    "$\\alpha = 0.75$:  \n",
    "$\\alpha = 0.99$: 0.238  \n",
    "\n",
    "### Blend: Best Episode\n",
    "\n",
    "$\\beta = 0.07$:  \n",
    "$\\beta = 0.15$: 0.244\n",
    "\n",
    "| Method      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n",
    "| ----------- | ------- | ------- | ------- | ------- | ------- | ---- |\n",
    "| Blend (Epi) |         |         |         |         |         |      |\n",
    "| Blend (Epo) |         |         |         |         |         |      |\n",
    "| TD          |         |         |         |         |         |      |\n",
    "| TD  + ????? |         |         |         |         |         |      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
