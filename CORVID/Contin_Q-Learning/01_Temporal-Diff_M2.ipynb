{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    # if thetaDotN > maxThetaDot\n",
    "    #     R -= thetaDotN\n",
    "    # end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.15\n",
    "gamma    = 0.99 \n",
    "epsMin   = 0.05 # 0.05\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes =  64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   =  64 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0, Best Average: -100.0\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.07296875000000003\n",
      "BLEND\n",
      "\n",
      "Epoch 2, Best Score: 0.9000000000000006, Best Average: 0.07296875000000003\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.5100000000000002, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.3100000000000001, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.3100000000000001, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.23000000000000007, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.4400000000000002, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.26000000000000006, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.7400000000000004, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.11937500000000008\n",
      "BLEND\n",
      "\n",
      "Epoch 3, Best Score: 0.9900000000000007, Best Average: 0.11937500000000008\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.34000000000000014, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 1.360000000000001, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.5400000000000003, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.09375000000000004\n",
      "\n",
      "Epoch 4, Best Score: 1.360000000000001, Best Average: 0.11937500000000008\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.3100000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.6600000000000004, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.7000000000000004, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 1.270000000000001, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.11999999999999998, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.19093749999999832\n",
      "BLEND\n",
      "\n",
      "Epoch 5, Best Score: 7.23999999999989, Best Average: 0.19093749999999832\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.4000000000000002, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 2.2699999999999956, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.5900000000000003, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 1.290000000000001, epsilon: 0.05703125000000056\n",
      "Average Score: 0.4723437499999952\n",
      "BLEND\n",
      "\n",
      "Epoch 6, Best Score: 16.409999999999766, Best Average: 0.4723437499999952\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 1.1300000000000008, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 1.5700000000000012, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 3.429999999999971, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.45000000000000023, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.7700000000000005, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.3200000000000001, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.6400000000000003, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.5200000000000002, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.34999999999999976\n",
      "\n",
      "Epoch 7, Best Score: 16.409999999999766, Best Average: 0.4723437499999952\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.026562500000000013\n",
      "\n",
      "Epoch 8, Best Score: 16.409999999999766, Best Average: 0.4723437499999952\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.3100000000000001, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.2800000000000001, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.02250000000000001\n",
      "\n",
      "Epoch 9, Best Score: 16.409999999999766, Best Average: 0.4723437499999952\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.8200000000000005, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.6500000000000004, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.9835937500000228\n",
      "BLEND\n",
      "\n",
      "Epoch 10, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.10937500000000007\n",
      "\n",
      "Epoch 11, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.2800000000000001, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.38000000000000017, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 1.1600000000000008, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 1.490000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.25000000000000006, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.22000000000000006, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.4096874999999992\n",
      "\n",
      "Epoch 12, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.6400000000000003, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.34000000000000014, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.19000000000000003, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.38000000000000017, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.25500000000000006\n",
      "\n",
      "Epoch 13, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.14687499999999978\n",
      "\n",
      "Epoch 14, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.3000000000000001, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.18000000000000002, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.19453124999999924\n",
      "\n",
      "Epoch 15, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.9300000000000006, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.24906249999999985\n",
      "\n",
      "Epoch 16, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 23.950000000000944, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.2900000000000001, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.09, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.9600000000000006, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.2800000000000001, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.5500000000000003, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.9342187500000363\n",
      "\n",
      "Epoch 17, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.8800000000000006, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 1.1500000000000008, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 2.199999999999997, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.8500000000000005, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.4100000000000002, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.7700000000000005, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.45000000000000023, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.9000000000000006, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 1.400000000000001, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.07, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.07, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.11999999999999998, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.08, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.09, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.2700000000000001, epsilon: 0.05703125000000056\n",
      "Average Score: 0.5404687499999982\n",
      "\n",
      "Epoch 18, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.09999999999999999, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.26000000000000006, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.3200000000000001, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.26000000000000006, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.20000000000000004, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.15062499999999943\n",
      "\n",
      "Epoch 19, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.26000000000000006, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.3000000000000001, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.13999999999999999, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.35000000000000014, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.3200000000000001, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.34000000000000014, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.16, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.07234375000000004\n",
      "\n",
      "Epoch 20, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.2800000000000001, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.17, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.21000000000000005, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.2800000000000001, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.13999999999999999, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.25000000000000006, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.17, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.35000000000000014, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.2800000000000001, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.26000000000000006, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.17, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.11999999999999998, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.19000000000000003, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.2900000000000001, epsilon: 0.05703125000000056\n",
      "Average Score: 0.10421875000000001\n",
      "\n",
      "Epoch 21, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.3100000000000001, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.3000000000000001, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.19000000000000003, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.24000000000000007, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.13999999999999999, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.45000000000000023, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.4000000000000002, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.15, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.18000000000000002, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.18000000000000002, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.2800000000000001, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.21000000000000005, epsilon: 0.05703125000000056\n",
      "Average Score: 0.09593750000000002\n",
      "\n",
      "Epoch 22, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.24000000000000007, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.17, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.23000000000000007, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.17, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.22000000000000006, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.21000000000000005, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.4000000000000002, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.2800000000000001, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.15, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.38000000000000017, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.35000000000000014, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.17, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.37000000000000016, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.7000000000000004, epsilon: 0.05703125000000056\n",
      "Average Score: 0.13875000000000007\n",
      "\n",
      "Epoch 23, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.47000000000000025, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.46000000000000024, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.23000000000000007, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.2700000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.4400000000000002, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.16, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.24000000000000007, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.3300000000000001, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.23000000000000007, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.24000000000000007, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.19000000000000003, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.37000000000000016, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.5700000000000003, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.9500000000000006, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2632812500000001\n",
      "\n",
      "Epoch 24, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.36000000000000015, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.5300000000000002, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.5300000000000002, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.6100000000000003, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.2900000000000001, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.23000000000000007, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.09999999999999999, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.07, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.060000000000000005, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.2900000000000001, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.4400000000000002, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.25000000000000006, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.2900000000000001, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.21000000000000005, epsilon: 0.05703125000000056\n",
      "Average Score: 0.24296875000000018\n",
      "\n",
      "Epoch 25, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.17, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.08, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.2900000000000001, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.48000000000000026, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.5800000000000003, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.26000000000000006, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.07, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.18000000000000002, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.3900000000000002, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.48000000000000026, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.20000000000000004, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.36000000000000015, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.3300000000000001, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.22000000000000006, epsilon: 0.05703125000000056\n",
      "Average Score: 0.20250000000000007\n",
      "\n",
      "Epoch 26, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.22000000000000006, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.11999999999999998, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.15, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.24000000000000007, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.15, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.19000000000000003, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.20000000000000004, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 1.0000000000000007, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.13999999999999999, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.13999999999999999, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.09, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.11999999999999998, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2196875000000001\n",
      "\n",
      "Epoch 27, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.20000000000000004, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.35000000000000014, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.23000000000000007, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.48000000000000026, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.17, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.13999999999999999, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.26000000000000006, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.12999999999999998, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.25000000000000006, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.19000000000000003, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.7300000000000004, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.20000000000000004, epsilon: 0.05703125000000056\n",
      "Average Score: 0.16140625\n",
      "\n",
      "Epoch 28, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.3000000000000001, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.22000000000000006, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.45000000000000023, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.36000000000000015, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.12999999999999998, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.060000000000000005, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.2900000000000001, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.5600000000000003, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.12999999999999998, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.6900000000000004, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.6800000000000004, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.9000000000000006, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.19156250000000005\n",
      "\n",
      "Epoch 29, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.17, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.20000000000000004, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.18000000000000002, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.22000000000000006, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.8700000000000006, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.13999999999999999, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.15, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.5700000000000003, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.060000000000000005, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.16, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1876562500000001\n",
      "\n",
      "Epoch 30, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.12999999999999998, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.19000000000000003, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.20000000000000004, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.6500000000000004, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.22000000000000006, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.13999999999999999, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.5000000000000002, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.3100000000000001, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.20000000000000004, epsilon: 0.05703125000000056\n",
      "Average Score: 0.15281250000000007\n",
      "\n",
      "Epoch 31, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.35000000000000014, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.48000000000000026, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.18000000000000002, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.11999999999999998, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.21000000000000005, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.6800000000000004, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.47000000000000025, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.34000000000000014, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.34000000000000014, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.34000000000000014, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.4000000000000002, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.24000000000000007, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1720312500000001\n",
      "\n",
      "Epoch 32, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.5900000000000003, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.19000000000000003, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.48000000000000026, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.12999999999999998, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.24000000000000007, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.21000000000000005, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.20000000000000004, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.22000000000000006, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.18000000000000002, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.36000000000000015, epsilon: 0.05703125000000056\n",
      "Average Score: 0.16171875000000008\n",
      "\n",
      "Epoch 33, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.3900000000000002, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.5200000000000002, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.15, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.21000000000000005, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.23000000000000007, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.21000000000000005, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.2800000000000001, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.2700000000000001, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.20671874999999904\n",
      "\n",
      "Epoch 34, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.26000000000000006, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.16, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.5300000000000002, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.5400000000000003, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.7400000000000004, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.7900000000000005, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.08, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1717187500000001\n",
      "\n",
      "Epoch 35, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.8200000000000005, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.4100000000000002, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.18000000000000002, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.8100000000000005, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.8800000000000006, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.13999999999999999, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.2900000000000001, epsilon: 0.05703125000000056\n",
      "Average Score: 0.20656250000000007\n",
      "\n",
      "Epoch 36, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.21000000000000005, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.4300000000000002, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.3900000000000002, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.3900000000000002, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.25000000000000006, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.20000000000000004, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.20000000000000004, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.36000000000000015, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.36000000000000015, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.18000000000000002, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.19000000000000003, epsilon: 0.05703125000000056\n",
      "Average Score: 0.18640625000000005\n",
      "\n",
      "Epoch 37, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.48000000000000026, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.19000000000000003, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.16, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.15, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.5900000000000003, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.16, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.48000000000000026, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.45000000000000023, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.5900000000000003, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.13999999999999999, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.2900000000000001, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1373437500000001\n",
      "\n",
      "Epoch 38, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.3000000000000001, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.19000000000000003, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.2700000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.9600000000000006, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.24000000000000007, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.26000000000000006, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.23000000000000007, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 1.5300000000000011, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.3300000000000001, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.17203125000000008\n",
      "\n",
      "Epoch 39, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.15, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.25000000000000006, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.5500000000000003, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.17, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.10999999999999999, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.34000000000000014, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.49000000000000027, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.18000000000000002, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.17, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.17, epsilon: 0.05703125000000056\n",
      "Average Score: 0.15546875000000004\n",
      "\n",
      "Epoch 40, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.35000000000000014, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.18000000000000002, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.060000000000000005, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.22000000000000006, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.45000000000000023, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.13999999999999999, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.38000000000000017, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.14953125000000003\n",
      "\n",
      "Epoch 41, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.36000000000000015, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.3000000000000001, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.10999999999999999, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 1.1200000000000008, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.12999999999999998, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.5000000000000002, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.20000000000000004, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.17, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.38000000000000017, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.38000000000000017, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.19843750000000013\n",
      "\n",
      "Epoch 42, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.4400000000000002, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.18000000000000002, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.6600000000000004, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.10999999999999999, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.11999999999999998, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.38000000000000017, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.11999999999999998, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.10999999999999999, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.20000000000000004, epsilon: 0.05703125000000056\n",
      "Average Score: 0.18937500000000004\n",
      "\n",
      "Epoch 43, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.48000000000000026, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.3000000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.5600000000000003, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.19000000000000003, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.18000000000000002, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.15, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.060000000000000005, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.12999999999999998, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2043750000000001\n",
      "\n",
      "Epoch 44, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.6800000000000004, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.13999999999999999, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.2900000000000001, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.46000000000000024, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.23000000000000007, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.5400000000000003, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.07, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.26000000000000006, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.15, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.21000000000000005, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.3300000000000001, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.20359375000000007\n",
      "\n",
      "Epoch 45, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.18000000000000002, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.15, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.17, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.13999999999999999, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.24000000000000007, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.24000000000000007, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.7300000000000004, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.3900000000000002, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1907812500000001\n",
      "\n",
      "Epoch 46, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 1.8700000000000014, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.35000000000000014, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.22000000000000006, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.11999999999999998, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.16, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.18000000000000002, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 1.440000000000001, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1973437500000001\n",
      "\n",
      "Epoch 47, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.36000000000000015, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.15, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.18000000000000002, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.9800000000000006, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.21000000000000005, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.3300000000000001, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.37000000000000016, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.4200000000000002, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.35000000000000014, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.26000000000000006, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.20296875000000006\n",
      "\n",
      "Epoch 48, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.18000000000000002, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.23000000000000007, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.2900000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.3200000000000001, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.3900000000000002, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.6900000000000004, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.3100000000000001, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.23000000000000007, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.16, epsilon: 0.05703125000000056\n",
      "Average Score: 0.2126562500000001\n",
      "\n",
      "Epoch 49, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.22000000000000006, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.13999999999999999, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.24000000000000007, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.19000000000000003, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 1.5500000000000012, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.4300000000000002, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.18000000000000002, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.2800000000000001, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.19390625000000006\n",
      "\n",
      "Epoch 50, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.6900000000000004, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.12999999999999998, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.13999999999999999, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.17, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.34000000000000014, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.19000000000000003, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.17, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.24000000000000007, epsilon: 0.05703125000000056\n",
      "Average Score: 0.12812500000000002\n",
      "\n",
      "Epoch 51, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.5200000000000002, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.17, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.4300000000000002, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.9800000000000006, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.4100000000000002, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.16234375\n",
      "\n",
      "Epoch 52, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.2900000000000001, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.23000000000000007, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.05, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.18000000000000002, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.11999999999999998, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.3000000000000001, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 1.1000000000000008, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.8500000000000005, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.5800000000000003, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.4100000000000002, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.6600000000000004, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.25671875000000016\n",
      "\n",
      "Epoch 53, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.16, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.16, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.5900000000000003, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.18000000000000002, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.25000000000000006, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.4300000000000002, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.36000000000000015, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.13999999999999999, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.22000000000000006, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1764062500000001\n",
      "\n",
      "Epoch 54, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.25000000000000006, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.7300000000000004, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.12999999999999998, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.6000000000000003, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.15, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.12999999999999998, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.37000000000000016, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.23000000000000007, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.4200000000000002, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.17500000000000013\n",
      "\n",
      "Epoch 55, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.25000000000000006, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.22000000000000006, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.21000000000000005, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.16, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.17, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.45000000000000023, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.5700000000000003, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.22000000000000006, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.20000000000000004, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.19062500000000004\n",
      "\n",
      "Epoch 56, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.18000000000000002, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.26000000000000006, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.49000000000000027, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.15, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.24000000000000007, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.22000000000000006, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.2800000000000001, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.6800000000000004, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1623437500000001\n",
      "\n",
      "Epoch 57, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.6700000000000004, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.13999999999999999, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.5200000000000002, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.46000000000000024, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.16, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.2800000000000001, epsilon: 0.05703125000000056\n",
      "Average Score: 0.17796875000000004\n",
      "\n",
      "Epoch 58, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.3100000000000001, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.35000000000000014, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.21000000000000005, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.13999999999999999, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 1.1900000000000008, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.11999999999999998, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1664062500000001\n",
      "\n",
      "Epoch 59, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.15, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.19000000000000003, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.15, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.49000000000000027, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.13999999999999999, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.12999999999999998, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.2900000000000001, epsilon: 0.05703125000000056\n",
      "Average Score: 0.10390625000000002\n",
      "\n",
      "Epoch 60, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.12999999999999998, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.16, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.3200000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.25000000000000006, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.17, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.26000000000000006, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.19000000000000003, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 1.350000000000001, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.2900000000000001, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.2800000000000001, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.8600000000000005, epsilon: 0.05703125000000056\n",
      "Average Score: 0.22203125000000015\n",
      "\n",
      "Epoch 61, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.23000000000000007, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.21000000000000005, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.2700000000000001, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.060000000000000005, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.12999999999999998, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.15, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.36000000000000015, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.17, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.35000000000000014, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.09999999999999999, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.3000000000000001, epsilon: 0.05703125000000056\n",
      "Average Score: 0.16062500000000007\n",
      "\n",
      "Epoch 62, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.15, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.21000000000000005, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.20000000000000004, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.11999999999999998, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.16, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.25000000000000006, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.26000000000000006, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.34000000000000014, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.36000000000000015, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.12999999999999998, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.22000000000000006, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.18468750000000012\n",
      "\n",
      "Epoch 63, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.22000000000000006, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.16, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.3200000000000001, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.37000000000000016, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.21000000000000005, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 0.34000000000000014, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.22000000000000006, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.12999999999999998, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.25000000000000006, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.21000000000000005, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.16, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.16, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.17, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.05703125000000056\n",
      "Average Score: 0.15671875\n",
      "\n",
      "Epoch 64, Best Score: 27.030000000001426, Best Average: 0.9835937500000228\n",
      "Training Iteration 4 score: 0.5100000000000002, epsilon: 0.47890625000000003\n",
      "Training Iteration 8 score: 0.11999999999999998, epsilon: 0.4507812500000001\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4226562500000001\n",
      "Training Iteration 16 score: 0.26000000000000006, epsilon: 0.39453125000000017\n",
      "Training Iteration 20 score: 0.20000000000000004, epsilon: 0.3664062500000002\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.33828125000000026\n",
      "Training Iteration 28 score: 1.0300000000000007, epsilon: 0.3101562500000003\n",
      "Training Iteration 32 score: 0.35000000000000014, epsilon: 0.28203125000000034\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2539062500000004\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.22578125000000043\n",
      "Training Iteration 44 score: 0.16, epsilon: 0.19765625000000048\n",
      "Training Iteration 48 score: 0.34000000000000014, epsilon: 0.16953125000000052\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.14140625000000057\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.11328125000000058\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.08515625000000057\n",
      "Training Iteration 64 score: 0.24000000000000007, epsilon: 0.05703125000000056\n",
      "Average Score: 0.1685937500000001\n",
      "Saved a trained Q-table with size (76032,), After 25.917946815490723 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip580\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip580)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip581\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip580)\" d=\"\n",
       "M186.274 1486.45 L2352.76 1486.45 L2352.76 47.2441 L186.274 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip582\">\n",
       "    <rect x=\"186\" y=\"47\" width=\"2167\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  215.147,1486.45 215.147,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  539.568,1486.45 539.568,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  863.989,1486.45 863.989,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1188.41,1486.45 1188.41,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1512.83,1486.45 1512.83,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1837.25,1486.45 1837.25,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2161.67,1486.45 2161.67,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  215.147,1486.45 215.147,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  539.568,1486.45 539.568,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  863.989,1486.45 863.989,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1188.41,1486.45 1188.41,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1512.83,1486.45 1512.83,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1837.25,1486.45 1837.25,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2161.67,1486.45 2161.67,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip580)\" d=\"M215.147 1517.37 Q211.536 1517.37 209.708 1520.93 Q207.902 1524.47 207.902 1531.6 Q207.902 1538.71 209.708 1542.27 Q211.536 1545.82 215.147 1545.82 Q218.782 1545.82 220.587 1542.27 Q222.416 1538.71 222.416 1531.6 Q222.416 1524.47 220.587 1520.93 Q218.782 1517.37 215.147 1517.37 M215.147 1513.66 Q220.958 1513.66 224.013 1518.27 Q227.092 1522.85 227.092 1531.6 Q227.092 1540.33 224.013 1544.94 Q220.958 1549.52 215.147 1549.52 Q209.337 1549.52 206.259 1544.94 Q203.203 1540.33 203.203 1531.6 Q203.203 1522.85 206.259 1518.27 Q209.337 1513.66 215.147 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M514.256 1544.91 L521.895 1544.91 L521.895 1518.55 L513.585 1520.21 L513.585 1515.95 L521.848 1514.29 L526.524 1514.29 L526.524 1544.91 L534.163 1544.91 L534.163 1548.85 L514.256 1548.85 L514.256 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M553.607 1517.37 Q549.996 1517.37 548.168 1520.93 Q546.362 1524.47 546.362 1531.6 Q546.362 1538.71 548.168 1542.27 Q549.996 1545.82 553.607 1545.82 Q557.242 1545.82 559.047 1542.27 Q560.876 1538.71 560.876 1531.6 Q560.876 1524.47 559.047 1520.93 Q557.242 1517.37 553.607 1517.37 M553.607 1513.66 Q559.418 1513.66 562.473 1518.27 Q565.552 1522.85 565.552 1531.6 Q565.552 1540.33 562.473 1544.94 Q559.418 1549.52 553.607 1549.52 Q547.797 1549.52 544.719 1544.94 Q541.663 1540.33 541.663 1531.6 Q541.663 1522.85 544.719 1518.27 Q547.797 1513.66 553.607 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M842.762 1544.91 L859.082 1544.91 L859.082 1548.85 L837.137 1548.85 L837.137 1544.91 Q839.799 1542.16 844.383 1537.53 Q848.989 1532.88 850.17 1531.53 Q852.415 1529.01 853.295 1527.27 Q854.197 1525.51 854.197 1523.82 Q854.197 1521.07 852.253 1519.33 Q850.332 1517.6 847.23 1517.6 Q845.031 1517.6 842.577 1518.36 Q840.147 1519.13 837.369 1520.68 L837.369 1515.95 Q840.193 1514.82 842.647 1514.24 Q845.1 1513.66 847.137 1513.66 Q852.508 1513.66 855.702 1516.35 Q858.896 1519.03 858.896 1523.52 Q858.896 1525.65 858.086 1527.57 Q857.299 1529.47 855.193 1532.07 Q854.614 1532.74 851.512 1535.95 Q848.41 1539.15 842.762 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M878.896 1517.37 Q875.285 1517.37 873.457 1520.93 Q871.651 1524.47 871.651 1531.6 Q871.651 1538.71 873.457 1542.27 Q875.285 1545.82 878.896 1545.82 Q882.531 1545.82 884.336 1542.27 Q886.165 1538.71 886.165 1531.6 Q886.165 1524.47 884.336 1520.93 Q882.531 1517.37 878.896 1517.37 M878.896 1513.66 Q884.706 1513.66 887.762 1518.27 Q890.841 1522.85 890.841 1531.6 Q890.841 1540.33 887.762 1544.94 Q884.706 1549.52 878.896 1549.52 Q873.086 1549.52 870.007 1544.94 Q866.952 1540.33 866.952 1531.6 Q866.952 1522.85 870.007 1518.27 Q873.086 1513.66 878.896 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1177.25 1530.21 Q1180.61 1530.93 1182.48 1533.2 Q1184.38 1535.47 1184.38 1538.8 Q1184.38 1543.92 1180.86 1546.72 Q1177.35 1549.52 1170.86 1549.52 Q1168.69 1549.52 1166.37 1549.08 Q1164.08 1548.66 1161.63 1547.81 L1161.63 1543.29 Q1163.57 1544.43 1165.89 1545.01 Q1168.2 1545.58 1170.72 1545.58 Q1175.12 1545.58 1177.41 1543.85 Q1179.73 1542.11 1179.73 1538.8 Q1179.73 1535.75 1177.58 1534.03 Q1175.45 1532.3 1171.63 1532.3 L1167.6 1532.3 L1167.6 1528.45 L1171.81 1528.45 Q1175.26 1528.45 1177.09 1527.09 Q1178.92 1525.7 1178.92 1523.11 Q1178.92 1520.45 1177.02 1519.03 Q1175.15 1517.6 1171.63 1517.6 Q1169.71 1517.6 1167.51 1518.01 Q1165.31 1518.43 1162.67 1519.31 L1162.67 1515.14 Q1165.33 1514.4 1167.65 1514.03 Q1169.98 1513.66 1172.04 1513.66 Q1177.37 1513.66 1180.47 1516.09 Q1183.57 1518.5 1183.57 1522.62 Q1183.57 1525.49 1181.93 1527.48 Q1180.28 1529.45 1177.25 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1203.25 1517.37 Q1199.64 1517.37 1197.81 1520.93 Q1196 1524.47 1196 1531.6 Q1196 1538.71 1197.81 1542.27 Q1199.64 1545.82 1203.25 1545.82 Q1206.88 1545.82 1208.69 1542.27 Q1210.52 1538.71 1210.52 1531.6 Q1210.52 1524.47 1208.69 1520.93 Q1206.88 1517.37 1203.25 1517.37 M1203.25 1513.66 Q1209.06 1513.66 1212.11 1518.27 Q1215.19 1522.85 1215.19 1531.6 Q1215.19 1540.33 1212.11 1544.94 Q1209.06 1549.52 1203.25 1549.52 Q1197.44 1549.52 1194.36 1544.94 Q1191.3 1540.33 1191.3 1531.6 Q1191.3 1522.85 1194.36 1518.27 Q1197.44 1513.66 1203.25 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1501 1518.36 L1489.2 1536.81 L1501 1536.81 L1501 1518.36 M1499.78 1514.29 L1505.65 1514.29 L1505.65 1536.81 L1510.59 1536.81 L1510.59 1540.7 L1505.65 1540.7 L1505.65 1548.85 L1501 1548.85 L1501 1540.7 L1485.4 1540.7 L1485.4 1536.19 L1499.78 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1528.32 1517.37 Q1524.71 1517.37 1522.88 1520.93 Q1521.07 1524.47 1521.07 1531.6 Q1521.07 1538.71 1522.88 1542.27 Q1524.71 1545.82 1528.32 1545.82 Q1531.95 1545.82 1533.76 1542.27 Q1535.59 1538.71 1535.59 1531.6 Q1535.59 1524.47 1533.76 1520.93 Q1531.95 1517.37 1528.32 1517.37 M1528.32 1513.66 Q1534.13 1513.66 1537.18 1518.27 Q1540.26 1522.85 1540.26 1531.6 Q1540.26 1540.33 1537.18 1544.94 Q1534.13 1549.52 1528.32 1549.52 Q1522.51 1549.52 1519.43 1544.94 Q1516.37 1540.33 1516.37 1531.6 Q1516.37 1522.85 1519.43 1518.27 Q1522.51 1513.66 1528.32 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1811.95 1514.29 L1830.31 1514.29 L1830.31 1518.22 L1816.23 1518.22 L1816.23 1526.7 Q1817.25 1526.35 1818.27 1526.19 Q1819.29 1526 1820.31 1526 Q1826.09 1526 1829.47 1529.17 Q1832.85 1532.34 1832.85 1537.76 Q1832.85 1543.34 1829.38 1546.44 Q1825.91 1549.52 1819.59 1549.52 Q1817.41 1549.52 1815.14 1549.15 Q1812.9 1548.78 1810.49 1548.04 L1810.49 1543.34 Q1812.58 1544.47 1814.8 1545.03 Q1817.02 1545.58 1819.5 1545.58 Q1823.5 1545.58 1825.84 1543.48 Q1828.18 1541.37 1828.18 1537.76 Q1828.18 1534.15 1825.84 1532.04 Q1823.5 1529.94 1819.5 1529.94 Q1817.62 1529.94 1815.75 1530.35 Q1813.89 1530.77 1811.95 1531.65 L1811.95 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1852.07 1517.37 Q1848.45 1517.37 1846.63 1520.93 Q1844.82 1524.47 1844.82 1531.6 Q1844.82 1538.71 1846.63 1542.27 Q1848.45 1545.82 1852.07 1545.82 Q1855.7 1545.82 1857.51 1542.27 Q1859.33 1538.71 1859.33 1531.6 Q1859.33 1524.47 1857.51 1520.93 Q1855.7 1517.37 1852.07 1517.37 M1852.07 1513.66 Q1857.88 1513.66 1860.93 1518.27 Q1864.01 1522.85 1864.01 1531.6 Q1864.01 1540.33 1860.93 1544.94 Q1857.88 1549.52 1852.07 1549.52 Q1846.26 1549.52 1843.18 1544.94 Q1840.12 1540.33 1840.12 1531.6 Q1840.12 1522.85 1843.18 1518.27 Q1846.26 1513.66 1852.07 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M2147.08 1529.7 Q2143.93 1529.7 2142.08 1531.86 Q2140.25 1534.01 2140.25 1537.76 Q2140.25 1541.49 2142.08 1543.66 Q2143.93 1545.82 2147.08 1545.82 Q2150.23 1545.82 2152.05 1543.66 Q2153.91 1541.49 2153.91 1537.76 Q2153.91 1534.01 2152.05 1531.86 Q2150.23 1529.7 2147.08 1529.7 M2156.36 1515.05 L2156.36 1519.31 Q2154.6 1518.48 2152.79 1518.04 Q2151.01 1517.6 2149.25 1517.6 Q2144.62 1517.6 2142.17 1520.72 Q2139.74 1523.85 2139.39 1530.17 Q2140.76 1528.15 2142.82 1527.09 Q2144.88 1526 2147.36 1526 Q2152.56 1526 2155.57 1529.17 Q2158.6 1532.32 2158.6 1537.76 Q2158.6 1543.08 2155.46 1546.3 Q2152.31 1549.52 2147.08 1549.52 Q2141.08 1549.52 2137.91 1544.94 Q2134.74 1540.33 2134.74 1531.6 Q2134.74 1523.41 2138.63 1518.55 Q2142.52 1513.66 2149.07 1513.66 Q2150.83 1513.66 2152.61 1514.01 Q2154.42 1514.36 2156.36 1515.05 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M2176.66 1517.37 Q2173.05 1517.37 2171.22 1520.93 Q2169.42 1524.47 2169.42 1531.6 Q2169.42 1538.71 2171.22 1542.27 Q2173.05 1545.82 2176.66 1545.82 Q2180.29 1545.82 2182.1 1542.27 Q2183.93 1538.71 2183.93 1531.6 Q2183.93 1524.47 2182.1 1520.93 Q2180.29 1517.37 2176.66 1517.37 M2176.66 1513.66 Q2182.47 1513.66 2185.53 1518.27 Q2188.6 1522.85 2188.6 1531.6 Q2188.6 1540.33 2185.53 1544.94 Q2182.47 1549.52 2176.66 1549.52 Q2170.85 1549.52 2167.77 1544.94 Q2164.72 1540.33 2164.72 1531.6 Q2164.72 1522.85 2167.77 1518.27 Q2170.85 1513.66 2176.66 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,1477.5 2352.76,1477.5 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,1124.33 2352.76,1124.33 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,771.15 2352.76,771.15 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,417.975 2352.76,417.975 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,64.7991 2352.76,64.7991 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,1486.45 186.274,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,1477.5 205.172,1477.5 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,1124.33 205.172,1124.33 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,771.15 205.172,771.15 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,417.975 205.172,417.975 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,64.7991 205.172,64.7991 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip580)\" d=\"M62.9365 1463.3 Q59.3254 1463.3 57.4967 1466.86 Q55.6912 1470.41 55.6912 1477.54 Q55.6912 1484.64 57.4967 1488.21 Q59.3254 1491.75 62.9365 1491.75 Q66.5707 1491.75 68.3763 1488.21 Q70.205 1484.64 70.205 1477.54 Q70.205 1470.41 68.3763 1466.86 Q66.5707 1463.3 62.9365 1463.3 M62.9365 1459.6 Q68.7467 1459.6 71.8022 1464.2 Q74.8809 1468.79 74.8809 1477.54 Q74.8809 1486.26 71.8022 1490.87 Q68.7467 1495.45 62.9365 1495.45 Q57.1264 1495.45 54.0477 1490.87 Q50.9921 1486.26 50.9921 1477.54 Q50.9921 1468.79 54.0477 1464.2 Q57.1264 1459.6 62.9365 1459.6 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M83.0984 1488.9 L87.9827 1488.9 L87.9827 1494.78 L83.0984 1494.78 L83.0984 1488.9 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M108.168 1463.3 Q104.557 1463.3 102.728 1466.86 Q100.922 1470.41 100.922 1477.54 Q100.922 1484.64 102.728 1488.21 Q104.557 1491.75 108.168 1491.75 Q111.802 1491.75 113.608 1488.21 Q115.436 1484.64 115.436 1477.54 Q115.436 1470.41 113.608 1466.86 Q111.802 1463.3 108.168 1463.3 M108.168 1459.6 Q113.978 1459.6 117.033 1464.2 Q120.112 1468.79 120.112 1477.54 Q120.112 1486.26 117.033 1490.87 Q113.978 1495.45 108.168 1495.45 Q102.358 1495.45 99.2789 1490.87 Q96.2234 1486.26 96.2234 1477.54 Q96.2234 1468.79 99.2789 1464.2 Q102.358 1459.6 108.168 1459.6 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M138.33 1463.3 Q134.719 1463.3 132.89 1466.86 Q131.084 1470.41 131.084 1477.54 Q131.084 1484.64 132.89 1488.21 Q134.719 1491.75 138.33 1491.75 Q141.964 1491.75 143.769 1488.21 Q145.598 1484.64 145.598 1477.54 Q145.598 1470.41 143.769 1466.86 Q141.964 1463.3 138.33 1463.3 M138.33 1459.6 Q144.14 1459.6 147.195 1464.2 Q150.274 1468.79 150.274 1477.54 Q150.274 1486.26 147.195 1490.87 Q144.14 1495.45 138.33 1495.45 Q132.519 1495.45 129.441 1490.87 Q126.385 1486.26 126.385 1477.54 Q126.385 1468.79 129.441 1464.2 Q132.519 1459.6 138.33 1459.6 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M63.9319 1110.12 Q60.3208 1110.12 58.4921 1113.69 Q56.6865 1117.23 56.6865 1124.36 Q56.6865 1131.47 58.4921 1135.03 Q60.3208 1138.57 63.9319 1138.57 Q67.5661 1138.57 69.3717 1135.03 Q71.2004 1131.47 71.2004 1124.36 Q71.2004 1117.23 69.3717 1113.69 Q67.5661 1110.12 63.9319 1110.12 M63.9319 1106.42 Q69.742 1106.42 72.7976 1111.03 Q75.8763 1115.61 75.8763 1124.36 Q75.8763 1133.09 72.7976 1137.69 Q69.742 1142.28 63.9319 1142.28 Q58.1217 1142.28 55.043 1137.69 Q51.9875 1133.09 51.9875 1124.36 Q51.9875 1115.61 55.043 1111.03 Q58.1217 1106.42 63.9319 1106.42 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M84.0938 1135.73 L88.978 1135.73 L88.978 1141.61 L84.0938 1141.61 L84.0938 1135.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M103.191 1137.67 L119.51 1137.67 L119.51 1141.61 L97.566 1141.61 L97.566 1137.67 Q100.228 1134.92 104.811 1130.29 Q109.418 1125.63 110.598 1124.29 Q112.844 1121.77 113.723 1120.03 Q114.626 1118.27 114.626 1116.58 Q114.626 1113.83 112.682 1112.09 Q110.76 1110.36 107.658 1110.36 Q105.459 1110.36 103.006 1111.12 Q100.575 1111.88 97.7974 1113.43 L97.7974 1108.71 Q100.621 1107.58 103.075 1107 Q105.529 1106.42 107.566 1106.42 Q112.936 1106.42 116.131 1109.11 Q119.325 1111.79 119.325 1116.28 Q119.325 1118.41 118.515 1120.33 Q117.728 1122.23 115.621 1124.82 Q115.043 1125.49 111.941 1128.71 Q108.839 1131.91 103.191 1137.67 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M129.371 1107.05 L147.728 1107.05 L147.728 1110.98 L133.654 1110.98 L133.654 1119.45 Q134.672 1119.11 135.691 1118.94 Q136.709 1118.76 137.728 1118.76 Q143.515 1118.76 146.894 1121.93 Q150.274 1125.1 150.274 1130.52 Q150.274 1136.1 146.802 1139.2 Q143.33 1142.28 137.01 1142.28 Q134.834 1142.28 132.566 1141.91 Q130.32 1141.54 127.913 1140.8 L127.913 1136.1 Q129.996 1137.23 132.219 1137.79 Q134.441 1138.34 136.918 1138.34 Q140.922 1138.34 143.26 1136.24 Q145.598 1134.13 145.598 1130.52 Q145.598 1126.91 143.26 1124.8 Q140.922 1122.69 136.918 1122.69 Q135.043 1122.69 133.168 1123.11 Q131.316 1123.53 129.371 1124.41 L129.371 1107.05 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M62.9365 756.949 Q59.3254 756.949 57.4967 760.514 Q55.6912 764.055 55.6912 771.185 Q55.6912 778.291 57.4967 781.856 Q59.3254 785.398 62.9365 785.398 Q66.5707 785.398 68.3763 781.856 Q70.205 778.291 70.205 771.185 Q70.205 764.055 68.3763 760.514 Q66.5707 756.949 62.9365 756.949 M62.9365 753.245 Q68.7467 753.245 71.8022 757.852 Q74.8809 762.435 74.8809 771.185 Q74.8809 779.912 71.8022 784.518 Q68.7467 789.102 62.9365 789.102 Q57.1264 789.102 54.0477 784.518 Q50.9921 779.912 50.9921 771.185 Q50.9921 762.435 54.0477 757.852 Q57.1264 753.245 62.9365 753.245 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M83.0984 782.551 L87.9827 782.551 L87.9827 788.43 L83.0984 788.43 L83.0984 782.551 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M98.2141 753.87 L116.57 753.87 L116.57 757.805 L102.496 757.805 L102.496 766.278 Q103.515 765.93 104.534 765.768 Q105.552 765.583 106.571 765.583 Q112.358 765.583 115.737 768.754 Q119.117 771.926 119.117 777.342 Q119.117 782.921 115.645 786.023 Q112.172 789.102 105.853 789.102 Q103.677 789.102 101.409 788.731 Q99.1632 788.361 96.7558 787.62 L96.7558 782.921 Q98.8391 784.055 101.061 784.611 Q103.284 785.166 105.76 785.166 Q109.765 785.166 112.103 783.06 Q114.441 780.953 114.441 777.342 Q114.441 773.731 112.103 771.625 Q109.765 769.518 105.76 769.518 Q103.885 769.518 102.01 769.935 Q100.159 770.352 98.2141 771.231 L98.2141 753.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M138.33 756.949 Q134.719 756.949 132.89 760.514 Q131.084 764.055 131.084 771.185 Q131.084 778.291 132.89 781.856 Q134.719 785.398 138.33 785.398 Q141.964 785.398 143.769 781.856 Q145.598 778.291 145.598 771.185 Q145.598 764.055 143.769 760.514 Q141.964 756.949 138.33 756.949 M138.33 753.245 Q144.14 753.245 147.195 757.852 Q150.274 762.435 150.274 771.185 Q150.274 779.912 147.195 784.518 Q144.14 789.102 138.33 789.102 Q132.519 789.102 129.441 784.518 Q126.385 779.912 126.385 771.185 Q126.385 762.435 129.441 757.852 Q132.519 753.245 138.33 753.245 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M63.9319 403.773 Q60.3208 403.773 58.4921 407.338 Q56.6865 410.88 56.6865 418.009 Q56.6865 425.116 58.4921 428.681 Q60.3208 432.222 63.9319 432.222 Q67.5661 432.222 69.3717 428.681 Q71.2004 425.116 71.2004 418.009 Q71.2004 410.88 69.3717 407.338 Q67.5661 403.773 63.9319 403.773 M63.9319 400.07 Q69.742 400.07 72.7976 404.676 Q75.8763 409.259 75.8763 418.009 Q75.8763 426.736 72.7976 431.343 Q69.742 435.926 63.9319 435.926 Q58.1217 435.926 55.043 431.343 Q51.9875 426.736 51.9875 418.009 Q51.9875 409.259 55.043 404.676 Q58.1217 400.07 63.9319 400.07 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M84.0938 429.375 L88.978 429.375 L88.978 435.255 L84.0938 435.255 L84.0938 429.375 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M97.9826 400.695 L120.205 400.695 L120.205 402.685 L107.658 435.255 L102.774 435.255 L114.58 404.63 L97.9826 404.63 L97.9826 400.695 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M129.371 400.695 L147.728 400.695 L147.728 404.63 L133.654 404.63 L133.654 413.102 Q134.672 412.755 135.691 412.593 Q136.709 412.408 137.728 412.408 Q143.515 412.408 146.894 415.579 Q150.274 418.75 150.274 424.167 Q150.274 429.745 146.802 432.847 Q143.33 435.926 137.01 435.926 Q134.834 435.926 132.566 435.556 Q130.32 435.185 127.913 434.445 L127.913 429.745 Q129.996 430.88 132.219 431.435 Q134.441 431.991 136.918 431.991 Q140.922 431.991 143.26 429.884 Q145.598 427.778 145.598 424.167 Q145.598 420.556 143.26 418.449 Q140.922 416.343 136.918 416.343 Q135.043 416.343 133.168 416.759 Q131.316 417.176 129.371 418.056 L129.371 400.695 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M53.7467 78.144 L61.3856 78.144 L61.3856 51.7784 L53.0754 53.445 L53.0754 49.1858 L61.3393 47.5191 L66.0152 47.5191 L66.0152 78.144 L73.654 78.144 L73.654 82.0791 L53.7467 82.0791 L53.7467 78.144 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M83.0984 76.1995 L87.9827 76.1995 L87.9827 82.0791 L83.0984 82.0791 L83.0984 76.1995 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M108.168 50.5978 Q104.557 50.5978 102.728 54.1626 Q100.922 57.7043 100.922 64.8339 Q100.922 71.9403 102.728 75.5051 Q104.557 79.0467 108.168 79.0467 Q111.802 79.0467 113.608 75.5051 Q115.436 71.9403 115.436 64.8339 Q115.436 57.7043 113.608 54.1626 Q111.802 50.5978 108.168 50.5978 M108.168 46.8941 Q113.978 46.8941 117.033 51.5006 Q120.112 56.0839 120.112 64.8339 Q120.112 73.5607 117.033 78.1671 Q113.978 82.7504 108.168 82.7504 Q102.358 82.7504 99.2789 78.1671 Q96.2234 73.5607 96.2234 64.8339 Q96.2234 56.0839 99.2789 51.5006 Q102.358 46.8941 108.168 46.8941 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M138.33 50.5978 Q134.719 50.5978 132.89 54.1626 Q131.084 57.7043 131.084 64.8339 Q131.084 71.9403 132.89 75.5051 Q134.719 79.0467 138.33 79.0467 Q141.964 79.0467 143.769 75.5051 Q145.598 71.9403 145.598 64.8339 Q145.598 57.7043 143.769 54.1626 Q141.964 50.5978 138.33 50.5978 M138.33 46.8941 Q144.14 46.8941 147.195 51.5006 Q150.274 56.0839 150.274 64.8339 Q150.274 73.5607 147.195 78.1671 Q144.14 82.7504 138.33 82.7504 Q132.519 82.7504 129.441 78.1671 Q126.385 73.5607 126.385 64.8339 Q126.385 56.0839 129.441 51.5006 Q132.519 46.8941 138.33 46.8941 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip582)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  247.59,1374.42 280.032,1308.86 312.474,1345.06 344.916,1207.76 377.358,810.22 409.8,983.056 442.242,1439.98 474.684,1445.72 507.126,87.9763 539.568,1322.99 \n",
       "  572.01,898.735 604.452,1117.26 636.894,1270.01 669.337,1202.69 701.779,1125.65 734.221,157.728 766.663,713.98 799.105,1264.71 831.547,1375.3 863.989,1330.27 \n",
       "  896.431,1341.97 928.873,1281.49 961.315,1105.56 993.757,1134.26 1026.2,1191.43 1058.64,1167.15 1091.08,1249.48 1123.53,1206.88 1155.97,1212.4 1188.41,1261.62 \n",
       "  1220.85,1234.47 1253.29,1249.04 1285.74,1185.47 1318.18,1234.91 1350.62,1185.69 1383.06,1214.16 1415.5,1283.48 1447.95,1234.47 1480.39,1257.87 1512.83,1266.26 \n",
       "  1545.27,1197.17 1577.71,1209.97 1610.16,1188.78 1642.6,1189.88 1675.04,1207.98 1707.48,1198.71 1739.93,1190.77 1772.37,1177.08 1804.81,1203.57 1837.25,1296.5 \n",
       "  1869.69,1248.16 1902.14,1114.83 1934.58,1228.29 1967.02,1230.28 1999.46,1208.21 2031.9,1248.16 2064.35,1226.08 2096.79,1242.42 2129.23,1330.71 2161.67,1163.84 \n",
       "  2194.11,1250.59 2226.56,1216.59 2259,1256.1 2291.44,1239.33 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip580)\" d=\"\n",
       "M1987.39 198.898 L2280.54 198.898 L2280.54 95.2176 L1987.39 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1987.39,198.898 2280.54,198.898 2280.54,95.2176 1987.39,95.2176 1987.39,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2011.46,147.058 2155.89,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip580)\" d=\"M2193.81 166.745 Q2192 171.375 2190.29 172.787 Q2188.58 174.199 2185.71 174.199 L2182.3 174.199 L2182.3 170.634 L2184.8 170.634 Q2186.56 170.634 2187.53 169.8 Q2188.51 168.967 2189.69 165.865 L2190.45 163.921 L2179.97 138.412 L2184.48 138.412 L2192.58 158.689 L2200.68 138.412 L2205.2 138.412 L2193.81 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M2212.49 160.402 L2220.13 160.402 L2220.13 134.037 L2211.82 135.703 L2211.82 131.444 L2220.08 129.778 L2224.76 129.778 L2224.76 160.402 L2232.4 160.402 L2232.4 164.338 L2212.49 164.338 L2212.49 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/episodes\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        X  = X_0\n",
    "\n",
    "        for k = 1:T\n",
    "\n",
    "            # 1. Choose action\n",
    "            if rand() < epsilon\n",
    "                if rand() < EXPrand \n",
    "                    A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                else\n",
    "                    A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                end\n",
    "            else\n",
    "\n",
    "                A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                if A == 1000.0 # Indicates no values in this region\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "\n",
    "            # 2. Cache last state\n",
    "            qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "            # 3. Generate the next stae\n",
    "            Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "            # 4. Collect reward R( s, a, s' )\n",
    "            R_t = cartpole_reward( Xp )\n",
    "\n",
    "            # 5. Get the optimal action at the next state\n",
    "            a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "            # 6. Compute the value at the next state\n",
    "\n",
    "            V_tp1_opt = query_value_fuzzy( \n",
    "                Q_kdTree, G, V, \n",
    "                get_Q( \n",
    "                    select_X_vector( Xp ), \n",
    "                    a_tp1_opt \n",
    "                ); \n",
    "                k = vNN \n",
    "            )\n",
    "            if isnan( V_tp1_opt )\n",
    "                V_tp1_opt = 0.0\n",
    "            end\n",
    "\n",
    "\n",
    "            # 7. Blend the value back into nearest points\n",
    "\n",
    "            idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "            nNear      = size( idxs, 1 )\n",
    "            for i = 1:nNear\n",
    "                j    = idxs[i]\n",
    "                if !isnan( wgts[i] ) \n",
    "\n",
    "                    # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                    VS[j] = VS[j] + alpha*( R_t + V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "                    \n",
    "                end\n",
    "            end\n",
    "\n",
    "            states[:,k] = Xp\n",
    "            actions[k]  = A\n",
    "\n",
    "            X = Xp\n",
    "        end\n",
    "\n",
    "        s_l    = vertical_score_s( states, aMargin, ts )\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "\n",
    "        # Swap Q-functions for Double Q-Learning\n",
    "        vSwp = copy( VS   )\n",
    "        VS   = copy( V    )\n",
    "        V    = copy( vSwp )\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "    \n",
    "    if (s_Avg > bestAvg) && true\n",
    "        println( \"BLEND\" )\n",
    "        bestAvg = s_Avg\n",
    "        vBAv    = copy( V ) # Try a blend of both next\n",
    "        vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V )\n",
    "    end\n",
    "    \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9defcf2b-31cb-4f1f-b0bc-829ced9549eb",
   "metadata": {},
   "source": [
    "# Method 2 Performance, Longest Vertical Duration [s]\n",
    "Each score is the best run out of an entire training period: 64 epochs of 64 episodes each, Q-function swap after every episode  \n",
    "* Plain: 2.12\n",
    "* Blended: 3.14, 33.15, 2.61, 3.45, 2.5 - Avg: 8.97\n",
    "* TD: 28.24, 17.57, 34.31, 34.32, 33.65 - Avg: 29.62\n",
    "* TD, Blended: 25.21, 30.70, 24.22, 33.53, 27.03 - Avg: 28.13  \n",
    "\n",
    "Blending does not appear to improve Q(TD) top performance. You should still check if it raises average performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
