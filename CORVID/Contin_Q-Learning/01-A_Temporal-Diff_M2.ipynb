{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.02148 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 # 0.00782 # 0.00391\n",
    "beta     = 0.999\n",
    "gamma    = 1.00\n",
    "swapDiv  = 64\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes = 64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   = 32 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = true\n",
    "N_peaks =  32\n",
    "N_steps = 128\n",
    "lambda  =   0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.19000000000000003, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.08, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.34000000000000014, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.5800000000000003, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.22000000000000006, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.16, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.8700000000000006, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.35000000000000014, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.2700000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 1.320000000000001, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.7300000000000004, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.2128125000000001\n",
      "\n",
      "Epoch 2, Best Score: 1.320000000000001\n",
      "Training Iteration 4 score: 0.4000000000000002, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.15, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.47000000000000025, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.7000000000000004, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.26000000000000006, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.08, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.5400000000000003, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.8200000000000005, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.3000000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.09, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.6200000000000003, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.13999999999999999, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.10999999999999999, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.38000000000000017, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.6800000000000004, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.34859375\n",
      "\n",
      "Epoch 3, Best Score: 1.380000000000001\n",
      "Training Iteration 4 score: 0.4400000000000002, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.23000000000000007, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 1.5100000000000011, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.3100000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.23000000000000007, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.6900000000000004, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 2.299999999999995, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.12999999999999998, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.3900000000000002, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.5200000000000002, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.3317187500000001\n",
      "\n",
      "Epoch 4, Best Score: 2.299999999999995\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.3100000000000001, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.014375000000000004\n",
      "\n",
      "Epoch 5, Best Score: 2.299999999999995\n",
      "Training Iteration 4 score: 0.08, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 1.1000000000000008, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.5100000000000002, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 1.0800000000000007, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 1.310000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.48000000000000026, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.4200000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 7.539999999999884, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.20000000000000004, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.45000000000000023, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 1.6000000000000012, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.6268749999999983\n",
      "\n",
      "Epoch 6, Best Score: 7.539999999999884\n",
      "Training Iteration 4 score: 0.12999999999999998, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.25000000000000006, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.15, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.07, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.18000000000000002, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.09999999999999999, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.23000000000000007, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.07, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.25000000000000006, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.07, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.07578125000000002\n",
      "\n",
      "Epoch 7, Best Score: 7.539999999999884\n",
      "Training Iteration 4 score: 0.6900000000000004, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.48000000000000026, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 1.0400000000000007, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 1.270000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.6900000000000004, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.6200000000000003, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.5000000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.3200000000000001, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.18000000000000002, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.9400000000000006, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.6200000000000003, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 2.0899999999999994, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.2800000000000001, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.6100000000000003, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.5539062500000003\n",
      "\n",
      "Epoch 8, Best Score: 7.539999999999884\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.004687500000000001\n",
      "\n",
      "Epoch 9, Best Score: 7.539999999999884\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.2900000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.039843750000000025\n",
      "\n",
      "Epoch 10, Best Score: 7.539999999999884\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.9400000000000006, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.35000000000000014, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.37000000000000016, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.7700000000000005, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.4000000000000002, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.36000000000000015, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.47000000000000025, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.25000000000000006, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.26437500000000014\n",
      "\n",
      "Epoch 11, Best Score: 7.539999999999884\n",
      "Training Iteration 4 score: 0.25000000000000006, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.011875000000000002\n",
      "\n",
      "Epoch 12, Best Score: 7.539999999999884\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.01765625000000001\n",
      "\n",
      "Epoch 13, Best Score: 7.539999999999884\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.12999999999999998, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.2900000000000001, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.08, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.3100000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 1.2500000000000009, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.08, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.16578125000000013\n",
      "\n",
      "Epoch 14, Best Score: 7.539999999999884\n",
      "Training Iteration 4 score: 0.2700000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.4100000000000002, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.7400000000000004, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.5900000000000003, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.35000000000000014, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.6300000000000003, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.8700000000000006, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.7300000000000004, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 1.1400000000000008, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.8700000000000006, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 1.6700000000000013, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 30.220000000001924, epsilon: 8.881784197001252e-16\n",
      "Average Score: 2.548906250000095\n",
      "\n",
      "Epoch 15, Best Score: 36.0500000000014\n",
      "Training Iteration 4 score: 0.4000000000000002, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.4000000000000002, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 1.0500000000000007, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.16625000000000006\n",
      "\n",
      "Epoch 16, Best Score: 36.0500000000014\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.12999999999999998, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.9100000000000006, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.7700000000000005, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.3300000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.5300000000000002, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.14078125000000008\n",
      "\n",
      "Epoch 17, Best Score: 36.0500000000014\n",
      "Training Iteration 4 score: 0.3200000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.07, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.9100000000000006, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 1.0200000000000007, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.8000000000000005, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 3.1199999999999775, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 4.929999999999939, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 2.9299999999999815, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.604218749999996\n",
      "\n",
      "Epoch 18, Best Score: 36.0500000000014\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 19, Best Score: 36.0500000000014\n",
      "Training Iteration 4 score: 0.8400000000000005, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.22000000000000006, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 1.1300000000000008, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.19000000000000003, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.35000000000000014, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.15, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.22000000000000006, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.36000000000000015, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.060000000000000005, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.14875000000000008\n",
      "\n",
      "Epoch 20, Best Score: 36.0500000000014\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.004375000000000001\n",
      "\n",
      "Epoch 21, Best Score: 36.0500000000014\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.09, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 1.320000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.9000000000000006, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.08781250000000004\n",
      "\n",
      "Epoch 22, Best Score: 36.0500000000014\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.021093750000000015\n",
      "\n",
      "Epoch 23, Best Score: 36.0500000000014\n",
      "Training Iteration 4 score: 0.5000000000000002, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 1.1300000000000008, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 8.739999999999858, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 10.569999999999819, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 15.049999999999724, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 1.9667187499999814\n",
      "\n",
      "Epoch 24, Best Score: 36.0500000000014\n",
      "Training Iteration 4 score: 0.16, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 16.11999999999972, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.18000000000000002, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.34000000000000014, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 23.430000000000863, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 16.6199999999998, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 23.520000000000877, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 9.54999999999984, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 5.469999999999928, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 5.009999999999938, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 5.61406250000009\n",
      "\n",
      "Epoch 25, Best Score: 36.0500000000014\n",
      "Training Iteration 4 score: 2.159999999999998, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.5700000000000003, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.3900000000000002, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.36000000000000015, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.4100000000000002, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 2.2299999999999964, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 2.719999999999986, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 2.52999999999999, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 1.1200000000000008, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 1.360000000000001, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 2.4599999999999915, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 1.6500000000000012, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 1.6100000000000012, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 2.1299999999999986, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 1.9100000000000015, epsilon: 8.881784197001252e-16\n",
      "Average Score: 1.4501562499999963\n",
      "\n",
      "Epoch 26, Best Score: 36.0500000000014\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.37000000000000016, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.18000000000000002, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.10999999999999999, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.3100000000000001, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.8700000000000006, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.6300000000000003, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.16, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.16, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.32187499999999986\n",
      "\n",
      "Epoch 27, Best Score: 36.0500000000014\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 28, Best Score: 36.0500000000014\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.7100000000000004, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 1.0400000000000007, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.38000000000000017, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.19890625000000012\n",
      "\n",
      "Epoch 29, Best Score: 36.0500000000014\n",
      "Training Iteration 4 score: 0.11999999999999998, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.26000000000000006, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.21000000000000005, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.4100000000000002, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 1.7400000000000013, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.18000000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.8800000000000006, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.36000000000000015, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 1.5900000000000012, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.5000000000000002, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.24515625000000008\n",
      "\n",
      "Epoch 30, Best Score: 36.0500000000014\n",
      "Training Iteration 4 score: 0.17, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.48000000000000026, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 1.8100000000000014, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.37000000000000016, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.6200000000000003, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 2.4999999999999907, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.5800000000000003, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.6900000000000004, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.350000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.5200000000000002, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 1.2200000000000009, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.7100000000000004, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 1.350000000000001, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.7600000000000005, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 3.7399999999999642, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 2.5099999999999905, epsilon: 8.881784197001252e-16\n",
      "Average Score: 1.1392187499999984\n",
      "\n",
      "Epoch 31, Best Score: 36.0500000000014\n",
      "Training Iteration 4 score: 0.9200000000000006, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.8600000000000005, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 2.020000000000001, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.3900000000000002, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 1.0900000000000007, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.24000000000000007, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.26000000000000006, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.3200000000000001, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.1400000000000008, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.8500000000000005, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.2700000000000001, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.9100000000000006, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.34000000000000014, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.8026562499999998\n",
      "\n",
      "Epoch 32, Best Score: 36.0500000000014\n",
      "Training Iteration 4 score: 0.21000000000000005, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.15, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.5000000000000002, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.5300000000000002, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 16.82999999999983, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.35000000000000014, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.3100000000000001, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 17.409999999999922, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.12999999999999998, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 23.940000000000943, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 28.07000000000159, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.34000000000000014, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.2700000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.13999999999999999, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 29.540000000001818, epsilon: 8.881784197001252e-16\n",
      "Average Score: 11.402656250000422\n",
      "Saved a trained Q-table with size (76032,), After 13.36494976679484 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip740\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip740)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip741\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip740)\" d=\"\n",
       "M184.191 1486.45 L2352.76 1486.45 L2352.76 47.2441 L184.191 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip742\">\n",
       "    <rect x=\"184\" y=\"47\" width=\"2170\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip742)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  509.541,1486.45 509.541,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip742)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  839.512,1486.45 839.512,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip742)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1169.48,1486.45 1169.48,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip742)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1499.45,1486.45 1499.45,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip742)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1829.42,1486.45 1829.42,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip742)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2159.39,1486.45 2159.39,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip740)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip740)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  509.541,1486.45 509.541,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip740)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  839.512,1486.45 839.512,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip740)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1169.48,1486.45 1169.48,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip740)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1499.45,1486.45 1499.45,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip740)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1829.42,1486.45 1829.42,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip740)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2159.39,1486.45 2159.39,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip740)\" d=\"M499.819 1514.29 L518.176 1514.29 L518.176 1518.22 L504.102 1518.22 L504.102 1526.7 Q505.12 1526.35 506.139 1526.19 Q507.157 1526 508.176 1526 Q513.963 1526 517.342 1529.17 Q520.722 1532.34 520.722 1537.76 Q520.722 1543.34 517.25 1546.44 Q513.778 1549.52 507.458 1549.52 Q505.282 1549.52 503.014 1549.15 Q500.768 1548.78 498.361 1548.04 L498.361 1543.34 Q500.444 1544.47 502.666 1545.03 Q504.889 1545.58 507.366 1545.58 Q511.37 1545.58 513.708 1543.48 Q516.046 1541.37 516.046 1537.76 Q516.046 1534.15 513.708 1532.04 Q511.37 1529.94 507.366 1529.94 Q505.491 1529.94 503.616 1530.35 Q501.764 1530.77 499.819 1531.65 L499.819 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M814.199 1544.91 L821.838 1544.91 L821.838 1518.55 L813.528 1520.21 L813.528 1515.95 L821.792 1514.29 L826.468 1514.29 L826.468 1544.91 L834.107 1544.91 L834.107 1548.85 L814.199 1548.85 L814.199 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M853.551 1517.37 Q849.94 1517.37 848.111 1520.93 Q846.306 1524.47 846.306 1531.6 Q846.306 1538.71 848.111 1542.27 Q849.94 1545.82 853.551 1545.82 Q857.185 1545.82 858.991 1542.27 Q860.82 1538.71 860.82 1531.6 Q860.82 1524.47 858.991 1520.93 Q857.185 1517.37 853.551 1517.37 M853.551 1513.66 Q859.361 1513.66 862.417 1518.27 Q865.495 1522.85 865.495 1531.6 Q865.495 1540.33 862.417 1544.94 Q859.361 1549.52 853.551 1549.52 Q847.741 1549.52 844.662 1544.94 Q841.607 1540.33 841.607 1531.6 Q841.607 1522.85 844.662 1518.27 Q847.741 1513.66 853.551 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M1144.67 1544.91 L1152.31 1544.91 L1152.31 1518.55 L1144 1520.21 L1144 1515.95 L1152.26 1514.29 L1156.94 1514.29 L1156.94 1544.91 L1164.57 1544.91 L1164.57 1548.85 L1144.67 1548.85 L1144.67 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M1174.07 1514.29 L1192.42 1514.29 L1192.42 1518.22 L1178.35 1518.22 L1178.35 1526.7 Q1179.37 1526.35 1180.38 1526.19 Q1181.4 1526 1182.42 1526 Q1188.21 1526 1191.59 1529.17 Q1194.97 1532.34 1194.97 1537.76 Q1194.97 1543.34 1191.5 1546.44 Q1188.02 1549.52 1181.7 1549.52 Q1179.53 1549.52 1177.26 1549.15 Q1175.01 1548.78 1172.61 1548.04 L1172.61 1543.34 Q1174.69 1544.47 1176.91 1545.03 Q1179.13 1545.58 1181.61 1545.58 Q1185.62 1545.58 1187.95 1543.48 Q1190.29 1541.37 1190.29 1537.76 Q1190.29 1534.15 1187.95 1532.04 Q1185.62 1529.94 1181.61 1529.94 Q1179.74 1529.94 1177.86 1530.35 Q1176.01 1530.77 1174.07 1531.65 L1174.07 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M1478.23 1544.91 L1494.55 1544.91 L1494.55 1548.85 L1472.6 1548.85 L1472.6 1544.91 Q1475.26 1542.16 1479.85 1537.53 Q1484.45 1532.88 1485.63 1531.53 Q1487.88 1529.01 1488.76 1527.27 Q1489.66 1525.51 1489.66 1523.82 Q1489.66 1521.07 1487.72 1519.33 Q1485.8 1517.6 1482.69 1517.6 Q1480.49 1517.6 1478.04 1518.36 Q1475.61 1519.13 1472.83 1520.68 L1472.83 1515.95 Q1475.66 1514.82 1478.11 1514.24 Q1480.56 1513.66 1482.6 1513.66 Q1487.97 1513.66 1491.17 1516.35 Q1494.36 1519.03 1494.36 1523.52 Q1494.36 1525.65 1493.55 1527.57 Q1492.76 1529.47 1490.66 1532.07 Q1490.08 1532.74 1486.98 1535.95 Q1483.87 1539.15 1478.23 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M1514.36 1517.37 Q1510.75 1517.37 1508.92 1520.93 Q1507.11 1524.47 1507.11 1531.6 Q1507.11 1538.71 1508.92 1542.27 Q1510.75 1545.82 1514.36 1545.82 Q1517.99 1545.82 1519.8 1542.27 Q1521.63 1538.71 1521.63 1531.6 Q1521.63 1524.47 1519.8 1520.93 Q1517.99 1517.37 1514.36 1517.37 M1514.36 1513.66 Q1520.17 1513.66 1523.23 1518.27 Q1526.3 1522.85 1526.3 1531.6 Q1526.3 1540.33 1523.23 1544.94 Q1520.17 1549.52 1514.36 1549.52 Q1508.55 1549.52 1505.47 1544.94 Q1502.42 1540.33 1502.42 1531.6 Q1502.42 1522.85 1505.47 1518.27 Q1508.55 1513.66 1514.36 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M1808.69 1544.91 L1825.01 1544.91 L1825.01 1548.85 L1803.07 1548.85 L1803.07 1544.91 Q1805.73 1542.16 1810.31 1537.53 Q1814.92 1532.88 1816.1 1531.53 Q1818.35 1529.01 1819.23 1527.27 Q1820.13 1525.51 1820.13 1523.82 Q1820.13 1521.07 1818.18 1519.33 Q1816.26 1517.6 1813.16 1517.6 Q1810.96 1517.6 1808.51 1518.36 Q1806.08 1519.13 1803.3 1520.68 L1803.3 1515.95 Q1806.12 1514.82 1808.58 1514.24 Q1811.03 1513.66 1813.07 1513.66 Q1818.44 1513.66 1821.63 1516.35 Q1824.83 1519.03 1824.83 1523.52 Q1824.83 1525.65 1824.02 1527.57 Q1823.23 1529.47 1821.12 1532.07 Q1820.55 1532.74 1817.44 1535.95 Q1814.34 1539.15 1808.69 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M1834.87 1514.29 L1853.23 1514.29 L1853.23 1518.22 L1839.16 1518.22 L1839.16 1526.7 Q1840.18 1526.35 1841.19 1526.19 Q1842.21 1526 1843.23 1526 Q1849.02 1526 1852.4 1529.17 Q1855.78 1532.34 1855.78 1537.76 Q1855.78 1543.34 1852.3 1546.44 Q1848.83 1549.52 1842.51 1549.52 Q1840.34 1549.52 1838.07 1549.15 Q1835.82 1548.78 1833.42 1548.04 L1833.42 1543.34 Q1835.5 1544.47 1837.72 1545.03 Q1839.94 1545.58 1842.42 1545.58 Q1846.43 1545.58 1848.76 1543.48 Q1851.1 1541.37 1851.1 1537.76 Q1851.1 1534.15 1848.76 1532.04 Q1846.43 1529.94 1842.42 1529.94 Q1840.55 1529.94 1838.67 1530.35 Q1836.82 1530.77 1834.87 1531.65 L1834.87 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M2148.24 1530.21 Q2151.59 1530.93 2153.47 1533.2 Q2155.37 1535.47 2155.37 1538.8 Q2155.37 1543.92 2151.85 1546.72 Q2148.33 1549.52 2141.85 1549.52 Q2139.67 1549.52 2137.36 1549.08 Q2135.06 1548.66 2132.61 1547.81 L2132.61 1543.29 Q2134.56 1544.43 2136.87 1545.01 Q2139.19 1545.58 2141.71 1545.58 Q2146.11 1545.58 2148.4 1543.85 Q2150.71 1542.11 2150.71 1538.8 Q2150.71 1535.75 2148.56 1534.03 Q2146.43 1532.3 2142.61 1532.3 L2138.58 1532.3 L2138.58 1528.45 L2142.8 1528.45 Q2146.25 1528.45 2148.07 1527.09 Q2149.9 1525.7 2149.9 1523.11 Q2149.9 1520.45 2148 1519.03 Q2146.13 1517.6 2142.61 1517.6 Q2140.69 1517.6 2138.49 1518.01 Q2136.29 1518.43 2133.65 1519.31 L2133.65 1515.14 Q2136.31 1514.4 2138.63 1514.03 Q2140.97 1513.66 2143.03 1513.66 Q2148.35 1513.66 2151.45 1516.09 Q2154.56 1518.5 2154.56 1522.62 Q2154.56 1525.49 2152.91 1527.48 Q2151.27 1529.45 2148.24 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M2174.23 1517.37 Q2170.62 1517.37 2168.79 1520.93 Q2166.99 1524.47 2166.99 1531.6 Q2166.99 1538.71 2168.79 1542.27 Q2170.62 1545.82 2174.23 1545.82 Q2177.87 1545.82 2179.67 1542.27 Q2181.5 1538.71 2181.5 1531.6 Q2181.5 1524.47 2179.67 1520.93 Q2177.87 1517.37 2174.23 1517.37 M2174.23 1513.66 Q2180.04 1513.66 2183.1 1518.27 Q2186.18 1522.85 2186.18 1531.6 Q2186.18 1540.33 2183.1 1544.94 Q2180.04 1549.52 2174.23 1549.52 Q2168.42 1549.52 2165.34 1544.94 Q2162.29 1540.33 2162.29 1531.6 Q2162.29 1522.85 2165.34 1518.27 Q2168.42 1513.66 2174.23 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip742)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,1445.72 2352.76,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip742)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,1148.04 2352.76,1148.04 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip742)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,850.355 2352.76,850.355 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip742)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,552.674 2352.76,552.674 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip742)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,254.994 2352.76,254.994 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip740)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,1486.45 184.191,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip740)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,1445.72 203.088,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip740)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,1148.04 203.088,1148.04 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip740)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,850.355 203.088,850.355 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip740)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,552.674 203.088,552.674 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip740)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,254.994 203.088,254.994 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip740)\" d=\"M91.0151 1431.51 Q87.404 1431.51 85.5753 1435.08 Q83.7697 1438.62 83.7697 1445.75 Q83.7697 1452.86 85.5753 1456.42 Q87.404 1459.96 91.0151 1459.96 Q94.6493 1459.96 96.4548 1456.42 Q98.2835 1452.86 98.2835 1445.75 Q98.2835 1438.62 96.4548 1435.08 Q94.6493 1431.51 91.0151 1431.51 M91.0151 1427.81 Q96.8252 1427.81 99.8808 1432.42 Q102.959 1437 102.959 1445.75 Q102.959 1454.48 99.8808 1459.08 Q96.8252 1463.67 91.0151 1463.67 Q85.2049 1463.67 82.1262 1459.08 Q79.0707 1454.48 79.0707 1445.75 Q79.0707 1437 82.1262 1432.42 Q85.2049 1427.81 91.0151 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M111.177 1457.12 L116.061 1457.12 L116.061 1463 L111.177 1463 L111.177 1457.12 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M136.246 1431.51 Q132.635 1431.51 130.807 1435.08 Q129.001 1438.62 129.001 1445.75 Q129.001 1452.86 130.807 1456.42 Q132.635 1459.96 136.246 1459.96 Q139.881 1459.96 141.686 1456.42 Q143.515 1452.86 143.515 1445.75 Q143.515 1438.62 141.686 1435.08 Q139.881 1431.51 136.246 1431.51 M136.246 1427.81 Q142.056 1427.81 145.112 1432.42 Q148.191 1437 148.191 1445.75 Q148.191 1454.48 145.112 1459.08 Q142.056 1463.67 136.246 1463.67 Q130.436 1463.67 127.357 1459.08 Q124.302 1454.48 124.302 1445.75 Q124.302 1437 127.357 1432.42 Q130.436 1427.81 136.246 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M86.0382 1161.38 L102.358 1161.38 L102.358 1165.32 L80.4133 1165.32 L80.4133 1161.38 Q83.0753 1158.63 87.6586 1154 Q92.2651 1149.34 93.4456 1148 Q95.691 1145.48 96.5706 1143.74 Q97.4734 1141.98 97.4734 1140.29 Q97.4734 1137.54 95.5289 1135.8 Q93.6076 1134.07 90.5058 1134.07 Q88.3067 1134.07 85.8531 1134.83 Q83.4225 1135.59 80.6447 1137.14 L80.6447 1132.42 Q83.4688 1131.29 85.9225 1130.71 Q88.3762 1130.13 90.4132 1130.13 Q95.7836 1130.13 98.978 1132.82 Q102.172 1135.5 102.172 1139.99 Q102.172 1142.12 101.362 1144.04 Q100.575 1145.94 98.4687 1148.53 Q97.89 1149.2 94.7882 1152.42 Q91.6864 1155.62 86.0382 1161.38 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M112.172 1159.44 L117.057 1159.44 L117.057 1165.32 L112.172 1165.32 L112.172 1159.44 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M127.288 1130.76 L145.644 1130.76 L145.644 1134.69 L131.57 1134.69 L131.57 1143.16 Q132.589 1142.82 133.607 1142.65 Q134.626 1142.47 135.644 1142.47 Q141.431 1142.47 144.811 1145.64 Q148.191 1148.81 148.191 1154.23 Q148.191 1159.81 144.718 1162.91 Q141.246 1165.99 134.927 1165.99 Q132.751 1165.99 130.482 1165.62 Q128.237 1165.25 125.83 1164.5 L125.83 1159.81 Q127.913 1160.94 130.135 1161.5 Q132.357 1162.05 134.834 1162.05 Q138.839 1162.05 141.177 1159.94 Q143.515 1157.84 143.515 1154.23 Q143.515 1150.62 141.177 1148.51 Q138.839 1146.4 134.834 1146.4 Q132.959 1146.4 131.084 1146.82 Q129.232 1147.24 127.288 1148.12 L127.288 1130.76 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M81.0614 833.075 L99.4178 833.075 L99.4178 837.01 L85.3438 837.01 L85.3438 845.482 Q86.3623 845.135 87.3808 844.973 Q88.3993 844.788 89.4178 844.788 Q95.2049 844.788 98.5845 847.959 Q101.964 851.13 101.964 856.547 Q101.964 862.125 98.4919 865.227 Q95.0197 868.306 88.7003 868.306 Q86.5243 868.306 84.2558 867.936 Q82.0105 867.565 79.6031 866.824 L79.6031 862.125 Q81.6864 863.26 83.9086 863.815 Q86.1308 864.371 88.6077 864.371 Q92.6123 864.371 94.9502 862.264 Q97.2882 860.158 97.2882 856.547 Q97.2882 852.936 94.9502 850.829 Q92.6123 848.723 88.6077 848.723 Q86.7327 848.723 84.8577 849.139 Q83.0058 849.556 81.0614 850.436 L81.0614 833.075 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M111.177 861.755 L116.061 861.755 L116.061 867.635 L111.177 867.635 L111.177 861.755 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M136.246 836.153 Q132.635 836.153 130.807 839.718 Q129.001 843.26 129.001 850.389 Q129.001 857.496 130.807 861.061 Q132.635 864.602 136.246 864.602 Q139.881 864.602 141.686 861.061 Q143.515 857.496 143.515 850.389 Q143.515 843.26 141.686 839.718 Q139.881 836.153 136.246 836.153 M136.246 832.45 Q142.056 832.45 145.112 837.056 Q148.191 841.639 148.191 850.389 Q148.191 859.116 145.112 863.723 Q142.056 868.306 136.246 868.306 Q130.436 868.306 127.357 863.723 Q124.302 859.116 124.302 850.389 Q124.302 841.639 127.357 837.056 Q130.436 832.45 136.246 832.45 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M80.8299 535.394 L103.052 535.394 L103.052 537.385 L90.5058 569.954 L85.6216 569.954 L97.4271 539.329 L80.8299 539.329 L80.8299 535.394 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M112.172 564.075 L117.057 564.075 L117.057 569.954 L112.172 569.954 L112.172 564.075 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M127.288 535.394 L145.644 535.394 L145.644 539.329 L131.57 539.329 L131.57 547.802 Q132.589 547.454 133.607 547.292 Q134.626 547.107 135.644 547.107 Q141.431 547.107 144.811 550.278 Q148.191 553.45 148.191 558.866 Q148.191 564.445 144.718 567.547 Q141.246 570.625 134.927 570.625 Q132.751 570.625 130.482 570.255 Q128.237 569.885 125.83 569.144 L125.83 564.445 Q127.913 565.579 130.135 566.135 Q132.357 566.69 134.834 566.69 Q138.839 566.69 141.177 564.584 Q143.515 562.477 143.515 558.866 Q143.515 555.255 141.177 553.149 Q138.839 551.042 134.834 551.042 Q132.959 551.042 131.084 551.459 Q129.232 551.876 127.288 552.755 L127.288 535.394 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M51.6634 268.338 L59.3023 268.338 L59.3023 241.973 L50.9921 243.64 L50.9921 239.38 L59.256 237.714 L63.9319 237.714 L63.9319 268.338 L71.5707 268.338 L71.5707 272.274 L51.6634 272.274 L51.6634 268.338 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M91.0151 240.792 Q87.404 240.792 85.5753 244.357 Q83.7697 247.899 83.7697 255.028 Q83.7697 262.135 85.5753 265.7 Q87.404 269.241 91.0151 269.241 Q94.6493 269.241 96.4548 265.7 Q98.2835 262.135 98.2835 255.028 Q98.2835 247.899 96.4548 244.357 Q94.6493 240.792 91.0151 240.792 M91.0151 237.089 Q96.8252 237.089 99.8808 241.695 Q102.959 246.278 102.959 255.028 Q102.959 263.755 99.8808 268.362 Q96.8252 272.945 91.0151 272.945 Q85.2049 272.945 82.1262 268.362 Q79.0707 263.755 79.0707 255.028 Q79.0707 246.278 82.1262 241.695 Q85.2049 237.089 91.0151 237.089 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M111.177 266.394 L116.061 266.394 L116.061 272.274 L111.177 272.274 L111.177 266.394 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M136.246 240.792 Q132.635 240.792 130.807 244.357 Q129.001 247.899 129.001 255.028 Q129.001 262.135 130.807 265.7 Q132.635 269.241 136.246 269.241 Q139.881 269.241 141.686 265.7 Q143.515 262.135 143.515 255.028 Q143.515 247.899 141.686 244.357 Q139.881 240.792 136.246 240.792 M136.246 237.089 Q142.056 237.089 145.112 241.695 Q148.191 246.278 148.191 255.028 Q148.191 263.755 145.112 268.362 Q142.056 272.945 136.246 272.945 Q130.436 272.945 127.357 268.362 Q124.302 263.755 124.302 255.028 Q124.302 246.278 127.357 241.695 Q130.436 237.089 136.246 237.089 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip742)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  245.565,1420.38 311.559,1404.21 377.553,1406.22 443.547,1444 509.541,1371.07 575.536,1436.69 641.53,1379.76 707.524,1445.16 773.518,1440.97 839.512,1414.24 \n",
       "  905.506,1444.3 971.5,1443.61 1037.49,1425.98 1103.49,1142.21 1169.48,1425.92 1235.48,1428.95 1301.47,1373.77 1367.46,1445.72 1433.46,1428 1499.45,1445.19 \n",
       "  1565.45,1435.26 1631.44,1443.2 1697.43,1211.53 1763.43,777.237 1829.42,1273.04 1895.42,1407.39 1961.41,1445.72 2027.41,1422.03 2093.4,1416.52 2159.39,1310.07 \n",
       "  2225.39,1350.14 2291.38,87.9763 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip740)\" d=\"\n",
       "M1987.09 198.898 L2280.47 198.898 L2280.47 95.2176 L1987.09 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip740)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1987.09,198.898 2280.47,198.898 2280.47,95.2176 1987.09,95.2176 1987.09,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip740)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2011.18,147.058 2155.75,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip740)\" d=\"M2193.69 166.745 Q2191.89 171.375 2190.17 172.787 Q2188.46 174.199 2185.59 174.199 L2182.19 174.199 L2182.19 170.634 L2184.69 170.634 Q2186.45 170.634 2187.42 169.8 Q2188.39 168.967 2189.57 165.865 L2190.34 163.921 L2179.85 138.412 L2184.36 138.412 L2192.47 158.689 L2200.57 138.412 L2205.08 138.412 L2193.69 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip740)\" d=\"M2212.37 160.402 L2220.01 160.402 L2220.01 134.037 L2211.7 135.703 L2211.7 131.444 L2219.97 129.778 L2224.64 129.778 L2224.64 160.402 L2232.28 160.402 L2232.28 164.338 L2212.37 164.338 L2212.37 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    bestEpSc    = -100.0;\n",
    "    statesBest  = zeros( size( X_0, 1 ), T )\n",
    "    actionsBest = zeros( T );\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/(episodes-1)\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        \n",
    "        s_l = 0.0\n",
    "        # while s_l == 0\n",
    "        \n",
    "            X  = X_0\n",
    "\n",
    "            ##### Double Q-Learning ###########################################\n",
    "\n",
    "            for k = 1:T\n",
    "\n",
    "                # 1. Choose action\n",
    "                if rand() < epsilon\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                else\n",
    "\n",
    "                    A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                    if A == 1000.0 # Indicates no values in this region\n",
    "                        if rand() < EXPrand \n",
    "                            A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                        else\n",
    "                            A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                # 2. Cache last state\n",
    "                qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "                # 3. Generate the next stae\n",
    "                Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "                # 4. Collect reward R( s, a, s' )\n",
    "                R_t = cartpole_reward( Xp )\n",
    "\n",
    "                # 5. Get the optimal action at the next state\n",
    "                a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "                # 6. Compute the value at the next state\n",
    "\n",
    "                V_tp1_opt = query_value_fuzzy( \n",
    "                    Q_kdTree, G, V, \n",
    "                    get_Q( \n",
    "                        select_X_vector( Xp ), \n",
    "                        a_tp1_opt \n",
    "                    ); \n",
    "                    k = vNN \n",
    "                )\n",
    "                if isnan( V_tp1_opt )\n",
    "                    V_tp1_opt = 0.0\n",
    "                end\n",
    "\n",
    "\n",
    "                # 7. Blend the value back into nearest points\n",
    "\n",
    "                idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "                nNear      = size( idxs, 1 )\n",
    "                for i = 1:nNear\n",
    "                    j    = idxs[i]\n",
    "                    if !isnan( wgts[i] ) \n",
    "\n",
    "                        # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                        VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                states[:,k] = Xp\n",
    "                actions[k]  = A\n",
    "\n",
    "                X = Xp\n",
    "            end\n",
    "\n",
    "            s_l    = vertical_score_s( states, aMargin, ts )\n",
    "            \n",
    "        # end\n",
    "            \n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if s_l > bestEpSc\n",
    "            bestEpSc    = s_l\n",
    "            statesBest  = copy( states  )\n",
    "            actionsBest = copy( actions )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        # if useElig && (s_l > s_Totl/(1.0*l)) && (s_l > 0.0) \n",
    "        # if useElig && (s_l > 0.0) \n",
    "        if useElig \n",
    "            \n",
    "            # if s_l == 0.0\n",
    "            #     states  = copy( bestXs )\n",
    "            #     actions = copy( bestAs )\n",
    "            # end\n",
    "            \n",
    "            # println( \"Assign eligibility for a history with score \", s_l )\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "    \n",
    "    ##### Learning Rate Schedule ##########################################\n",
    "    alpha *= beta\n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
