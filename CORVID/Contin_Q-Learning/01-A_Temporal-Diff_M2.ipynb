{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.02148 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 # 0.00782 # 0.00391\n",
    "gamma    = 1.00\n",
    "swapDiv  = 64\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes = 64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   = 32 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "beta   = 0.15\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = true\n",
    "N_peaks =  16\n",
    "N_steps =   4\n",
    "lambda  =   0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.38000000000000017, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.7500000000000004, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.4200000000000002, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.16, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.13999999999999999, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.2700000000000001, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.6000000000000003, epsilon: 0.0078125\n",
      "Average Score: 0.19046875000000013\n",
      "\n",
      "Epoch 2, Best Score: 1.0000000000000007\n",
      "Training Iteration 4 score: 0.25000000000000006, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.35000000000000014, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.49000000000000027, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.4300000000000002, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.13999999999999999, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.2800000000000001, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.09, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.20000000000000004, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.3300000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.18000000000000002, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.17, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.20000000000000004, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.13999999999999999, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.16, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.12999999999999998, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.3100000000000001, epsilon: 0.0078125\n",
      "Average Score: 0.38421875000000016\n",
      "\n",
      "Epoch 3, Best Score: 1.8500000000000014\n",
      "Training Iteration 4 score: 2.859999999999983, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.09999999999999999, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.22000000000000006, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.15, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.22000000000000006, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.34000000000000014, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.09999999999999999, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.12999999999999998, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.2800000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.24000000000000007, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.20000000000000004, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.22000000000000006, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.09999999999999999, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.10999999999999999, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.09999999999999999, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.21000000000000005, epsilon: 0.0078125\n",
      "Average Score: 0.25484374999999976\n",
      "\n",
      "Epoch 4, Best Score: 2.859999999999983\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 5, Best Score: 2.859999999999983\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.11999999999999998, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.09999999999999999, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.6800000000000004, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.25000000000000006, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.13999999999999999, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.7100000000000004, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.7100000000000004, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.15484375000000006\n",
      "\n",
      "Epoch 6, Best Score: 2.859999999999983\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.5000000000000002, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.05687500000000004\n",
      "\n",
      "Epoch 7, Best Score: 2.859999999999983\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.11999999999999998, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.16, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.17, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.4000000000000002, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.3300000000000001, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.13999999999999999, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.19000000000000003, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 1.1800000000000008, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.12999999999999998, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.24000000000000007, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.18000000000000002, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.9500000000000006, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.4100000000000002, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.4300000000000002, epsilon: 0.0078125\n",
      "Average Score: 0.32531250000000017\n",
      "\n",
      "Epoch 8, Best Score: 2.859999999999983\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.7700000000000005, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.3000000000000001, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.18000000000000002, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.21000000000000005, epsilon: 0.0078125\n",
      "Average Score: 0.07203125000000002\n",
      "\n",
      "Epoch 9, Best Score: 2.859999999999983\n",
      "Training Iteration 4 score: 1.0700000000000007, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.21000000000000005, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.24000000000000007, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.22000000000000006, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.17, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.45000000000000023, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.7600000000000005, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.34000000000000014, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.1739062500000001\n",
      "\n",
      "Epoch 10, Best Score: 2.859999999999983\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.7000000000000004, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.5400000000000003, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.24000000000000007, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.2800000000000001, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.48000000000000026, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.7800000000000005, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.24000000000000007, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.17, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.21000000000000005, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.37000000000000016, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.5300000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.24468750000000017\n",
      "\n",
      "Epoch 11, Best Score: 2.859999999999983\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.19000000000000003, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.10999999999999999, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.21000000000000005, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.16, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0484375\n",
      "\n",
      "Epoch 12, Best Score: 2.859999999999983\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 13, Best Score: 2.859999999999983\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.9400000000000006, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 1.6600000000000013, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.09, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.13999999999999999, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 1.8000000000000014, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 3.5299999999999687, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.35000000000000014, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.12999999999999998, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.16, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.09999999999999999, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.7400000000000004, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.11999999999999998, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.2800000000000001, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.10999999999999999, epsilon: 0.0078125\n",
      "Average Score: 0.3840624999999997\n",
      "\n",
      "Epoch 14, Best Score: 3.5299999999999687\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.09999999999999999, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0015624999999999999\n",
      "\n",
      "Epoch 15, Best Score: 3.5299999999999687\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.015312500000000005\n",
      "\n",
      "Epoch 16, Best Score: 3.5299999999999687\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.4100000000000002, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.006406250000000003\n",
      "\n",
      "Epoch 17, Best Score: 3.5299999999999687\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.020781250000000008\n",
      "\n",
      "Epoch 18, Best Score: 3.5299999999999687\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 19, Best Score: 3.5299999999999687\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0020312499999999996\n",
      "\n",
      "Epoch 20, Best Score: 3.5299999999999687\n",
      "Training Iteration 4 score: 0.18000000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.26000000000000006, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.9700000000000006, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.4400000000000002, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.6600000000000004, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.8400000000000005, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 1.2100000000000009, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.9000000000000006, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.2800000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.6400000000000003, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.7000000000000004, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.8500000000000005, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 2.3599999999999937, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 1.1700000000000008, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 1.5800000000000012, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 1.6200000000000012, epsilon: 0.0078125\n",
      "Average Score: 0.9773437499999987\n",
      "\n",
      "Epoch 21, Best Score: 4.529999999999948\n",
      "Training Iteration 4 score: 0.13999999999999999, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.11999999999999998, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.7900000000000005, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.3000000000000001, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.16, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.16875000000000007\n",
      "\n",
      "Epoch 22, Best Score: 4.529999999999948\n",
      "Training Iteration 4 score: 0.5200000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.5600000000000003, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.3000000000000001, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.18000000000000002, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.06312500000000001\n",
      "\n",
      "Epoch 23, Best Score: 4.529999999999948\n",
      "Training Iteration 4 score: 0.34000000000000014, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.2900000000000001, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.07171875000000003\n",
      "\n",
      "Epoch 24, Best Score: 4.529999999999948\n",
      "Training Iteration 4 score: 0.5300000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.10999999999999999, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.3300000000000001, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.38000000000000017, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.7600000000000005, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.09999999999999999, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.12999999999999998, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.15375000000000008\n",
      "\n",
      "Epoch 25, Best Score: 4.529999999999948\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.7600000000000005, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.25000000000000006, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.047656250000000025\n",
      "\n",
      "Epoch 26, Best Score: 4.529999999999948\n",
      "Training Iteration 4 score: 0.10999999999999999, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.37000000000000016, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.19000000000000003, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.15, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.2800000000000001, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.11999999999999998, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.6300000000000003, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.22000000000000006, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.15, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.36000000000000015, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.2700000000000001, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.4100000000000002, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.3900000000000002, epsilon: 0.0078125\n",
      "Average Score: 0.3089062500000001\n",
      "\n",
      "Epoch 27, Best Score: 4.529999999999948\n",
      "Training Iteration 4 score: 0.7300000000000004, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 2.349999999999994, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 2.869999999999983, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 1.7600000000000013, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.7200000000000004, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.09, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 1.2300000000000009, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.7800000000000005, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 2.0000000000000013, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.7200000000000004, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 1.0200000000000007, epsilon: 0.0078125\n",
      "Average Score: 0.6978124999999987\n",
      "\n",
      "Epoch 28, Best Score: 4.679999999999945\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.5700000000000003, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.3000000000000001, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.15, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.10999999999999999, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.9100000000000006, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.11140625000000007\n",
      "\n",
      "Epoch 29, Best Score: 4.679999999999945\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.25000000000000006, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.8500000000000005, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.8700000000000006, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.17562499999999995\n",
      "\n",
      "Epoch 30, Best Score: 4.679999999999945\n",
      "Training Iteration 4 score: 0.10999999999999999, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.2800000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.3100000000000001, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.26000000000000006, epsilon: 0.0078125\n",
      "Average Score: 0.09781250000000004\n",
      "\n",
      "Epoch 31, Best Score: 4.679999999999945\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 32, Best Score: 4.679999999999945\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.15, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.00234375\n",
      "Saved a trained Q-table with size (76032,), After 12.067788251241048 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip260\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip260)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip261\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip260)\" d=\"\n",
       "M186.274 1486.45 L2352.76 1486.45 L2352.76 47.2441 L186.274 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip262\">\n",
       "    <rect x=\"186\" y=\"47\" width=\"2167\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  511.312,1486.45 511.312,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  840.966,1486.45 840.966,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1170.62,1486.45 1170.62,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1500.27,1486.45 1500.27,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1829.93,1486.45 1829.93,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2159.58,1486.45 2159.58,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  511.312,1486.45 511.312,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  840.966,1486.45 840.966,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1170.62,1486.45 1170.62,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1500.27,1486.45 1500.27,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1829.93,1486.45 1829.93,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2159.58,1486.45 2159.58,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip260)\" d=\"M501.59 1514.29 L519.946 1514.29 L519.946 1518.22 L505.872 1518.22 L505.872 1526.7 Q506.891 1526.35 507.909 1526.19 Q508.928 1526 509.946 1526 Q515.733 1526 519.113 1529.17 Q522.493 1532.34 522.493 1537.76 Q522.493 1543.34 519.021 1546.44 Q515.548 1549.52 509.229 1549.52 Q507.053 1549.52 504.784 1549.15 Q502.539 1548.78 500.132 1548.04 L500.132 1543.34 Q502.215 1544.47 504.437 1545.03 Q506.659 1545.58 509.136 1545.58 Q513.141 1545.58 515.479 1543.48 Q517.817 1541.37 517.817 1537.76 Q517.817 1534.15 515.479 1532.04 Q513.141 1529.94 509.136 1529.94 Q507.261 1529.94 505.386 1530.35 Q503.534 1530.77 501.59 1531.65 L501.59 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M815.653 1544.91 L823.292 1544.91 L823.292 1518.55 L814.982 1520.21 L814.982 1515.95 L823.246 1514.29 L827.922 1514.29 L827.922 1544.91 L835.561 1544.91 L835.561 1548.85 L815.653 1548.85 L815.653 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M855.005 1517.37 Q851.394 1517.37 849.565 1520.93 Q847.76 1524.47 847.76 1531.6 Q847.76 1538.71 849.565 1542.27 Q851.394 1545.82 855.005 1545.82 Q858.639 1545.82 860.445 1542.27 Q862.273 1538.71 862.273 1531.6 Q862.273 1524.47 860.445 1520.93 Q858.639 1517.37 855.005 1517.37 M855.005 1513.66 Q860.815 1513.66 863.871 1518.27 Q866.949 1522.85 866.949 1531.6 Q866.949 1540.33 863.871 1544.94 Q860.815 1549.52 855.005 1549.52 Q849.195 1549.52 846.116 1544.94 Q843.06 1540.33 843.06 1531.6 Q843.06 1522.85 846.116 1518.27 Q849.195 1513.66 855.005 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1145.8 1544.91 L1153.44 1544.91 L1153.44 1518.55 L1145.13 1520.21 L1145.13 1515.95 L1153.4 1514.29 L1158.07 1514.29 L1158.07 1544.91 L1165.71 1544.91 L1165.71 1548.85 L1145.8 1548.85 L1145.8 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1175.2 1514.29 L1193.56 1514.29 L1193.56 1518.22 L1179.48 1518.22 L1179.48 1526.7 Q1180.5 1526.35 1181.52 1526.19 Q1182.54 1526 1183.56 1526 Q1189.35 1526 1192.73 1529.17 Q1196.1 1532.34 1196.1 1537.76 Q1196.1 1543.34 1192.63 1546.44 Q1189.16 1549.52 1182.84 1549.52 Q1180.67 1549.52 1178.4 1549.15 Q1176.15 1548.78 1173.74 1548.04 L1173.74 1543.34 Q1175.83 1544.47 1178.05 1545.03 Q1180.27 1545.58 1182.75 1545.58 Q1186.75 1545.58 1189.09 1543.48 Q1191.43 1541.37 1191.43 1537.76 Q1191.43 1534.15 1189.09 1532.04 Q1186.75 1529.94 1182.75 1529.94 Q1180.87 1529.94 1179 1530.35 Q1177.15 1530.77 1175.2 1531.65 L1175.2 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1479.05 1544.91 L1495.36 1544.91 L1495.36 1548.85 L1473.42 1548.85 L1473.42 1544.91 Q1476.08 1542.16 1480.67 1537.53 Q1485.27 1532.88 1486.45 1531.53 Q1488.7 1529.01 1489.58 1527.27 Q1490.48 1525.51 1490.48 1523.82 Q1490.48 1521.07 1488.54 1519.33 Q1486.61 1517.6 1483.51 1517.6 Q1481.31 1517.6 1478.86 1518.36 Q1476.43 1519.13 1473.65 1520.68 L1473.65 1515.95 Q1476.48 1514.82 1478.93 1514.24 Q1481.38 1513.66 1483.42 1513.66 Q1488.79 1513.66 1491.99 1516.35 Q1495.18 1519.03 1495.18 1523.52 Q1495.18 1525.65 1494.37 1527.57 Q1493.58 1529.47 1491.48 1532.07 Q1490.9 1532.74 1487.8 1535.95 Q1484.69 1539.15 1479.05 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1515.18 1517.37 Q1511.57 1517.37 1509.74 1520.93 Q1507.93 1524.47 1507.93 1531.6 Q1507.93 1538.71 1509.74 1542.27 Q1511.57 1545.82 1515.18 1545.82 Q1518.81 1545.82 1520.62 1542.27 Q1522.45 1538.71 1522.45 1531.6 Q1522.45 1524.47 1520.62 1520.93 Q1518.81 1517.37 1515.18 1517.37 M1515.18 1513.66 Q1520.99 1513.66 1524.05 1518.27 Q1527.12 1522.85 1527.12 1531.6 Q1527.12 1540.33 1524.05 1544.94 Q1520.99 1549.52 1515.18 1549.52 Q1509.37 1549.52 1506.29 1544.94 Q1503.24 1540.33 1503.24 1531.6 Q1503.24 1522.85 1506.29 1518.27 Q1509.37 1513.66 1515.18 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1809.2 1544.91 L1825.52 1544.91 L1825.52 1548.85 L1803.57 1548.85 L1803.57 1544.91 Q1806.23 1542.16 1810.82 1537.53 Q1815.42 1532.88 1816.6 1531.53 Q1818.85 1529.01 1819.73 1527.27 Q1820.63 1525.51 1820.63 1523.82 Q1820.63 1521.07 1818.69 1519.33 Q1816.77 1517.6 1813.66 1517.6 Q1811.47 1517.6 1809.01 1518.36 Q1806.58 1519.13 1803.8 1520.68 L1803.8 1515.95 Q1806.63 1514.82 1809.08 1514.24 Q1811.53 1513.66 1813.57 1513.66 Q1818.94 1513.66 1822.14 1516.35 Q1825.33 1519.03 1825.33 1523.52 Q1825.33 1525.65 1824.52 1527.57 Q1823.73 1529.47 1821.63 1532.07 Q1821.05 1532.74 1817.95 1535.95 Q1814.84 1539.15 1809.2 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1835.38 1514.29 L1853.73 1514.29 L1853.73 1518.22 L1839.66 1518.22 L1839.66 1526.7 Q1840.68 1526.35 1841.7 1526.19 Q1842.71 1526 1843.73 1526 Q1849.52 1526 1852.9 1529.17 Q1856.28 1532.34 1856.28 1537.76 Q1856.28 1543.34 1852.81 1546.44 Q1849.34 1549.52 1843.02 1549.52 Q1840.84 1549.52 1838.57 1549.15 Q1836.33 1548.78 1833.92 1548.04 L1833.92 1543.34 Q1836 1544.47 1838.22 1545.03 Q1840.45 1545.58 1842.92 1545.58 Q1846.93 1545.58 1849.27 1543.48 Q1851.6 1541.37 1851.6 1537.76 Q1851.6 1534.15 1849.27 1532.04 Q1846.93 1529.94 1842.92 1529.94 Q1841.05 1529.94 1839.17 1530.35 Q1837.32 1530.77 1835.38 1531.65 L1835.38 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M2148.42 1530.21 Q2151.78 1530.93 2153.65 1533.2 Q2155.55 1535.47 2155.55 1538.8 Q2155.55 1543.92 2152.03 1546.72 Q2148.51 1549.52 2142.03 1549.52 Q2139.86 1549.52 2137.54 1549.08 Q2135.25 1548.66 2132.8 1547.81 L2132.8 1543.29 Q2134.74 1544.43 2137.06 1545.01 Q2139.37 1545.58 2141.89 1545.58 Q2146.29 1545.58 2148.58 1543.85 Q2150.9 1542.11 2150.9 1538.8 Q2150.9 1535.75 2148.75 1534.03 Q2146.62 1532.3 2142.8 1532.3 L2138.77 1532.3 L2138.77 1528.45 L2142.98 1528.45 Q2146.43 1528.45 2148.26 1527.09 Q2150.09 1525.7 2150.09 1523.11 Q2150.09 1520.45 2148.19 1519.03 Q2146.32 1517.6 2142.8 1517.6 Q2140.88 1517.6 2138.68 1518.01 Q2136.48 1518.43 2133.84 1519.31 L2133.84 1515.14 Q2136.5 1514.4 2138.82 1514.03 Q2141.15 1513.66 2143.21 1513.66 Q2148.54 1513.66 2151.64 1516.09 Q2154.74 1518.5 2154.74 1522.62 Q2154.74 1525.49 2153.1 1527.48 Q2151.45 1529.45 2148.42 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M2174.42 1517.37 Q2170.81 1517.37 2168.98 1520.93 Q2167.17 1524.47 2167.17 1531.6 Q2167.17 1538.71 2168.98 1542.27 Q2170.81 1545.82 2174.42 1545.82 Q2178.05 1545.82 2179.86 1542.27 Q2181.69 1538.71 2181.69 1531.6 Q2181.69 1524.47 2179.86 1520.93 Q2178.05 1517.37 2174.42 1517.37 M2174.42 1513.66 Q2180.23 1513.66 2183.28 1518.27 Q2186.36 1522.85 2186.36 1531.6 Q2186.36 1540.33 2183.28 1544.94 Q2180.23 1549.52 2174.42 1549.52 Q2168.61 1549.52 2165.53 1544.94 Q2162.47 1540.33 2162.47 1531.6 Q2162.47 1522.85 2165.53 1518.27 Q2168.61 1513.66 2174.42 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,1445.72 2352.76,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,1098.41 2352.76,1098.41 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,751.109 2352.76,751.109 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,403.805 2352.76,403.805 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,56.5019 2352.76,56.5019 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,1486.45 186.274,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,1445.72 205.172,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,1098.41 205.172,1098.41 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,751.109 205.172,751.109 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,403.805 205.172,403.805 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,56.5019 205.172,56.5019 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip260)\" d=\"M62.9365 1431.51 Q59.3254 1431.51 57.4967 1435.08 Q55.6912 1438.62 55.6912 1445.75 Q55.6912 1452.86 57.4967 1456.42 Q59.3254 1459.96 62.9365 1459.96 Q66.5707 1459.96 68.3763 1456.42 Q70.205 1452.86 70.205 1445.75 Q70.205 1438.62 68.3763 1435.08 Q66.5707 1431.51 62.9365 1431.51 M62.9365 1427.81 Q68.7467 1427.81 71.8022 1432.42 Q74.8809 1437 74.8809 1445.75 Q74.8809 1454.48 71.8022 1459.08 Q68.7467 1463.67 62.9365 1463.67 Q57.1264 1463.67 54.0477 1459.08 Q50.9921 1454.48 50.9921 1445.75 Q50.9921 1437 54.0477 1432.42 Q57.1264 1427.81 62.9365 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M83.0984 1457.12 L87.9827 1457.12 L87.9827 1463 L83.0984 1463 L83.0984 1457.12 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M108.168 1431.51 Q104.557 1431.51 102.728 1435.08 Q100.922 1438.62 100.922 1445.75 Q100.922 1452.86 102.728 1456.42 Q104.557 1459.96 108.168 1459.96 Q111.802 1459.96 113.608 1456.42 Q115.436 1452.86 115.436 1445.75 Q115.436 1438.62 113.608 1435.08 Q111.802 1431.51 108.168 1431.51 M108.168 1427.81 Q113.978 1427.81 117.033 1432.42 Q120.112 1437 120.112 1445.75 Q120.112 1454.48 117.033 1459.08 Q113.978 1463.67 108.168 1463.67 Q102.358 1463.67 99.2789 1459.08 Q96.2234 1454.48 96.2234 1445.75 Q96.2234 1437 99.2789 1432.42 Q102.358 1427.81 108.168 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M138.33 1431.51 Q134.719 1431.51 132.89 1435.08 Q131.084 1438.62 131.084 1445.75 Q131.084 1452.86 132.89 1456.42 Q134.719 1459.96 138.33 1459.96 Q141.964 1459.96 143.769 1456.42 Q145.598 1452.86 145.598 1445.75 Q145.598 1438.62 143.769 1435.08 Q141.964 1431.51 138.33 1431.51 M138.33 1427.81 Q144.14 1427.81 147.195 1432.42 Q150.274 1437 150.274 1445.75 Q150.274 1454.48 147.195 1459.08 Q144.14 1463.67 138.33 1463.67 Q132.519 1463.67 129.441 1459.08 Q126.385 1454.48 126.385 1445.75 Q126.385 1437 129.441 1432.42 Q132.519 1427.81 138.33 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M63.9319 1084.21 Q60.3208 1084.21 58.4921 1087.78 Q56.6865 1091.32 56.6865 1098.45 Q56.6865 1105.55 58.4921 1109.12 Q60.3208 1112.66 63.9319 1112.66 Q67.5661 1112.66 69.3717 1109.12 Q71.2004 1105.55 71.2004 1098.45 Q71.2004 1091.32 69.3717 1087.78 Q67.5661 1084.21 63.9319 1084.21 M63.9319 1080.51 Q69.742 1080.51 72.7976 1085.11 Q75.8763 1089.7 75.8763 1098.45 Q75.8763 1107.17 72.7976 1111.78 Q69.742 1116.36 63.9319 1116.36 Q58.1217 1116.36 55.043 1111.78 Q51.9875 1107.17 51.9875 1098.45 Q51.9875 1089.7 55.043 1085.11 Q58.1217 1080.51 63.9319 1080.51 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M84.0938 1109.81 L88.978 1109.81 L88.978 1115.69 L84.0938 1115.69 L84.0938 1109.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M103.191 1111.76 L119.51 1111.76 L119.51 1115.69 L97.566 1115.69 L97.566 1111.76 Q100.228 1109 104.811 1104.37 Q109.418 1099.72 110.598 1098.38 Q112.844 1095.85 113.723 1094.12 Q114.626 1092.36 114.626 1090.67 Q114.626 1087.91 112.682 1086.18 Q110.76 1084.44 107.658 1084.44 Q105.459 1084.44 103.006 1085.21 Q100.575 1085.97 97.7974 1087.52 L97.7974 1082.8 Q100.621 1081.66 103.075 1081.09 Q105.529 1080.51 107.566 1080.51 Q112.936 1080.51 116.131 1083.19 Q119.325 1085.88 119.325 1090.37 Q119.325 1092.5 118.515 1094.42 Q117.728 1096.32 115.621 1098.91 Q115.043 1099.58 111.941 1102.8 Q108.839 1105.99 103.191 1111.76 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M129.371 1081.13 L147.728 1081.13 L147.728 1085.07 L133.654 1085.07 L133.654 1093.54 Q134.672 1093.19 135.691 1093.03 Q136.709 1092.85 137.728 1092.85 Q143.515 1092.85 146.894 1096.02 Q150.274 1099.19 150.274 1104.6 Q150.274 1110.18 146.802 1113.28 Q143.33 1116.36 137.01 1116.36 Q134.834 1116.36 132.566 1115.99 Q130.32 1115.62 127.913 1114.88 L127.913 1110.18 Q129.996 1111.32 132.219 1111.87 Q134.441 1112.43 136.918 1112.43 Q140.922 1112.43 143.26 1110.32 Q145.598 1108.22 145.598 1104.6 Q145.598 1100.99 143.26 1098.89 Q140.922 1096.78 136.918 1096.78 Q135.043 1096.78 133.168 1097.2 Q131.316 1097.61 129.371 1098.49 L129.371 1081.13 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M62.9365 736.907 Q59.3254 736.907 57.4967 740.472 Q55.6912 744.014 55.6912 751.144 Q55.6912 758.25 57.4967 761.815 Q59.3254 765.356 62.9365 765.356 Q66.5707 765.356 68.3763 761.815 Q70.205 758.25 70.205 751.144 Q70.205 744.014 68.3763 740.472 Q66.5707 736.907 62.9365 736.907 M62.9365 733.204 Q68.7467 733.204 71.8022 737.81 Q74.8809 742.394 74.8809 751.144 Q74.8809 759.87 71.8022 764.477 Q68.7467 769.06 62.9365 769.06 Q57.1264 769.06 54.0477 764.477 Q50.9921 759.87 50.9921 751.144 Q50.9921 742.394 54.0477 737.81 Q57.1264 733.204 62.9365 733.204 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M83.0984 762.509 L87.9827 762.509 L87.9827 768.389 L83.0984 768.389 L83.0984 762.509 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M98.2141 733.829 L116.57 733.829 L116.57 737.764 L102.496 737.764 L102.496 746.236 Q103.515 745.889 104.534 745.727 Q105.552 745.542 106.571 745.542 Q112.358 745.542 115.737 748.713 Q119.117 751.884 119.117 757.301 Q119.117 762.88 115.645 765.981 Q112.172 769.06 105.853 769.06 Q103.677 769.06 101.409 768.69 Q99.1632 768.319 96.7558 767.579 L96.7558 762.88 Q98.8391 764.014 101.061 764.569 Q103.284 765.125 105.76 765.125 Q109.765 765.125 112.103 763.018 Q114.441 760.912 114.441 757.301 Q114.441 753.69 112.103 751.583 Q109.765 749.477 105.76 749.477 Q103.885 749.477 102.01 749.894 Q100.159 750.31 98.2141 751.19 L98.2141 733.829 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M138.33 736.907 Q134.719 736.907 132.89 740.472 Q131.084 744.014 131.084 751.144 Q131.084 758.25 132.89 761.815 Q134.719 765.356 138.33 765.356 Q141.964 765.356 143.769 761.815 Q145.598 758.25 145.598 751.144 Q145.598 744.014 143.769 740.472 Q141.964 736.907 138.33 736.907 M138.33 733.204 Q144.14 733.204 147.195 737.81 Q150.274 742.394 150.274 751.144 Q150.274 759.87 147.195 764.477 Q144.14 769.06 138.33 769.06 Q132.519 769.06 129.441 764.477 Q126.385 759.87 126.385 751.144 Q126.385 742.394 129.441 737.81 Q132.519 733.204 138.33 733.204 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M63.9319 389.604 Q60.3208 389.604 58.4921 393.169 Q56.6865 396.71 56.6865 403.84 Q56.6865 410.947 58.4921 414.511 Q60.3208 418.053 63.9319 418.053 Q67.5661 418.053 69.3717 414.511 Q71.2004 410.947 71.2004 403.84 Q71.2004 396.71 69.3717 393.169 Q67.5661 389.604 63.9319 389.604 M63.9319 385.9 Q69.742 385.9 72.7976 390.507 Q75.8763 395.09 75.8763 403.84 Q75.8763 412.567 72.7976 417.173 Q69.742 421.757 63.9319 421.757 Q58.1217 421.757 55.043 417.173 Q51.9875 412.567 51.9875 403.84 Q51.9875 395.09 55.043 390.507 Q58.1217 385.9 63.9319 385.9 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M84.0938 415.206 L88.978 415.206 L88.978 421.085 L84.0938 421.085 L84.0938 415.206 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M97.9826 386.525 L120.205 386.525 L120.205 388.516 L107.658 421.085 L102.774 421.085 L114.58 390.461 L97.9826 390.461 L97.9826 386.525 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M129.371 386.525 L147.728 386.525 L147.728 390.461 L133.654 390.461 L133.654 398.933 Q134.672 398.585 135.691 398.423 Q136.709 398.238 137.728 398.238 Q143.515 398.238 146.894 401.41 Q150.274 404.581 150.274 409.997 Q150.274 415.576 146.802 418.678 Q143.33 421.757 137.01 421.757 Q134.834 421.757 132.566 421.386 Q130.32 421.016 127.913 420.275 L127.913 415.576 Q129.996 416.71 132.219 417.266 Q134.441 417.821 136.918 417.821 Q140.922 417.821 143.26 415.715 Q145.598 413.609 145.598 409.997 Q145.598 406.386 143.26 404.28 Q140.922 402.173 136.918 402.173 Q135.043 402.173 133.168 402.59 Q131.316 403.007 129.371 403.886 L129.371 386.525 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M53.7467 69.8467 L61.3856 69.8467 L61.3856 43.4811 L53.0754 45.1478 L53.0754 40.8886 L61.3393 39.2219 L66.0152 39.2219 L66.0152 69.8467 L73.654 69.8467 L73.654 73.7819 L53.7467 73.7819 L53.7467 69.8467 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M83.0984 67.9023 L87.9827 67.9023 L87.9827 73.7819 L83.0984 73.7819 L83.0984 67.9023 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M108.168 42.3006 Q104.557 42.3006 102.728 45.8654 Q100.922 49.407 100.922 56.5366 Q100.922 63.6431 102.728 67.2079 Q104.557 70.7495 108.168 70.7495 Q111.802 70.7495 113.608 67.2079 Q115.436 63.6431 115.436 56.5366 Q115.436 49.407 113.608 45.8654 Q111.802 42.3006 108.168 42.3006 M108.168 38.5969 Q113.978 38.5969 117.033 43.2034 Q120.112 47.7867 120.112 56.5366 Q120.112 65.2634 117.033 69.8699 Q113.978 74.4532 108.168 74.4532 Q102.358 74.4532 99.2789 69.8699 Q96.2234 65.2634 96.2234 56.5366 Q96.2234 47.7867 99.2789 43.2034 Q102.358 38.5969 108.168 38.5969 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M138.33 42.3006 Q134.719 42.3006 132.89 45.8654 Q131.084 49.407 131.084 56.5366 Q131.084 63.6431 132.89 67.2079 Q134.719 70.7495 138.33 70.7495 Q141.964 70.7495 143.769 67.2079 Q145.598 63.6431 145.598 56.5366 Q145.598 49.407 143.769 45.8654 Q141.964 42.3006 138.33 42.3006 M138.33 38.5969 Q144.14 38.5969 147.195 43.2034 Q150.274 47.7867 150.274 56.5366 Q150.274 65.2634 147.195 69.8699 Q144.14 74.4532 138.33 74.4532 Q132.519 74.4532 129.441 69.8699 Q126.385 65.2634 126.385 56.5366 Q126.385 47.7867 129.441 43.2034 Q132.519 38.5969 138.33 38.5969 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip262)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  247.59,1181.11 313.52,911.954 379.451,1091.68 445.382,1445.72 511.312,1230.6 577.243,1366.7 643.174,993.787 709.104,1345.65 775.035,1204.12 840.966,1105.79 \n",
       "  906.896,1378.43 972.827,1445.72 1038.76,912.171 1104.69,1443.55 1170.62,1424.44 1236.55,1436.82 1302.48,1416.85 1368.41,1445.72 1434.34,1442.89 1500.27,87.9763 \n",
       "  1566.2,1211.29 1632.13,1358.02 1698.06,1346.08 1763.99,1232.12 1829.93,1379.51 1895.86,1016.58 1961.79,476.305 2027.72,1290.95 2093.65,1201.74 2159.58,1309.83 \n",
       "  2225.51,1445.72 2291.44,1442.46 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip260)\" d=\"\n",
       "M1987.39 198.898 L2280.54 198.898 L2280.54 95.2176 L1987.39 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1987.39,198.898 2280.54,198.898 2280.54,95.2176 1987.39,95.2176 1987.39,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2011.46,147.058 2155.89,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip260)\" d=\"M2193.81 166.745 Q2192 171.375 2190.29 172.787 Q2188.58 174.199 2185.71 174.199 L2182.3 174.199 L2182.3 170.634 L2184.8 170.634 Q2186.56 170.634 2187.53 169.8 Q2188.51 168.967 2189.69 165.865 L2190.45 163.921 L2179.97 138.412 L2184.48 138.412 L2192.58 158.689 L2200.68 138.412 L2205.2 138.412 L2193.81 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M2212.49 160.402 L2220.13 160.402 L2220.13 134.037 L2211.82 135.703 L2211.82 131.444 L2220.08 129.778 L2224.76 129.778 L2224.76 160.402 L2232.4 160.402 L2232.4 164.338 L2212.49 164.338 L2212.49 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/episodes\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        X  = X_0\n",
    "        \n",
    "        ##### Double Q-Learning ###########################################\n",
    "\n",
    "        for k = 1:T\n",
    "\n",
    "            # 1. Choose action\n",
    "            if rand() < epsilon\n",
    "                if rand() < EXPrand \n",
    "                    A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                else\n",
    "                    A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                end\n",
    "            else\n",
    "\n",
    "                A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                if A == 1000.0 # Indicates no values in this region\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "\n",
    "            # 2. Cache last state\n",
    "            qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "            # 3. Generate the next stae\n",
    "            Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "            # 4. Collect reward R( s, a, s' )\n",
    "            R_t = cartpole_reward( Xp )\n",
    "\n",
    "            # 5. Get the optimal action at the next state\n",
    "            a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "            # 6. Compute the value at the next state\n",
    "\n",
    "            V_tp1_opt = query_value_fuzzy( \n",
    "                Q_kdTree, G, V, \n",
    "                get_Q( \n",
    "                    select_X_vector( Xp ), \n",
    "                    a_tp1_opt \n",
    "                ); \n",
    "                k = vNN \n",
    "            )\n",
    "            if isnan( V_tp1_opt )\n",
    "                V_tp1_opt = 0.0\n",
    "            end\n",
    "\n",
    "\n",
    "            # 7. Blend the value back into nearest points\n",
    "\n",
    "            idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "            nNear      = size( idxs, 1 )\n",
    "            for i = 1:nNear\n",
    "                j    = idxs[i]\n",
    "                if !isnan( wgts[i] ) \n",
    "\n",
    "                    # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                    VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "                    \n",
    "                end\n",
    "            end\n",
    "\n",
    "            states[:,k] = Xp\n",
    "            actions[k]  = A\n",
    "\n",
    "            X = Xp\n",
    "        end\n",
    "\n",
    "        s_l    = vertical_score_s( states, aMargin, ts )\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        if useElig\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
