{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.02148 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 # 0.00782 # 0.00391\n",
    "beta     = 0.90\n",
    "gamma    = 1.00\n",
    "swapDiv  = 64\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes = 64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   = 32 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = true\n",
    "N_peaks =  32\n",
    "N_steps = 128\n",
    "lambda  =   0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.6000000000000003, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.23000000000000007, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.22000000000000006, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.18000000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.3100000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.25000000000000006, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.18000000000000002, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.15, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.14703125000000006\n",
      "\n",
      "Epoch 2, Best Score: 0.6000000000000003\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.08, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.3100000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.23000000000000007, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.11999999999999998, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.35000000000000014, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.2900000000000001, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.19000000000000003, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.13187500000000008\n",
      "\n",
      "Epoch 3, Best Score: 0.6400000000000003\n",
      "Training Iteration 4 score: 0.17, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.48000000000000026, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.19000000000000003, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.10999999999999999, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.16, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.04671875\n",
      "\n",
      "Epoch 4, Best Score: 0.6400000000000003\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.005000000000000002\n",
      "\n",
      "Epoch 5, Best Score: 0.6400000000000003\n",
      "Training Iteration 4 score: 0.22000000000000006, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.35000000000000014, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.08, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.13999999999999999, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.12125000000000005\n",
      "\n",
      "Epoch 6, Best Score: 0.9000000000000006\n",
      "Training Iteration 4 score: 0.16, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.6500000000000004, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.16, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.6000000000000003, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.3100000000000001, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.06718750000000004\n",
      "\n",
      "Epoch 7, Best Score: 1.1600000000000008\n",
      "Training Iteration 4 score: 0.3100000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.13999999999999999, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.24000000000000007, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.11999999999999998, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 2.439999999999992, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.13999999999999999, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.09999999999999999, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.6900000000000013, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.18000000000000002, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 19.31000000000022, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 17.92, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.4200000000000002, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 25.680000000001215, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 30.83000000000202, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 30.77000000000201, epsilon: 8.881784197001252e-16\n",
      "Average Score: 8.208906250000357\n",
      "\n",
      "Epoch 8, Best Score: 31.200000000002078\n",
      "Training Iteration 4 score: 0.15, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.5400000000000003, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.34000000000000014, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.26000000000000006, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.38000000000000017, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.4100000000000002, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.6600000000000004, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.5300000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.6400000000000003, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.16, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.20000000000000004, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.15, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.3300000000000001, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.16, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.09999999999999999, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.09999999999999999, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.43468750000000034\n",
      "\n",
      "Epoch 9, Best Score: 31.200000000002078\n",
      "Training Iteration 4 score: 1.320000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.09999999999999999, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 2.899999999999982, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.12999999999999998, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.10999999999999999, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 1.9900000000000015, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.4100000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.270000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.8500000000000005, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.5200000000000002, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.9900000000000007, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.7800000000000005, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.5000000000000002, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 32.16000000000217, epsilon: 8.881784197001252e-16\n",
      "Average Score: 1.7173437500000537\n",
      "\n",
      "Epoch 10, Best Score: 32.16000000000217\n",
      "Training Iteration 4 score: 0.7100000000000004, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.4000000000000002, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.9000000000000006, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 1.5600000000000012, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 2.52999999999999, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.8500000000000005, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.5800000000000003, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.6200000000000003, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.15, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.36000000000000015, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.45000000000000023, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.3900000000000002, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.16, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.7626562499999983\n",
      "\n",
      "Epoch 11, Best Score: 32.16000000000217\n",
      "Training Iteration 4 score: 0.5300000000000002, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.7800000000000005, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.22000000000000006, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.6100000000000003, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 1.330000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.6000000000000003, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.25000000000000006, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.22000000000000006, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.430000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.8400000000000005, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.7900000000000005, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 1.0400000000000007, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.21000000000000005, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 2.1399999999999983, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 2.010000000000001, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 2.1399999999999983, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.8900000000000006\n",
      "\n",
      "Epoch 12, Best Score: 32.16000000000217\n",
      "Training Iteration 4 score: 0.25000000000000006, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.3000000000000001, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.8500000000000005, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.38000000000000017, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.9400000000000006, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.6000000000000003, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.35000000000000014, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.5800000000000003, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.4400000000000002, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.6700000000000004, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.3100000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.3710937500000002\n",
      "\n",
      "Epoch 13, Best Score: 32.16000000000217\n",
      "Training Iteration 4 score: 0.6400000000000003, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.24000000000000007, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.5700000000000003, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.5300000000000002, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.22000000000000006, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.6500000000000004, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.7100000000000004, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.4200000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.350000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 1.0400000000000007, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.45000000000000023, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 1.410000000000001, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.8800000000000006, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 1.340000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 1.6600000000000013, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 1.5800000000000012, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.7560937500000006\n",
      "\n",
      "Epoch 14, Best Score: 32.16000000000217\n",
      "Training Iteration 4 score: 1.1800000000000008, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.47000000000000025, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.4000000000000002, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.48000000000000026, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.3900000000000002, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.12999999999999998, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.09999999999999999, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.24000000000000007, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.3900000000000002, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.5500000000000003, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 1.0000000000000007, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.24000000000000007, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 1.0100000000000007, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.7300000000000004, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.9200000000000006, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.2700000000000001, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.48453125000000036\n",
      "\n",
      "Epoch 15, Best Score: 32.16000000000217\n",
      "Training Iteration 4 score: 0.46000000000000024, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.4300000000000002, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.09999999999999999, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.8300000000000005, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 1.280000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.10999999999999999, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.7700000000000005, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.5900000000000003, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.6600000000000004, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.4300000000000002, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.6500000000000004, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.8400000000000005, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.09, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.25000000000000006, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.9500000000000006, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.7200000000000004, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.60578125\n",
      "\n",
      "Epoch 16, Best Score: 32.16000000000217\n",
      "Training Iteration 4 score: 0.9400000000000006, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.25000000000000006, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.5500000000000003, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.3000000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.6700000000000004, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.22000000000000006, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.2800000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.47000000000000025, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.2951562500000001\n",
      "\n",
      "Epoch 17, Best Score: 32.16000000000217\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 18, Best Score: 32.16000000000217\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 19, Best Score: 32.16000000000217\n",
      "Training Iteration 4 score: 0.3300000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.5500000000000003, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.07, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.060000000000000005, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.05, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.060000000000000005, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.06515625000000003\n",
      "\n",
      "Epoch 20, Best Score: 32.16000000000217\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 21, Best Score: 32.16000000000217\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.49000000000000027, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.3000000000000001, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.04, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.08296875000000005\n",
      "\n",
      "Epoch 22, Best Score: 32.16000000000217\n",
      "Training Iteration 4 score: 0.6500000000000004, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.38000000000000017, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.3100000000000001, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.4300000000000002, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.6500000000000004, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.23000000000000007, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.25000000000000006, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.4400000000000002, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.5700000000000003, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.2900000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.6100000000000003, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.3087500000000002\n",
      "\n",
      "Epoch 23, Best Score: 32.16000000000217\n",
      "Training Iteration 4 score: 0.5100000000000002, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.3300000000000001, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.9800000000000006, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 1.6400000000000012, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.6200000000000003, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.9700000000000006, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.3100000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.4859374999999963\n",
      "\n",
      "Epoch 24, Best Score: 32.16000000000217\n",
      "Training Iteration 4 score: 0.4400000000000002, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.13999999999999999, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.2700000000000001, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.8900000000000006, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.12999999999999998, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.4100000000000002, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.13999999999999999, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.2900000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.4100000000000002, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.6600000000000004, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.3362499999999988\n",
      "\n",
      "Epoch 25, Best Score: 32.16000000000217\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.20000000000000004, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.18000000000000002, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.2800000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.03921875000000001\n",
      "\n",
      "Epoch 26, Best Score: 32.16000000000217\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.7900000000000005, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.11999999999999998, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.09999999999999999, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.38000000000000017, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.47000000000000025, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.25000000000000006, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.12953125000000007\n",
      "\n",
      "Epoch 27, Best Score: 32.16000000000217\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.4400000000000002, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.3200000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.1404687500000001\n",
      "\n",
      "Epoch 28, Best Score: 32.16000000000217\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 1.320000000000001, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.34000000000000014, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.07031250000000004\n",
      "\n",
      "Epoch 29, Best Score: 32.16000000000217\n",
      "Training Iteration 4 score: 1.8900000000000015, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 1.0200000000000007, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.9000000000000006, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.21828124999999998\n",
      "\n",
      "Epoch 30, Best Score: 32.16000000000217\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.2800000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.3200000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.5400000000000003, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.058906250000000035\n",
      "\n",
      "Epoch 31, Best Score: 32.16000000000217\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 1.1200000000000008, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 1.1700000000000008, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.09234375000000006\n",
      "\n",
      "Epoch 32, Best Score: 32.16000000000217\n",
      "Training Iteration 4 score: 0.34000000000000014, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.6600000000000004, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.6900000000000004, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.2800000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.5500000000000003, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.3300000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.7000000000000004, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 1.380000000000001, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.9200000000000006, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.5000000000000002, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.4995312499999991\n",
      "Saved a trained Q-table with size (76032,), After 14.430469465255737 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip830\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip830)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip831\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip830)\" d=\"\n",
       "M112.177 1486.45 L2352.76 1486.45 L2352.76 47.2441 L112.177 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip832\">\n",
       "    <rect x=\"112\" y=\"47\" width=\"2242\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  448.332,1486.45 448.332,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  789.26,1486.45 789.26,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1130.19,1486.45 1130.19,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1471.12,1486.45 1471.12,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1812.04,1486.45 1812.04,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2152.97,1486.45 2152.97,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip830)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  112.177,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip830)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  448.332,1486.45 448.332,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip830)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  789.26,1486.45 789.26,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip830)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1130.19,1486.45 1130.19,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip830)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1471.12,1486.45 1471.12,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip830)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1812.04,1486.45 1812.04,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip830)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2152.97,1486.45 2152.97,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip830)\" d=\"M438.61 1514.29 L456.966 1514.29 L456.966 1518.22 L442.892 1518.22 L442.892 1526.7 Q443.911 1526.35 444.929 1526.19 Q445.948 1526 446.966 1526 Q452.753 1526 456.133 1529.17 Q459.513 1532.34 459.513 1537.76 Q459.513 1543.34 456.04 1546.44 Q452.568 1549.52 446.249 1549.52 Q444.073 1549.52 441.804 1549.15 Q439.559 1548.78 437.152 1548.04 L437.152 1543.34 Q439.235 1544.47 441.457 1545.03 Q443.679 1545.58 446.156 1545.58 Q450.161 1545.58 452.499 1543.48 Q454.837 1541.37 454.837 1537.76 Q454.837 1534.15 452.499 1532.04 Q450.161 1529.94 446.156 1529.94 Q444.281 1529.94 442.406 1530.35 Q440.554 1530.77 438.61 1531.65 L438.61 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip830)\" d=\"M763.948 1544.91 L771.587 1544.91 L771.587 1518.55 L763.277 1520.21 L763.277 1515.95 L771.54 1514.29 L776.216 1514.29 L776.216 1544.91 L783.855 1544.91 L783.855 1548.85 L763.948 1548.85 L763.948 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip830)\" d=\"M803.299 1517.37 Q799.688 1517.37 797.86 1520.93 Q796.054 1524.47 796.054 1531.6 Q796.054 1538.71 797.86 1542.27 Q799.688 1545.82 803.299 1545.82 Q806.934 1545.82 808.739 1542.27 Q810.568 1538.71 810.568 1531.6 Q810.568 1524.47 808.739 1520.93 Q806.934 1517.37 803.299 1517.37 M803.299 1513.66 Q809.11 1513.66 812.165 1518.27 Q815.244 1522.85 815.244 1531.6 Q815.244 1540.33 812.165 1544.94 Q809.11 1549.52 803.299 1549.52 Q797.489 1549.52 794.411 1544.94 Q791.355 1540.33 791.355 1531.6 Q791.355 1522.85 794.411 1518.27 Q797.489 1513.66 803.299 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip830)\" d=\"M1105.37 1544.91 L1113.01 1544.91 L1113.01 1518.55 L1104.7 1520.21 L1104.7 1515.95 L1112.97 1514.29 L1117.64 1514.29 L1117.64 1544.91 L1125.28 1544.91 L1125.28 1548.85 L1105.37 1548.85 L1105.37 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip830)\" d=\"M1134.77 1514.29 L1153.13 1514.29 L1153.13 1518.22 L1139.05 1518.22 L1139.05 1526.7 Q1140.07 1526.35 1141.09 1526.19 Q1142.11 1526 1143.13 1526 Q1148.91 1526 1152.29 1529.17 Q1155.67 1532.34 1155.67 1537.76 Q1155.67 1543.34 1152.2 1546.44 Q1148.73 1549.52 1142.41 1549.52 Q1140.23 1549.52 1137.97 1549.15 Q1135.72 1548.78 1133.31 1548.04 L1133.31 1543.34 Q1135.4 1544.47 1137.62 1545.03 Q1139.84 1545.58 1142.32 1545.58 Q1146.32 1545.58 1148.66 1543.48 Q1151 1541.37 1151 1537.76 Q1151 1534.15 1148.66 1532.04 Q1146.32 1529.94 1142.32 1529.94 Q1140.44 1529.94 1138.57 1530.35 Q1136.72 1530.77 1134.77 1531.65 L1134.77 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip830)\" d=\"M1449.89 1544.91 L1466.21 1544.91 L1466.21 1548.85 L1444.26 1548.85 L1444.26 1544.91 Q1446.93 1542.16 1451.51 1537.53 Q1456.12 1532.88 1457.3 1531.53 Q1459.54 1529.01 1460.42 1527.27 Q1461.32 1525.51 1461.32 1523.82 Q1461.32 1521.07 1459.38 1519.33 Q1457.46 1517.6 1454.36 1517.6 Q1452.16 1517.6 1449.7 1518.36 Q1447.27 1519.13 1444.5 1520.68 L1444.5 1515.95 Q1447.32 1514.82 1449.77 1514.24 Q1452.23 1513.66 1454.26 1513.66 Q1459.63 1513.66 1462.83 1516.35 Q1466.02 1519.03 1466.02 1523.52 Q1466.02 1525.65 1465.21 1527.57 Q1464.43 1529.47 1462.32 1532.07 Q1461.74 1532.74 1458.64 1535.95 Q1455.54 1539.15 1449.89 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip830)\" d=\"M1486.02 1517.37 Q1482.41 1517.37 1480.58 1520.93 Q1478.78 1524.47 1478.78 1531.6 Q1478.78 1538.71 1480.58 1542.27 Q1482.41 1545.82 1486.02 1545.82 Q1489.66 1545.82 1491.46 1542.27 Q1493.29 1538.71 1493.29 1531.6 Q1493.29 1524.47 1491.46 1520.93 Q1489.66 1517.37 1486.02 1517.37 M1486.02 1513.66 Q1491.83 1513.66 1494.89 1518.27 Q1497.97 1522.85 1497.97 1531.6 Q1497.97 1540.33 1494.89 1544.94 Q1491.83 1549.52 1486.02 1549.52 Q1480.21 1549.52 1477.13 1544.94 Q1474.08 1540.33 1474.08 1531.6 Q1474.08 1522.85 1477.13 1518.27 Q1480.21 1513.66 1486.02 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip830)\" d=\"M1791.32 1544.91 L1807.63 1544.91 L1807.63 1548.85 L1785.69 1548.85 L1785.69 1544.91 Q1788.35 1542.16 1792.94 1537.53 Q1797.54 1532.88 1798.72 1531.53 Q1800.97 1529.01 1801.85 1527.27 Q1802.75 1525.51 1802.75 1523.82 Q1802.75 1521.07 1800.81 1519.33 Q1798.88 1517.6 1795.78 1517.6 Q1793.58 1517.6 1791.13 1518.36 Q1788.7 1519.13 1785.92 1520.68 L1785.92 1515.95 Q1788.75 1514.82 1791.2 1514.24 Q1793.65 1513.66 1795.69 1513.66 Q1801.06 1513.66 1804.25 1516.35 Q1807.45 1519.03 1807.45 1523.52 Q1807.45 1525.65 1806.64 1527.57 Q1805.85 1529.47 1803.75 1532.07 Q1803.17 1532.74 1800.07 1535.95 Q1796.96 1539.15 1791.32 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip830)\" d=\"M1817.5 1514.29 L1835.85 1514.29 L1835.85 1518.22 L1821.78 1518.22 L1821.78 1526.7 Q1822.8 1526.35 1823.81 1526.19 Q1824.83 1526 1825.85 1526 Q1831.64 1526 1835.02 1529.17 Q1838.4 1532.34 1838.4 1537.76 Q1838.4 1543.34 1834.93 1546.44 Q1831.45 1549.52 1825.13 1549.52 Q1822.96 1549.52 1820.69 1549.15 Q1818.44 1548.78 1816.04 1548.04 L1816.04 1543.34 Q1818.12 1544.47 1820.34 1545.03 Q1822.56 1545.58 1825.04 1545.58 Q1829.05 1545.58 1831.38 1543.48 Q1833.72 1541.37 1833.72 1537.76 Q1833.72 1534.15 1831.38 1532.04 Q1829.05 1529.94 1825.04 1529.94 Q1823.17 1529.94 1821.29 1530.35 Q1819.44 1530.77 1817.5 1531.65 L1817.5 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip830)\" d=\"M2141.81 1530.21 Q2145.17 1530.93 2147.05 1533.2 Q2148.94 1535.47 2148.94 1538.8 Q2148.94 1543.92 2145.43 1546.72 Q2141.91 1549.52 2135.43 1549.52 Q2133.25 1549.52 2130.94 1549.08 Q2128.64 1548.66 2126.19 1547.81 L2126.19 1543.29 Q2128.13 1544.43 2130.45 1545.01 Q2132.76 1545.58 2135.29 1545.58 Q2139.69 1545.58 2141.98 1543.85 Q2144.29 1542.11 2144.29 1538.8 Q2144.29 1535.75 2142.14 1534.03 Q2140.01 1532.3 2136.19 1532.3 L2132.16 1532.3 L2132.16 1528.45 L2136.37 1528.45 Q2139.82 1528.45 2141.65 1527.09 Q2143.48 1525.7 2143.48 1523.11 Q2143.48 1520.45 2141.58 1519.03 Q2139.71 1517.6 2136.19 1517.6 Q2134.27 1517.6 2132.07 1518.01 Q2129.87 1518.43 2127.23 1519.31 L2127.23 1515.14 Q2129.89 1514.4 2132.21 1514.03 Q2134.55 1513.66 2136.61 1513.66 Q2141.93 1513.66 2145.03 1516.09 Q2148.13 1518.5 2148.13 1522.62 Q2148.13 1525.49 2146.49 1527.48 Q2144.85 1529.45 2141.81 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip830)\" d=\"M2167.81 1517.37 Q2164.2 1517.37 2162.37 1520.93 Q2160.56 1524.47 2160.56 1531.6 Q2160.56 1538.71 2162.37 1542.27 Q2164.2 1545.82 2167.81 1545.82 Q2171.44 1545.82 2173.25 1542.27 Q2175.08 1538.71 2175.08 1531.6 Q2175.08 1524.47 2173.25 1520.93 Q2171.44 1517.37 2167.81 1517.37 M2167.81 1513.66 Q2173.62 1513.66 2176.68 1518.27 Q2179.75 1522.85 2179.75 1531.6 Q2179.75 1540.33 2176.68 1544.94 Q2173.62 1549.52 2167.81 1549.52 Q2162 1549.52 2158.92 1544.94 Q2155.87 1540.33 2155.87 1531.6 Q2155.87 1522.85 2158.92 1518.27 Q2162 1513.66 2167.81 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip832)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  112.177,1445.72 2352.76,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  112.177,1114.92 2352.76,1114.92 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  112.177,784.122 2352.76,784.122 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  112.177,453.326 2352.76,453.326 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  112.177,122.529 2352.76,122.529 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip830)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  112.177,1486.45 112.177,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip830)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  112.177,1445.72 131.075,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip830)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  112.177,1114.92 131.075,1114.92 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip830)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  112.177,784.122 131.075,784.122 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip830)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  112.177,453.326 131.075,453.326 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip830)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  112.177,122.529 131.075,122.529 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip830)\" d=\"M64.2328 1431.51 Q60.6217 1431.51 58.793 1435.08 Q56.9875 1438.62 56.9875 1445.75 Q56.9875 1452.86 58.793 1456.42 Q60.6217 1459.96 64.2328 1459.96 Q67.867 1459.96 69.6726 1456.42 Q71.5013 1452.86 71.5013 1445.75 Q71.5013 1438.62 69.6726 1435.08 Q67.867 1431.51 64.2328 1431.51 M64.2328 1427.81 Q70.0429 1427.81 73.0985 1432.42 Q76.1772 1437 76.1772 1445.75 Q76.1772 1454.48 73.0985 1459.08 Q70.0429 1463.67 64.2328 1463.67 Q58.4226 1463.67 55.344 1459.08 Q52.2884 1454.48 52.2884 1445.75 Q52.2884 1437 55.344 1432.42 Q58.4226 1427.81 64.2328 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip830)\" d=\"M59.8578 1128.26 L76.1772 1128.26 L76.1772 1132.2 L54.2328 1132.2 L54.2328 1128.26 Q56.8949 1125.51 61.4782 1120.88 Q66.0846 1116.23 67.2652 1114.88 Q69.5105 1112.36 70.3902 1110.63 Q71.2929 1108.87 71.2929 1107.18 Q71.2929 1104.42 69.3485 1102.69 Q67.4272 1100.95 64.3254 1100.95 Q62.1263 1100.95 59.6726 1101.71 Q57.2421 1102.48 54.4643 1104.03 L54.4643 1099.31 Q57.2884 1098.17 59.7421 1097.59 Q62.1958 1097.01 64.2328 1097.01 Q69.6031 1097.01 72.7976 1099.7 Q75.992 1102.38 75.992 1106.88 Q75.992 1109 75.1818 1110.93 Q74.3948 1112.82 72.2883 1115.42 Q71.7096 1116.09 68.6078 1119.31 Q65.5059 1122.5 59.8578 1128.26 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip830)\" d=\"M66.5939 770.916 L54.7884 789.365 L66.5939 789.365 L66.5939 770.916 M65.367 766.842 L71.2466 766.842 L71.2466 789.365 L76.1772 789.365 L76.1772 793.254 L71.2466 793.254 L71.2466 801.402 L66.5939 801.402 L66.5939 793.254 L50.9921 793.254 L50.9921 788.74 L65.367 766.842 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip830)\" d=\"M64.6495 451.462 Q61.5013 451.462 59.6495 453.615 Q57.8208 455.768 57.8208 459.518 Q57.8208 463.245 59.6495 465.421 Q61.5013 467.573 64.6495 467.573 Q67.7976 467.573 69.6263 465.421 Q71.4781 463.245 71.4781 459.518 Q71.4781 455.768 69.6263 453.615 Q67.7976 451.462 64.6495 451.462 M73.9318 436.81 L73.9318 441.069 Q72.1726 440.235 70.367 439.796 Q68.5846 439.356 66.8254 439.356 Q62.1958 439.356 59.7421 442.481 Q57.3115 445.606 56.9643 451.925 Q58.33 449.911 60.3902 448.847 Q62.4504 447.759 64.9272 447.759 Q70.1355 447.759 73.1448 450.93 Q76.1772 454.078 76.1772 459.518 Q76.1772 464.842 73.029 468.059 Q69.8809 471.277 64.6495 471.277 Q58.6541 471.277 55.4828 466.694 Q52.3116 462.087 52.3116 453.36 Q52.3116 445.166 56.2004 440.305 Q60.0893 435.421 66.6402 435.421 Q68.3994 435.421 70.1818 435.768 Q71.9874 436.115 73.9318 436.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip830)\" d=\"M64.3254 123.397 Q60.9921 123.397 59.0708 125.179 Q57.1726 126.962 57.1726 130.087 Q57.1726 133.212 59.0708 134.994 Q60.9921 136.777 64.3254 136.777 Q67.6587 136.777 69.58 134.994 Q71.5013 133.189 71.5013 130.087 Q71.5013 126.962 69.58 125.179 Q67.6819 123.397 64.3254 123.397 M59.6495 121.406 Q56.6402 120.666 54.9504 118.605 Q53.2838 116.545 53.2838 113.582 Q53.2838 109.439 56.2236 107.031 Q59.1865 104.624 64.3254 104.624 Q69.4874 104.624 72.4272 107.031 Q75.367 109.439 75.367 113.582 Q75.367 116.545 73.6772 118.605 Q72.0105 120.666 69.0244 121.406 Q72.404 122.193 74.279 124.485 Q76.1772 126.777 76.1772 130.087 Q76.1772 135.11 73.0985 137.795 Q70.0429 140.48 64.3254 140.48 Q58.6078 140.48 55.5291 137.795 Q52.4736 135.11 52.4736 130.087 Q52.4736 126.777 54.3717 124.485 Q56.2699 122.193 59.6495 121.406 M57.9365 114.022 Q57.9365 116.707 59.6032 118.212 Q61.293 119.717 64.3254 119.717 Q67.3346 119.717 69.0244 118.212 Q70.7374 116.707 70.7374 114.022 Q70.7374 111.337 69.0244 109.832 Q67.3346 108.328 64.3254 108.328 Q61.293 108.328 59.6032 109.832 Q57.9365 111.337 57.9365 114.022 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip832)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  175.59,1421.4 243.775,1423.9 311.961,1437.99 380.147,1444.89 448.332,1425.66 516.518,1434.6 584.703,87.9763 652.889,1373.82 721.075,1161.67 789.26,1319.57 \n",
       "  857.446,1298.51 925.631,1384.34 993.817,1320.66 1062,1365.58 1130.19,1345.52 1198.37,1396.9 1266.56,1445.72 1334.74,1445.72 1402.93,1434.94 1471.12,1445.72 \n",
       "  1539.3,1431.99 1607.49,1394.65 1675.67,1365.34 1743.86,1390.1 1812.04,1439.23 1880.23,1424.29 1948.42,1422.48 2016.6,1434.09 2084.79,1409.61 2152.97,1435.97 \n",
       "  2221.16,1430.44 2289.34,1363.09 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip830)\" d=\"\n",
       "M1976.69 198.898 L2278.07 198.898 L2278.07 95.2176 L1976.69 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip830)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1976.69,198.898 2278.07,198.898 2278.07,95.2176 1976.69,95.2176 1976.69,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip830)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2001.58,147.058 2150.95,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip830)\" d=\"M2189.69 166.745 Q2187.89 171.375 2186.17 172.787 Q2184.46 174.199 2181.59 174.199 L2178.19 174.199 L2178.19 170.634 L2180.69 170.634 Q2182.45 170.634 2183.42 169.8 Q2184.39 168.967 2185.57 165.865 L2186.34 163.921 L2175.85 138.412 L2180.36 138.412 L2188.46 158.689 L2196.57 138.412 L2201.08 138.412 L2189.69 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip830)\" d=\"M2208.37 160.402 L2216.01 160.402 L2216.01 134.037 L2207.7 135.703 L2207.7 131.444 L2215.96 129.778 L2220.64 129.778 L2220.64 160.402 L2228.28 160.402 L2228.28 164.338 L2208.37 164.338 L2208.37 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    bestEpSc    = -100.0;\n",
    "    statesBest  = zeros( size( X_0, 1 ), T )\n",
    "    actionsBest = zeros( T );\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/(episodes-1)\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        \n",
    "        s_l = 0.0\n",
    "        # while s_l == 0\n",
    "        \n",
    "            X  = X_0\n",
    "\n",
    "            ##### Double Q-Learning ###########################################\n",
    "\n",
    "            for k = 1:T\n",
    "\n",
    "                # 1. Choose action\n",
    "                if rand() < epsilon\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                else\n",
    "\n",
    "                    A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                    if A == 1000.0 # Indicates no values in this region\n",
    "                        if rand() < EXPrand \n",
    "                            A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                        else\n",
    "                            A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                # 2. Cache last state\n",
    "                qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "                # 3. Generate the next stae\n",
    "                Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "                # 4. Collect reward R( s, a, s' )\n",
    "                R_t = cartpole_reward( Xp )\n",
    "\n",
    "                # 5. Get the optimal action at the next state\n",
    "                a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "                # 6. Compute the value at the next state\n",
    "\n",
    "                V_tp1_opt = query_value_fuzzy( \n",
    "                    Q_kdTree, G, V, \n",
    "                    get_Q( \n",
    "                        select_X_vector( Xp ), \n",
    "                        a_tp1_opt \n",
    "                    ); \n",
    "                    k = vNN \n",
    "                )\n",
    "                if isnan( V_tp1_opt )\n",
    "                    V_tp1_opt = 0.0\n",
    "                end\n",
    "\n",
    "\n",
    "                # 7. Blend the value back into nearest points\n",
    "\n",
    "                idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "                nNear      = size( idxs, 1 )\n",
    "                for i = 1:nNear\n",
    "                    j    = idxs[i]\n",
    "                    if !isnan( wgts[i] ) \n",
    "\n",
    "                        # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                        VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                states[:,k] = Xp\n",
    "                actions[k]  = A\n",
    "\n",
    "                X = Xp\n",
    "            end\n",
    "\n",
    "            s_l    = vertical_score_s( states, aMargin, ts )\n",
    "            \n",
    "        # end\n",
    "            \n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if s_l > bestEpSc\n",
    "            bestEpSc    = s_l\n",
    "            statesBest  = copy( states  )\n",
    "            actionsBest = copy( actions )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        # if useElig && (s_l > s_Totl/(1.0*l)) && (s_l > 0.0) \n",
    "        # if useElig && (s_l > 0.0) \n",
    "        if useElig \n",
    "            \n",
    "            # if s_l == 0.0\n",
    "            #     states  = copy( bestXs )\n",
    "            #     actions = copy( bestAs )\n",
    "            # end\n",
    "            \n",
    "            # println( \"Assign eligibility for a history with score \", s_l )\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "    \n",
    "    ##### Learning Rate Schedule ##########################################\n",
    "    alpha *= beta\n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
