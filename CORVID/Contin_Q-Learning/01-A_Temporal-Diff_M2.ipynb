{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.02148 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 # 0.00782 # 0.00391\n",
    "gamma    = 0.999\n",
    "swapDiv  = 1\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes =  64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   =  32 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "beta   = 0.15\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = false\n",
    "N_peaks =  40\n",
    "N_steps = 200\n",
    "lambda  =   0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.13999999999999999, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.18000000000000002, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.09187500000000007\n",
      "\n",
      "Epoch 2, Best Score: 0.9900000000000007\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.7700000000000005, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.10999999999999999, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.15, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.22000000000000006, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.07218750000000002\n",
      "\n",
      "Epoch 3, Best Score: 0.9900000000000007\n",
      "Training Iteration 4 score: 0.4200000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.16, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 1.370000000000001, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.12999999999999998, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.09999999999999999, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.36000000000000015, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.12999999999999998, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.3100000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.13999999999999999, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.16, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.08, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.09687500000000004\n",
      "\n",
      "Epoch 4, Best Score: 1.7600000000000013\n",
      "Training Iteration 4 score: 0.17, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.22000000000000006, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.12999999999999998, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.4400000000000002, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.36000000000000015, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.12999999999999998, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.16, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.09999999999999999, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.24000000000000007, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.17, epsilon: 0.0078125\n",
      "Average Score: 0.06015625000000002\n",
      "\n",
      "Epoch 5, Best Score: 1.7600000000000013\n",
      "Training Iteration 4 score: 0.4100000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.02203125000000001\n",
      "\n",
      "Epoch 6, Best Score: 1.7600000000000013\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.2700000000000001, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.8500000000000005, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.4400000000000002, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.2700000000000001, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 2.439999999999992, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.8800000000000006, epsilon: 0.0078125\n",
      "Average Score: 0.26093749999999993\n",
      "\n",
      "Epoch 7, Best Score: 2.439999999999992\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.6000000000000003, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.38000000000000017, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.7200000000000004, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.08, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 2.020000000000001, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.12999999999999998, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 2.239999999999996, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.5300000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.09999999999999999, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.26687500000000003\n",
      "\n",
      "Epoch 8, Best Score: 2.439999999999992\n",
      "Training Iteration 4 score: 0.20000000000000004, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.6800000000000004, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.7700000000000005, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.6400000000000003, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 2.2299999999999964, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.6900000000000004, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 4.87999999999994, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 1.6800000000000013, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 7.429999999999886, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 3.9499999999999598, epsilon: 0.0078125\n",
      "Average Score: 0.6743749999999938\n",
      "\n",
      "Epoch 9, Best Score: 8.809999999999857\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.6100000000000003, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.2800000000000001, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.09999999999999999, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.08687499999999991\n",
      "\n",
      "Epoch 10, Best Score: 8.809999999999857\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.19000000000000003, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 1.260000000000001, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 2.07, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 1.490000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.9000000000000006, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.6900000000000004, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 3.0299999999999794, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 1.7500000000000013, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.7700000000000005, epsilon: 0.0078125\n",
      "Average Score: 0.25171874999999977\n",
      "\n",
      "Epoch 11, Best Score: 8.809999999999857\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 1.420000000000001, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 2.629999999999988, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 3.8699999999999615, epsilon: 0.0078125\n",
      "Average Score: 0.29328124999999755\n",
      "\n",
      "Epoch 12, Best Score: 8.809999999999857\n",
      "Training Iteration 4 score: 0.09999999999999999, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.034843750000000014\n",
      "\n",
      "Epoch 13, Best Score: 8.809999999999857\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.6700000000000004, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.35000000000000014, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.4400000000000002, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 5.329999999999931, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.10999999999999999, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.15734374999999895\n",
      "\n",
      "Epoch 14, Best Score: 8.809999999999857\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.006562500000000001\n",
      "\n",
      "Epoch 15, Best Score: 8.809999999999857\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.8600000000000005, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.26000000000000006, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.11999999999999998, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.49000000000000027, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.12999999999999998, epsilon: 0.0078125\n",
      "Average Score: 0.29562499999999986\n",
      "\n",
      "Epoch 16, Best Score: 8.809999999999857\n",
      "Training Iteration 4 score: 0.26000000000000006, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.7000000000000004, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 1.1500000000000008, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.46000000000000024, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.7100000000000004, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.36000000000000015, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 1.0000000000000007, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.5400000000000003, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.9300000000000006, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.36000000000000015, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.3900000000000002, epsilon: 0.0078125\n",
      "Average Score: 0.7528124999999981\n",
      "\n",
      "Epoch 17, Best Score: 8.809999999999857\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.13999999999999999, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.13999999999999999, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.8500000000000005, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.13999999999999999, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.24000000000000007, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.11999999999999998, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.5000000000000002, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.13999999999999999, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.4000000000000002, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.9800000000000006, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.7500000000000004, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.4300000000000002, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.10999999999999999, epsilon: 0.0078125\n",
      "Average Score: 2.230937500000053\n",
      "\n",
      "Epoch 18, Best Score: 33.590000000001886\n",
      "Training Iteration 4 score: 0.45000000000000023, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.34000000000000014, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.12999999999999998, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.2800000000000001, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.7100000000000004, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.09999999999999999, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.36000000000000015, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.09, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.17, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.22000000000000006, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.24000000000000007, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.24000000000000007, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.16, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.16, epsilon: 0.0078125\n",
      "Average Score: 0.4935937499999998\n",
      "\n",
      "Epoch 19, Best Score: 33.590000000001886\n",
      "Training Iteration 4 score: 0.24000000000000007, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.12999999999999998, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.12999999999999998, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.10999999999999999, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.18000000000000002, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.24000000000000007, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.37000000000000016, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.24000000000000007, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.11999999999999998, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.13999999999999999, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 1.0100000000000007, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.23375000000000015\n",
      "\n",
      "Epoch 20, Best Score: 33.590000000001886\n",
      "Training Iteration 4 score: 0.12999999999999998, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.052656250000000016\n",
      "\n",
      "Epoch 21, Best Score: 33.590000000001886\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.13999999999999999, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.3000000000000001, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.7500000000000004, epsilon: 0.0078125\n",
      "Average Score: 0.07015625000000004\n",
      "\n",
      "Epoch 22, Best Score: 33.590000000001886\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.6000000000000003, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 1.7900000000000014, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.12999999999999998, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.3200000000000001, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.07, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.7400000000000004, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.20000000000000004, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.2900000000000001, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.5900000000000003, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.22000000000000006, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.17046875000000006\n",
      "\n",
      "Epoch 23, Best Score: 33.590000000001886\n",
      "Training Iteration 4 score: 0.8500000000000005, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.26000000000000006, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 3.089999999999978, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.2900000000000001, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.5800000000000003, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.5300000000000002, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.3000000000000001, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.7800000000000005, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.25000000000000006, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.47000000000000025, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.2700000000000001, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.47000000000000025, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.5100000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 1.400000000000001, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 1.2400000000000009, epsilon: 0.0078125\n",
      "Average Score: 0.34656249999999966\n",
      "\n",
      "Epoch 24, Best Score: 33.590000000001886\n",
      "Training Iteration 4 score: 2.339999999999994, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 1.0000000000000007, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.9600000000000006, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.34000000000000014, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.3100000000000001, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 1.0700000000000007, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 2.5099999999999905, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.8400000000000005, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.2800000000000001, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.4200000000000002, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.23000000000000007, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.30249999999999994\n",
      "\n",
      "Epoch 25, Best Score: 33.590000000001886\n",
      "Training Iteration 4 score: 0.5500000000000003, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.12999999999999998, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.13999999999999999, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.35000000000000014, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.3900000000000002, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.25000000000000006, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.35000000000000014, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.10999999999999999, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.5600000000000003, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.21000000000000005, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.36000000000000015, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 1.2200000000000009, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.4200000000000002, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.38000000000000017, epsilon: 0.0078125\n",
      "Average Score: 0.23124999999999973\n",
      "\n",
      "Epoch 26, Best Score: 33.590000000001886\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.36000000000000015, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.2700000000000001, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.8100000000000005, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.16, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.12999999999999998, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 1.340000000000001, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.5600000000000003, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.45000000000000023, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.22000000000000006, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.25000000000000006, epsilon: 0.0078125\n",
      "Average Score: 0.15500000000000008\n",
      "\n",
      "Epoch 27, Best Score: 33.590000000001886\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 3.569999999999968, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.6600000000000004, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.4754687499999981\n",
      "\n",
      "Epoch 28, Best Score: 33.590000000001886\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.03812500000000002\n",
      "\n",
      "Epoch 29, Best Score: 33.590000000001886\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.5000000000000002, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.6400000000000003, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 1.2400000000000009, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 1.9800000000000015, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.060000000000000005, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 2.0799999999999996, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 1.1000000000000008, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.35000000000000014, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.6500000000000004, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 1.7100000000000013, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 7.8299999999998775, epsilon: 0.0078125\n",
      "Average Score: 0.5485937499999962\n",
      "\n",
      "Epoch 30, Best Score: 33.590000000001886\n",
      "Training Iteration 4 score: 2.389999999999993, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 1.5800000000000012, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 21.190000000000513, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 6.2799999999999105, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.7200000000000004, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 1.440000000000001, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.5300000000000002, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.15, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 13.82999999999975, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 6.579999999999904, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.4000000000000002, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.23000000000000007, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.26000000000000006, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.4200000000000002, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.49000000000000027, epsilon: 0.0078125\n",
      "Average Score: 2.674375000000056\n",
      "\n",
      "Epoch 31, Best Score: 33.590000000001886\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 22.530000000000722, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 18.060000000000024, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 11.559999999999798, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 21.410000000000547, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 1.330000000000001, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 1.5400000000000011, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 2.299999999999995, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.7100000000000004, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.5200000000000002, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 2.3799999999999932, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.46000000000000024, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.35000000000000014, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.36000000000000015, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 1.0300000000000007, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.060000000000000005, epsilon: 0.0078125\n",
      "Average Score: 3.0385937500000364\n",
      "\n",
      "Epoch 32, Best Score: 33.590000000001886\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.34000000000000014, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 1.0000000000000007, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.48000000000000026, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.3300000000000001, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.22000000000000006, epsilon: 0.0078125\n",
      "Average Score: 0.31749999999999845\n",
      "Saved a trained Q-table with size (76032,), After 11.895565080642701 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip380\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip380)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip381\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip380)\" d=\"\n",
       "M110.881 1486.45 L2352.76 1486.45 L2352.76 47.2441 L110.881 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip382\">\n",
       "    <rect x=\"110\" y=\"47\" width=\"2243\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip382)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  447.23,1486.45 447.23,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip382)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  788.356,1486.45 788.356,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip382)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1129.48,1486.45 1129.48,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip382)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1470.61,1486.45 1470.61,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip382)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1811.73,1486.45 1811.73,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip382)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2152.86,1486.45 2152.86,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip380)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  110.881,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip380)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  447.23,1486.45 447.23,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip380)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  788.356,1486.45 788.356,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip380)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1129.48,1486.45 1129.48,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip380)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1470.61,1486.45 1470.61,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip380)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1811.73,1486.45 1811.73,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip380)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2152.86,1486.45 2152.86,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip380)\" d=\"M437.508 1514.29 L455.865 1514.29 L455.865 1518.22 L441.791 1518.22 L441.791 1526.7 Q442.809 1526.35 443.828 1526.19 Q444.846 1526 445.865 1526 Q451.652 1526 455.031 1529.17 Q458.411 1532.34 458.411 1537.76 Q458.411 1543.34 454.939 1546.44 Q451.466 1549.52 445.147 1549.52 Q442.971 1549.52 440.703 1549.15 Q438.457 1548.78 436.05 1548.04 L436.05 1543.34 Q438.133 1544.47 440.355 1545.03 Q442.578 1545.58 445.054 1545.58 Q449.059 1545.58 451.397 1543.48 Q453.735 1541.37 453.735 1537.76 Q453.735 1534.15 451.397 1532.04 Q449.059 1529.94 445.054 1529.94 Q443.179 1529.94 441.304 1530.35 Q439.453 1530.77 437.508 1531.65 L437.508 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip380)\" d=\"M763.043 1544.91 L770.682 1544.91 L770.682 1518.55 L762.372 1520.21 L762.372 1515.95 L770.636 1514.29 L775.312 1514.29 L775.312 1544.91 L782.951 1544.91 L782.951 1548.85 L763.043 1548.85 L763.043 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip380)\" d=\"M802.395 1517.37 Q798.784 1517.37 796.955 1520.93 Q795.15 1524.47 795.15 1531.6 Q795.15 1538.71 796.955 1542.27 Q798.784 1545.82 802.395 1545.82 Q806.029 1545.82 807.835 1542.27 Q809.663 1538.71 809.663 1531.6 Q809.663 1524.47 807.835 1520.93 Q806.029 1517.37 802.395 1517.37 M802.395 1513.66 Q808.205 1513.66 811.261 1518.27 Q814.339 1522.85 814.339 1531.6 Q814.339 1540.33 811.261 1544.94 Q808.205 1549.52 802.395 1549.52 Q796.585 1549.52 793.506 1544.94 Q790.45 1540.33 790.45 1531.6 Q790.45 1522.85 793.506 1518.27 Q796.585 1513.66 802.395 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip380)\" d=\"M1104.67 1544.91 L1112.3 1544.91 L1112.3 1518.55 L1103.99 1520.21 L1103.99 1515.95 L1112.26 1514.29 L1116.93 1514.29 L1116.93 1544.91 L1124.57 1544.91 L1124.57 1548.85 L1104.67 1548.85 L1104.67 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip380)\" d=\"M1134.06 1514.29 L1152.42 1514.29 L1152.42 1518.22 L1138.35 1518.22 L1138.35 1526.7 Q1139.37 1526.35 1140.38 1526.19 Q1141.4 1526 1142.42 1526 Q1148.21 1526 1151.59 1529.17 Q1154.97 1532.34 1154.97 1537.76 Q1154.97 1543.34 1151.49 1546.44 Q1148.02 1549.52 1141.7 1549.52 Q1139.53 1549.52 1137.26 1549.15 Q1135.01 1548.78 1132.61 1548.04 L1132.61 1543.34 Q1134.69 1544.47 1136.91 1545.03 Q1139.13 1545.58 1141.61 1545.58 Q1145.61 1545.58 1147.95 1543.48 Q1150.29 1541.37 1150.29 1537.76 Q1150.29 1534.15 1147.95 1532.04 Q1145.61 1529.94 1141.61 1529.94 Q1139.74 1529.94 1137.86 1530.35 Q1136.01 1530.77 1134.06 1531.65 L1134.06 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip380)\" d=\"M1449.38 1544.91 L1465.7 1544.91 L1465.7 1548.85 L1443.75 1548.85 L1443.75 1544.91 Q1446.42 1542.16 1451 1537.53 Q1455.61 1532.88 1456.79 1531.53 Q1459.03 1529.01 1459.91 1527.27 Q1460.81 1525.51 1460.81 1523.82 Q1460.81 1521.07 1458.87 1519.33 Q1456.95 1517.6 1453.85 1517.6 Q1451.65 1517.6 1449.19 1518.36 Q1446.76 1519.13 1443.99 1520.68 L1443.99 1515.95 Q1446.81 1514.82 1449.26 1514.24 Q1451.72 1513.66 1453.75 1513.66 Q1459.12 1513.66 1462.32 1516.35 Q1465.51 1519.03 1465.51 1523.52 Q1465.51 1525.65 1464.7 1527.57 Q1463.92 1529.47 1461.81 1532.07 Q1461.23 1532.74 1458.13 1535.95 Q1455.03 1539.15 1449.38 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip380)\" d=\"M1485.51 1517.37 Q1481.9 1517.37 1480.07 1520.93 Q1478.27 1524.47 1478.27 1531.6 Q1478.27 1538.71 1480.07 1542.27 Q1481.9 1545.82 1485.51 1545.82 Q1489.15 1545.82 1490.95 1542.27 Q1492.78 1538.71 1492.78 1531.6 Q1492.78 1524.47 1490.95 1520.93 Q1489.15 1517.37 1485.51 1517.37 M1485.51 1513.66 Q1491.32 1513.66 1494.38 1518.27 Q1497.46 1522.85 1497.46 1531.6 Q1497.46 1540.33 1494.38 1544.94 Q1491.32 1549.52 1485.51 1549.52 Q1479.7 1549.52 1476.62 1544.94 Q1473.57 1540.33 1473.57 1531.6 Q1473.57 1522.85 1476.62 1518.27 Q1479.7 1513.66 1485.51 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip380)\" d=\"M1791 1544.91 L1807.32 1544.91 L1807.32 1548.85 L1785.38 1548.85 L1785.38 1544.91 Q1788.04 1542.16 1792.62 1537.53 Q1797.23 1532.88 1798.41 1531.53 Q1800.65 1529.01 1801.53 1527.27 Q1802.44 1525.51 1802.44 1523.82 Q1802.44 1521.07 1800.49 1519.33 Q1798.57 1517.6 1795.47 1517.6 Q1793.27 1517.6 1790.82 1518.36 Q1788.39 1519.13 1785.61 1520.68 L1785.61 1515.95 Q1788.43 1514.82 1790.89 1514.24 Q1793.34 1513.66 1795.38 1513.66 Q1800.75 1513.66 1803.94 1516.35 Q1807.14 1519.03 1807.14 1523.52 Q1807.14 1525.65 1806.33 1527.57 Q1805.54 1529.47 1803.43 1532.07 Q1802.85 1532.74 1799.75 1535.95 Q1796.65 1539.15 1791 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip380)\" d=\"M1817.18 1514.29 L1835.54 1514.29 L1835.54 1518.22 L1821.47 1518.22 L1821.47 1526.7 Q1822.48 1526.35 1823.5 1526.19 Q1824.52 1526 1825.54 1526 Q1831.33 1526 1834.71 1529.17 Q1838.09 1532.34 1838.09 1537.76 Q1838.09 1543.34 1834.61 1546.44 Q1831.14 1549.52 1824.82 1549.52 Q1822.65 1549.52 1820.38 1549.15 Q1818.13 1548.78 1815.72 1548.04 L1815.72 1543.34 Q1817.81 1544.47 1820.03 1545.03 Q1822.25 1545.58 1824.73 1545.58 Q1828.73 1545.58 1831.07 1543.48 Q1833.41 1541.37 1833.41 1537.76 Q1833.41 1534.15 1831.07 1532.04 Q1828.73 1529.94 1824.73 1529.94 Q1822.85 1529.94 1820.98 1530.35 Q1819.13 1530.77 1817.18 1531.65 L1817.18 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip380)\" d=\"M2141.7 1530.21 Q2145.06 1530.93 2146.93 1533.2 Q2148.83 1535.47 2148.83 1538.8 Q2148.83 1543.92 2145.31 1546.72 Q2141.79 1549.52 2135.31 1549.52 Q2133.13 1549.52 2130.82 1549.08 Q2128.53 1548.66 2126.07 1547.81 L2126.07 1543.29 Q2128.02 1544.43 2130.33 1545.01 Q2132.65 1545.58 2135.17 1545.58 Q2139.57 1545.58 2141.86 1543.85 Q2144.18 1542.11 2144.18 1538.8 Q2144.18 1535.75 2142.02 1534.03 Q2139.89 1532.3 2136.07 1532.3 L2132.05 1532.3 L2132.05 1528.45 L2136.26 1528.45 Q2139.71 1528.45 2141.54 1527.09 Q2143.37 1525.7 2143.37 1523.11 Q2143.37 1520.45 2141.47 1519.03 Q2139.59 1517.6 2136.07 1517.6 Q2134.15 1517.6 2131.95 1518.01 Q2129.75 1518.43 2127.12 1519.31 L2127.12 1515.14 Q2129.78 1514.4 2132.09 1514.03 Q2134.43 1513.66 2136.49 1513.66 Q2141.81 1513.66 2144.92 1516.09 Q2148.02 1518.5 2148.02 1522.62 Q2148.02 1525.49 2146.38 1527.48 Q2144.73 1529.45 2141.7 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip380)\" d=\"M2167.69 1517.37 Q2164.08 1517.37 2162.25 1520.93 Q2160.45 1524.47 2160.45 1531.6 Q2160.45 1538.71 2162.25 1542.27 Q2164.08 1545.82 2167.69 1545.82 Q2171.33 1545.82 2173.13 1542.27 Q2174.96 1538.71 2174.96 1531.6 Q2174.96 1524.47 2173.13 1520.93 Q2171.33 1517.37 2167.69 1517.37 M2167.69 1513.66 Q2173.5 1513.66 2176.56 1518.27 Q2179.64 1522.85 2179.64 1531.6 Q2179.64 1540.33 2176.56 1544.94 Q2173.5 1549.52 2167.69 1549.52 Q2161.88 1549.52 2158.81 1544.94 Q2155.75 1540.33 2155.75 1531.6 Q2155.75 1522.85 2158.81 1518.27 Q2161.88 1513.66 2167.69 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip382)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  110.881,1448.65 2352.76,1448.65 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip382)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  110.881,1000.86 2352.76,1000.86 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip382)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  110.881,553.057 2352.76,553.057 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip382)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  110.881,105.259 2352.76,105.259 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip380)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  110.881,1486.45 110.881,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip380)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  110.881,1448.65 129.779,1448.65 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip380)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  110.881,1000.86 129.779,1000.86 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip380)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  110.881,553.057 129.779,553.057 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip380)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  110.881,105.259 129.779,105.259 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip380)\" d=\"M62.9365 1434.45 Q59.3254 1434.45 57.4967 1438.02 Q55.6912 1441.56 55.6912 1448.69 Q55.6912 1455.8 57.4967 1459.36 Q59.3254 1462.9 62.9365 1462.9 Q66.5707 1462.9 68.3763 1459.36 Q70.205 1455.8 70.205 1448.69 Q70.205 1441.56 68.3763 1438.02 Q66.5707 1434.45 62.9365 1434.45 M62.9365 1430.75 Q68.7467 1430.75 71.8022 1435.36 Q74.8809 1439.94 74.8809 1448.69 Q74.8809 1457.42 71.8022 1462.02 Q68.7467 1466.61 62.9365 1466.61 Q57.1264 1466.61 54.0477 1462.02 Q50.9921 1457.42 50.9921 1448.69 Q50.9921 1439.94 54.0477 1435.36 Q57.1264 1430.75 62.9365 1430.75 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip380)\" d=\"M54.9736 1014.2 L62.6124 1014.2 L62.6124 987.835 L54.3023 989.502 L54.3023 985.242 L62.5661 983.576 L67.242 983.576 L67.242 1014.2 L74.8809 1014.2 L74.8809 1018.14 L54.9736 1018.14 L54.9736 1014.2 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip380)\" d=\"M58.5615 566.402 L74.8809 566.402 L74.8809 570.337 L52.9366 570.337 L52.9366 566.402 Q55.5986 563.647 60.1819 559.018 Q64.7883 554.365 65.9689 553.022 Q68.2143 550.499 69.0939 548.763 Q69.9967 547.004 69.9967 545.314 Q69.9967 542.559 68.0522 540.823 Q66.1309 539.087 63.0291 539.087 Q60.83 539.087 58.3763 539.851 Q55.9458 540.615 53.168 542.166 L53.168 537.444 Q55.9921 536.31 58.4458 535.731 Q60.8995 535.152 62.9365 535.152 Q68.3068 535.152 71.5013 537.837 Q74.6957 540.522 74.6957 545.013 Q74.6957 547.143 73.8855 549.064 Q73.0985 550.962 70.992 553.555 Q70.4133 554.226 67.3115 557.444 Q64.2096 560.638 58.5615 566.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip380)\" d=\"M67.7513 103.904 Q71.1078 104.622 72.9827 106.89 Q74.8809 109.159 74.8809 112.492 Q74.8809 117.608 71.3624 120.409 Q67.8439 123.21 61.3624 123.21 Q59.1865 123.21 56.8717 122.77 Q54.5801 122.353 52.1264 121.497 L52.1264 116.983 Q54.0708 118.117 56.3856 118.696 Q58.7004 119.275 61.2236 119.275 Q65.6217 119.275 67.9133 117.539 Q70.2281 115.802 70.2281 112.492 Q70.2281 109.437 68.0754 107.724 Q65.9457 105.988 62.1263 105.988 L58.0986 105.988 L58.0986 102.145 L62.3115 102.145 Q65.7606 102.145 67.5893 100.779 Q69.418 99.3905 69.418 96.7979 Q69.418 94.1359 67.5198 92.7238 Q65.6448 91.2887 62.1263 91.2887 Q60.205 91.2887 58.006 91.7053 Q55.8069 92.122 53.168 93.0016 L53.168 88.835 Q55.8301 88.0942 58.1449 87.7239 Q60.4828 87.3535 62.543 87.3535 Q67.867 87.3535 70.9689 89.7841 Q74.0707 92.1914 74.0707 96.3118 Q74.0707 99.1821 72.4272 101.173 Q70.7837 103.14 67.7513 103.904 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip382)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.33,1407.51 242.555,1416.33 310.78,1405.27 379.005,1421.72 447.23,1438.79 515.455,1331.81 583.68,1329.15 651.906,1146.67 720.131,1409.75 788.356,1335.94 \n",
       "  856.581,1317.32 924.806,1433.05 993.031,1378.2 1061.26,1445.72 1129.48,1316.27 1197.71,1111.55 1265.93,449.644 1334.16,1227.62 1402.38,1343.98 1470.61,1425.07 \n",
       "  1538.83,1417.24 1607.06,1372.32 1675.28,1293.46 1743.51,1313.2 1811.73,1345.1 1879.96,1379.25 1948.18,1235.74 2016.41,1431.58 2084.63,1202.99 2152.86,251.073 \n",
       "  2221.08,87.9763 2289.31,1306.48 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip380)\" d=\"\n",
       "M1976.5 198.898 L2278.03 198.898 L2278.03 95.2176 L1976.5 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip380)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1976.5,198.898 2278.03,198.898 2278.03,95.2176 1976.5,95.2176 1976.5,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip380)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2001.41,147.058 2150.87,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip380)\" d=\"M2189.62 166.745 Q2187.81 171.375 2186.1 172.787 Q2184.39 174.199 2181.52 174.199 L2178.11 174.199 L2178.11 170.634 L2180.61 170.634 Q2182.37 170.634 2183.35 169.8 Q2184.32 168.967 2185.5 165.865 L2186.26 163.921 L2175.78 138.412 L2180.29 138.412 L2188.39 158.689 L2196.49 138.412 L2201.01 138.412 L2189.62 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip380)\" d=\"M2208.3 160.402 L2215.94 160.402 L2215.94 134.037 L2207.63 135.703 L2207.63 131.444 L2215.89 129.778 L2220.57 129.778 L2220.57 160.402 L2228.21 160.402 L2228.21 164.338 L2208.3 164.338 L2208.3 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/episodes\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        X  = X_0\n",
    "        \n",
    "        ##### Double Q-Learning ###########################################\n",
    "\n",
    "        for k = 1:T\n",
    "\n",
    "            # 1. Choose action\n",
    "            if rand() < epsilon\n",
    "                if rand() < EXPrand \n",
    "                    A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                else\n",
    "                    A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                end\n",
    "            else\n",
    "\n",
    "                A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                if A == 1000.0 # Indicates no values in this region\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "\n",
    "            # 2. Cache last state\n",
    "            qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "            # 3. Generate the next stae\n",
    "            Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "            # 4. Collect reward R( s, a, s' )\n",
    "            R_t = cartpole_reward( Xp )\n",
    "\n",
    "            # 5. Get the optimal action at the next state\n",
    "            a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "            # 6. Compute the value at the next state\n",
    "\n",
    "            V_tp1_opt = query_value_fuzzy( \n",
    "                Q_kdTree, G, V, \n",
    "                get_Q( \n",
    "                    select_X_vector( Xp ), \n",
    "                    a_tp1_opt \n",
    "                ); \n",
    "                k = vNN \n",
    "            )\n",
    "            if isnan( V_tp1_opt )\n",
    "                V_tp1_opt = 0.0\n",
    "            end\n",
    "\n",
    "\n",
    "            # 7. Blend the value back into nearest points\n",
    "\n",
    "            idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "            nNear      = size( idxs, 1 )\n",
    "            for i = 1:nNear\n",
    "                j    = idxs[i]\n",
    "                if !isnan( wgts[i] ) \n",
    "\n",
    "                    # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                    VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "                    \n",
    "                end\n",
    "            end\n",
    "\n",
    "            states[:,k] = Xp\n",
    "            actions[k]  = A\n",
    "\n",
    "            X = Xp\n",
    "        end\n",
    "\n",
    "        s_l    = vertical_score_s( states, aMargin, ts )\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        if useElig\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
