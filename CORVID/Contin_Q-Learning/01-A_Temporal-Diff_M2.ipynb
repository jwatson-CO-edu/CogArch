{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.25 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 \n",
    "gamma    = 1.00 \n",
    "swapDiv  = 1\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes =  64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   =  32 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "beta   = 0.15\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = false\n",
    "N_peaks =  40\n",
    "N_steps = 200\n",
    "lambda  =   0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 3.8299999999999623, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 1.9700000000000015, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 1.7800000000000014, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 1.310000000000001, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.48000000000000026, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.6651562500000173\n",
      "\n",
      "Epoch 2, Best Score: 25.170000000001135\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.07750000000000004\n",
      "\n",
      "Epoch 3, Best Score: 25.170000000001135\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 1.1200000000000008, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.07, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.4000000000000002, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 1.2500000000000009, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.7300000000000004, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.19000000000000003, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.25000000000000006, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.10999999999999999, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.24000000000000007, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.5978124999999955\n",
      "\n",
      "Epoch 4, Best Score: 25.170000000001135\n",
      "Training Iteration 4 score: 0.37000000000000016, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.09, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.17, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.37000000000000016, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.3300000000000001, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 1.490000000000001, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.09999999999999999, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.17, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.2309375\n",
      "\n",
      "Epoch 5, Best Score: 25.170000000001135\n",
      "Training Iteration 4 score: 1.440000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.9300000000000006, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.6400000000000003, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.8300000000000005, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.6600000000000004, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 3.1099999999999777, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.23000000000000007, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.13999999999999999, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.19000000000000003, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.16, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 21.790000000000607, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 3.2999999999999736, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 3.7799999999999634, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.3900000000000002, epsilon: 0.0078125\n",
      "Average Score: 1.0984375000000042\n",
      "\n",
      "Epoch 6, Best Score: 25.170000000001135\n",
      "Training Iteration 4 score: 0.6100000000000003, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.8400000000000005, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.3000000000000001, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.45000000000000023, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.3200000000000001, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.5620312499999971\n",
      "\n",
      "Epoch 7, Best Score: 25.170000000001135\n",
      "Training Iteration 4 score: 0.09999999999999999, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.11999999999999998, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.8600000000000005, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.12999999999999998, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.6500000000000004, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.34000000000000014, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.2800000000000001, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 1.1100000000000008, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 1.1600000000000008, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.2800000000000001, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.3200000000000001, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.8968750000000233\n",
      "\n",
      "Epoch 8, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.37000000000000016, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.16, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.3100000000000001, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.26000000000000006, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.08828125000000006\n",
      "\n",
      "Epoch 9, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.4000000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.4300000000000002, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 3.1299999999999772, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.2900000000000001, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.20000000000000004, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.4200000000000002, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.3900000000000002, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.5007812499999954\n",
      "\n",
      "Epoch 10, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.37000000000000016, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.11999999999999998, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.2700000000000001, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.4000000000000002, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.4400000000000002, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.11718750000000006\n",
      "\n",
      "Epoch 11, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.47000000000000025, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 2.010000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.7500000000000004, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.4300000000000002, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.4714062500000134\n",
      "\n",
      "Epoch 12, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.16390625000000006\n",
      "\n",
      "Epoch 13, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.08843750000000004\n",
      "\n",
      "Epoch 14, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.3300000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 1.6000000000000012, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.4400000000000002, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.6000000000000003, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.19000000000000003, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 1.5200000000000011, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.19546875000000008\n",
      "\n",
      "Epoch 15, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.2900000000000001, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.5000000000000002, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.34000000000000014, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.3200000000000001, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.3000000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.35000000000000014, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.48000000000000026, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.21031249999999985\n",
      "\n",
      "Epoch 16, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.5100000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.48000000000000026, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.21000000000000005, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.3100000000000001, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.20031249999999998\n",
      "\n",
      "Epoch 17, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.10999999999999999, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 1.5300000000000011, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.2692187499999994\n",
      "\n",
      "Epoch 18, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.24000000000000007, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.19000000000000003, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.16, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.24000000000000007, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.16, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.18000000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.19156249999999994\n",
      "\n",
      "Epoch 19, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.20000000000000004, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.23000000000000007, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.24000000000000007, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.3200000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.15, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.12999999999999998, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.11843750000000004\n",
      "\n",
      "Epoch 20, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.35000000000000014, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.25000000000000006, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.2900000000000001, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.10999999999999999, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.9200000000000006, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.10999999999999999, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.19000000000000003, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.18000000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.2021875000000001\n",
      "\n",
      "Epoch 21, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.26000000000000006, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.24000000000000007, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.09, epsilon: 0.0078125\n",
      "Average Score: 0.14328125000000005\n",
      "\n",
      "Epoch 22, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.22000000000000006, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.09, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.11999999999999998, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.20000000000000004, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.24000000000000007, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 1.1000000000000008, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.13140625000000003\n",
      "\n",
      "Epoch 23, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.7000000000000004, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.19000000000000003, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.17, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.08, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 1.260000000000001, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.09, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.13906250000000003\n",
      "\n",
      "Epoch 24, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.08, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.09999999999999999, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.10999999999999999, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.12999999999999998, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.07, epsilon: 0.0078125\n",
      "Average Score: 0.06125\n",
      "\n",
      "Epoch 25, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.09999999999999999, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.16, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.11343750000000004\n",
      "\n",
      "Epoch 26, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.46000000000000024, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.25000000000000006, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.3100000000000001, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.09, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.18000000000000002, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.11999999999999998, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.09, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.07703125\n",
      "\n",
      "Epoch 27, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.10999999999999999, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.15, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.13999999999999999, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.11999999999999998, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.17, epsilon: 0.0078125\n",
      "Average Score: 0.11953125000000003\n",
      "\n",
      "Epoch 28, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.2800000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.5100000000000002, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.2800000000000001, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.060000000000000005, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 1.0300000000000007, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.12999999999999998, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.17468750000000008\n",
      "\n",
      "Epoch 29, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.10999999999999999, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.16, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.09, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.07, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.8500000000000005, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.15, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.34000000000000014, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.6500000000000004, epsilon: 0.0078125\n",
      "Average Score: 0.14265625000000004\n",
      "\n",
      "Epoch 30, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.37000000000000016, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.3200000000000001, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.060000000000000005, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.16, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.13999999999999999, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.09999999999999999, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.09, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.09, epsilon: 0.0078125\n",
      "Average Score: 0.13968750000000005\n",
      "\n",
      "Epoch 31, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.01, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.25000000000000006, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.34000000000000014, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.08, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.10703125000000004\n",
      "\n",
      "Epoch 32, Best Score: 28.230000000001613\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.16, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.07, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.15, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.09, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.23000000000000007, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.09718750000000002\n",
      "Saved a trained Q-table with size (76032,), After 12.637970316410065 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip950\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip950)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip951\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip950)\" d=\"\n",
       "M156.598 1486.45 L2352.76 1486.45 L2352.76 47.2441 L156.598 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip952\">\n",
       "    <rect x=\"156\" y=\"47\" width=\"2197\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip952)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  486.089,1486.45 486.089,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip952)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  820.258,1486.45 820.258,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip952)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1154.43,1486.45 1154.43,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip952)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1488.6,1486.45 1488.6,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip952)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1822.76,1486.45 1822.76,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip952)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2156.93,1486.45 2156.93,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  486.089,1486.45 486.089,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  820.258,1486.45 820.258,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1154.43,1486.45 1154.43,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1488.6,1486.45 1488.6,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1822.76,1486.45 1822.76,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2156.93,1486.45 2156.93,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip950)\" d=\"M476.367 1514.29 L494.723 1514.29 L494.723 1518.22 L480.649 1518.22 L480.649 1526.7 Q481.667 1526.35 482.686 1526.19 Q483.704 1526 484.723 1526 Q490.51 1526 493.89 1529.17 Q497.269 1532.34 497.269 1537.76 Q497.269 1543.34 493.797 1546.44 Q490.325 1549.52 484.005 1549.52 Q481.829 1549.52 479.561 1549.15 Q477.316 1548.78 474.908 1548.04 L474.908 1543.34 Q476.992 1544.47 479.214 1545.03 Q481.436 1545.58 483.913 1545.58 Q487.917 1545.58 490.255 1543.48 Q492.593 1541.37 492.593 1537.76 Q492.593 1534.15 490.255 1532.04 Q487.917 1529.94 483.913 1529.94 Q482.038 1529.94 480.163 1530.35 Q478.311 1530.77 476.367 1531.65 L476.367 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M794.945 1544.91 L802.584 1544.91 L802.584 1518.55 L794.274 1520.21 L794.274 1515.95 L802.538 1514.29 L807.214 1514.29 L807.214 1544.91 L814.853 1544.91 L814.853 1548.85 L794.945 1548.85 L794.945 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M834.297 1517.37 Q830.686 1517.37 828.857 1520.93 Q827.052 1524.47 827.052 1531.6 Q827.052 1538.71 828.857 1542.27 Q830.686 1545.82 834.297 1545.82 Q837.931 1545.82 839.737 1542.27 Q841.565 1538.71 841.565 1531.6 Q841.565 1524.47 839.737 1520.93 Q837.931 1517.37 834.297 1517.37 M834.297 1513.66 Q840.107 1513.66 843.163 1518.27 Q846.241 1522.85 846.241 1531.6 Q846.241 1540.33 843.163 1544.94 Q840.107 1549.52 834.297 1549.52 Q828.487 1549.52 825.408 1544.94 Q822.352 1540.33 822.352 1531.6 Q822.352 1522.85 825.408 1518.27 Q828.487 1513.66 834.297 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M1129.61 1544.91 L1137.25 1544.91 L1137.25 1518.55 L1128.94 1520.21 L1128.94 1515.95 L1137.2 1514.29 L1141.88 1514.29 L1141.88 1544.91 L1149.52 1544.91 L1149.52 1548.85 L1129.61 1548.85 L1129.61 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M1159.01 1514.29 L1177.37 1514.29 L1177.37 1518.22 L1163.29 1518.22 L1163.29 1526.7 Q1164.31 1526.35 1165.33 1526.19 Q1166.35 1526 1167.37 1526 Q1173.15 1526 1176.53 1529.17 Q1179.91 1532.34 1179.91 1537.76 Q1179.91 1543.34 1176.44 1546.44 Q1172.97 1549.52 1166.65 1549.52 Q1164.47 1549.52 1162.2 1549.15 Q1159.96 1548.78 1157.55 1548.04 L1157.55 1543.34 Q1159.63 1544.47 1161.86 1545.03 Q1164.08 1545.58 1166.56 1545.58 Q1170.56 1545.58 1172.9 1543.48 Q1175.24 1541.37 1175.24 1537.76 Q1175.24 1534.15 1172.9 1532.04 Q1170.56 1529.94 1166.56 1529.94 Q1164.68 1529.94 1162.81 1530.35 Q1160.95 1530.77 1159.01 1531.65 L1159.01 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M1467.37 1544.91 L1483.69 1544.91 L1483.69 1548.85 L1461.74 1548.85 L1461.74 1544.91 Q1464.41 1542.16 1468.99 1537.53 Q1473.6 1532.88 1474.78 1531.53 Q1477.02 1529.01 1477.9 1527.27 Q1478.8 1525.51 1478.8 1523.82 Q1478.8 1521.07 1476.86 1519.33 Q1474.94 1517.6 1471.84 1517.6 Q1469.64 1517.6 1467.18 1518.36 Q1464.75 1519.13 1461.98 1520.68 L1461.98 1515.95 Q1464.8 1514.82 1467.25 1514.24 Q1469.71 1513.66 1471.74 1513.66 Q1477.11 1513.66 1480.31 1516.35 Q1483.5 1519.03 1483.5 1523.52 Q1483.5 1525.65 1482.69 1527.57 Q1481.91 1529.47 1479.8 1532.07 Q1479.22 1532.74 1476.12 1535.95 Q1473.02 1539.15 1467.37 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M1503.5 1517.37 Q1499.89 1517.37 1498.06 1520.93 Q1496.26 1524.47 1496.26 1531.6 Q1496.26 1538.71 1498.06 1542.27 Q1499.89 1545.82 1503.5 1545.82 Q1507.14 1545.82 1508.94 1542.27 Q1510.77 1538.71 1510.77 1531.6 Q1510.77 1524.47 1508.94 1520.93 Q1507.14 1517.37 1503.5 1517.37 M1503.5 1513.66 Q1509.31 1513.66 1512.37 1518.27 Q1515.45 1522.85 1515.45 1531.6 Q1515.45 1540.33 1512.37 1544.94 Q1509.31 1549.52 1503.5 1549.52 Q1497.69 1549.52 1494.61 1544.94 Q1491.56 1540.33 1491.56 1531.6 Q1491.56 1522.85 1494.61 1518.27 Q1497.69 1513.66 1503.5 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M1802.04 1544.91 L1818.35 1544.91 L1818.35 1548.85 L1796.41 1548.85 L1796.41 1544.91 Q1799.07 1542.16 1803.66 1537.53 Q1808.26 1532.88 1809.44 1531.53 Q1811.69 1529.01 1812.57 1527.27 Q1813.47 1525.51 1813.47 1523.82 Q1813.47 1521.07 1811.53 1519.33 Q1809.6 1517.6 1806.5 1517.6 Q1804.3 1517.6 1801.85 1518.36 Q1799.42 1519.13 1796.64 1520.68 L1796.64 1515.95 Q1799.47 1514.82 1801.92 1514.24 Q1804.37 1513.66 1806.41 1513.66 Q1811.78 1513.66 1814.97 1516.35 Q1818.17 1519.03 1818.17 1523.52 Q1818.17 1525.65 1817.36 1527.57 Q1816.57 1529.47 1814.47 1532.07 Q1813.89 1532.74 1810.79 1535.95 Q1807.68 1539.15 1802.04 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M1828.22 1514.29 L1846.57 1514.29 L1846.57 1518.22 L1832.5 1518.22 L1832.5 1526.7 Q1833.52 1526.35 1834.53 1526.19 Q1835.55 1526 1836.57 1526 Q1842.36 1526 1845.74 1529.17 Q1849.12 1532.34 1849.12 1537.76 Q1849.12 1543.34 1845.65 1546.44 Q1842.17 1549.52 1835.85 1549.52 Q1833.68 1549.52 1831.41 1549.15 Q1829.16 1548.78 1826.76 1548.04 L1826.76 1543.34 Q1828.84 1544.47 1831.06 1545.03 Q1833.28 1545.58 1835.76 1545.58 Q1839.77 1545.58 1842.1 1543.48 Q1844.44 1541.37 1844.44 1537.76 Q1844.44 1534.15 1842.1 1532.04 Q1839.77 1529.94 1835.76 1529.94 Q1833.89 1529.94 1832.01 1530.35 Q1830.16 1530.77 1828.22 1531.65 L1828.22 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M2145.78 1530.21 Q2149.13 1530.93 2151.01 1533.2 Q2152.91 1535.47 2152.91 1538.8 Q2152.91 1543.92 2149.39 1546.72 Q2145.87 1549.52 2139.39 1549.52 Q2137.21 1549.52 2134.9 1549.08 Q2132.6 1548.66 2130.15 1547.81 L2130.15 1543.29 Q2132.1 1544.43 2134.41 1545.01 Q2136.72 1545.58 2139.25 1545.58 Q2143.65 1545.58 2145.94 1543.85 Q2148.25 1542.11 2148.25 1538.8 Q2148.25 1535.75 2146.1 1534.03 Q2143.97 1532.3 2140.15 1532.3 L2136.12 1532.3 L2136.12 1528.45 L2140.34 1528.45 Q2143.78 1528.45 2145.61 1527.09 Q2147.44 1525.7 2147.44 1523.11 Q2147.44 1520.45 2145.54 1519.03 Q2143.67 1517.6 2140.15 1517.6 Q2138.23 1517.6 2136.03 1518.01 Q2133.83 1518.43 2131.19 1519.31 L2131.19 1515.14 Q2133.85 1514.4 2136.17 1514.03 Q2138.51 1513.66 2140.57 1513.66 Q2145.89 1513.66 2148.99 1516.09 Q2152.1 1518.5 2152.1 1522.62 Q2152.1 1525.49 2150.45 1527.48 Q2148.81 1529.45 2145.78 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M2171.77 1517.37 Q2168.16 1517.37 2166.33 1520.93 Q2164.53 1524.47 2164.53 1531.6 Q2164.53 1538.71 2166.33 1542.27 Q2168.16 1545.82 2171.77 1545.82 Q2175.41 1545.82 2177.21 1542.27 Q2179.04 1538.71 2179.04 1531.6 Q2179.04 1524.47 2177.21 1520.93 Q2175.41 1517.37 2171.77 1517.37 M2171.77 1513.66 Q2177.58 1513.66 2180.64 1518.27 Q2183.72 1522.85 2183.72 1531.6 Q2183.72 1540.33 2180.64 1544.94 Q2177.58 1549.52 2171.77 1549.52 Q2165.96 1549.52 2162.88 1544.94 Q2159.83 1540.33 2159.83 1531.6 Q2159.83 1522.85 2162.88 1518.27 Q2165.96 1513.66 2171.77 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip952)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,1264.08 2352.76,1264.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip952)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,1002.27 2352.76,1002.27 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip952)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,740.46 2352.76,740.46 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip952)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,478.649 2352.76,478.649 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip952)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,216.837 2352.76,216.837 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1486.45 156.598,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1264.08 175.496,1264.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1002.27 175.496,1002.27 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,740.46 175.496,740.46 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,478.649 175.496,478.649 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,216.837 175.496,216.837 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip950)\" d=\"M65.0198 1249.88 Q61.4087 1249.88 59.58 1253.45 Q57.7745 1256.99 57.7745 1264.12 Q57.7745 1271.22 59.58 1274.79 Q61.4087 1278.33 65.0198 1278.33 Q68.6541 1278.33 70.4596 1274.79 Q72.2883 1271.22 72.2883 1264.12 Q72.2883 1256.99 70.4596 1253.45 Q68.6541 1249.88 65.0198 1249.88 M65.0198 1246.18 Q70.83 1246.18 73.8855 1250.79 Q76.9642 1255.37 76.9642 1264.12 Q76.9642 1272.85 73.8855 1277.45 Q70.83 1282.04 65.0198 1282.04 Q59.2097 1282.04 56.131 1277.45 Q53.0754 1272.85 53.0754 1264.12 Q53.0754 1255.37 56.131 1250.79 Q59.2097 1246.18 65.0198 1246.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M85.1818 1275.48 L90.066 1275.48 L90.066 1281.36 L85.1818 1281.36 L85.1818 1275.48 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M104.279 1277.43 L120.598 1277.43 L120.598 1281.36 L98.6539 1281.36 L98.6539 1277.43 Q101.316 1274.67 105.899 1270.04 Q110.506 1265.39 111.686 1264.05 Q113.932 1261.53 114.811 1259.79 Q115.714 1258.03 115.714 1256.34 Q115.714 1253.59 113.77 1251.85 Q111.848 1250.11 108.746 1250.11 Q106.547 1250.11 104.094 1250.88 Q101.663 1251.64 98.8854 1253.19 L98.8854 1248.47 Q101.709 1247.34 104.163 1246.76 Q106.617 1246.18 108.654 1246.18 Q114.024 1246.18 117.219 1248.86 Q120.413 1251.55 120.413 1256.04 Q120.413 1258.17 119.603 1260.09 Q118.816 1261.99 116.709 1264.58 Q116.131 1265.25 113.029 1268.47 Q109.927 1271.66 104.279 1277.43 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M62.9365 988.071 Q59.3254 988.071 57.4967 991.636 Q55.6912 995.177 55.6912 1002.31 Q55.6912 1009.41 57.4967 1012.98 Q59.3254 1016.52 62.9365 1016.52 Q66.5707 1016.52 68.3763 1012.98 Q70.205 1009.41 70.205 1002.31 Q70.205 995.177 68.3763 991.636 Q66.5707 988.071 62.9365 988.071 M62.9365 984.367 Q68.7467 984.367 71.8022 988.973 Q74.8809 993.557 74.8809 1002.31 Q74.8809 1011.03 71.8022 1015.64 Q68.7467 1020.22 62.9365 1020.22 Q57.1264 1020.22 54.0477 1015.64 Q50.9921 1011.03 50.9921 1002.31 Q50.9921 993.557 54.0477 988.973 Q57.1264 984.367 62.9365 984.367 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M83.0984 1013.67 L87.9827 1013.67 L87.9827 1019.55 L83.0984 1019.55 L83.0984 1013.67 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M111.015 989.066 L99.2095 1007.52 L111.015 1007.52 L111.015 989.066 M109.788 984.992 L115.668 984.992 L115.668 1007.52 L120.598 1007.52 L120.598 1011.4 L115.668 1011.4 L115.668 1019.55 L111.015 1019.55 L111.015 1011.4 L95.4132 1011.4 L95.4132 1006.89 L109.788 984.992 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M63.2606 726.259 Q59.6495 726.259 57.8208 729.824 Q56.0152 733.365 56.0152 740.495 Q56.0152 747.601 57.8208 751.166 Q59.6495 754.708 63.2606 754.708 Q66.8948 754.708 68.7004 751.166 Q70.5291 747.601 70.5291 740.495 Q70.5291 733.365 68.7004 729.824 Q66.8948 726.259 63.2606 726.259 M63.2606 722.555 Q69.0707 722.555 72.1263 727.162 Q75.205 731.745 75.205 740.495 Q75.205 749.222 72.1263 753.828 Q69.0707 758.412 63.2606 758.412 Q57.4504 758.412 54.3717 753.828 Q51.3162 749.222 51.3162 740.495 Q51.3162 731.745 54.3717 727.162 Q57.4504 722.555 63.2606 722.555 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M83.4225 751.861 L88.3067 751.861 L88.3067 757.74 L83.4225 757.74 L83.4225 751.861 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M109.071 738.597 Q105.922 738.597 104.071 740.75 Q102.242 742.902 102.242 746.652 Q102.242 750.379 104.071 752.555 Q105.922 754.708 109.071 754.708 Q112.219 754.708 114.047 752.555 Q115.899 750.379 115.899 746.652 Q115.899 742.902 114.047 740.75 Q112.219 738.597 109.071 738.597 M118.353 723.944 L118.353 728.203 Q116.594 727.37 114.788 726.93 Q113.006 726.49 111.246 726.49 Q106.617 726.49 104.163 729.615 Q101.733 732.74 101.385 739.06 Q102.751 737.046 104.811 735.981 Q106.871 734.893 109.348 734.893 Q114.557 734.893 117.566 738.064 Q120.598 741.213 120.598 746.652 Q120.598 751.976 117.45 755.194 Q114.302 758.412 109.071 758.412 Q103.075 758.412 99.9039 753.828 Q96.7326 749.222 96.7326 740.495 Q96.7326 732.301 100.621 727.44 Q104.51 722.555 111.061 722.555 Q112.82 722.555 114.603 722.902 Q116.408 723.25 118.353 723.944 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M63.5152 464.447 Q59.9041 464.447 58.0754 468.012 Q56.2699 471.554 56.2699 478.683 Q56.2699 485.79 58.0754 489.354 Q59.9041 492.896 63.5152 492.896 Q67.1494 492.896 68.955 489.354 Q70.7837 485.79 70.7837 478.683 Q70.7837 471.554 68.955 468.012 Q67.1494 464.447 63.5152 464.447 M63.5152 460.744 Q69.3254 460.744 72.3809 465.35 Q75.4596 469.933 75.4596 478.683 Q75.4596 487.41 72.3809 492.016 Q69.3254 496.6 63.5152 496.6 Q57.7051 496.6 54.6264 492.016 Q51.5708 487.41 51.5708 478.683 Q51.5708 469.933 54.6264 465.35 Q57.7051 460.744 63.5152 460.744 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M83.6771 490.049 L88.5614 490.049 L88.5614 495.929 L83.6771 495.929 L83.6771 490.049 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M108.746 479.517 Q105.413 479.517 103.492 481.299 Q101.594 483.081 101.594 486.206 Q101.594 489.331 103.492 491.114 Q105.413 492.896 108.746 492.896 Q112.08 492.896 114.001 491.114 Q115.922 489.308 115.922 486.206 Q115.922 483.081 114.001 481.299 Q112.103 479.517 108.746 479.517 M104.071 477.526 Q101.061 476.785 99.3715 474.725 Q97.7048 472.665 97.7048 469.702 Q97.7048 465.558 100.645 463.151 Q103.608 460.744 108.746 460.744 Q113.908 460.744 116.848 463.151 Q119.788 465.558 119.788 469.702 Q119.788 472.665 118.098 474.725 Q116.432 476.785 113.445 477.526 Q116.825 478.313 118.7 480.605 Q120.598 482.896 120.598 486.206 Q120.598 491.229 117.52 493.915 Q114.464 496.6 108.746 496.6 Q103.029 496.6 99.9502 493.915 Q96.8947 491.229 96.8947 486.206 Q96.8947 482.896 98.7928 480.605 Q100.691 478.313 104.071 477.526 M102.358 470.142 Q102.358 472.827 104.024 474.331 Q105.714 475.836 108.746 475.836 Q111.756 475.836 113.445 474.331 Q115.158 472.827 115.158 470.142 Q115.158 467.456 113.445 465.952 Q111.756 464.447 108.746 464.447 Q105.714 464.447 104.024 465.952 Q102.358 467.456 102.358 470.142 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M54.2328 230.182 L61.8717 230.182 L61.8717 203.816 L53.5616 205.483 L53.5616 201.223 L61.8254 199.557 L66.5013 199.557 L66.5013 230.182 L74.1402 230.182 L74.1402 234.117 L54.2328 234.117 L54.2328 230.182 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M83.5845 228.237 L88.4688 228.237 L88.4688 234.117 L83.5845 234.117 L83.5845 228.237 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M108.654 202.635 Q105.043 202.635 103.214 206.2 Q101.409 209.742 101.409 216.871 Q101.409 223.978 103.214 227.543 Q105.043 231.084 108.654 231.084 Q112.288 231.084 114.094 227.543 Q115.922 223.978 115.922 216.871 Q115.922 209.742 114.094 206.2 Q112.288 202.635 108.654 202.635 M108.654 198.932 Q114.464 198.932 117.52 203.538 Q120.598 208.122 120.598 216.871 Q120.598 225.598 117.52 230.205 Q114.464 234.788 108.654 234.788 Q102.844 234.788 99.765 230.205 Q96.7095 225.598 96.7095 216.871 Q96.7095 208.122 99.765 203.538 Q102.844 198.932 108.654 198.932 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip952)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  218.754,655.167 285.587,1424.44 352.421,743.324 419.255,1223.58 486.089,87.9763 552.922,790.164 619.756,351.833 686.59,1410.33 753.424,870.343 820.258,1372.49 \n",
       "  887.091,908.797 953.925,1311.33 1020.76,1410.13 1087.59,1270.02 1154.43,1250.58 1221.26,1263.67 1288.09,1173.47 1354.93,1275.13 1421.76,1370.85 1488.6,1261.22 \n",
       "  1555.43,1338.33 1622.26,1353.88 1689.1,1343.85 1755.93,1445.72 1822.76,1377.4 1889.6,1425.06 1956.43,1369.42 2023.27,1297.22 2090.1,1339.15 2156.93,1343.04 \n",
       "  2223.77,1385.79 2290.6,1398.67 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip950)\" d=\"\n",
       "M1983.1 198.898 L2279.55 198.898 L2279.55 95.2176 L1983.1 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1983.1,198.898 2279.55,198.898 2279.55,95.2176 1983.1,95.2176 1983.1,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2007.5,147.058 2153.92,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip950)\" d=\"M2192.16 166.745 Q2190.35 171.375 2188.64 172.787 Q2186.93 174.199 2184.06 174.199 L2180.65 174.199 L2180.65 170.634 L2183.15 170.634 Q2184.91 170.634 2185.89 169.8 Q2186.86 168.967 2188.04 165.865 L2188.8 163.921 L2178.32 138.412 L2182.83 138.412 L2190.93 158.689 L2199.03 138.412 L2203.55 138.412 L2192.16 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M2210.84 160.402 L2218.48 160.402 L2218.48 134.037 L2210.17 135.703 L2210.17 131.444 L2218.43 129.778 L2223.11 129.778 L2223.11 160.402 L2230.75 160.402 L2230.75 164.338 L2210.84 164.338 L2210.84 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/episodes\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        X  = X_0\n",
    "        \n",
    "        ##### Double Q-Learning ###########################################\n",
    "\n",
    "        for k = 1:T\n",
    "\n",
    "            # 1. Choose action\n",
    "            if rand() < epsilon\n",
    "                if rand() < EXPrand \n",
    "                    A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                else\n",
    "                    A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                end\n",
    "            else\n",
    "\n",
    "                A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                if A == 1000.0 # Indicates no values in this region\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "\n",
    "            # 2. Cache last state\n",
    "            qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "            # 3. Generate the next stae\n",
    "            Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "            # 4. Collect reward R( s, a, s' )\n",
    "            R_t = cartpole_reward( Xp )\n",
    "\n",
    "            # 5. Get the optimal action at the next state\n",
    "            a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "            # 6. Compute the value at the next state\n",
    "\n",
    "            V_tp1_opt = query_value_fuzzy( \n",
    "                Q_kdTree, G, V, \n",
    "                get_Q( \n",
    "                    select_X_vector( Xp ), \n",
    "                    a_tp1_opt \n",
    "                ); \n",
    "                k = vNN \n",
    "            )\n",
    "            if isnan( V_tp1_opt )\n",
    "                V_tp1_opt = 0.0\n",
    "            end\n",
    "\n",
    "\n",
    "            # 7. Blend the value back into nearest points\n",
    "\n",
    "            idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "            nNear      = size( idxs, 1 )\n",
    "            for i = 1:nNear\n",
    "                j    = idxs[i]\n",
    "                if !isnan( wgts[i] ) \n",
    "\n",
    "                    # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                    VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "                    \n",
    "                end\n",
    "            end\n",
    "\n",
    "            states[:,k] = Xp\n",
    "            actions[k]  = A\n",
    "\n",
    "            X = Xp\n",
    "        end\n",
    "\n",
    "        s_l    = vertical_score_s( states, aMargin, ts )\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        if useElig\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709555b9-2598-4281-a634-c7b0681277d0",
   "metadata": {},
   "source": [
    "# Method 2 Performance, Average Vertical Duration [s]\n",
    "Each score is the best average score of the last two epochs: 64 epochs of 64 episodes each, Q-function swap after every episode \n",
    "\n",
    "### TD Tuning\n",
    "\n",
    "$\\alpha = 0.99$:  \n",
    "$\\alpha = 0.75$:   \n",
    "$\\alpha = 0.50$:    \n",
    "$\\alpha = 0.25$:  \n",
    "$\\alpha = 0.125$:   \n",
    "$\\alpha = 0.0625$: \n",
    "$\\alpha = 0.03125$:   \n",
    "$\\alpha = 0.02344$:  \n",
    "$\\alpha = 0.01953$:   \n",
    "$\\alpha = 0.015625$:   \n",
    " \n",
    "### Add gamma?\n",
    " \n",
    "### Double-Q Tuning, Swap Evey N Episodes\n",
    "$\\%\\ \\ 2$:  \n",
    "$\\%\\ \\ 4$:  \n",
    "$\\%\\ \\ 8$:  \n",
    "$\\%16$:  \n",
    "$\\%32$:  \n",
    "$\\%64$:  \n",
    "\n",
    "\n",
    "\n",
    "### Blend: Best Episode\n",
    "\n",
    "$\\beta = 0.07$:  \n",
    "$\\beta = 0.15$: 0.244\n",
    "\n",
    "| Method      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n",
    "| ----------- | ------- | ------- | ------- | ------- | ------- | ---- |\n",
    "| Blend (Epi) |         |         |         |         |         |      |\n",
    "| Blend (Epo) |         |         |         |         |         |      |\n",
    "| TD          |         |         |         |         |         |      |\n",
    "| TD  + ????? |         |         |         |         |         |      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
