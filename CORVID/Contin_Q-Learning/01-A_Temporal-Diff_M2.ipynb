{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.03125 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 \n",
    "gamma    = 1.00 \n",
    "swapDiv  = 1\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes =  64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   =  32 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "beta   = 0.15\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = false\n",
    "N_peaks =  40\n",
    "N_steps = 200\n",
    "lambda  =   0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.12999999999999998, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.38000000000000017, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.053437500000000006\n",
      "\n",
      "Epoch 2, Best Score: 0.5100000000000002\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.09500000000000004\n",
      "\n",
      "Epoch 3, Best Score: 0.8600000000000005\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.05109375000000002\n",
      "\n",
      "Epoch 4, Best Score: 0.8600000000000005\n",
      "Training Iteration 4 score: 0.16, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.11999999999999998, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.9400000000000006, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.15, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 1.6700000000000013, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.34000000000000014, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.35000000000000014, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.13999999999999999, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.1453125000000001\n",
      "\n",
      "Epoch 5, Best Score: 1.6700000000000013\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.45000000000000023, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.2803124999999996\n",
      "\n",
      "Epoch 6, Best Score: 3.749999999999964\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 1.340000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.2900000000000001, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 1.0200000000000007, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 2.7799999999999847, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 1.9300000000000015, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.9200000000000006, epsilon: 0.0078125\n",
      "Average Score: 0.3424999999999998\n",
      "\n",
      "Epoch 7, Best Score: 3.749999999999964\n",
      "Training Iteration 4 score: 1.270000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.37000000000000016, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.5700000000000003, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.48000000000000026, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.5800000000000003, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.23000000000000007, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.20687499999999986\n",
      "\n",
      "Epoch 8, Best Score: 3.749999999999964\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 1.0931250000000672\n",
      "\n",
      "Epoch 9, Best Score: 32.11000000000218\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.5700000000000003, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 1.330000000000001, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.10171874999999983\n",
      "\n",
      "Epoch 10, Best Score: 32.11000000000218\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.05, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.6300000000000003, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.05, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.11015624999999994\n",
      "\n",
      "Epoch 11, Best Score: 32.11000000000218\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.38328124999999397\n",
      "\n",
      "Epoch 12, Best Score: 32.11000000000218\n",
      "Training Iteration 4 score: 0.4400000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.3200000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.4100000000000002, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.4200000000000002, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.46000000000000024, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.19000000000000003, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.3100000000000001, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.3200000000000001, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.1675000000000001\n",
      "\n",
      "Epoch 13, Best Score: 32.11000000000218\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.3200000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.46000000000000024, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.3000000000000001, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.5600000000000003, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.09281250000000005\n",
      "\n",
      "Epoch 14, Best Score: 32.11000000000218\n",
      "Training Iteration 4 score: 0.34000000000000014, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.7000000000000004, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.19000000000000003, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 4.869999999999941, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.6400000000000003, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 1.0200000000000007, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 1.8200000000000014, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 1.0800000000000007, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.7400000000000004, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 1.290000000000001, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.15, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.36000000000000015, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.7500000000000004, epsilon: 0.0078125\n",
      "Average Score: 0.5962499999999987\n",
      "\n",
      "Epoch 15, Best Score: 32.11000000000218\n",
      "Training Iteration 4 score: 0.8000000000000005, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 1.5400000000000011, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.5000000000000002, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.6500000000000004, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.12953125000000007\n",
      "\n",
      "Epoch 16, Best Score: 32.11000000000218\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.025468750000000012\n",
      "\n",
      "Epoch 17, Best Score: 32.11000000000218\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.5400000000000003, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.5400000000000003, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.22000000000000006, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 1.0100000000000007, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.6600000000000004, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.11999999999999998, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 1.6300000000000012, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.17031249999999962\n",
      "\n",
      "Epoch 18, Best Score: 32.11000000000218\n",
      "Training Iteration 4 score: 0.9400000000000006, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.3900000000000002, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.8100000000000005, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.10999999999999999, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 1.0100000000000007, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 5.9999999999999165, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.21000000000000005, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.21000000000000005, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.5300000000000002, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.8700000000000006, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.6400000000000003, epsilon: 0.0078125\n",
      "Average Score: 0.32796874999999875\n",
      "\n",
      "Epoch 19, Best Score: 32.11000000000218\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 10.579999999999819, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.48000000000000026, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.23000000000000007, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.25000000000000006, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.3100000000000001, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.20000000000000004, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.5700000000000003, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.3900000000000002, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.7000000000000004, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.8600000000000005, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.46000000000000024, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.21000000000000005, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.7900000000000005, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.8300000000000005, epsilon: 0.0078125\n",
      "Average Score: 0.40406249999999727\n",
      "\n",
      "Epoch 20, Best Score: 32.11000000000218\n",
      "Training Iteration 4 score: 0.9400000000000006, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.9000000000000006, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.6400000000000003, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 3.989999999999959, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.11999999999999998, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 1.9400000000000015, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.8400000000000005, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.7300000000000004, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 7.289999999999889, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 4.979999999999938, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.20000000000000004, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 1.6200000000000012, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 1.0200000000000007, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.24000000000000007, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.23000000000000007, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 1.0200000000000007, epsilon: 0.0078125\n",
      "Average Score: 0.6042187499999964\n",
      "\n",
      "Epoch 21, Best Score: 32.11000000000218\n",
      "Training Iteration 4 score: 0.26000000000000006, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.11999999999999998, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.48000000000000026, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.05, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.23000000000000007, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.9100000000000006, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.7700000000000005, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.7100000000000004, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.12999999999999998, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.7600000000000005, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.10999999999999999, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.8900000000000006, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.7800000000000005, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.12999999999999998, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 2.3099999999999947, epsilon: 0.0078125\n",
      "Average Score: 0.22140625000000005\n",
      "\n",
      "Epoch 22, Best Score: 32.11000000000218\n",
      "Training Iteration 4 score: 0.21000000000000005, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.25000000000000006, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.10999999999999999, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.2800000000000001, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.49000000000000027, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 1.290000000000001, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.09, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.6300000000000003, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.5800000000000003, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.13625000000000007\n",
      "\n",
      "Epoch 23, Best Score: 32.11000000000218\n",
      "Training Iteration 4 score: 1.0100000000000007, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.3301562499999978\n",
      "\n",
      "Epoch 24, Best Score: 32.11000000000218\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.10515625000000005\n",
      "\n",
      "Epoch 25, Best Score: 32.11000000000218\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.07218750000000003\n",
      "\n",
      "Epoch 26, Best Score: 32.11000000000218\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.3300000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.09999999999999999, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.061562500000000034\n",
      "\n",
      "Epoch 27, Best Score: 32.11000000000218\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.03671875000000002\n",
      "\n",
      "Epoch 28, Best Score: 32.11000000000218\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 29, Best Score: 32.11000000000218\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.9000000000000006, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.014062500000000009\n",
      "\n",
      "Epoch 30, Best Score: 32.11000000000218\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 31, Best Score: 32.11000000000218\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 32, Best Score: 32.11000000000218\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0\n",
      "Saved a trained Q-table with size (76032,), After 12.491862432161968 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip060\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip060)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip061\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip060)\" d=\"\n",
       "M186.274 1486.45 L2352.76 1486.45 L2352.76 47.2441 L186.274 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip062\">\n",
       "    <rect x=\"186\" y=\"47\" width=\"2167\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  511.312,1486.45 511.312,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  840.966,1486.45 840.966,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1170.62,1486.45 1170.62,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1500.27,1486.45 1500.27,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1829.93,1486.45 1829.93,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2159.58,1486.45 2159.58,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  511.312,1486.45 511.312,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  840.966,1486.45 840.966,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1170.62,1486.45 1170.62,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1500.27,1486.45 1500.27,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1829.93,1486.45 1829.93,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2159.58,1486.45 2159.58,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip060)\" d=\"M501.59 1514.29 L519.946 1514.29 L519.946 1518.22 L505.872 1518.22 L505.872 1526.7 Q506.891 1526.35 507.909 1526.19 Q508.928 1526 509.946 1526 Q515.733 1526 519.113 1529.17 Q522.493 1532.34 522.493 1537.76 Q522.493 1543.34 519.021 1546.44 Q515.548 1549.52 509.229 1549.52 Q507.053 1549.52 504.784 1549.15 Q502.539 1548.78 500.132 1548.04 L500.132 1543.34 Q502.215 1544.47 504.437 1545.03 Q506.659 1545.58 509.136 1545.58 Q513.141 1545.58 515.479 1543.48 Q517.817 1541.37 517.817 1537.76 Q517.817 1534.15 515.479 1532.04 Q513.141 1529.94 509.136 1529.94 Q507.261 1529.94 505.386 1530.35 Q503.534 1530.77 501.59 1531.65 L501.59 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M815.653 1544.91 L823.292 1544.91 L823.292 1518.55 L814.982 1520.21 L814.982 1515.95 L823.246 1514.29 L827.922 1514.29 L827.922 1544.91 L835.561 1544.91 L835.561 1548.85 L815.653 1548.85 L815.653 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M855.005 1517.37 Q851.394 1517.37 849.565 1520.93 Q847.76 1524.47 847.76 1531.6 Q847.76 1538.71 849.565 1542.27 Q851.394 1545.82 855.005 1545.82 Q858.639 1545.82 860.445 1542.27 Q862.273 1538.71 862.273 1531.6 Q862.273 1524.47 860.445 1520.93 Q858.639 1517.37 855.005 1517.37 M855.005 1513.66 Q860.815 1513.66 863.871 1518.27 Q866.949 1522.85 866.949 1531.6 Q866.949 1540.33 863.871 1544.94 Q860.815 1549.52 855.005 1549.52 Q849.195 1549.52 846.116 1544.94 Q843.06 1540.33 843.06 1531.6 Q843.06 1522.85 846.116 1518.27 Q849.195 1513.66 855.005 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1145.8 1544.91 L1153.44 1544.91 L1153.44 1518.55 L1145.13 1520.21 L1145.13 1515.95 L1153.4 1514.29 L1158.07 1514.29 L1158.07 1544.91 L1165.71 1544.91 L1165.71 1548.85 L1145.8 1548.85 L1145.8 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1175.2 1514.29 L1193.56 1514.29 L1193.56 1518.22 L1179.48 1518.22 L1179.48 1526.7 Q1180.5 1526.35 1181.52 1526.19 Q1182.54 1526 1183.56 1526 Q1189.35 1526 1192.73 1529.17 Q1196.1 1532.34 1196.1 1537.76 Q1196.1 1543.34 1192.63 1546.44 Q1189.16 1549.52 1182.84 1549.52 Q1180.67 1549.52 1178.4 1549.15 Q1176.15 1548.78 1173.74 1548.04 L1173.74 1543.34 Q1175.83 1544.47 1178.05 1545.03 Q1180.27 1545.58 1182.75 1545.58 Q1186.75 1545.58 1189.09 1543.48 Q1191.43 1541.37 1191.43 1537.76 Q1191.43 1534.15 1189.09 1532.04 Q1186.75 1529.94 1182.75 1529.94 Q1180.87 1529.94 1179 1530.35 Q1177.15 1530.77 1175.2 1531.65 L1175.2 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1479.05 1544.91 L1495.36 1544.91 L1495.36 1548.85 L1473.42 1548.85 L1473.42 1544.91 Q1476.08 1542.16 1480.67 1537.53 Q1485.27 1532.88 1486.45 1531.53 Q1488.7 1529.01 1489.58 1527.27 Q1490.48 1525.51 1490.48 1523.82 Q1490.48 1521.07 1488.54 1519.33 Q1486.61 1517.6 1483.51 1517.6 Q1481.31 1517.6 1478.86 1518.36 Q1476.43 1519.13 1473.65 1520.68 L1473.65 1515.95 Q1476.48 1514.82 1478.93 1514.24 Q1481.38 1513.66 1483.42 1513.66 Q1488.79 1513.66 1491.99 1516.35 Q1495.18 1519.03 1495.18 1523.52 Q1495.18 1525.65 1494.37 1527.57 Q1493.58 1529.47 1491.48 1532.07 Q1490.9 1532.74 1487.8 1535.95 Q1484.69 1539.15 1479.05 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1515.18 1517.37 Q1511.57 1517.37 1509.74 1520.93 Q1507.93 1524.47 1507.93 1531.6 Q1507.93 1538.71 1509.74 1542.27 Q1511.57 1545.82 1515.18 1545.82 Q1518.81 1545.82 1520.62 1542.27 Q1522.45 1538.71 1522.45 1531.6 Q1522.45 1524.47 1520.62 1520.93 Q1518.81 1517.37 1515.18 1517.37 M1515.18 1513.66 Q1520.99 1513.66 1524.05 1518.27 Q1527.12 1522.85 1527.12 1531.6 Q1527.12 1540.33 1524.05 1544.94 Q1520.99 1549.52 1515.18 1549.52 Q1509.37 1549.52 1506.29 1544.94 Q1503.24 1540.33 1503.24 1531.6 Q1503.24 1522.85 1506.29 1518.27 Q1509.37 1513.66 1515.18 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1809.2 1544.91 L1825.52 1544.91 L1825.52 1548.85 L1803.57 1548.85 L1803.57 1544.91 Q1806.23 1542.16 1810.82 1537.53 Q1815.42 1532.88 1816.6 1531.53 Q1818.85 1529.01 1819.73 1527.27 Q1820.63 1525.51 1820.63 1523.82 Q1820.63 1521.07 1818.69 1519.33 Q1816.77 1517.6 1813.66 1517.6 Q1811.47 1517.6 1809.01 1518.36 Q1806.58 1519.13 1803.8 1520.68 L1803.8 1515.95 Q1806.63 1514.82 1809.08 1514.24 Q1811.53 1513.66 1813.57 1513.66 Q1818.94 1513.66 1822.14 1516.35 Q1825.33 1519.03 1825.33 1523.52 Q1825.33 1525.65 1824.52 1527.57 Q1823.73 1529.47 1821.63 1532.07 Q1821.05 1532.74 1817.95 1535.95 Q1814.84 1539.15 1809.2 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1835.38 1514.29 L1853.73 1514.29 L1853.73 1518.22 L1839.66 1518.22 L1839.66 1526.7 Q1840.68 1526.35 1841.7 1526.19 Q1842.71 1526 1843.73 1526 Q1849.52 1526 1852.9 1529.17 Q1856.28 1532.34 1856.28 1537.76 Q1856.28 1543.34 1852.81 1546.44 Q1849.34 1549.52 1843.02 1549.52 Q1840.84 1549.52 1838.57 1549.15 Q1836.33 1548.78 1833.92 1548.04 L1833.92 1543.34 Q1836 1544.47 1838.22 1545.03 Q1840.45 1545.58 1842.92 1545.58 Q1846.93 1545.58 1849.27 1543.48 Q1851.6 1541.37 1851.6 1537.76 Q1851.6 1534.15 1849.27 1532.04 Q1846.93 1529.94 1842.92 1529.94 Q1841.05 1529.94 1839.17 1530.35 Q1837.32 1530.77 1835.38 1531.65 L1835.38 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M2148.42 1530.21 Q2151.78 1530.93 2153.65 1533.2 Q2155.55 1535.47 2155.55 1538.8 Q2155.55 1543.92 2152.03 1546.72 Q2148.51 1549.52 2142.03 1549.52 Q2139.86 1549.52 2137.54 1549.08 Q2135.25 1548.66 2132.8 1547.81 L2132.8 1543.29 Q2134.74 1544.43 2137.06 1545.01 Q2139.37 1545.58 2141.89 1545.58 Q2146.29 1545.58 2148.58 1543.85 Q2150.9 1542.11 2150.9 1538.8 Q2150.9 1535.75 2148.75 1534.03 Q2146.62 1532.3 2142.8 1532.3 L2138.77 1532.3 L2138.77 1528.45 L2142.98 1528.45 Q2146.43 1528.45 2148.26 1527.09 Q2150.09 1525.7 2150.09 1523.11 Q2150.09 1520.45 2148.19 1519.03 Q2146.32 1517.6 2142.8 1517.6 Q2140.88 1517.6 2138.68 1518.01 Q2136.48 1518.43 2133.84 1519.31 L2133.84 1515.14 Q2136.5 1514.4 2138.82 1514.03 Q2141.15 1513.66 2143.21 1513.66 Q2148.54 1513.66 2151.64 1516.09 Q2154.74 1518.5 2154.74 1522.62 Q2154.74 1525.49 2153.1 1527.48 Q2151.45 1529.45 2148.42 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M2174.42 1517.37 Q2170.81 1517.37 2168.98 1520.93 Q2167.17 1524.47 2167.17 1531.6 Q2167.17 1538.71 2168.98 1542.27 Q2170.81 1545.82 2174.42 1545.82 Q2178.05 1545.82 2179.86 1542.27 Q2181.69 1538.71 2181.69 1531.6 Q2181.69 1524.47 2179.86 1520.93 Q2178.05 1517.37 2174.42 1517.37 M2174.42 1513.66 Q2180.23 1513.66 2183.28 1518.27 Q2186.36 1522.85 2186.36 1531.6 Q2186.36 1540.33 2183.28 1544.94 Q2180.23 1549.52 2174.42 1549.52 Q2168.61 1549.52 2165.53 1544.94 Q2162.47 1540.33 2162.47 1531.6 Q2162.47 1522.85 2165.53 1518.27 Q2168.61 1513.66 2174.42 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,1445.72 2352.76,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,1135.2 2352.76,1135.2 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,824.68 2352.76,824.68 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,514.162 2352.76,514.162 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,203.644 2352.76,203.644 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,1486.45 186.274,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,1445.72 205.172,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,1135.2 205.172,1135.2 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,824.68 205.172,824.68 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,514.162 205.172,514.162 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,203.644 205.172,203.644 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip060)\" d=\"M62.9365 1431.51 Q59.3254 1431.51 57.4967 1435.08 Q55.6912 1438.62 55.6912 1445.75 Q55.6912 1452.86 57.4967 1456.42 Q59.3254 1459.96 62.9365 1459.96 Q66.5707 1459.96 68.3763 1456.42 Q70.205 1452.86 70.205 1445.75 Q70.205 1438.62 68.3763 1435.08 Q66.5707 1431.51 62.9365 1431.51 M62.9365 1427.81 Q68.7467 1427.81 71.8022 1432.42 Q74.8809 1437 74.8809 1445.75 Q74.8809 1454.48 71.8022 1459.08 Q68.7467 1463.67 62.9365 1463.67 Q57.1264 1463.67 54.0477 1459.08 Q50.9921 1454.48 50.9921 1445.75 Q50.9921 1437 54.0477 1432.42 Q57.1264 1427.81 62.9365 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M83.0984 1457.12 L87.9827 1457.12 L87.9827 1463 L83.0984 1463 L83.0984 1457.12 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M108.168 1431.51 Q104.557 1431.51 102.728 1435.08 Q100.922 1438.62 100.922 1445.75 Q100.922 1452.86 102.728 1456.42 Q104.557 1459.96 108.168 1459.96 Q111.802 1459.96 113.608 1456.42 Q115.436 1452.86 115.436 1445.75 Q115.436 1438.62 113.608 1435.08 Q111.802 1431.51 108.168 1431.51 M108.168 1427.81 Q113.978 1427.81 117.033 1432.42 Q120.112 1437 120.112 1445.75 Q120.112 1454.48 117.033 1459.08 Q113.978 1463.67 108.168 1463.67 Q102.358 1463.67 99.2789 1459.08 Q96.2234 1454.48 96.2234 1445.75 Q96.2234 1437 99.2789 1432.42 Q102.358 1427.81 108.168 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M138.33 1431.51 Q134.719 1431.51 132.89 1435.08 Q131.084 1438.62 131.084 1445.75 Q131.084 1452.86 132.89 1456.42 Q134.719 1459.96 138.33 1459.96 Q141.964 1459.96 143.769 1456.42 Q145.598 1452.86 145.598 1445.75 Q145.598 1438.62 143.769 1435.08 Q141.964 1431.51 138.33 1431.51 M138.33 1427.81 Q144.14 1427.81 147.195 1432.42 Q150.274 1437 150.274 1445.75 Q150.274 1454.48 147.195 1459.08 Q144.14 1463.67 138.33 1463.67 Q132.519 1463.67 129.441 1459.08 Q126.385 1454.48 126.385 1445.75 Q126.385 1437 129.441 1432.42 Q132.519 1427.81 138.33 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M63.9319 1121 Q60.3208 1121 58.4921 1124.56 Q56.6865 1128.1 56.6865 1135.23 Q56.6865 1142.34 58.4921 1145.9 Q60.3208 1149.45 63.9319 1149.45 Q67.5661 1149.45 69.3717 1145.9 Q71.2004 1142.34 71.2004 1135.23 Q71.2004 1128.1 69.3717 1124.56 Q67.5661 1121 63.9319 1121 M63.9319 1117.29 Q69.742 1117.29 72.7976 1121.9 Q75.8763 1126.48 75.8763 1135.23 Q75.8763 1143.96 72.7976 1148.57 Q69.742 1153.15 63.9319 1153.15 Q58.1217 1153.15 55.043 1148.57 Q51.9875 1143.96 51.9875 1135.23 Q51.9875 1126.48 55.043 1121.9 Q58.1217 1117.29 63.9319 1117.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M84.0938 1146.6 L88.978 1146.6 L88.978 1152.48 L84.0938 1152.48 L84.0938 1146.6 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M103.191 1148.54 L119.51 1148.54 L119.51 1152.48 L97.566 1152.48 L97.566 1148.54 Q100.228 1145.79 104.811 1141.16 Q109.418 1136.51 110.598 1135.16 Q112.844 1132.64 113.723 1130.9 Q114.626 1129.14 114.626 1127.45 Q114.626 1124.7 112.682 1122.96 Q110.76 1121.23 107.658 1121.23 Q105.459 1121.23 103.006 1121.99 Q100.575 1122.76 97.7974 1124.31 L97.7974 1119.58 Q100.621 1118.45 103.075 1117.87 Q105.529 1117.29 107.566 1117.29 Q112.936 1117.29 116.131 1119.98 Q119.325 1122.66 119.325 1127.15 Q119.325 1129.28 118.515 1131.2 Q117.728 1133.1 115.621 1135.7 Q115.043 1136.37 111.941 1139.58 Q108.839 1142.78 103.191 1148.54 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M129.371 1117.92 L147.728 1117.92 L147.728 1121.85 L133.654 1121.85 L133.654 1130.33 Q134.672 1129.98 135.691 1129.82 Q136.709 1129.63 137.728 1129.63 Q143.515 1129.63 146.894 1132.8 Q150.274 1135.97 150.274 1141.39 Q150.274 1146.97 146.802 1150.07 Q143.33 1153.15 137.01 1153.15 Q134.834 1153.15 132.566 1152.78 Q130.32 1152.41 127.913 1151.67 L127.913 1146.97 Q129.996 1148.1 132.219 1148.66 Q134.441 1149.21 136.918 1149.21 Q140.922 1149.21 143.26 1147.11 Q145.598 1145 145.598 1141.39 Q145.598 1137.78 143.26 1135.67 Q140.922 1133.57 136.918 1133.57 Q135.043 1133.57 133.168 1133.98 Q131.316 1134.4 129.371 1135.28 L129.371 1117.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M62.9365 810.479 Q59.3254 810.479 57.4967 814.043 Q55.6912 817.585 55.6912 824.715 Q55.6912 831.821 57.4967 835.386 Q59.3254 838.928 62.9365 838.928 Q66.5707 838.928 68.3763 835.386 Q70.205 831.821 70.205 824.715 Q70.205 817.585 68.3763 814.043 Q66.5707 810.479 62.9365 810.479 M62.9365 806.775 Q68.7467 806.775 71.8022 811.381 Q74.8809 815.965 74.8809 824.715 Q74.8809 833.441 71.8022 838.048 Q68.7467 842.631 62.9365 842.631 Q57.1264 842.631 54.0477 838.048 Q50.9921 833.441 50.9921 824.715 Q50.9921 815.965 54.0477 811.381 Q57.1264 806.775 62.9365 806.775 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M83.0984 836.08 L87.9827 836.08 L87.9827 841.96 L83.0984 841.96 L83.0984 836.08 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M98.2141 807.4 L116.57 807.4 L116.57 811.335 L102.496 811.335 L102.496 819.807 Q103.515 819.46 104.534 819.298 Q105.552 819.113 106.571 819.113 Q112.358 819.113 115.737 822.284 Q119.117 825.455 119.117 830.872 Q119.117 836.451 115.645 839.553 Q112.172 842.631 105.853 842.631 Q103.677 842.631 101.409 842.261 Q99.1632 841.89 96.7558 841.15 L96.7558 836.451 Q98.8391 837.585 101.061 838.141 Q103.284 838.696 105.76 838.696 Q109.765 838.696 112.103 836.59 Q114.441 834.483 114.441 830.872 Q114.441 827.261 112.103 825.154 Q109.765 823.048 105.76 823.048 Q103.885 823.048 102.01 823.465 Q100.159 823.881 98.2141 824.761 L98.2141 807.4 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M138.33 810.479 Q134.719 810.479 132.89 814.043 Q131.084 817.585 131.084 824.715 Q131.084 831.821 132.89 835.386 Q134.719 838.928 138.33 838.928 Q141.964 838.928 143.769 835.386 Q145.598 831.821 145.598 824.715 Q145.598 817.585 143.769 814.043 Q141.964 810.479 138.33 810.479 M138.33 806.775 Q144.14 806.775 147.195 811.381 Q150.274 815.965 150.274 824.715 Q150.274 833.441 147.195 838.048 Q144.14 842.631 138.33 842.631 Q132.519 842.631 129.441 838.048 Q126.385 833.441 126.385 824.715 Q126.385 815.965 129.441 811.381 Q132.519 806.775 138.33 806.775 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M63.9319 499.961 Q60.3208 499.961 58.4921 503.526 Q56.6865 507.067 56.6865 514.197 Q56.6865 521.303 58.4921 524.868 Q60.3208 528.41 63.9319 528.41 Q67.5661 528.41 69.3717 524.868 Q71.2004 521.303 71.2004 514.197 Q71.2004 507.067 69.3717 503.526 Q67.5661 499.961 63.9319 499.961 M63.9319 496.257 Q69.742 496.257 72.7976 500.864 Q75.8763 505.447 75.8763 514.197 Q75.8763 522.924 72.7976 527.53 Q69.742 532.113 63.9319 532.113 Q58.1217 532.113 55.043 527.53 Q51.9875 522.924 51.9875 514.197 Q51.9875 505.447 55.043 500.864 Q58.1217 496.257 63.9319 496.257 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M84.0938 525.562 L88.978 525.562 L88.978 531.442 L84.0938 531.442 L84.0938 525.562 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M97.9826 496.882 L120.205 496.882 L120.205 498.873 L107.658 531.442 L102.774 531.442 L114.58 500.817 L97.9826 500.817 L97.9826 496.882 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M129.371 496.882 L147.728 496.882 L147.728 500.817 L133.654 500.817 L133.654 509.289 Q134.672 508.942 135.691 508.78 Q136.709 508.595 137.728 508.595 Q143.515 508.595 146.894 511.766 Q150.274 514.938 150.274 520.354 Q150.274 525.933 146.802 529.035 Q143.33 532.113 137.01 532.113 Q134.834 532.113 132.566 531.743 Q130.32 531.373 127.913 530.632 L127.913 525.933 Q129.996 527.067 132.219 527.623 Q134.441 528.178 136.918 528.178 Q140.922 528.178 143.26 526.072 Q145.598 523.965 145.598 520.354 Q145.598 516.743 143.26 514.637 Q140.922 512.53 136.918 512.53 Q135.043 512.53 133.168 512.947 Q131.316 513.363 129.371 514.243 L129.371 496.882 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M53.7467 216.989 L61.3856 216.989 L61.3856 190.623 L53.0754 192.29 L53.0754 188.031 L61.3393 186.364 L66.0152 186.364 L66.0152 216.989 L73.654 216.989 L73.654 220.924 L53.7467 220.924 L53.7467 216.989 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M83.0984 215.045 L87.9827 215.045 L87.9827 220.924 L83.0984 220.924 L83.0984 215.045 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M108.168 189.443 Q104.557 189.443 102.728 193.008 Q100.922 196.549 100.922 203.679 Q100.922 210.785 102.728 214.35 Q104.557 217.892 108.168 217.892 Q111.802 217.892 113.608 214.35 Q115.436 210.785 115.436 203.679 Q115.436 196.549 113.608 193.008 Q111.802 189.443 108.168 189.443 M108.168 185.739 Q113.978 185.739 117.033 190.346 Q120.112 194.929 120.112 203.679 Q120.112 212.406 117.033 217.012 Q113.978 221.595 108.168 221.595 Q102.358 221.595 99.2789 217.012 Q96.2234 212.406 96.2234 203.679 Q96.2234 194.929 99.2789 190.346 Q102.358 185.739 108.168 185.739 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M138.33 189.443 Q134.719 189.443 132.89 193.008 Q131.084 196.549 131.084 203.679 Q131.084 210.785 132.89 214.35 Q134.719 217.892 138.33 217.892 Q141.964 217.892 143.769 214.35 Q145.598 210.785 145.598 203.679 Q145.598 196.549 143.769 193.008 Q141.964 189.443 138.33 189.443 M138.33 185.739 Q144.14 185.739 147.195 190.346 Q150.274 194.929 150.274 203.679 Q150.274 212.406 147.195 217.012 Q144.14 221.595 138.33 221.595 Q132.519 221.595 129.441 217.012 Q126.385 212.406 126.385 203.679 Q126.385 194.929 129.441 190.346 Q132.519 185.739 138.33 185.739 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip062)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  247.59,1379.34 313.52,1327.72 379.451,1382.25 445.382,1265.23 511.312,1097.55 577.243,1020.31 643.174,1188.76 709.104,87.9763 775.035,1319.37 840.966,1308.89 \n",
       "  906.896,969.653 972.827,1237.67 1038.76,1330.44 1104.69,705.131 1170.62,1284.83 1236.55,1414.08 1302.48,1234.18 1368.41,1038.36 1434.34,943.841 1500.27,695.233 \n",
       "  1566.2,1170.71 1632.13,1276.48 1698.06,1035.64 1763.99,1315.1 1829.93,1356.05 1895.86,1369.25 1961.79,1400.11 2027.72,1445.72 2093.65,1428.25 2159.58,1445.72 \n",
       "  2225.51,1445.72 2291.44,1445.72 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip060)\" d=\"\n",
       "M1987.39 198.898 L2280.54 198.898 L2280.54 95.2176 L1987.39 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1987.39,198.898 2280.54,198.898 2280.54,95.2176 1987.39,95.2176 1987.39,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2011.46,147.058 2155.89,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip060)\" d=\"M2193.81 166.745 Q2192 171.375 2190.29 172.787 Q2188.58 174.199 2185.71 174.199 L2182.3 174.199 L2182.3 170.634 L2184.8 170.634 Q2186.56 170.634 2187.53 169.8 Q2188.51 168.967 2189.69 165.865 L2190.45 163.921 L2179.97 138.412 L2184.48 138.412 L2192.58 158.689 L2200.68 138.412 L2205.2 138.412 L2193.81 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M2212.49 160.402 L2220.13 160.402 L2220.13 134.037 L2211.82 135.703 L2211.82 131.444 L2220.08 129.778 L2224.76 129.778 L2224.76 160.402 L2232.4 160.402 L2232.4 164.338 L2212.49 164.338 L2212.49 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/episodes\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        X  = X_0\n",
    "        \n",
    "        ##### Double Q-Learning ###########################################\n",
    "\n",
    "        for k = 1:T\n",
    "\n",
    "            # 1. Choose action\n",
    "            if rand() < epsilon\n",
    "                if rand() < EXPrand \n",
    "                    A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                else\n",
    "                    A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                end\n",
    "            else\n",
    "\n",
    "                A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                if A == 1000.0 # Indicates no values in this region\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "\n",
    "            # 2. Cache last state\n",
    "            qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "            # 3. Generate the next stae\n",
    "            Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "            # 4. Collect reward R( s, a, s' )\n",
    "            R_t = cartpole_reward( Xp )\n",
    "\n",
    "            # 5. Get the optimal action at the next state\n",
    "            a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "            # 6. Compute the value at the next state\n",
    "\n",
    "            V_tp1_opt = query_value_fuzzy( \n",
    "                Q_kdTree, G, V, \n",
    "                get_Q( \n",
    "                    select_X_vector( Xp ), \n",
    "                    a_tp1_opt \n",
    "                ); \n",
    "                k = vNN \n",
    "            )\n",
    "            if isnan( V_tp1_opt )\n",
    "                V_tp1_opt = 0.0\n",
    "            end\n",
    "\n",
    "\n",
    "            # 7. Blend the value back into nearest points\n",
    "\n",
    "            idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "            nNear      = size( idxs, 1 )\n",
    "            for i = 1:nNear\n",
    "                j    = idxs[i]\n",
    "                if !isnan( wgts[i] ) \n",
    "\n",
    "                    # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                    VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "                    \n",
    "                end\n",
    "            end\n",
    "\n",
    "            states[:,k] = Xp\n",
    "            actions[k]  = A\n",
    "\n",
    "            X = Xp\n",
    "        end\n",
    "\n",
    "        s_l    = vertical_score_s( states, aMargin, ts )\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        if useElig\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709555b9-2598-4281-a634-c7b0681277d0",
   "metadata": {},
   "source": [
    "# Method 2 Performance, Average Vertical Duration [s]\n",
    "Each score is the best average score of the last two epochs: 64 epochs of 64 episodes each, Q-function swap after every episode \n",
    "\n",
    "### TD Tuning\n",
    "\n",
    "$\\alpha = 0.99$:  \n",
    "$\\alpha = 0.75$:   \n",
    "$\\alpha = 0.50$:    \n",
    "$\\alpha = 0.25$:  \n",
    "$\\alpha = 0.125$:   \n",
    "$\\alpha = 0.0625$: \n",
    "$\\alpha = 0.03125$:   \n",
    "$\\alpha = 0.02344$:  \n",
    "$\\alpha = 0.01953$:   \n",
    "$\\alpha = 0.015625$:   \n",
    " \n",
    "### Add gamma?\n",
    " \n",
    "### Double-Q Tuning, Swap Evey N Episodes\n",
    "$\\%\\ \\ 2$:  \n",
    "$\\%\\ \\ 4$:  \n",
    "$\\%\\ \\ 8$:  \n",
    "$\\%16$:  \n",
    "$\\%32$:  \n",
    "$\\%64$:  \n",
    "\n",
    "\n",
    "\n",
    "### Blend: Best Episode\n",
    "\n",
    "$\\beta = 0.07$:  \n",
    "$\\beta = 0.15$: 0.244\n",
    "\n",
    "| Method      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n",
    "| ----------- | ------- | ------- | ------- | ------- | ------- | ---- |\n",
    "| Blend (Epi) |         |         |         |         |         |      |\n",
    "| Blend (Epo) |         |         |         |         |         |      |\n",
    "| TD          |         |         |         |         |         |      |\n",
    "| TD  + ????? |         |         |         |         |         |      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
