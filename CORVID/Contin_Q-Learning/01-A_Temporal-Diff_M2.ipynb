{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.02148 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 # 0.00782 # 0.00391\n",
    "gamma    = 1.00\n",
    "swapDiv  = 64\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes = 64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   = 32 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "beta   = 0.15\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = true\n",
    "N_peaks =  32\n",
    "N_steps =  64\n",
    "lambda  =   0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.4000000000000002, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.25000000000000006, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.22000000000000006, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.4200000000000002, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.38000000000000017, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.4400000000000002, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.8200000000000005, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.15, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.19687500000000008\n",
      "\n",
      "Epoch 2, Best Score: 0.8300000000000005\n",
      "Training Iteration 4 score: 0.5200000000000002, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.5200000000000002, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.3900000000000002, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 2.52999999999999, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 3.279999999999974, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.7600000000000005, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.4100000000000002, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.6500000000000004, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.5812499999999993\n",
      "\n",
      "Epoch 3, Best Score: 3.279999999999974\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 4, Best Score: 3.279999999999974\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.5100000000000002, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.11999999999999998, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.8700000000000006, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 2.679999999999987, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.12999999999999998, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.9800000000000006, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.10999999999999999, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 4.299999999999953, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.11999999999999998, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 6.059999999999915, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.09, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.10999999999999999, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.9293749999999963\n",
      "\n",
      "Epoch 5, Best Score: 6.059999999999915\n",
      "Training Iteration 4 score: 0.2900000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.3100000000000001, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.26000000000000006, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.2800000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.2900000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.26000000000000006, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.5100000000000002, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.25000000000000006, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.24000000000000007, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.2800000000000001, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.26000000000000006, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.24000000000000007, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.26000000000000006, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.23000000000000007, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.23000000000000007, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.22000000000000006, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.23937500000000014\n",
      "\n",
      "Epoch 6, Best Score: 6.059999999999915\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.13749999999999954\n",
      "\n",
      "Epoch 7, Best Score: 6.059999999999915\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 8, Best Score: 6.059999999999915\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.13999999999999999, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.07, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.04, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.5651562500000342\n",
      "\n",
      "Epoch 9, Best Score: 31.93000000000219\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 10, Best Score: 31.93000000000219\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.6000000000000003, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.17, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.3100000000000001, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.12203125000000008\n",
      "\n",
      "Epoch 11, Best Score: 31.93000000000219\n",
      "Training Iteration 4 score: 0.17, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.3100000000000001, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.16, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.12999999999999998, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.11999999999999998, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.16, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.19000000000000003, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.08, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.08, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.12046875000000001\n",
      "\n",
      "Epoch 12, Best Score: 31.93000000000219\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 13, Best Score: 31.93000000000219\n",
      "Training Iteration 4 score: 0.3200000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.2700000000000001, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.20000000000000004, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.34000000000000014, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.20000000000000004, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.2800000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.23000000000000007, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.23000000000000007, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.2800000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.20000000000000004, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.26000000000000006, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.11999999999999998, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.11999999999999998, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.10999999999999999, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.13999999999999999, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.09999999999999999, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.22078125000000004\n",
      "\n",
      "Epoch 14, Best Score: 31.93000000000219\n",
      "Training Iteration 4 score: 1.8300000000000014, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.3000000000000001, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.5300000000000002, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.7800000000000005, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.38000000000000017, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.46000000000000024, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.5000000000000002, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 1.5400000000000011, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.6400000000000012, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.5900000000000003, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.8300000000000005, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 1.5900000000000012, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.6100000000000003, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.5860937500000003\n",
      "\n",
      "Epoch 15, Best Score: 31.93000000000219\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.02359375000000001\n",
      "\n",
      "Epoch 16, Best Score: 31.93000000000219\n",
      "Training Iteration 4 score: 0.17, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.05218749999999992\n",
      "\n",
      "Epoch 17, Best Score: 31.93000000000219\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 18, Best Score: 31.93000000000219\n",
      "Training Iteration 4 score: 1.1500000000000008, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 1.1900000000000008, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.34000000000000014, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.5000000000000002, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.4000000000000002, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.3100000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.9400000000000006, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 1.1300000000000008, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.7100000000000013, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.5900000000000003, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 2.109999999999999, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 1.400000000000001, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 1.440000000000001, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 1.370000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 5.3899999999999295, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 6.149999999999913, epsilon: 8.881784197001252e-16\n",
      "Average Score: 1.7523437499999903\n",
      "\n",
      "Epoch 19, Best Score: 31.93000000000219\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.5000000000000002, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.05515625000000004\n",
      "\n",
      "Epoch 20, Best Score: 31.93000000000219\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.5600000000000003, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.24000000000000007, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.5700000000000003, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.13999999999999999, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.3000000000000001, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.10999999999999999, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.46000000000000024, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.8500000000000005, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.12999999999999998, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.12999999999999998, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.09999999999999999, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.13999999999999999, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.12999999999999998, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.09999999999999999, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.27406250000000015\n",
      "\n",
      "Epoch 21, Best Score: 31.93000000000219\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 22, Best Score: 31.93000000000219\n",
      "Training Iteration 4 score: 0.2900000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.12999999999999998, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 1.1000000000000008, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.48000000000000026, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.12999999999999998, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.12999999999999998, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.13999999999999999, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.5500000000000003, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.15, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.11999999999999998, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.5700000000000003, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.10999999999999999, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.37000000000000016, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.12999999999999998, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.11999999999999998, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.2900000000000001, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.36625000000000024\n",
      "\n",
      "Epoch 23, Best Score: 31.93000000000219\n",
      "Training Iteration 4 score: 2.859999999999983, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 26.210000000001298, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 24.540000000001037, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 11.539999999999798, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 17.960000000000008, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 10.139999999999828, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.6500000000000004, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 21.270000000000525, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 15.70999999999971, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 25.480000000001183, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 15.25999999999972, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 23.550000000000882, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 28.540000000001662, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 25.050000000001116, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 28.690000000001685, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 9.039999999999852, epsilon: 8.881784197001252e-16\n",
      "Average Score: 19.775156250000695\n",
      "\n",
      "Epoch 24, Best Score: 32.05000000000219\n",
      "Training Iteration 4 score: 0.6900000000000004, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.9800000000000006, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.8900000000000006, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 1.0100000000000007, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 2.0300000000000007, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 1.460000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 1.450000000000001, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.6700000000000004, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.9000000000000006, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.5700000000000003, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.5500000000000003, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 1.0300000000000007, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.8300000000000005, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.8300000000000005, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 1.2500000000000009, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.8200000000000005, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.9034375000000001\n",
      "\n",
      "Epoch 25, Best Score: 32.05000000000219\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 26, Best Score: 32.05000000000219\n",
      "Training Iteration 4 score: 10.319999999999824, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.38000000000000017, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.21000000000000005, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 7.479999999999885, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 13.969999999999747, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 19.100000000000186, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 3.519999999999969, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 4.129687500000097\n",
      "\n",
      "Epoch 27, Best Score: 32.05000000000219\n",
      "Training Iteration 4 score: 1.1900000000000008, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.6000000000000003, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.8000000000000005, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 3.649999999999966, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 3.3899999999999717, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 4.609999999999946, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 2.5899999999999888, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 7.269999999999889, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.7400000000000013, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 1.6000000000000012, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 2.8799999999999826, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 2.9899999999999802, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 7.589999999999883, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.9500000000000006, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 2.8799999999999826, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 3.197031250000009\n",
      "\n",
      "Epoch 28, Best Score: 32.05000000000219\n",
      "Training Iteration 4 score: 0.47000000000000025, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.6200000000000003, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.8000000000000005, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 1.450000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.7100000000000004, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.49000000000000027, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 1.1700000000000008, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 1.0200000000000007, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.1600000000000008, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.3900000000000002, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.6500000000000004, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.9100000000000006, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.2800000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.5089062500000002\n",
      "\n",
      "Epoch 29, Best Score: 32.05000000000219\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 30, Best Score: 32.05000000000219\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 31, Best Score: 32.05000000000219\n",
      "Training Iteration 4 score: 0.8400000000000005, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.5100000000000002, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.4200000000000002, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 1.9900000000000015, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.6600000000000004, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 2.4199999999999924, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 1.1400000000000008, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.7400000000000004, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 2.159999999999998, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.9200000000000006, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 1.8500000000000014, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 2.389999999999993, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.3300000000000001, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 1.2300000000000009, epsilon: 8.881784197001252e-16\n",
      "Average Score: 1.203749999999998\n",
      "\n",
      "Epoch 32, Best Score: 32.05000000000219\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "Saved a trained Q-table with size (76032,), After 12.874915198485057 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip670\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip670)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip671\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip670)\" d=\"\n",
       "M140.696 1486.45 L2352.76 1486.45 L2352.76 47.2441 L140.696 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip672\">\n",
       "    <rect x=\"140\" y=\"47\" width=\"2213\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip672)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  472.572,1486.45 472.572,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip672)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  809.161,1486.45 809.161,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip672)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1145.75,1486.45 1145.75,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip672)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1482.34,1486.45 1482.34,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip672)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1818.93,1486.45 1818.93,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip672)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2155.51,1486.45 2155.51,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip670)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip670)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  472.572,1486.45 472.572,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip670)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  809.161,1486.45 809.161,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip670)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1145.75,1486.45 1145.75,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip670)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1482.34,1486.45 1482.34,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip670)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1818.93,1486.45 1818.93,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip670)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2155.51,1486.45 2155.51,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip670)\" d=\"M462.85 1514.29 L481.206 1514.29 L481.206 1518.22 L467.132 1518.22 L467.132 1526.7 Q468.151 1526.35 469.169 1526.19 Q470.188 1526 471.206 1526 Q476.993 1526 480.373 1529.17 Q483.752 1532.34 483.752 1537.76 Q483.752 1543.34 480.28 1546.44 Q476.808 1549.52 470.489 1549.52 Q468.313 1549.52 466.044 1549.15 Q463.799 1548.78 461.391 1548.04 L461.391 1543.34 Q463.475 1544.47 465.697 1545.03 Q467.919 1545.58 470.396 1545.58 Q474.401 1545.58 476.739 1543.48 Q479.077 1541.37 479.077 1537.76 Q479.077 1534.15 476.739 1532.04 Q474.401 1529.94 470.396 1529.94 Q468.521 1529.94 466.646 1530.35 Q464.794 1530.77 462.85 1531.65 L462.85 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip670)\" d=\"M783.848 1544.91 L791.487 1544.91 L791.487 1518.55 L783.177 1520.21 L783.177 1515.95 L791.441 1514.29 L796.117 1514.29 L796.117 1544.91 L803.755 1544.91 L803.755 1548.85 L783.848 1548.85 L783.848 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip670)\" d=\"M823.2 1517.37 Q819.589 1517.37 817.76 1520.93 Q815.954 1524.47 815.954 1531.6 Q815.954 1538.71 817.76 1542.27 Q819.589 1545.82 823.2 1545.82 Q826.834 1545.82 828.64 1542.27 Q830.468 1538.71 830.468 1531.6 Q830.468 1524.47 828.64 1520.93 Q826.834 1517.37 823.2 1517.37 M823.2 1513.66 Q829.01 1513.66 832.065 1518.27 Q835.144 1522.85 835.144 1531.6 Q835.144 1540.33 832.065 1544.94 Q829.01 1549.52 823.2 1549.52 Q817.39 1549.52 814.311 1544.94 Q811.255 1540.33 811.255 1531.6 Q811.255 1522.85 814.311 1518.27 Q817.39 1513.66 823.2 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip670)\" d=\"M1120.93 1544.91 L1128.57 1544.91 L1128.57 1518.55 L1120.26 1520.21 L1120.26 1515.95 L1128.53 1514.29 L1133.2 1514.29 L1133.2 1544.91 L1140.84 1544.91 L1140.84 1548.85 L1120.93 1548.85 L1120.93 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip670)\" d=\"M1150.33 1514.29 L1168.69 1514.29 L1168.69 1518.22 L1154.61 1518.22 L1154.61 1526.7 Q1155.63 1526.35 1156.65 1526.19 Q1157.67 1526 1158.69 1526 Q1164.48 1526 1167.86 1529.17 Q1171.24 1532.34 1171.24 1537.76 Q1171.24 1543.34 1167.76 1546.44 Q1164.29 1549.52 1157.97 1549.52 Q1155.8 1549.52 1153.53 1549.15 Q1151.28 1548.78 1148.87 1548.04 L1148.87 1543.34 Q1150.96 1544.47 1153.18 1545.03 Q1155.4 1545.58 1157.88 1545.58 Q1161.88 1545.58 1164.22 1543.48 Q1166.56 1541.37 1166.56 1537.76 Q1166.56 1534.15 1164.22 1532.04 Q1161.88 1529.94 1157.88 1529.94 Q1156 1529.94 1154.13 1530.35 Q1152.28 1530.77 1150.33 1531.65 L1150.33 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip670)\" d=\"M1461.11 1544.91 L1477.43 1544.91 L1477.43 1548.85 L1455.49 1548.85 L1455.49 1544.91 Q1458.15 1542.16 1462.73 1537.53 Q1467.34 1532.88 1468.52 1531.53 Q1470.76 1529.01 1471.64 1527.27 Q1472.55 1525.51 1472.55 1523.82 Q1472.55 1521.07 1470.6 1519.33 Q1468.68 1517.6 1465.58 1517.6 Q1463.38 1517.6 1460.93 1518.36 Q1458.5 1519.13 1455.72 1520.68 L1455.72 1515.95 Q1458.54 1514.82 1461 1514.24 Q1463.45 1513.66 1465.49 1513.66 Q1470.86 1513.66 1474.05 1516.35 Q1477.25 1519.03 1477.25 1523.52 Q1477.25 1525.65 1476.44 1527.57 Q1475.65 1529.47 1473.54 1532.07 Q1472.96 1532.74 1469.86 1535.95 Q1466.76 1539.15 1461.11 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip670)\" d=\"M1497.25 1517.37 Q1493.63 1517.37 1491.81 1520.93 Q1490 1524.47 1490 1531.6 Q1490 1538.71 1491.81 1542.27 Q1493.63 1545.82 1497.25 1545.82 Q1500.88 1545.82 1502.68 1542.27 Q1504.51 1538.71 1504.51 1531.6 Q1504.51 1524.47 1502.68 1520.93 Q1500.88 1517.37 1497.25 1517.37 M1497.25 1513.66 Q1503.06 1513.66 1506.11 1518.27 Q1509.19 1522.85 1509.19 1531.6 Q1509.19 1540.33 1506.11 1544.94 Q1503.06 1549.52 1497.25 1549.52 Q1491.43 1549.52 1488.36 1544.94 Q1485.3 1540.33 1485.3 1531.6 Q1485.3 1522.85 1488.36 1518.27 Q1491.43 1513.66 1497.25 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip670)\" d=\"M1798.2 1544.91 L1814.52 1544.91 L1814.52 1548.85 L1792.57 1548.85 L1792.57 1544.91 Q1795.23 1542.16 1799.82 1537.53 Q1804.42 1532.88 1805.6 1531.53 Q1807.85 1529.01 1808.73 1527.27 Q1809.63 1525.51 1809.63 1523.82 Q1809.63 1521.07 1807.69 1519.33 Q1805.77 1517.6 1802.66 1517.6 Q1800.47 1517.6 1798.01 1518.36 Q1795.58 1519.13 1792.8 1520.68 L1792.8 1515.95 Q1795.63 1514.82 1798.08 1514.24 Q1800.54 1513.66 1802.57 1513.66 Q1807.94 1513.66 1811.14 1516.35 Q1814.33 1519.03 1814.33 1523.52 Q1814.33 1525.65 1813.52 1527.57 Q1812.73 1529.47 1810.63 1532.07 Q1810.05 1532.74 1806.95 1535.95 Q1803.85 1539.15 1798.2 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip670)\" d=\"M1824.38 1514.29 L1842.73 1514.29 L1842.73 1518.22 L1828.66 1518.22 L1828.66 1526.7 Q1829.68 1526.35 1830.7 1526.19 Q1831.72 1526 1832.73 1526 Q1838.52 1526 1841.9 1529.17 Q1845.28 1532.34 1845.28 1537.76 Q1845.28 1543.34 1841.81 1546.44 Q1838.34 1549.52 1832.02 1549.52 Q1829.84 1549.52 1827.57 1549.15 Q1825.33 1548.78 1822.92 1548.04 L1822.92 1543.34 Q1825 1544.47 1827.22 1545.03 Q1829.45 1545.58 1831.92 1545.58 Q1835.93 1545.58 1838.27 1543.48 Q1840.6 1541.37 1840.6 1537.76 Q1840.6 1534.15 1838.27 1532.04 Q1835.93 1529.94 1831.92 1529.94 Q1830.05 1529.94 1828.17 1530.35 Q1826.32 1530.77 1824.38 1531.65 L1824.38 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip670)\" d=\"M2144.36 1530.21 Q2147.71 1530.93 2149.59 1533.2 Q2151.49 1535.47 2151.49 1538.8 Q2151.49 1543.92 2147.97 1546.72 Q2144.45 1549.52 2137.97 1549.52 Q2135.79 1549.52 2133.48 1549.08 Q2131.19 1548.66 2128.73 1547.81 L2128.73 1543.29 Q2130.68 1544.43 2132.99 1545.01 Q2135.31 1545.58 2137.83 1545.58 Q2142.23 1545.58 2144.52 1543.85 Q2146.83 1542.11 2146.83 1538.8 Q2146.83 1535.75 2144.68 1534.03 Q2142.55 1532.3 2138.73 1532.3 L2134.7 1532.3 L2134.7 1528.45 L2138.92 1528.45 Q2142.37 1528.45 2144.2 1527.09 Q2146.02 1525.7 2146.02 1523.11 Q2146.02 1520.45 2144.13 1519.03 Q2142.25 1517.6 2138.73 1517.6 Q2136.81 1517.6 2134.61 1518.01 Q2132.41 1518.43 2129.77 1519.31 L2129.77 1515.14 Q2132.44 1514.4 2134.75 1514.03 Q2137.09 1513.66 2139.15 1513.66 Q2144.47 1513.66 2147.58 1516.09 Q2150.68 1518.5 2150.68 1522.62 Q2150.68 1525.49 2149.03 1527.48 Q2147.39 1529.45 2144.36 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip670)\" d=\"M2170.35 1517.37 Q2166.74 1517.37 2164.91 1520.93 Q2163.11 1524.47 2163.11 1531.6 Q2163.11 1538.71 2164.91 1542.27 Q2166.74 1545.82 2170.35 1545.82 Q2173.99 1545.82 2175.79 1542.27 Q2177.62 1538.71 2177.62 1531.6 Q2177.62 1524.47 2175.79 1520.93 Q2173.99 1517.37 2170.35 1517.37 M2170.35 1513.66 Q2176.16 1513.66 2179.22 1518.27 Q2182.3 1522.85 2182.3 1531.6 Q2182.3 1540.33 2179.22 1544.94 Q2176.16 1549.52 2170.35 1549.52 Q2164.54 1549.52 2161.46 1544.94 Q2158.41 1540.33 2158.41 1531.6 Q2158.41 1522.85 2161.46 1518.27 Q2164.54 1513.66 2170.35 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip672)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.696,1445.72 2352.76,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip672)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.696,1102.42 2352.76,1102.42 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip672)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.696,759.127 2352.76,759.127 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip672)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.696,415.833 2352.76,415.833 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip672)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.696,72.5388 2352.76,72.5388 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip670)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,1486.45 140.696,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip670)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,1445.72 159.593,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip670)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,1102.42 159.593,1102.42 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip670)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,759.127 159.593,759.127 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip670)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,415.833 159.593,415.833 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip670)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,72.5388 159.593,72.5388 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip670)\" d=\"M92.7512 1431.51 Q89.1401 1431.51 87.3114 1435.08 Q85.5058 1438.62 85.5058 1445.75 Q85.5058 1452.86 87.3114 1456.42 Q89.1401 1459.96 92.7512 1459.96 Q96.3854 1459.96 98.1909 1456.42 Q100.02 1452.86 100.02 1445.75 Q100.02 1438.62 98.1909 1435.08 Q96.3854 1431.51 92.7512 1431.51 M92.7512 1427.81 Q98.5613 1427.81 101.617 1432.42 Q104.696 1437 104.696 1445.75 Q104.696 1454.48 101.617 1459.08 Q98.5613 1463.67 92.7512 1463.67 Q86.941 1463.67 83.8623 1459.08 Q80.8068 1454.48 80.8068 1445.75 Q80.8068 1437 83.8623 1432.42 Q86.941 1427.81 92.7512 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip670)\" d=\"M83.7929 1085.14 L102.149 1085.14 L102.149 1089.08 L88.0753 1089.08 L88.0753 1097.55 Q89.0938 1097.2 90.1123 1097.04 Q91.1308 1096.85 92.1493 1096.85 Q97.9363 1096.85 101.316 1100.03 Q104.696 1103.2 104.696 1108.61 Q104.696 1114.19 101.223 1117.29 Q97.7511 1120.37 91.4317 1120.37 Q89.2558 1120.37 86.9873 1120 Q84.7419 1119.63 82.3346 1118.89 L82.3346 1114.19 Q84.4179 1115.33 86.6401 1115.88 Q88.8623 1116.44 91.3391 1116.44 Q95.3437 1116.44 97.6817 1114.33 Q100.02 1112.22 100.02 1108.61 Q100.02 1105 97.6817 1102.9 Q95.3437 1100.79 91.3391 1100.79 Q89.4641 1100.79 87.5892 1101.21 Q85.7373 1101.62 83.7929 1102.5 L83.7929 1085.14 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip670)\" d=\"M53.3995 772.472 L61.0384 772.472 L61.0384 746.106 L52.7282 747.773 L52.7282 743.514 L60.9921 741.847 L65.668 741.847 L65.668 772.472 L73.3068 772.472 L73.3068 776.407 L53.3995 776.407 L53.3995 772.472 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip670)\" d=\"M92.7512 744.926 Q89.1401 744.926 87.3114 748.491 Q85.5058 752.032 85.5058 759.162 Q85.5058 766.268 87.3114 769.833 Q89.1401 773.375 92.7512 773.375 Q96.3854 773.375 98.1909 769.833 Q100.02 766.268 100.02 759.162 Q100.02 752.032 98.1909 748.491 Q96.3854 744.926 92.7512 744.926 M92.7512 741.222 Q98.5613 741.222 101.617 745.829 Q104.696 750.412 104.696 759.162 Q104.696 767.889 101.617 772.495 Q98.5613 777.079 92.7512 777.079 Q86.941 777.079 83.8623 772.495 Q80.8068 767.889 80.8068 759.162 Q80.8068 750.412 83.8623 745.829 Q86.941 741.222 92.7512 741.222 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip670)\" d=\"M54.3949 429.178 L62.0337 429.178 L62.0337 402.812 L53.7236 404.479 L53.7236 400.22 L61.9874 398.553 L66.6633 398.553 L66.6633 429.178 L74.3022 429.178 L74.3022 433.113 L54.3949 433.113 L54.3949 429.178 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip670)\" d=\"M83.7929 398.553 L102.149 398.553 L102.149 402.488 L88.0753 402.488 L88.0753 410.96 Q89.0938 410.613 90.1123 410.451 Q91.1308 410.266 92.1493 410.266 Q97.9363 410.266 101.316 413.437 Q104.696 416.608 104.696 422.025 Q104.696 427.604 101.223 430.706 Q97.7511 433.784 91.4317 433.784 Q89.2558 433.784 86.9873 433.414 Q84.7419 433.044 82.3346 432.303 L82.3346 427.604 Q84.4179 428.738 86.6401 429.294 Q88.8623 429.849 91.3391 429.849 Q95.3437 429.849 97.6817 427.743 Q100.02 425.636 100.02 422.025 Q100.02 418.414 97.6817 416.308 Q95.3437 414.201 91.3391 414.201 Q89.4641 414.201 87.5892 414.618 Q85.7373 415.034 83.7929 415.914 L83.7929 398.553 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip670)\" d=\"M56.6171 85.8836 L72.9365 85.8836 L72.9365 89.8188 L50.9921 89.8188 L50.9921 85.8836 Q53.6541 83.129 58.2375 78.4994 Q62.8439 73.8466 64.0245 72.504 Q66.2698 69.9809 67.1494 68.2448 Q68.0522 66.4856 68.0522 64.7958 Q68.0522 62.0411 66.1078 60.305 Q64.1865 58.5689 61.0847 58.5689 Q58.8856 58.5689 56.4319 59.3328 Q54.0014 60.0967 51.2236 61.6476 L51.2236 56.9254 Q54.0477 55.7912 56.5014 55.2125 Q58.955 54.6338 60.9921 54.6338 Q66.3624 54.6338 69.5568 57.3189 Q72.7513 60.0041 72.7513 64.4948 Q72.7513 66.6244 71.9411 68.5457 Q71.1541 70.4439 69.0476 73.0364 Q68.4689 73.7077 65.367 76.9253 Q62.2652 80.1197 56.6171 85.8836 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip670)\" d=\"M92.7512 58.3375 Q89.1401 58.3375 87.3114 61.9022 Q85.5058 65.4439 85.5058 72.5735 Q85.5058 79.6799 87.3114 83.2447 Q89.1401 86.7864 92.7512 86.7864 Q96.3854 86.7864 98.1909 83.2447 Q100.02 79.6799 100.02 72.5735 Q100.02 65.4439 98.1909 61.9022 Q96.3854 58.3375 92.7512 58.3375 M92.7512 54.6338 Q98.5613 54.6338 101.617 59.2402 Q104.696 63.8235 104.696 72.5735 Q104.696 81.3003 101.617 85.9067 Q98.5613 90.4901 92.7512 90.4901 Q86.941 90.4901 83.8623 85.9067 Q80.8068 81.3003 80.8068 72.5735 Q80.8068 63.8235 83.8623 59.2402 Q86.941 54.6338 92.7512 54.6338 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip672)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  203.301,1432.2 270.619,1405.81 337.936,1445.72 405.254,1381.91 472.572,1429.28 539.89,1436.28 607.207,1445.72 674.525,1406.91 741.843,1445.72 809.161,1437.34 \n",
       "  876.478,1437.44 943.796,1445.72 1011.11,1430.56 1078.43,1405.48 1145.75,1444.1 1213.07,1442.13 1280.38,1445.72 1347.7,1325.4 1415.02,1441.93 1482.34,1426.9 \n",
       "  1549.66,1445.72 1616.97,1420.57 1684.29,87.9763 1751.61,1383.69 1818.93,1445.72 1886.24,1162.18 1953.56,1226.21 2020.88,1410.77 2088.2,1445.72 2155.51,1445.72 \n",
       "  2222.83,1363.07 2290.15,1445.72 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip670)\" d=\"\n",
       "M1980.81 198.898 L2279.02 198.898 L2279.02 95.2176 L1980.81 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip670)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1980.81,198.898 2279.02,198.898 2279.02,95.2176 1980.81,95.2176 1980.81,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip670)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2005.38,147.058 2152.85,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip670)\" d=\"M2191.28 166.745 Q2189.47 171.375 2187.76 172.787 Q2186.04 174.199 2183.17 174.199 L2179.77 174.199 L2179.77 170.634 L2182.27 170.634 Q2184.03 170.634 2185 169.8 Q2185.98 168.967 2187.16 165.865 L2187.92 163.921 L2177.43 138.412 L2181.95 138.412 L2190.05 158.689 L2198.15 138.412 L2202.66 138.412 L2191.28 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip670)\" d=\"M2209.96 160.402 L2217.6 160.402 L2217.6 134.037 L2209.29 135.703 L2209.29 131.444 L2217.55 129.778 L2222.22 129.778 L2222.22 160.402 L2229.86 160.402 L2229.86 164.338 L2209.96 164.338 L2209.96 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    bestEpSc    = -100.0;\n",
    "    statesBest  = zeros( size( X_0, 1 ), T )\n",
    "    actionsBest = zeros( T );\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/(episodes-1)\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        \n",
    "        s_l = 0.0\n",
    "        # while s_l == 0\n",
    "        \n",
    "            X  = X_0\n",
    "\n",
    "            ##### Double Q-Learning ###########################################\n",
    "\n",
    "            for k = 1:T\n",
    "\n",
    "                # 1. Choose action\n",
    "                if rand() < epsilon\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                else\n",
    "\n",
    "                    A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                    if A == 1000.0 # Indicates no values in this region\n",
    "                        if rand() < EXPrand \n",
    "                            A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                        else\n",
    "                            A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                # 2. Cache last state\n",
    "                qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "                # 3. Generate the next stae\n",
    "                Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "                # 4. Collect reward R( s, a, s' )\n",
    "                R_t = cartpole_reward( Xp )\n",
    "\n",
    "                # 5. Get the optimal action at the next state\n",
    "                a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "                # 6. Compute the value at the next state\n",
    "\n",
    "                V_tp1_opt = query_value_fuzzy( \n",
    "                    Q_kdTree, G, V, \n",
    "                    get_Q( \n",
    "                        select_X_vector( Xp ), \n",
    "                        a_tp1_opt \n",
    "                    ); \n",
    "                    k = vNN \n",
    "                )\n",
    "                if isnan( V_tp1_opt )\n",
    "                    V_tp1_opt = 0.0\n",
    "                end\n",
    "\n",
    "\n",
    "                # 7. Blend the value back into nearest points\n",
    "\n",
    "                idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "                nNear      = size( idxs, 1 )\n",
    "                for i = 1:nNear\n",
    "                    j    = idxs[i]\n",
    "                    if !isnan( wgts[i] ) \n",
    "\n",
    "                        # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                        VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                states[:,k] = Xp\n",
    "                actions[k]  = A\n",
    "\n",
    "                X = Xp\n",
    "            end\n",
    "\n",
    "            s_l    = vertical_score_s( states, aMargin, ts )\n",
    "            \n",
    "        # end\n",
    "            \n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if s_l > bestEpSc\n",
    "            bestEpSc    = s_l\n",
    "            statesBest  = copy( states  )\n",
    "            actionsBest = copy( actions )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        # if useElig && (s_l > s_Totl/(1.0*l)) && (s_l > 0.0) \n",
    "        # if useElig && (s_l > 0.0) \n",
    "        if useElig \n",
    "            \n",
    "            # if s_l == 0.0\n",
    "            #     states  = copy( bestXs )\n",
    "            #     actions = copy( bestAs )\n",
    "            # end\n",
    "            \n",
    "            # println( \"Assign eligibility for a history with score \", s_l )\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
