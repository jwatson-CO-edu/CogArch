{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.02148 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 # 0.00782 # 0.00391\n",
    "gamma    = 1.00\n",
    "swapDiv  = 4\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes = 128 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   =  16 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "beta   = 0.15\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = false\n",
    "N_peaks =  40\n",
    "N_steps = 200\n",
    "lambda  =   0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.26000000000000006, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.4200000000000002, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 1.1900000000000008, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.6100000000000003, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.7000000000000004, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.09, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.5700000000000003, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.3900000000000002, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.6200000000000003, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.13999999999999999, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.13999999999999999, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.11999999999999998, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.11999999999999998, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.13999999999999999, epsilon: 0.00390625\n",
      "Average Score: 0.20179687500000015\n",
      "\n",
      "Epoch 2, Best Score: 2.3799999999999932\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.15, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.12999999999999998, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.13999999999999999, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.18000000000000002, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.18000000000000002, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.23000000000000007, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.5600000000000003, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.20000000000000004, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.22000000000000006, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.07000000000000002\n",
      "\n",
      "Epoch 3, Best Score: 2.3799999999999932\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.4100000000000002, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.3100000000000001, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.10999999999999999, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.7600000000000005, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 25.540000000001193, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.5500000000000003, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 2.4599999999999915, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 4.389999999999951, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.25000000000000006, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 2.239999999999996, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.38000000000000017, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.12999999999999998, epsilon: 0.00390625\n",
      "Average Score: 1.0853906250000238\n",
      "\n",
      "Epoch 4, Best Score: 25.540000000001193\n",
      "Training Iteration 4 score: 1.320000000000001, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.5500000000000003, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.6200000000000003, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.4100000000000002, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.13999999999999999, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 1.5800000000000012, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.19000000000000003, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 25.040000000001115, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.4300000000000002, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.49000000000000027, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.45000000000000023, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.16, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.37000000000000016, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.2900000000000001, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.8100000000000005, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.2900000000000001, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.17, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 1.400000000000001, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.5600000000000003, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.25000000000000006, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.5850781250000076\n",
      "\n",
      "Epoch 5, Best Score: 25.540000000001193\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 1.1400000000000008, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.4000000000000002, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.9400000000000006, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.08, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.34000000000000014, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.15, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 1.1500000000000008, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.3100000000000001, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.9500000000000006, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.3300000000000001, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.13999999999999999, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.25000000000000006, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 1.370000000000001, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.05, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.060000000000000005, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 1.8700000000000014, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.5100000000000002, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.10999999999999999, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.5000000000000002, epsilon: 0.00390625\n",
      "Average Score: 0.35632812499999955\n",
      "\n",
      "Epoch 6, Best Score: 25.540000000001193\n",
      "Training Iteration 4 score: 0.21000000000000005, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.46000000000000024, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.4400000000000002, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.5300000000000002, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.4100000000000002, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.34000000000000014, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.5200000000000002, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.5800000000000003, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.4100000000000002, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.6100000000000003, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.6200000000000003, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.9600000000000006, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.07, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.6000000000000003, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 11.95999999999979, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.2700000000000001, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.45625000000000415\n",
      "\n",
      "Epoch 7, Best Score: 25.540000000001193\n",
      "Training Iteration 4 score: 0.19000000000000003, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 1.490000000000001, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.060000000000000005, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.2800000000000001, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.05, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.18000000000000002, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 25.5900000000012, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.07, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.8700000000000006, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.5592187500000209\n",
      "\n",
      "Epoch 8, Best Score: 35.60000000000149\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 1.2200000000000009, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.3200000000000001, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.09999999999999999, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.08343749999999969\n",
      "\n",
      "Epoch 9, Best Score: 35.60000000000149\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.6200000000000003, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.23000000000000007, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.3200000000000001, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.9400000000000006, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.9400000000000006, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.5500000000000003, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.07, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 6.389999999999908, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.4400000000000002, epsilon: 0.00390625\n",
      "Average Score: 0.42226562499999626\n",
      "\n",
      "Epoch 10, Best Score: 35.60000000000149\n",
      "Training Iteration 4 score: 0.18000000000000002, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.08, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.38000000000000017, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.38000000000000017, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.8400000000000005, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.48000000000000026, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.8100000000000005, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 27.210000000001454, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 3.2499999999999747, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.5000000000000002, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.49000000000000027, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.6700000000000004, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.6300000000000003, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.8600000000000005, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.3300000000000001, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 5.119999999999935, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.2900000000000001, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 3.2599999999999745, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.3100000000000001, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.4000000000000002, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.25000000000000006, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 2.9299999999999815, epsilon: 0.00390625\n",
      "Average Score: 1.6453906250000219\n",
      "\n",
      "Epoch 11, Best Score: 35.60000000000149\n",
      "Training Iteration 4 score: 0.5600000000000003, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 1.9100000000000015, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.6500000000000004, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 1.8200000000000014, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.6300000000000003, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.6100000000000003, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 1.2200000000000009, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 1.1500000000000008, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 1.470000000000001, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.3200000000000001, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.24000000000000007, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.22000000000000006, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.5200000000000002, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.07, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.2900000000000001, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 1.8900000000000015, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.7000000000000004, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.6000000000000003, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.6700000000000004, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.5823437500000062\n",
      "\n",
      "Epoch 12, Best Score: 35.60000000000149\n",
      "Training Iteration 4 score: 0.6700000000000004, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.23000000000000007, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 1.340000000000001, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 1.2000000000000008, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.48000000000000026, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.5700000000000003, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.3000000000000001, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.6500000000000004, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.05, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.1689062500000001\n",
      "\n",
      "Epoch 13, Best Score: 35.60000000000149\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 3.789999999999963, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.3100000000000001, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.9000000000000006, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.6600000000000004, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 1.8000000000000014, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.2700000000000001, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 24.37000000000101, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 3.9699999999999593, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 1.5300000000000011, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.16, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.5800000000000003, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.23000000000000007, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.9858593750000155\n",
      "\n",
      "Epoch 14, Best Score: 35.60000000000149\n",
      "Training Iteration 4 score: 0.6800000000000004, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.2800000000000001, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 1.0700000000000007, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.7100000000000004, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.05804687500000003\n",
      "\n",
      "Epoch 15, Best Score: 35.60000000000149\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.47000000000000025, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.45000000000000023, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.7600000000000005, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.3100000000000001, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.34000000000000014, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.7400000000000004, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.7000000000000004, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.3200000000000001, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.4000000000000002, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.2700000000000001, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.14921875\n",
      "\n",
      "Epoch 16, Best Score: 35.60000000000149\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.6400000000000003, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.5100000000000002, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 2.669999999999987, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.8100000000000005, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.34000000000000014, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.22000000000000006, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.12242187499999994\n",
      "Saved a trained Q-table with size (76032,), After 24.47355668147405 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip060\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip060)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip061\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip060)\" d=\"\n",
       "M156.274 1486.45 L2352.76 1486.45 L2352.76 47.2441 L156.274 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip062\">\n",
       "    <rect x=\"156\" y=\"47\" width=\"2197\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  494.726,1486.45 494.726,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  909.156,1486.45 909.156,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1323.59,1486.45 1323.59,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1738.02,1486.45 1738.02,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2152.45,1486.45 2152.45,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.274,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  494.726,1486.45 494.726,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  909.156,1486.45 909.156,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1323.59,1486.45 1323.59,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1738.02,1486.45 1738.02,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2152.45,1486.45 2152.45,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip060)\" d=\"M498.973 1530.21 Q502.33 1530.93 504.205 1533.2 Q506.103 1535.47 506.103 1538.8 Q506.103 1543.92 502.585 1546.72 Q499.066 1549.52 492.585 1549.52 Q490.409 1549.52 488.094 1549.08 Q485.802 1548.66 483.348 1547.81 L483.348 1543.29 Q485.293 1544.43 487.608 1545.01 Q489.923 1545.58 492.446 1545.58 Q496.844 1545.58 499.135 1543.85 Q501.45 1542.11 501.45 1538.8 Q501.45 1535.75 499.297 1534.03 Q497.168 1532.3 493.348 1532.3 L489.321 1532.3 L489.321 1528.45 L493.534 1528.45 Q496.983 1528.45 498.811 1527.09 Q500.64 1525.7 500.64 1523.11 Q500.64 1520.45 498.742 1519.03 Q496.867 1517.6 493.348 1517.6 Q491.427 1517.6 489.228 1518.01 Q487.029 1518.43 484.39 1519.31 L484.39 1515.14 Q487.052 1514.4 489.367 1514.03 Q491.705 1513.66 493.765 1513.66 Q499.089 1513.66 502.191 1516.09 Q505.293 1518.5 505.293 1522.62 Q505.293 1525.49 503.649 1527.48 Q502.006 1529.45 498.973 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M909.561 1529.7 Q906.413 1529.7 904.561 1531.86 Q902.733 1534.01 902.733 1537.76 Q902.733 1541.49 904.561 1543.66 Q906.413 1545.82 909.561 1545.82 Q912.709 1545.82 914.538 1543.66 Q916.39 1541.49 916.39 1537.76 Q916.39 1534.01 914.538 1531.86 Q912.709 1529.7 909.561 1529.7 M918.844 1515.05 L918.844 1519.31 Q917.084 1518.48 915.279 1518.04 Q913.497 1517.6 911.737 1517.6 Q907.108 1517.6 904.654 1520.72 Q902.223 1523.85 901.876 1530.17 Q903.242 1528.15 905.302 1527.09 Q907.362 1526 909.839 1526 Q915.047 1526 918.057 1529.17 Q921.089 1532.32 921.089 1537.76 Q921.089 1543.08 917.941 1546.3 Q914.793 1549.52 909.561 1549.52 Q903.566 1549.52 900.395 1544.94 Q897.223 1540.33 897.223 1531.6 Q897.223 1523.41 901.112 1518.55 Q905.001 1513.66 911.552 1513.66 Q913.311 1513.66 915.094 1514.01 Q916.899 1514.36 918.844 1515.05 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1313.89 1548.13 L1313.89 1543.87 Q1315.65 1544.7 1317.45 1545.14 Q1319.26 1545.58 1320.99 1545.58 Q1325.62 1545.58 1328.05 1542.48 Q1330.51 1539.36 1330.86 1533.01 Q1329.51 1535.01 1327.45 1536.07 Q1325.39 1537.13 1322.89 1537.13 Q1317.71 1537.13 1314.67 1534.01 Q1311.67 1530.86 1311.67 1525.42 Q1311.67 1520.1 1314.81 1516.88 Q1317.96 1513.66 1323.19 1513.66 Q1329.19 1513.66 1332.34 1518.27 Q1335.51 1522.85 1335.51 1531.6 Q1335.51 1539.77 1331.62 1544.66 Q1327.75 1549.52 1321.2 1549.52 Q1319.44 1549.52 1317.64 1549.17 Q1315.83 1548.82 1313.89 1548.13 M1323.19 1533.48 Q1326.34 1533.48 1328.17 1531.32 Q1330.02 1529.17 1330.02 1525.42 Q1330.02 1521.7 1328.17 1519.54 Q1326.34 1517.37 1323.19 1517.37 Q1320.05 1517.37 1318.19 1519.54 Q1316.36 1521.7 1316.36 1525.42 Q1316.36 1529.17 1318.19 1531.32 Q1320.05 1533.48 1323.19 1533.48 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1713.5 1544.91 L1721.14 1544.91 L1721.14 1518.55 L1712.83 1520.21 L1712.83 1515.95 L1721.1 1514.29 L1725.77 1514.29 L1725.77 1544.91 L1733.41 1544.91 L1733.41 1548.85 L1713.5 1548.85 L1713.5 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1746.88 1544.91 L1763.2 1544.91 L1763.2 1548.85 L1741.26 1548.85 L1741.26 1544.91 Q1743.92 1542.16 1748.5 1537.53 Q1753.11 1532.88 1754.29 1531.53 Q1756.54 1529.01 1757.42 1527.27 Q1758.32 1525.51 1758.32 1523.82 Q1758.32 1521.07 1756.37 1519.33 Q1754.45 1517.6 1751.35 1517.6 Q1749.15 1517.6 1746.7 1518.36 Q1744.27 1519.13 1741.49 1520.68 L1741.49 1515.95 Q1744.31 1514.82 1746.77 1514.24 Q1749.22 1513.66 1751.26 1513.66 Q1756.63 1513.66 1759.82 1516.35 Q1763.02 1519.03 1763.02 1523.52 Q1763.02 1525.65 1762.21 1527.57 Q1761.42 1529.47 1759.31 1532.07 Q1758.73 1532.74 1755.63 1535.95 Q1752.53 1539.15 1746.88 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M2127.63 1544.91 L2135.27 1544.91 L2135.27 1518.55 L2126.96 1520.21 L2126.96 1515.95 L2135.23 1514.29 L2139.9 1514.29 L2139.9 1544.91 L2147.54 1544.91 L2147.54 1548.85 L2127.63 1548.85 L2127.63 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M2157.03 1514.29 L2175.39 1514.29 L2175.39 1518.22 L2161.31 1518.22 L2161.31 1526.7 Q2162.33 1526.35 2163.35 1526.19 Q2164.37 1526 2165.39 1526 Q2171.17 1526 2174.55 1529.17 Q2177.93 1532.34 2177.93 1537.76 Q2177.93 1543.34 2174.46 1546.44 Q2170.99 1549.52 2164.67 1549.52 Q2162.49 1549.52 2160.23 1549.15 Q2157.98 1548.78 2155.57 1548.04 L2155.57 1543.34 Q2157.66 1544.47 2159.88 1545.03 Q2162.1 1545.58 2164.58 1545.58 Q2168.58 1545.58 2170.92 1543.48 Q2173.26 1541.37 2173.26 1537.76 Q2173.26 1534.15 2170.92 1532.04 Q2168.58 1529.94 2164.58 1529.94 Q2162.7 1529.94 2160.83 1530.35 Q2158.98 1530.77 2157.03 1531.65 L2157.03 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.274,1238.76 2352.76,1238.76 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.274,982.154 2352.76,982.154 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.274,725.548 2352.76,725.548 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.274,468.943 2352.76,468.943 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.274,212.337 2352.76,212.337 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.274,1486.45 156.274,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.274,1238.76 175.172,1238.76 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.274,982.154 175.172,982.154 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.274,725.548 175.172,725.548 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.274,468.943 175.172,468.943 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.274,212.337 175.172,212.337 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip060)\" d=\"M63.7467 1224.56 Q60.1356 1224.56 58.3069 1228.12 Q56.5014 1231.67 56.5014 1238.8 Q56.5014 1245.9 58.3069 1249.47 Q60.1356 1253.01 63.7467 1253.01 Q67.3809 1253.01 69.1865 1249.47 Q71.0152 1245.9 71.0152 1238.8 Q71.0152 1231.67 69.1865 1228.12 Q67.3809 1224.56 63.7467 1224.56 M63.7467 1220.86 Q69.5568 1220.86 72.6124 1225.46 Q75.6911 1230.05 75.6911 1238.8 Q75.6911 1247.52 72.6124 1252.13 Q69.5568 1256.71 63.7467 1256.71 Q57.9365 1256.71 54.8578 1252.13 Q51.8023 1247.52 51.8023 1238.8 Q51.8023 1230.05 54.8578 1225.46 Q57.9365 1220.86 63.7467 1220.86 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M83.9086 1250.16 L88.7928 1250.16 L88.7928 1256.04 L83.9086 1256.04 L83.9086 1250.16 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M113.145 1237.41 Q116.501 1238.12 118.376 1240.39 Q120.274 1242.66 120.274 1245.99 Q120.274 1251.11 116.756 1253.91 Q113.237 1256.71 106.756 1256.71 Q104.58 1256.71 102.265 1256.27 Q99.9733 1255.86 97.5197 1255 L97.5197 1250.48 Q99.4641 1251.62 101.779 1252.2 Q104.094 1252.78 106.617 1252.78 Q111.015 1252.78 113.307 1251.04 Q115.621 1249.3 115.621 1245.99 Q115.621 1242.94 113.469 1241.23 Q111.339 1239.49 107.52 1239.49 L103.492 1239.49 L103.492 1235.65 L107.705 1235.65 Q111.154 1235.65 112.983 1234.28 Q114.811 1232.89 114.811 1230.3 Q114.811 1227.64 112.913 1226.23 Q111.038 1224.79 107.52 1224.79 Q105.598 1224.79 103.399 1225.21 Q101.2 1225.62 98.5613 1226.5 L98.5613 1222.34 Q101.223 1221.6 103.538 1221.23 Q105.876 1220.86 107.936 1220.86 Q113.26 1220.86 116.362 1223.29 Q119.464 1225.69 119.464 1229.81 Q119.464 1232.68 117.82 1234.67 Q116.177 1236.64 113.145 1237.41 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M62.9365 967.953 Q59.3254 967.953 57.4967 971.518 Q55.6912 975.06 55.6912 982.189 Q55.6912 989.296 57.4967 992.86 Q59.3254 996.402 62.9365 996.402 Q66.5707 996.402 68.3763 992.86 Q70.205 989.296 70.205 982.189 Q70.205 975.06 68.3763 971.518 Q66.5707 967.953 62.9365 967.953 M62.9365 964.249 Q68.7467 964.249 71.8022 968.856 Q74.8809 973.439 74.8809 982.189 Q74.8809 990.916 71.8022 995.522 Q68.7467 1000.11 62.9365 1000.11 Q57.1264 1000.11 54.0477 995.522 Q50.9921 990.916 50.9921 982.189 Q50.9921 973.439 54.0477 968.856 Q57.1264 964.249 62.9365 964.249 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M83.0984 993.555 L87.9827 993.555 L87.9827 999.434 L83.0984 999.434 L83.0984 993.555 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M108.746 980.291 Q105.598 980.291 103.746 982.444 Q101.918 984.597 101.918 988.346 Q101.918 992.073 103.746 994.249 Q105.598 996.402 108.746 996.402 Q111.895 996.402 113.723 994.249 Q115.575 992.073 115.575 988.346 Q115.575 984.597 113.723 982.444 Q111.895 980.291 108.746 980.291 M118.029 965.638 L118.029 969.898 Q116.27 969.064 114.464 968.624 Q112.682 968.185 110.922 968.185 Q106.293 968.185 103.839 971.31 Q101.409 974.435 101.061 980.754 Q102.427 978.74 104.487 977.675 Q106.547 976.587 109.024 976.587 Q114.233 976.587 117.242 979.759 Q120.274 982.907 120.274 988.346 Q120.274 993.671 117.126 996.888 Q113.978 1000.11 108.746 1000.11 Q102.751 1000.11 99.5798 995.522 Q96.4085 990.916 96.4085 982.189 Q96.4085 973.995 100.297 969.134 Q104.186 964.249 110.737 964.249 Q112.496 964.249 114.279 964.597 Q116.084 964.944 118.029 965.638 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M63.2837 711.347 Q59.6726 711.347 57.8439 714.912 Q56.0384 718.454 56.0384 725.583 Q56.0384 732.69 57.8439 736.254 Q59.6726 739.796 63.2837 739.796 Q66.918 739.796 68.7235 736.254 Q70.5522 732.69 70.5522 725.583 Q70.5522 718.454 68.7235 714.912 Q66.918 711.347 63.2837 711.347 M63.2837 707.643 Q69.0939 707.643 72.1494 712.25 Q75.2281 716.833 75.2281 725.583 Q75.2281 734.31 72.1494 738.916 Q69.0939 743.5 63.2837 743.5 Q57.4736 743.5 54.3949 738.916 Q51.3393 734.31 51.3393 725.583 Q51.3393 716.833 54.3949 712.25 Q57.4736 707.643 63.2837 707.643 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M83.4457 736.949 L88.3299 736.949 L88.3299 742.828 L83.4457 742.828 L83.4457 736.949 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M98.6539 742.111 L98.6539 737.852 Q100.413 738.685 102.219 739.125 Q104.024 739.565 105.76 739.565 Q110.39 739.565 112.82 736.463 Q115.274 733.338 115.621 726.995 Q114.279 728.986 112.219 730.051 Q110.158 731.116 107.658 731.116 Q102.473 731.116 99.4409 727.991 Q96.4317 724.842 96.4317 719.403 Q96.4317 714.079 99.5798 710.861 Q102.728 707.643 107.959 707.643 Q113.955 707.643 117.103 712.25 Q120.274 716.833 120.274 725.583 Q120.274 733.754 116.385 738.639 Q112.52 743.5 105.969 743.5 Q104.209 743.5 102.404 743.153 Q100.598 742.805 98.6539 742.111 M107.959 727.458 Q111.108 727.458 112.936 725.305 Q114.788 723.153 114.788 719.403 Q114.788 715.676 112.936 713.523 Q111.108 711.347 107.959 711.347 Q104.811 711.347 102.959 713.523 Q101.131 715.676 101.131 719.403 Q101.131 723.153 102.959 725.305 Q104.811 727.458 107.959 727.458 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M55.506 482.287 L63.1448 482.287 L63.1448 455.922 L54.8347 457.588 L54.8347 453.329 L63.0985 451.663 L67.7744 451.663 L67.7744 482.287 L75.4133 482.287 L75.4133 486.223 L55.506 486.223 L55.506 482.287 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M84.8577 480.343 L89.7419 480.343 L89.7419 486.223 L84.8577 486.223 L84.8577 480.343 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M103.955 482.287 L120.274 482.287 L120.274 486.223 L98.3298 486.223 L98.3298 482.287 Q100.992 479.533 105.575 474.903 Q110.182 470.25 111.362 468.908 Q113.608 466.385 114.487 464.649 Q115.39 462.889 115.39 461.2 Q115.39 458.445 113.445 456.709 Q111.524 454.973 108.422 454.973 Q106.223 454.973 103.77 455.737 Q101.339 456.5 98.5613 458.051 L98.5613 453.329 Q101.385 452.195 103.839 451.616 Q106.293 451.038 108.33 451.038 Q113.7 451.038 116.895 453.723 Q120.089 456.408 120.089 460.899 Q120.089 463.028 119.279 464.949 Q118.492 466.848 116.385 469.44 Q115.807 470.112 112.705 473.329 Q109.603 476.524 103.955 482.287 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M54.9041 225.681 L62.543 225.681 L62.543 199.316 L54.2328 200.982 L54.2328 196.723 L62.4967 195.057 L67.1726 195.057 L67.1726 225.681 L74.8114 225.681 L74.8114 229.617 L54.9041 229.617 L54.9041 225.681 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M84.2558 223.737 L89.1401 223.737 L89.1401 229.617 L84.2558 229.617 L84.2558 223.737 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M99.3715 195.057 L117.728 195.057 L117.728 198.992 L103.654 198.992 L103.654 207.464 Q104.672 207.117 105.691 206.955 Q106.709 206.77 107.728 206.77 Q113.515 206.77 116.895 209.941 Q120.274 213.112 120.274 218.529 Q120.274 224.107 116.802 227.209 Q113.33 230.288 107.01 230.288 Q104.834 230.288 102.566 229.918 Q100.321 229.547 97.9132 228.806 L97.9132 224.107 Q99.9965 225.242 102.219 225.797 Q104.441 226.353 106.918 226.353 Q110.922 226.353 113.26 224.246 Q115.598 222.14 115.598 218.529 Q115.598 214.918 113.26 212.811 Q110.922 210.705 106.918 210.705 Q105.043 210.705 103.168 211.121 Q101.316 211.538 99.3715 212.418 L99.3715 195.057 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip062)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  218.439,1322.76 356.582,1435.49 494.726,566.974 632.869,994.918 771.013,1190.58 909.156,1105.11 1047.3,1017.04 1185.44,1424 1323.59,1134.18 1461.73,87.9763 \n",
       "  1599.87,997.257 1738.02,1350.89 1876.16,652.108 2014.3,1445.72 2152.45,1367.73 2290.59,1390.65 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip060)\" d=\"\n",
       "M2007.46 198.898 L2279.54 198.898 L2279.54 95.2176 L2007.46 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2007.46,198.898 2279.54,198.898 2279.54,95.2176 2007.46,95.2176 2007.46,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2031.87,147.058 2178.3,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip060)\" d=\"M2216.55 166.745 Q2214.74 171.375 2213.03 172.787 Q2211.32 174.199 2208.44 174.199 L2205.04 174.199 L2205.04 170.634 L2207.54 170.634 Q2209.3 170.634 2210.27 169.8 Q2211.25 168.967 2212.43 165.865 L2213.19 163.921 L2202.7 138.412 L2207.22 138.412 L2215.32 158.689 L2223.42 138.412 L2227.94 138.412 L2216.55 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M2235.23 160.402 L2242.87 160.402 L2242.87 134.037 L2234.56 135.703 L2234.56 131.444 L2242.82 129.778 L2247.5 129.778 L2247.5 160.402 L2255.13 160.402 L2255.13 164.338 L2235.23 164.338 L2235.23 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/episodes\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        X  = X_0\n",
    "        \n",
    "        ##### Double Q-Learning ###########################################\n",
    "\n",
    "        for k = 1:T\n",
    "\n",
    "            # 1. Choose action\n",
    "            if rand() < epsilon\n",
    "                if rand() < EXPrand \n",
    "                    A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                else\n",
    "                    A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                end\n",
    "            else\n",
    "\n",
    "                A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                if A == 1000.0 # Indicates no values in this region\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "\n",
    "            # 2. Cache last state\n",
    "            qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "            # 3. Generate the next stae\n",
    "            Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "            # 4. Collect reward R( s, a, s' )\n",
    "            R_t = cartpole_reward( Xp )\n",
    "\n",
    "            # 5. Get the optimal action at the next state\n",
    "            a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "            # 6. Compute the value at the next state\n",
    "\n",
    "            V_tp1_opt = query_value_fuzzy( \n",
    "                Q_kdTree, G, V, \n",
    "                get_Q( \n",
    "                    select_X_vector( Xp ), \n",
    "                    a_tp1_opt \n",
    "                ); \n",
    "                k = vNN \n",
    "            )\n",
    "            if isnan( V_tp1_opt )\n",
    "                V_tp1_opt = 0.0\n",
    "            end\n",
    "\n",
    "\n",
    "            # 7. Blend the value back into nearest points\n",
    "\n",
    "            idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "            nNear      = size( idxs, 1 )\n",
    "            for i = 1:nNear\n",
    "                j    = idxs[i]\n",
    "                if !isnan( wgts[i] ) \n",
    "\n",
    "                    # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                    VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "                    \n",
    "                end\n",
    "            end\n",
    "\n",
    "            states[:,k] = Xp\n",
    "            actions[k]  = A\n",
    "\n",
    "            X = Xp\n",
    "        end\n",
    "\n",
    "        s_l    = vertical_score_s( states, aMargin, ts )\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        if useElig\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
