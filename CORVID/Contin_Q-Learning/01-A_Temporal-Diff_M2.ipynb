{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.02148 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 # 0.00782 # 0.00391\n",
    "gamma    = 1.00\n",
    "swapDiv  = 64\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes = 64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   = 32 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "beta   = 0.15\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = true\n",
    "N_peaks =  16\n",
    "N_steps = 128\n",
    "lambda  =   0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.2800000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.20000000000000004, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.4400000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.13999999999999999, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.36000000000000015, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.6500000000000004, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.3000000000000001, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.19890625000000015\n",
      "\n",
      "Epoch 2, Best Score: 1.2200000000000009\n",
      "Training Iteration 4 score: 0.4100000000000002, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.9100000000000006, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.09, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.11999999999999998, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.22000000000000006, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.2900000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.2700000000000001, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.10999999999999999, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.49000000000000027, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.9800000000000006, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.35000000000000014, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.45000000000000023, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.5500000000000003, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.3900000000000002, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.3200000000000001, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.13999999999999999, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.4596874999999999\n",
      "\n",
      "Epoch 3, Best Score: 2.909999999999982\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 4, Best Score: 2.909999999999982\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.04109375000000002\n",
      "\n",
      "Epoch 5, Best Score: 2.909999999999982\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 6, Best Score: 2.909999999999982\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 7, Best Score: 2.909999999999982\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.35000000000000014, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.47000000000000025, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.21000000000000005, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.3300000000000001, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.13999999999999999, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.07734375000000003\n",
      "\n",
      "Epoch 8, Best Score: 2.909999999999982\n",
      "Training Iteration 4 score: 0.38000000000000017, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.010156250000000004\n",
      "\n",
      "Epoch 9, Best Score: 2.909999999999982\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.3200000000000001, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.25000000000000006, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.019062500000000003\n",
      "\n",
      "Epoch 10, Best Score: 2.909999999999982\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.010000000000000005\n",
      "\n",
      "Epoch 11, Best Score: 2.909999999999982\n",
      "Training Iteration 4 score: 1.290000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.11999999999999998, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.26000000000000006, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.9700000000000006, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.19000000000000003, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 1.430000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.23000000000000007, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.25000000000000006, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.2700000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.26000000000000006, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.21000000000000005, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.23000000000000007, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.7600000000000005, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 1.1300000000000008, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.7900000000000005, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 1.6700000000000013, epsilon: 8.881784197001252e-16\n",
      "Average Score: 4.605625000000201\n",
      "\n",
      "Epoch 12, Best Score: 35.500000000001506\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.3100000000000001, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 25.08000000000112, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.24000000000000007, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 25.13000000000113, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.21000000000000005, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 23.28000000000084, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 16.169999999999728, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 26.250000000001304, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 19.990000000000325, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 23.98000000000095, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 29.970000000001885, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 29.16000000000176, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 29.93000000000188, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 31.47000000000212, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 31.500000000002125, epsilon: 8.881784197001252e-16\n",
      "Average Score: 20.645000000000987\n",
      "\n",
      "Epoch 13, Best Score: 35.500000000001506\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 14, Best Score: 35.500000000001506\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 15, Best Score: 35.500000000001506\n",
      "Training Iteration 4 score: 1.0700000000000007, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.19000000000000003, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.049062500000000016\n",
      "\n",
      "Epoch 16, Best Score: 35.500000000001506\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 2.759999999999985, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 1.1200000000000008, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 1.260000000000001, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 1.290000000000001, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.3100000000000001, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.2934374999999999\n",
      "\n",
      "Epoch 17, Best Score: 35.500000000001506\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 18, Best Score: 35.500000000001506\n",
      "Training Iteration 4 score: 0.17, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.16, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.3200000000000001, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.25000000000000006, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.17, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.16, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.15, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.18000000000000002, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.16, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.12421875000000004\n",
      "\n",
      "Epoch 19, Best Score: 35.500000000001506\n",
      "Training Iteration 4 score: 0.3900000000000002, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 3.5799999999999677, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 1.0300000000000007, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 2.1399999999999983, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 1.7500000000000013, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.5900000000000003, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.5700000000000003, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 3.429999999999971, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 1.9700000000000015, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 3.45999999999997, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 3.4099999999999713, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 3.2699999999999743, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 2.2799999999999954, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 2.289999999999995, epsilon: 8.881784197001252e-16\n",
      "Average Score: 1.9787499999999907\n",
      "\n",
      "Epoch 20, Best Score: 35.500000000001506\n",
      "Training Iteration 4 score: 1.440000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.4300000000000002, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.24000000000000007, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 1.2200000000000009, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 1.0800000000000007, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 1.0600000000000007, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 3.1999999999999758, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.562187499999999\n",
      "\n",
      "Epoch 21, Best Score: 35.500000000001506\n",
      "Training Iteration 4 score: 1.5700000000000012, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 7.199999999999891, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 9.539999999999841, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 2.6499999999999875, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 9.019999999999852, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 9.999999999999831, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 12.90999999999977, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 10.829999999999814, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 9.969999999999832, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 18.180000000000042, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 8.19999999999987, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 13.039999999999766, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 11.649999999999796, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 11.4799999999998, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 11.579999999999798, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 5.209999999999933, epsilon: 8.881784197001252e-16\n",
      "Average Score: 9.877499999999866\n",
      "\n",
      "Epoch 22, Best Score: 35.500000000001506\n",
      "Training Iteration 4 score: 0.5600000000000003, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 18.330000000000066, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.5400000000000003, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 1.310000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 28.800000000001702, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 1.0200000000000007, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 33.87000000000183, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 1.1500000000000008, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 33.94000000000182, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.2800000000000001, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 25.13000000000113, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 33.77000000000185, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.38000000000000017, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.4300000000000002, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.46000000000000024, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.13999999999999999, epsilon: 8.881784197001252e-16\n",
      "Average Score: 13.755937500000721\n",
      "\n",
      "Epoch 23, Best Score: 35.560000000001494\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.030937500000000017\n",
      "\n",
      "Epoch 24, Best Score: 35.560000000001494\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 1.500000000000001, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.3200000000000001, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.6900000000000004, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.49000000000000027, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.6500000000000004, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.6200000000000003, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.3000000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.3900000000000002, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.38000000000000017, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.4200000000000002, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.19000000000000003, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.36000000000000015, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.46000000000000024, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.37000000000000016, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.6739062499999988\n",
      "\n",
      "Epoch 25, Best Score: 35.560000000001494\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 26, Best Score: 35.560000000001494\n",
      "Training Iteration 4 score: 0.5900000000000003, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 1.0500000000000007, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.24000000000000007, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 1.5900000000000012, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.35000000000000014, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.5300000000000002, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 1.460000000000001, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.36000000000000015, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.41453125\n",
      "\n",
      "Epoch 27, Best Score: 35.560000000001494\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 28, Best Score: 35.560000000001494\n",
      "Training Iteration 4 score: 0.7200000000000004, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.37000000000000016, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.19000000000000003, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.8600000000000005, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.07031250000000003\n",
      "\n",
      "Epoch 29, Best Score: 35.560000000001494\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 30, Best Score: 35.560000000001494\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.8500000000000005, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.05, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.07921875000000005\n",
      "\n",
      "Epoch 31, Best Score: 35.560000000001494\n",
      "Training Iteration 4 score: 0.34000000000000014, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.35000000000000014, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 6.079999999999915, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 14.039999999999745, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 12.969999999999768, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 5.969999999999917, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 23.870000000000932, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 6.969999999999896, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 20.01000000000033, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 17.549999999999944, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 9.389999999999844, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 3.8599999999999617, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 6.393281249999976\n",
      "\n",
      "Epoch 32, Best Score: 35.560000000001494\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "Saved a trained Q-table with size (76032,), After 13.155628097057342 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip060\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip060)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip061\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip060)\" d=\"\n",
       "M140.696 1486.45 L2352.76 1486.45 L2352.76 47.2441 L140.696 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip062\">\n",
       "    <rect x=\"140\" y=\"47\" width=\"2213\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  472.572,1486.45 472.572,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  809.161,1486.45 809.161,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1145.75,1486.45 1145.75,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1482.34,1486.45 1482.34,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1818.93,1486.45 1818.93,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2155.51,1486.45 2155.51,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  472.572,1486.45 472.572,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  809.161,1486.45 809.161,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1145.75,1486.45 1145.75,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1482.34,1486.45 1482.34,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1818.93,1486.45 1818.93,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2155.51,1486.45 2155.51,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip060)\" d=\"M462.85 1514.29 L481.206 1514.29 L481.206 1518.22 L467.132 1518.22 L467.132 1526.7 Q468.151 1526.35 469.169 1526.19 Q470.188 1526 471.206 1526 Q476.993 1526 480.373 1529.17 Q483.752 1532.34 483.752 1537.76 Q483.752 1543.34 480.28 1546.44 Q476.808 1549.52 470.489 1549.52 Q468.313 1549.52 466.044 1549.15 Q463.799 1548.78 461.391 1548.04 L461.391 1543.34 Q463.475 1544.47 465.697 1545.03 Q467.919 1545.58 470.396 1545.58 Q474.401 1545.58 476.739 1543.48 Q479.077 1541.37 479.077 1537.76 Q479.077 1534.15 476.739 1532.04 Q474.401 1529.94 470.396 1529.94 Q468.521 1529.94 466.646 1530.35 Q464.794 1530.77 462.85 1531.65 L462.85 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M783.848 1544.91 L791.487 1544.91 L791.487 1518.55 L783.177 1520.21 L783.177 1515.95 L791.441 1514.29 L796.117 1514.29 L796.117 1544.91 L803.755 1544.91 L803.755 1548.85 L783.848 1548.85 L783.848 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M823.2 1517.37 Q819.589 1517.37 817.76 1520.93 Q815.954 1524.47 815.954 1531.6 Q815.954 1538.71 817.76 1542.27 Q819.589 1545.82 823.2 1545.82 Q826.834 1545.82 828.64 1542.27 Q830.468 1538.71 830.468 1531.6 Q830.468 1524.47 828.64 1520.93 Q826.834 1517.37 823.2 1517.37 M823.2 1513.66 Q829.01 1513.66 832.065 1518.27 Q835.144 1522.85 835.144 1531.6 Q835.144 1540.33 832.065 1544.94 Q829.01 1549.52 823.2 1549.52 Q817.39 1549.52 814.311 1544.94 Q811.255 1540.33 811.255 1531.6 Q811.255 1522.85 814.311 1518.27 Q817.39 1513.66 823.2 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1120.93 1544.91 L1128.57 1544.91 L1128.57 1518.55 L1120.26 1520.21 L1120.26 1515.95 L1128.53 1514.29 L1133.2 1514.29 L1133.2 1544.91 L1140.84 1544.91 L1140.84 1548.85 L1120.93 1548.85 L1120.93 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1150.33 1514.29 L1168.69 1514.29 L1168.69 1518.22 L1154.61 1518.22 L1154.61 1526.7 Q1155.63 1526.35 1156.65 1526.19 Q1157.67 1526 1158.69 1526 Q1164.48 1526 1167.86 1529.17 Q1171.24 1532.34 1171.24 1537.76 Q1171.24 1543.34 1167.76 1546.44 Q1164.29 1549.52 1157.97 1549.52 Q1155.8 1549.52 1153.53 1549.15 Q1151.28 1548.78 1148.87 1548.04 L1148.87 1543.34 Q1150.96 1544.47 1153.18 1545.03 Q1155.4 1545.58 1157.88 1545.58 Q1161.88 1545.58 1164.22 1543.48 Q1166.56 1541.37 1166.56 1537.76 Q1166.56 1534.15 1164.22 1532.04 Q1161.88 1529.94 1157.88 1529.94 Q1156 1529.94 1154.13 1530.35 Q1152.28 1530.77 1150.33 1531.65 L1150.33 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1461.11 1544.91 L1477.43 1544.91 L1477.43 1548.85 L1455.49 1548.85 L1455.49 1544.91 Q1458.15 1542.16 1462.73 1537.53 Q1467.34 1532.88 1468.52 1531.53 Q1470.76 1529.01 1471.64 1527.27 Q1472.55 1525.51 1472.55 1523.82 Q1472.55 1521.07 1470.6 1519.33 Q1468.68 1517.6 1465.58 1517.6 Q1463.38 1517.6 1460.93 1518.36 Q1458.5 1519.13 1455.72 1520.68 L1455.72 1515.95 Q1458.54 1514.82 1461 1514.24 Q1463.45 1513.66 1465.49 1513.66 Q1470.86 1513.66 1474.05 1516.35 Q1477.25 1519.03 1477.25 1523.52 Q1477.25 1525.65 1476.44 1527.57 Q1475.65 1529.47 1473.54 1532.07 Q1472.96 1532.74 1469.86 1535.95 Q1466.76 1539.15 1461.11 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1497.25 1517.37 Q1493.63 1517.37 1491.81 1520.93 Q1490 1524.47 1490 1531.6 Q1490 1538.71 1491.81 1542.27 Q1493.63 1545.82 1497.25 1545.82 Q1500.88 1545.82 1502.68 1542.27 Q1504.51 1538.71 1504.51 1531.6 Q1504.51 1524.47 1502.68 1520.93 Q1500.88 1517.37 1497.25 1517.37 M1497.25 1513.66 Q1503.06 1513.66 1506.11 1518.27 Q1509.19 1522.85 1509.19 1531.6 Q1509.19 1540.33 1506.11 1544.94 Q1503.06 1549.52 1497.25 1549.52 Q1491.43 1549.52 1488.36 1544.94 Q1485.3 1540.33 1485.3 1531.6 Q1485.3 1522.85 1488.36 1518.27 Q1491.43 1513.66 1497.25 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1798.2 1544.91 L1814.52 1544.91 L1814.52 1548.85 L1792.57 1548.85 L1792.57 1544.91 Q1795.23 1542.16 1799.82 1537.53 Q1804.42 1532.88 1805.6 1531.53 Q1807.85 1529.01 1808.73 1527.27 Q1809.63 1525.51 1809.63 1523.82 Q1809.63 1521.07 1807.69 1519.33 Q1805.77 1517.6 1802.66 1517.6 Q1800.47 1517.6 1798.01 1518.36 Q1795.58 1519.13 1792.8 1520.68 L1792.8 1515.95 Q1795.63 1514.82 1798.08 1514.24 Q1800.54 1513.66 1802.57 1513.66 Q1807.94 1513.66 1811.14 1516.35 Q1814.33 1519.03 1814.33 1523.52 Q1814.33 1525.65 1813.52 1527.57 Q1812.73 1529.47 1810.63 1532.07 Q1810.05 1532.74 1806.95 1535.95 Q1803.85 1539.15 1798.2 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1824.38 1514.29 L1842.73 1514.29 L1842.73 1518.22 L1828.66 1518.22 L1828.66 1526.7 Q1829.68 1526.35 1830.7 1526.19 Q1831.72 1526 1832.73 1526 Q1838.52 1526 1841.9 1529.17 Q1845.28 1532.34 1845.28 1537.76 Q1845.28 1543.34 1841.81 1546.44 Q1838.34 1549.52 1832.02 1549.52 Q1829.84 1549.52 1827.57 1549.15 Q1825.33 1548.78 1822.92 1548.04 L1822.92 1543.34 Q1825 1544.47 1827.22 1545.03 Q1829.45 1545.58 1831.92 1545.58 Q1835.93 1545.58 1838.27 1543.48 Q1840.6 1541.37 1840.6 1537.76 Q1840.6 1534.15 1838.27 1532.04 Q1835.93 1529.94 1831.92 1529.94 Q1830.05 1529.94 1828.17 1530.35 Q1826.32 1530.77 1824.38 1531.65 L1824.38 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M2144.36 1530.21 Q2147.71 1530.93 2149.59 1533.2 Q2151.49 1535.47 2151.49 1538.8 Q2151.49 1543.92 2147.97 1546.72 Q2144.45 1549.52 2137.97 1549.52 Q2135.79 1549.52 2133.48 1549.08 Q2131.19 1548.66 2128.73 1547.81 L2128.73 1543.29 Q2130.68 1544.43 2132.99 1545.01 Q2135.31 1545.58 2137.83 1545.58 Q2142.23 1545.58 2144.52 1543.85 Q2146.83 1542.11 2146.83 1538.8 Q2146.83 1535.75 2144.68 1534.03 Q2142.55 1532.3 2138.73 1532.3 L2134.7 1532.3 L2134.7 1528.45 L2138.92 1528.45 Q2142.37 1528.45 2144.2 1527.09 Q2146.02 1525.7 2146.02 1523.11 Q2146.02 1520.45 2144.13 1519.03 Q2142.25 1517.6 2138.73 1517.6 Q2136.81 1517.6 2134.61 1518.01 Q2132.41 1518.43 2129.77 1519.31 L2129.77 1515.14 Q2132.44 1514.4 2134.75 1514.03 Q2137.09 1513.66 2139.15 1513.66 Q2144.47 1513.66 2147.58 1516.09 Q2150.68 1518.5 2150.68 1522.62 Q2150.68 1525.49 2149.03 1527.48 Q2147.39 1529.45 2144.36 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M2170.35 1517.37 Q2166.74 1517.37 2164.91 1520.93 Q2163.11 1524.47 2163.11 1531.6 Q2163.11 1538.71 2164.91 1542.27 Q2166.74 1545.82 2170.35 1545.82 Q2173.99 1545.82 2175.79 1542.27 Q2177.62 1538.71 2177.62 1531.6 Q2177.62 1524.47 2175.79 1520.93 Q2173.99 1517.37 2170.35 1517.37 M2170.35 1513.66 Q2176.16 1513.66 2179.22 1518.27 Q2182.3 1522.85 2182.3 1531.6 Q2182.3 1540.33 2179.22 1544.94 Q2176.16 1549.52 2170.35 1549.52 Q2164.54 1549.52 2161.46 1544.94 Q2158.41 1540.33 2158.41 1531.6 Q2158.41 1522.85 2161.46 1518.27 Q2164.54 1513.66 2170.35 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.696,1445.72 2352.76,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.696,1116.89 2352.76,1116.89 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.696,788.056 2352.76,788.056 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.696,459.225 2352.76,459.225 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.696,130.395 2352.76,130.395 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,1486.45 140.696,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,1445.72 159.593,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,1116.89 159.593,1116.89 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,788.056 159.593,788.056 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,459.225 159.593,459.225 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,130.395 159.593,130.395 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip060)\" d=\"M92.7512 1431.51 Q89.1401 1431.51 87.3114 1435.08 Q85.5058 1438.62 85.5058 1445.75 Q85.5058 1452.86 87.3114 1456.42 Q89.1401 1459.96 92.7512 1459.96 Q96.3854 1459.96 98.1909 1456.42 Q100.02 1452.86 100.02 1445.75 Q100.02 1438.62 98.1909 1435.08 Q96.3854 1431.51 92.7512 1431.51 M92.7512 1427.81 Q98.5613 1427.81 101.617 1432.42 Q104.696 1437 104.696 1445.75 Q104.696 1454.48 101.617 1459.08 Q98.5613 1463.67 92.7512 1463.67 Q86.941 1463.67 83.8623 1459.08 Q80.8068 1454.48 80.8068 1445.75 Q80.8068 1437 83.8623 1432.42 Q86.941 1427.81 92.7512 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M83.7929 1099.61 L102.149 1099.61 L102.149 1103.54 L88.0753 1103.54 L88.0753 1112.01 Q89.0938 1111.67 90.1123 1111.5 Q91.1308 1111.32 92.1493 1111.32 Q97.9363 1111.32 101.316 1114.49 Q104.696 1117.66 104.696 1123.08 Q104.696 1128.66 101.223 1131.76 Q97.7511 1134.84 91.4317 1134.84 Q89.2558 1134.84 86.9873 1134.47 Q84.7419 1134.1 82.3346 1133.36 L82.3346 1128.66 Q84.4179 1129.79 86.6401 1130.35 Q88.8623 1130.9 91.3391 1130.9 Q95.3437 1130.9 97.6817 1128.8 Q100.02 1126.69 100.02 1123.08 Q100.02 1119.47 97.6817 1117.36 Q95.3437 1115.25 91.3391 1115.25 Q89.4641 1115.25 87.5892 1115.67 Q85.7373 1116.09 83.7929 1116.97 L83.7929 1099.61 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M53.3995 801.4 L61.0384 801.4 L61.0384 775.035 L52.7282 776.701 L52.7282 772.442 L60.9921 770.776 L65.668 770.776 L65.668 801.4 L73.3068 801.4 L73.3068 805.336 L53.3995 805.336 L53.3995 801.4 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M92.7512 773.854 Q89.1401 773.854 87.3114 777.419 Q85.5058 780.961 85.5058 788.09 Q85.5058 795.197 87.3114 798.761 Q89.1401 802.303 92.7512 802.303 Q96.3854 802.303 98.1909 798.761 Q100.02 795.197 100.02 788.09 Q100.02 780.961 98.1909 777.419 Q96.3854 773.854 92.7512 773.854 M92.7512 770.151 Q98.5613 770.151 101.617 774.757 Q104.696 779.34 104.696 788.09 Q104.696 796.817 101.617 801.424 Q98.5613 806.007 92.7512 806.007 Q86.941 806.007 83.8623 801.424 Q80.8068 796.817 80.8068 788.09 Q80.8068 779.34 83.8623 774.757 Q86.941 770.151 92.7512 770.151 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M54.3949 472.57 L62.0337 472.57 L62.0337 446.205 L53.7236 447.871 L53.7236 443.612 L61.9874 441.945 L66.6633 441.945 L66.6633 472.57 L74.3022 472.57 L74.3022 476.505 L54.3949 476.505 L54.3949 472.57 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M83.7929 441.945 L102.149 441.945 L102.149 445.881 L88.0753 445.881 L88.0753 454.353 Q89.0938 454.006 90.1123 453.844 Q91.1308 453.658 92.1493 453.658 Q97.9363 453.658 101.316 456.83 Q104.696 460.001 104.696 465.418 Q104.696 470.996 101.223 474.098 Q97.7511 477.177 91.4317 477.177 Q89.2558 477.177 86.9873 476.806 Q84.7419 476.436 82.3346 475.695 L82.3346 470.996 Q84.4179 472.13 86.6401 472.686 Q88.8623 473.242 91.3391 473.242 Q95.3437 473.242 97.6817 471.135 Q100.02 469.029 100.02 465.418 Q100.02 461.806 97.6817 459.7 Q95.3437 457.594 91.3391 457.594 Q89.4641 457.594 87.5892 458.01 Q85.7373 458.427 83.7929 459.306 L83.7929 441.945 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M56.6171 143.74 L72.9365 143.74 L72.9365 147.675 L50.9921 147.675 L50.9921 143.74 Q53.6541 140.986 58.2375 136.356 Q62.8439 131.703 64.0245 130.361 Q66.2698 127.838 67.1494 126.101 Q68.0522 124.342 68.0522 122.652 Q68.0522 119.898 66.1078 118.162 Q64.1865 116.426 61.0847 116.426 Q58.8856 116.426 56.4319 117.189 Q54.0014 117.953 51.2236 119.504 L51.2236 114.782 Q54.0477 113.648 56.5014 113.069 Q58.955 112.49 60.9921 112.49 Q66.3624 112.49 69.5568 115.176 Q72.7513 117.861 72.7513 122.351 Q72.7513 124.481 71.9411 126.402 Q71.1541 128.3 69.0476 130.893 Q68.4689 131.564 65.367 134.782 Q62.2652 137.976 56.6171 143.74 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M92.7512 116.194 Q89.1401 116.194 87.3114 119.759 Q85.5058 123.3 85.5058 130.43 Q85.5058 137.537 87.3114 141.101 Q89.1401 144.643 92.7512 144.643 Q96.3854 144.643 98.1909 141.101 Q100.02 137.537 100.02 130.43 Q100.02 123.3 98.1909 119.759 Q96.3854 116.194 92.7512 116.194 M92.7512 112.49 Q98.5613 112.49 101.617 117.097 Q104.696 121.68 104.696 130.43 Q104.696 139.157 101.617 143.763 Q98.5613 148.347 92.7512 148.347 Q86.941 148.347 83.8623 143.763 Q80.8068 139.157 80.8068 130.43 Q80.8068 121.68 83.8623 117.097 Q86.941 112.49 92.7512 112.49 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip062)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  203.301,1432.63 270.619,1415.48 337.936,1445.72 405.254,1443.01 472.572,1445.72 539.89,1445.72 607.207,1440.63 674.525,1445.05 741.843,1444.46 809.161,1445.06 \n",
       "  876.478,1142.82 943.796,87.9763 1011.11,1445.72 1078.43,1445.72 1145.75,1442.49 1213.07,1426.42 1280.38,1445.72 1347.7,1437.55 1415.02,1315.58 1482.34,1408.74 \n",
       "  1549.66,796.112 1616.97,541.042 1684.29,1443.68 1751.61,1401.4 1818.93,1445.72 1886.24,1418.45 1953.56,1445.72 2020.88,1441.09 2088.2,1445.72 2155.51,1440.51 \n",
       "  2222.83,1025.26 2290.15,1445.72 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip060)\" d=\"\n",
       "M1980.81 198.898 L2279.02 198.898 L2279.02 95.2176 L1980.81 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1980.81,198.898 2279.02,198.898 2279.02,95.2176 1980.81,95.2176 1980.81,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip060)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2005.38,147.058 2152.85,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip060)\" d=\"M2191.28 166.745 Q2189.47 171.375 2187.76 172.787 Q2186.04 174.199 2183.17 174.199 L2179.77 174.199 L2179.77 170.634 L2182.27 170.634 Q2184.03 170.634 2185 169.8 Q2185.98 168.967 2187.16 165.865 L2187.92 163.921 L2177.43 138.412 L2181.95 138.412 L2190.05 158.689 L2198.15 138.412 L2202.66 138.412 L2191.28 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M2209.96 160.402 L2217.6 160.402 L2217.6 134.037 L2209.29 135.703 L2209.29 131.444 L2217.55 129.778 L2222.22 129.778 L2222.22 160.402 L2229.86 160.402 L2229.86 164.338 L2209.96 164.338 L2209.96 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    bestEpSc    = -100.0;\n",
    "    statesBest  = zeros( size( X_0, 1 ), T )\n",
    "    actionsBest = zeros( T );\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/(episodes-1)\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        \n",
    "        s_l = 0.0\n",
    "        # while s_l == 0\n",
    "        \n",
    "            X  = X_0\n",
    "\n",
    "            ##### Double Q-Learning ###########################################\n",
    "\n",
    "            for k = 1:T\n",
    "\n",
    "                # 1. Choose action\n",
    "                if rand() < epsilon\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                else\n",
    "\n",
    "                    A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                    if A == 1000.0 # Indicates no values in this region\n",
    "                        if rand() < EXPrand \n",
    "                            A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                        else\n",
    "                            A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                # 2. Cache last state\n",
    "                qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "                # 3. Generate the next stae\n",
    "                Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "                # 4. Collect reward R( s, a, s' )\n",
    "                R_t = cartpole_reward( Xp )\n",
    "\n",
    "                # 5. Get the optimal action at the next state\n",
    "                a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "                # 6. Compute the value at the next state\n",
    "\n",
    "                V_tp1_opt = query_value_fuzzy( \n",
    "                    Q_kdTree, G, V, \n",
    "                    get_Q( \n",
    "                        select_X_vector( Xp ), \n",
    "                        a_tp1_opt \n",
    "                    ); \n",
    "                    k = vNN \n",
    "                )\n",
    "                if isnan( V_tp1_opt )\n",
    "                    V_tp1_opt = 0.0\n",
    "                end\n",
    "\n",
    "\n",
    "                # 7. Blend the value back into nearest points\n",
    "\n",
    "                idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "                nNear      = size( idxs, 1 )\n",
    "                for i = 1:nNear\n",
    "                    j    = idxs[i]\n",
    "                    if !isnan( wgts[i] ) \n",
    "\n",
    "                        # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                        VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                states[:,k] = Xp\n",
    "                actions[k]  = A\n",
    "\n",
    "                X = Xp\n",
    "            end\n",
    "\n",
    "            s_l    = vertical_score_s( states, aMargin, ts )\n",
    "            \n",
    "        # end\n",
    "            \n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if s_l > bestEpSc\n",
    "            bestEpSc    = s_l\n",
    "            statesBest  = copy( states  )\n",
    "            actionsBest = copy( actions )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        # if useElig && (s_l > s_Totl/(1.0*l)) && (s_l > 0.0) \n",
    "        # if useElig && (s_l > 0.0) \n",
    "        if useElig \n",
    "            \n",
    "            # if s_l == 0.0\n",
    "            #     states  = copy( bestXs )\n",
    "            #     actions = copy( bestAs )\n",
    "            # end\n",
    "            \n",
    "            # println( \"Assign eligibility for a history with score \", s_l )\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
