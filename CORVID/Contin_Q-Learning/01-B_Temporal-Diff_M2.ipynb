{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.02148 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 # 0.00782 # 0.00391\n",
    "gamma    = 1.00 \n",
    "swapDiv  = 64\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes = 128 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   =  16 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "beta   = 0.15\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = false\n",
    "N_peaks =  40\n",
    "N_steps = 200\n",
    "lambda  =   0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.19000000000000003, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.19000000000000003, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.4200000000000002, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.21000000000000005, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.36000000000000015, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.3300000000000001, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.17, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.24000000000000007, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.3000000000000001, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.09999999999999999, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.46000000000000024, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.15, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.25000000000000006, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.26000000000000006, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.7700000000000005, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.16, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.3200000000000001, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.24000000000000007, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.17, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.6700000000000004, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.25000000000000006, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.16, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.21000000000000005, epsilon: 0.00390625\n",
      "Average Score: 0.24148437500000014\n",
      "\n",
      "Epoch 2, Best Score: 1.7200000000000013\n",
      "Training Iteration 4 score: 0.5500000000000003, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.17, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.37000000000000016, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.5100000000000002, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.10999999999999999, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.16, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.09999999999999999, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.09999999999999999, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.09601562500000005\n",
      "\n",
      "Epoch 3, Best Score: 1.7200000000000013\n",
      "Training Iteration 4 score: 0.20000000000000004, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.19000000000000003, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.12999999999999998, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.35000000000000014, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.22000000000000006, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.09, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.07304687500000002\n",
      "\n",
      "Epoch 4, Best Score: 1.7200000000000013\n",
      "Training Iteration 4 score: 0.19000000000000003, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.36000000000000015, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.3100000000000001, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.4200000000000002, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.3100000000000001, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.21000000000000005, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.12999999999999998, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.6100000000000003, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.08, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.06500000000000003\n",
      "\n",
      "Epoch 5, Best Score: 1.7200000000000013\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.24000000000000007, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.19000000000000003, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.6300000000000003, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.6200000000000003, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 1.0000000000000007, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.6700000000000004, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.10999999999999999, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.6300000000000003, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.46000000000000024, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.48000000000000026, epsilon: 0.00390625\n",
      "Average Score: 0.12968750000000007\n",
      "\n",
      "Epoch 6, Best Score: 1.7200000000000013\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.45000000000000023, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 1.290000000000001, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.06796875000000005\n",
      "\n",
      "Epoch 7, Best Score: 1.7200000000000013\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.6100000000000003, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.3300000000000001, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.25000000000000006, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.2900000000000001, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.2700000000000001, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.25000000000000006, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.12999999999999998, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.13999999999999999, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.7000000000000004, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.45000000000000023, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.23000000000000007, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.12999999999999998, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.13999999999999999, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.2097656249999991\n",
      "\n",
      "Epoch 8, Best Score: 7.25999999999989\n",
      "Training Iteration 4 score: 0.3000000000000001, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.3200000000000001, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.22000000000000006, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.34000000000000014, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.5600000000000003, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.18000000000000002, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.19000000000000003, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.2800000000000001, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.25000000000000006, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.12999999999999998, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.2900000000000001, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.6300000000000003, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.22000000000000006, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.3100000000000001, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.23000000000000007, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.17, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.19000000000000003, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.12999999999999998, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.18000000000000002, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.17, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.3100000000000001, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.2800000000000001, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.15, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.18148437500000003\n",
      "\n",
      "Epoch 9, Best Score: 7.25999999999989\n",
      "Training Iteration 4 score: 0.26000000000000006, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.19000000000000003, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.11999999999999998, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.4000000000000002, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.4300000000000002, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.3100000000000001, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.26000000000000006, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.36000000000000015, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.35000000000000014, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.26000000000000006, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.17, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.11999999999999998, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.23000000000000007, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.15, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.13242187500000005\n",
      "\n",
      "Epoch 10, Best Score: 7.25999999999989\n",
      "Training Iteration 4 score: 0.25000000000000006, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.49000000000000027, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.6100000000000003, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.5000000000000002, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.47000000000000025, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.4100000000000002, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.21000000000000005, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.6300000000000003, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.09999999999999999, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.35000000000000014, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.25000000000000006, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.5000000000000002, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.4100000000000002, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.7200000000000004, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.16, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.09999999999999999, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.45000000000000023, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.7600000000000005, epsilon: 0.00390625\n",
      "Average Score: 0.18976562500000008\n",
      "\n",
      "Epoch 11, Best Score: 7.25999999999989\n",
      "Training Iteration 4 score: 0.21000000000000005, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.18000000000000002, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.12999999999999998, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.21000000000000005, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.9300000000000006, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.18000000000000002, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.11999999999999998, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.12999999999999998, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.37000000000000016, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.6500000000000004, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.11999999999999998, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.5500000000000003, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.12273437500000005\n",
      "\n",
      "Epoch 12, Best Score: 7.25999999999989\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.15, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.009531250000000003\n",
      "\n",
      "Epoch 13, Best Score: 7.25999999999989\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.003593750000000001\n",
      "\n",
      "Epoch 14, Best Score: 7.25999999999989\n",
      "Training Iteration 4 score: 0.4100000000000002, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.12999999999999998, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 1.1900000000000008, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.47000000000000025, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.08, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.5500000000000003, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.12999999999999998, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.11023437500000008\n",
      "\n",
      "Epoch 15, Best Score: 7.25999999999989\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.005937500000000003\n",
      "\n",
      "Epoch 16, Best Score: 7.25999999999989\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.2700000000000001, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.0021093750000000006\n",
      "Saved a trained Q-table with size (76032,), After 12.966490884621939 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip540\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip540)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip541\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip540)\" d=\"\n",
       "M186.274 1486.45 L2352.76 1486.45 L2352.76 47.2441 L186.274 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip542\">\n",
       "    <rect x=\"186\" y=\"47\" width=\"2167\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip542)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  520.103,1486.45 520.103,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip542)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  928.873,1486.45 928.873,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip542)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1337.64,1486.45 1337.64,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip542)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1746.41,1486.45 1746.41,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip542)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2155.18,1486.45 2155.18,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  520.103,1486.45 520.103,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  928.873,1486.45 928.873,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1337.64,1486.45 1337.64,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1746.41,1486.45 1746.41,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2155.18,1486.45 2155.18,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip540)\" d=\"M524.351 1530.21 Q527.707 1530.93 529.582 1533.2 Q531.48 1535.47 531.48 1538.8 Q531.48 1543.92 527.962 1546.72 Q524.443 1549.52 517.962 1549.52 Q515.786 1549.52 513.471 1549.08 Q511.179 1548.66 508.726 1547.81 L508.726 1543.29 Q510.67 1544.43 512.985 1545.01 Q515.3 1545.58 517.823 1545.58 Q522.221 1545.58 524.513 1543.85 Q526.827 1542.11 526.827 1538.8 Q526.827 1535.75 524.675 1534.03 Q522.545 1532.3 518.726 1532.3 L514.698 1532.3 L514.698 1528.45 L518.911 1528.45 Q522.36 1528.45 524.189 1527.09 Q526.017 1525.7 526.017 1523.11 Q526.017 1520.45 524.119 1519.03 Q522.244 1517.6 518.726 1517.6 Q516.804 1517.6 514.605 1518.01 Q512.406 1518.43 509.767 1519.31 L509.767 1515.14 Q512.429 1514.4 514.744 1514.03 Q517.082 1513.66 519.142 1513.66 Q524.466 1513.66 527.568 1516.09 Q530.67 1518.5 530.67 1522.62 Q530.67 1525.49 529.027 1527.48 Q527.383 1529.45 524.351 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M929.278 1529.7 Q926.13 1529.7 924.278 1531.86 Q922.45 1534.01 922.45 1537.76 Q922.45 1541.49 924.278 1543.66 Q926.13 1545.82 929.278 1545.82 Q932.426 1545.82 934.255 1543.66 Q936.107 1541.49 936.107 1537.76 Q936.107 1534.01 934.255 1531.86 Q932.426 1529.7 929.278 1529.7 M938.561 1515.05 L938.561 1519.31 Q936.801 1518.48 934.996 1518.04 Q933.213 1517.6 931.454 1517.6 Q926.825 1517.6 924.371 1520.72 Q921.94 1523.85 921.593 1530.17 Q922.959 1528.15 925.019 1527.09 Q927.079 1526 929.556 1526 Q934.764 1526 937.774 1529.17 Q940.806 1532.32 940.806 1537.76 Q940.806 1543.08 937.658 1546.3 Q934.51 1549.52 929.278 1549.52 Q923.283 1549.52 920.112 1544.94 Q916.94 1540.33 916.94 1531.6 Q916.94 1523.41 920.829 1518.55 Q924.718 1513.66 931.269 1513.66 Q933.028 1513.66 934.811 1514.01 Q936.616 1514.36 938.561 1515.05 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M1327.94 1548.13 L1327.94 1543.87 Q1329.7 1544.7 1331.51 1545.14 Q1333.31 1545.58 1335.05 1545.58 Q1339.68 1545.58 1342.11 1542.48 Q1344.56 1539.36 1344.91 1533.01 Q1343.57 1535.01 1341.51 1536.07 Q1339.45 1537.13 1336.95 1537.13 Q1331.76 1537.13 1328.73 1534.01 Q1325.72 1530.86 1325.72 1525.42 Q1325.72 1520.1 1328.87 1516.88 Q1332.02 1513.66 1337.25 1513.66 Q1343.25 1513.66 1346.39 1518.27 Q1349.56 1522.85 1349.56 1531.6 Q1349.56 1539.77 1345.68 1544.66 Q1341.81 1549.52 1335.26 1549.52 Q1333.5 1549.52 1331.69 1549.17 Q1329.89 1548.82 1327.94 1548.13 M1337.25 1533.48 Q1340.4 1533.48 1342.23 1531.32 Q1344.08 1529.17 1344.08 1525.42 Q1344.08 1521.7 1342.23 1519.54 Q1340.4 1517.37 1337.25 1517.37 Q1334.1 1517.37 1332.25 1519.54 Q1330.42 1521.7 1330.42 1525.42 Q1330.42 1529.17 1332.25 1531.32 Q1334.1 1533.48 1337.25 1533.48 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M1721.9 1544.91 L1729.54 1544.91 L1729.54 1518.55 L1721.23 1520.21 L1721.23 1515.95 L1729.49 1514.29 L1734.17 1514.29 L1734.17 1544.91 L1741.81 1544.91 L1741.81 1548.85 L1721.9 1548.85 L1721.9 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M1755.28 1544.91 L1771.6 1544.91 L1771.6 1548.85 L1749.65 1548.85 L1749.65 1544.91 Q1752.32 1542.16 1756.9 1537.53 Q1761.51 1532.88 1762.69 1531.53 Q1764.93 1529.01 1765.81 1527.27 Q1766.71 1525.51 1766.71 1523.82 Q1766.71 1521.07 1764.77 1519.33 Q1762.85 1517.6 1759.75 1517.6 Q1757.55 1517.6 1755.09 1518.36 Q1752.66 1519.13 1749.89 1520.68 L1749.89 1515.95 Q1752.71 1514.82 1755.16 1514.24 Q1757.62 1513.66 1759.65 1513.66 Q1765.02 1513.66 1768.22 1516.35 Q1771.41 1519.03 1771.41 1523.52 Q1771.41 1525.65 1770.6 1527.57 Q1769.82 1529.47 1767.71 1532.07 Q1767.13 1532.74 1764.03 1535.95 Q1760.93 1539.15 1755.28 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M2130.37 1544.91 L2138.01 1544.91 L2138.01 1518.55 L2129.7 1520.21 L2129.7 1515.95 L2137.96 1514.29 L2142.64 1514.29 L2142.64 1544.91 L2150.28 1544.91 L2150.28 1548.85 L2130.37 1548.85 L2130.37 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M2159.77 1514.29 L2178.12 1514.29 L2178.12 1518.22 L2164.05 1518.22 L2164.05 1526.7 Q2165.07 1526.35 2166.09 1526.19 Q2167.1 1526 2168.12 1526 Q2173.91 1526 2177.29 1529.17 Q2180.67 1532.34 2180.67 1537.76 Q2180.67 1543.34 2177.2 1546.44 Q2173.73 1549.52 2167.41 1549.52 Q2165.23 1549.52 2162.96 1549.15 Q2160.72 1548.78 2158.31 1548.04 L2158.31 1543.34 Q2160.39 1544.47 2162.61 1545.03 Q2164.84 1545.58 2167.31 1545.58 Q2171.32 1545.58 2173.66 1543.48 Q2175.99 1541.37 2175.99 1537.76 Q2175.99 1534.15 2173.66 1532.04 Q2171.32 1529.94 2167.31 1529.94 Q2165.44 1529.94 2163.56 1530.35 Q2161.71 1530.77 2159.77 1531.65 L2159.77 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip542)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,1457.68 2352.76,1457.68 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip542)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,1174.08 2352.76,1174.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip542)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,890.478 2352.76,890.478 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip542)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,606.877 2352.76,606.877 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip542)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,323.276 2352.76,323.276 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,1486.45 186.274,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,1457.68 205.172,1457.68 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,1174.08 205.172,1174.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,890.478 205.172,890.478 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,606.877 205.172,606.877 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,323.276 205.172,323.276 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip540)\" d=\"M62.9365 1443.48 Q59.3254 1443.48 57.4967 1447.04 Q55.6912 1450.59 55.6912 1457.71 Q55.6912 1464.82 57.4967 1468.39 Q59.3254 1471.93 62.9365 1471.93 Q66.5707 1471.93 68.3763 1468.39 Q70.205 1464.82 70.205 1457.71 Q70.205 1450.59 68.3763 1447.04 Q66.5707 1443.48 62.9365 1443.48 M62.9365 1439.78 Q68.7467 1439.78 71.8022 1444.38 Q74.8809 1448.96 74.8809 1457.71 Q74.8809 1466.44 71.8022 1471.05 Q68.7467 1475.63 62.9365 1475.63 Q57.1264 1475.63 54.0477 1471.05 Q50.9921 1466.44 50.9921 1457.71 Q50.9921 1448.96 54.0477 1444.38 Q57.1264 1439.78 62.9365 1439.78 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M83.0984 1469.08 L87.9827 1469.08 L87.9827 1474.96 L83.0984 1474.96 L83.0984 1469.08 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M108.168 1443.48 Q104.557 1443.48 102.728 1447.04 Q100.922 1450.59 100.922 1457.71 Q100.922 1464.82 102.728 1468.39 Q104.557 1471.93 108.168 1471.93 Q111.802 1471.93 113.608 1468.39 Q115.436 1464.82 115.436 1457.71 Q115.436 1450.59 113.608 1447.04 Q111.802 1443.48 108.168 1443.48 M108.168 1439.78 Q113.978 1439.78 117.033 1444.38 Q120.112 1448.96 120.112 1457.71 Q120.112 1466.44 117.033 1471.05 Q113.978 1475.63 108.168 1475.63 Q102.358 1475.63 99.2789 1471.05 Q96.2234 1466.44 96.2234 1457.71 Q96.2234 1448.96 99.2789 1444.38 Q102.358 1439.78 108.168 1439.78 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M138.33 1443.48 Q134.719 1443.48 132.89 1447.04 Q131.084 1450.59 131.084 1457.71 Q131.084 1464.82 132.89 1468.39 Q134.719 1471.93 138.33 1471.93 Q141.964 1471.93 143.769 1468.39 Q145.598 1464.82 145.598 1457.71 Q145.598 1450.59 143.769 1447.04 Q141.964 1443.48 138.33 1443.48 M138.33 1439.78 Q144.14 1439.78 147.195 1444.38 Q150.274 1448.96 150.274 1457.71 Q150.274 1466.44 147.195 1471.05 Q144.14 1475.63 138.33 1475.63 Q132.519 1475.63 129.441 1471.05 Q126.385 1466.44 126.385 1457.71 Q126.385 1448.96 129.441 1444.38 Q132.519 1439.78 138.33 1439.78 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M63.9319 1159.88 Q60.3208 1159.88 58.4921 1163.44 Q56.6865 1166.98 56.6865 1174.11 Q56.6865 1181.22 58.4921 1184.79 Q60.3208 1188.33 63.9319 1188.33 Q67.5661 1188.33 69.3717 1184.79 Q71.2004 1181.22 71.2004 1174.11 Q71.2004 1166.98 69.3717 1163.44 Q67.5661 1159.88 63.9319 1159.88 M63.9319 1156.17 Q69.742 1156.17 72.7976 1160.78 Q75.8763 1165.36 75.8763 1174.11 Q75.8763 1182.84 72.7976 1187.45 Q69.742 1192.03 63.9319 1192.03 Q58.1217 1192.03 55.043 1187.45 Q51.9875 1182.84 51.9875 1174.11 Q51.9875 1165.36 55.043 1160.78 Q58.1217 1156.17 63.9319 1156.17 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M84.0938 1185.48 L88.978 1185.48 L88.978 1191.36 L84.0938 1191.36 L84.0938 1185.48 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M109.163 1159.88 Q105.552 1159.88 103.723 1163.44 Q101.918 1166.98 101.918 1174.11 Q101.918 1181.22 103.723 1184.79 Q105.552 1188.33 109.163 1188.33 Q112.797 1188.33 114.603 1184.79 Q116.432 1181.22 116.432 1174.11 Q116.432 1166.98 114.603 1163.44 Q112.797 1159.88 109.163 1159.88 M109.163 1156.17 Q114.973 1156.17 118.029 1160.78 Q121.107 1165.36 121.107 1174.11 Q121.107 1182.84 118.029 1187.45 Q114.973 1192.03 109.163 1192.03 Q103.353 1192.03 100.274 1187.45 Q97.2187 1182.84 97.2187 1174.11 Q97.2187 1165.36 100.274 1160.78 Q103.353 1156.17 109.163 1156.17 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M129.371 1156.8 L147.728 1156.8 L147.728 1160.73 L133.654 1160.73 L133.654 1169.21 Q134.672 1168.86 135.691 1168.7 Q136.709 1168.51 137.728 1168.51 Q143.515 1168.51 146.894 1171.68 Q150.274 1174.85 150.274 1180.27 Q150.274 1185.85 146.802 1188.95 Q143.33 1192.03 137.01 1192.03 Q134.834 1192.03 132.566 1191.66 Q130.32 1191.29 127.913 1190.55 L127.913 1185.85 Q129.996 1186.98 132.219 1187.54 Q134.441 1188.1 136.918 1188.1 Q140.922 1188.1 143.26 1185.99 Q145.598 1183.88 145.598 1180.27 Q145.598 1176.66 143.26 1174.55 Q140.922 1172.45 136.918 1172.45 Q135.043 1172.45 133.168 1172.86 Q131.316 1173.28 129.371 1174.16 L129.371 1156.8 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M62.9365 876.277 Q59.3254 876.277 57.4967 879.842 Q55.6912 883.383 55.6912 890.513 Q55.6912 897.619 57.4967 901.184 Q59.3254 904.726 62.9365 904.726 Q66.5707 904.726 68.3763 901.184 Q70.205 897.619 70.205 890.513 Q70.205 883.383 68.3763 879.842 Q66.5707 876.277 62.9365 876.277 M62.9365 872.573 Q68.7467 872.573 71.8022 877.18 Q74.8809 881.763 74.8809 890.513 Q74.8809 899.24 71.8022 903.846 Q68.7467 908.43 62.9365 908.43 Q57.1264 908.43 54.0477 903.846 Q50.9921 899.24 50.9921 890.513 Q50.9921 881.763 54.0477 877.18 Q57.1264 872.573 62.9365 872.573 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M83.0984 901.879 L87.9827 901.879 L87.9827 907.758 L83.0984 907.758 L83.0984 901.879 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M98.978 903.823 L106.617 903.823 L106.617 877.457 L98.3067 879.124 L98.3067 874.865 L106.571 873.198 L111.246 873.198 L111.246 903.823 L118.885 903.823 L118.885 907.758 L98.978 907.758 L98.978 903.823 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M138.33 876.277 Q134.719 876.277 132.89 879.842 Q131.084 883.383 131.084 890.513 Q131.084 897.619 132.89 901.184 Q134.719 904.726 138.33 904.726 Q141.964 904.726 143.769 901.184 Q145.598 897.619 145.598 890.513 Q145.598 883.383 143.769 879.842 Q141.964 876.277 138.33 876.277 M138.33 872.573 Q144.14 872.573 147.195 877.18 Q150.274 881.763 150.274 890.513 Q150.274 899.24 147.195 903.846 Q144.14 908.43 138.33 908.43 Q132.519 908.43 129.441 903.846 Q126.385 899.24 126.385 890.513 Q126.385 881.763 129.441 877.18 Q132.519 872.573 138.33 872.573 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M63.9319 592.676 Q60.3208 592.676 58.4921 596.241 Q56.6865 599.782 56.6865 606.912 Q56.6865 614.019 58.4921 617.583 Q60.3208 621.125 63.9319 621.125 Q67.5661 621.125 69.3717 617.583 Q71.2004 614.019 71.2004 606.912 Q71.2004 599.782 69.3717 596.241 Q67.5661 592.676 63.9319 592.676 M63.9319 588.972 Q69.742 588.972 72.7976 593.579 Q75.8763 598.162 75.8763 606.912 Q75.8763 615.639 72.7976 620.245 Q69.742 624.829 63.9319 624.829 Q58.1217 624.829 55.043 620.245 Q51.9875 615.639 51.9875 606.912 Q51.9875 598.162 55.043 593.579 Q58.1217 588.972 63.9319 588.972 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M84.0938 618.278 L88.978 618.278 L88.978 624.157 L84.0938 624.157 L84.0938 618.278 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M99.9733 620.222 L107.612 620.222 L107.612 593.857 L99.3021 595.523 L99.3021 591.264 L107.566 589.597 L112.242 589.597 L112.242 620.222 L119.881 620.222 L119.881 624.157 L99.9733 624.157 L99.9733 620.222 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M129.371 589.597 L147.728 589.597 L147.728 593.533 L133.654 593.533 L133.654 602.005 Q134.672 601.657 135.691 601.495 Q136.709 601.31 137.728 601.31 Q143.515 601.31 146.894 604.482 Q150.274 607.653 150.274 613.069 Q150.274 618.648 146.802 621.75 Q143.33 624.829 137.01 624.829 Q134.834 624.829 132.566 624.458 Q130.32 624.088 127.913 623.347 L127.913 618.648 Q129.996 619.782 132.219 620.338 Q134.441 620.893 136.918 620.893 Q140.922 620.893 143.26 618.787 Q145.598 616.681 145.598 613.069 Q145.598 609.458 143.26 607.352 Q140.922 605.245 136.918 605.245 Q135.043 605.245 133.168 605.662 Q131.316 606.079 129.371 606.958 L129.371 589.597 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M62.9365 309.075 Q59.3254 309.075 57.4967 312.64 Q55.6912 316.182 55.6912 323.311 Q55.6912 330.418 57.4967 333.982 Q59.3254 337.524 62.9365 337.524 Q66.5707 337.524 68.3763 333.982 Q70.205 330.418 70.205 323.311 Q70.205 316.182 68.3763 312.64 Q66.5707 309.075 62.9365 309.075 M62.9365 305.371 Q68.7467 305.371 71.8022 309.978 Q74.8809 314.561 74.8809 323.311 Q74.8809 332.038 71.8022 336.644 Q68.7467 341.228 62.9365 341.228 Q57.1264 341.228 54.0477 336.644 Q50.9921 332.038 50.9921 323.311 Q50.9921 314.561 54.0477 309.978 Q57.1264 305.371 62.9365 305.371 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M83.0984 334.677 L87.9827 334.677 L87.9827 340.556 L83.0984 340.556 L83.0984 334.677 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M102.196 336.621 L118.515 336.621 L118.515 340.556 L96.5706 340.556 L96.5706 336.621 Q99.2326 333.867 103.816 329.237 Q108.422 324.584 109.603 323.242 Q111.848 320.719 112.728 318.982 Q113.631 317.223 113.631 315.533 Q113.631 312.779 111.686 311.043 Q109.765 309.307 106.663 309.307 Q104.464 309.307 102.01 310.07 Q99.5798 310.834 96.8021 312.385 L96.8021 307.663 Q99.6261 306.529 102.08 305.95 Q104.534 305.371 106.571 305.371 Q111.941 305.371 115.135 308.057 Q118.33 310.742 118.33 315.232 Q118.33 317.362 117.52 319.283 Q116.733 321.182 114.626 323.774 Q114.047 324.445 110.946 327.663 Q107.844 330.857 102.196 336.621 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M138.33 309.075 Q134.719 309.075 132.89 312.64 Q131.084 316.182 131.084 323.311 Q131.084 330.418 132.89 333.982 Q134.719 337.524 138.33 337.524 Q141.964 337.524 143.769 333.982 Q145.598 330.418 145.598 323.311 Q145.598 316.182 143.769 312.64 Q141.964 309.075 138.33 309.075 M138.33 305.371 Q144.14 305.371 147.195 309.978 Q150.274 314.561 150.274 323.311 Q150.274 332.038 147.195 336.644 Q144.14 341.228 138.33 341.228 Q132.519 341.228 129.441 336.644 Q126.385 332.038 126.385 323.311 Q126.385 314.561 129.441 309.978 Q132.519 305.371 138.33 305.371 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip542)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  247.59,87.9763 383.846,913.078 520.103,1043.36 656.36,1089 792.616,722.09 928.873,1072.16 1065.13,267.886 1201.39,428.297 1337.64,706.581 1473.9,381.326 \n",
       "  1610.16,761.528 1746.41,1403.62 1882.67,1437.3 2018.93,832.429 2155.18,1424 2291.44,1445.72 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip540)\" d=\"\n",
       "M1987.39 198.898 L2280.54 198.898 L2280.54 95.2176 L1987.39 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1987.39,198.898 2280.54,198.898 2280.54,95.2176 1987.39,95.2176 1987.39,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2011.46,147.058 2155.89,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip540)\" d=\"M2193.81 166.745 Q2192 171.375 2190.29 172.787 Q2188.58 174.199 2185.71 174.199 L2182.3 174.199 L2182.3 170.634 L2184.8 170.634 Q2186.56 170.634 2187.53 169.8 Q2188.51 168.967 2189.69 165.865 L2190.45 163.921 L2179.97 138.412 L2184.48 138.412 L2192.58 158.689 L2200.68 138.412 L2205.2 138.412 L2193.81 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M2212.49 160.402 L2220.13 160.402 L2220.13 134.037 L2211.82 135.703 L2211.82 131.444 L2220.08 129.778 L2224.76 129.778 L2224.76 160.402 L2232.4 160.402 L2232.4 164.338 L2212.49 164.338 L2212.49 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/episodes\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        X  = X_0\n",
    "        \n",
    "        ##### Double Q-Learning ###########################################\n",
    "\n",
    "        for k = 1:T\n",
    "\n",
    "            # 1. Choose action\n",
    "            if rand() < epsilon\n",
    "                if rand() < EXPrand \n",
    "                    A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                else\n",
    "                    A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                end\n",
    "            else\n",
    "\n",
    "                A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                if A == 1000.0 # Indicates no values in this region\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "\n",
    "            # 2. Cache last state\n",
    "            qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "            # 3. Generate the next stae\n",
    "            Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "            # 4. Collect reward R( s, a, s' )\n",
    "            R_t = cartpole_reward( Xp )\n",
    "\n",
    "            # 5. Get the optimal action at the next state\n",
    "            a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "            # 6. Compute the value at the next state\n",
    "\n",
    "            V_tp1_opt = query_value_fuzzy( \n",
    "                Q_kdTree, G, V, \n",
    "                get_Q( \n",
    "                    select_X_vector( Xp ), \n",
    "                    a_tp1_opt \n",
    "                ); \n",
    "                k = vNN \n",
    "            )\n",
    "            if isnan( V_tp1_opt )\n",
    "                V_tp1_opt = 0.0\n",
    "            end\n",
    "\n",
    "\n",
    "            # 7. Blend the value back into nearest points\n",
    "\n",
    "            idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "            nNear      = size( idxs, 1 )\n",
    "            for i = 1:nNear\n",
    "                j    = idxs[i]\n",
    "                if !isnan( wgts[i] ) \n",
    "\n",
    "                    # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                    VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "                    \n",
    "                end\n",
    "            end\n",
    "\n",
    "            states[:,k] = Xp\n",
    "            actions[k]  = A\n",
    "\n",
    "            X = Xp\n",
    "        end\n",
    "\n",
    "        s_l    = vertical_score_s( states, aMargin, ts )\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        if useElig\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709555b9-2598-4281-a634-c7b0681277d0",
   "metadata": {},
   "source": [
    "# Method 2 Performance, Average Vertical Duration [s]\n",
    "Each score is the best average score of the last two epochs: 64 epochs of 64 episodes each, Q-function swap after every episode \n",
    "\n",
    "### TD Tuning\n",
    "\n",
    "$\\alpha = 0.99$: 0.238  \n",
    "$\\alpha = 0.75$: 0.257  \n",
    "$\\alpha = 0.50$: 0.191   \n",
    "$\\alpha = 0.25$: 0.170  \n",
    "$\\alpha = 0.125$: 0.290  \n",
    "$\\alpha = 0.0625$: 0.208, but fantastic performance in the middle of training  \n",
    "$\\alpha = 0.03125$: 0.978  \n",
    "$\\alpha = 0.02344$: 2.567  \n",
    "$\\alpha = 0.01953$: 0.268  \n",
    "$\\alpha = 0.015625$: 0.095  \n",
    " \n",
    "### Add gamma?\n",
    " \n",
    "### Double-Q Tuning, Swap Evey N Episodes\n",
    "$\\%\\ \\ 2$:  \n",
    "$\\%\\ \\ 4$:  \n",
    "$\\%\\ \\ 8$:  \n",
    "$\\%16$:  \n",
    "$\\%32$:  \n",
    "$\\%64$:  \n",
    "\n",
    "\n",
    "\n",
    "### Blend: Best Episode\n",
    "\n",
    "$\\beta = 0.07$:  \n",
    "$\\beta = 0.15$: 0.244\n",
    "\n",
    "| Method      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n",
    "| ----------- | ------- | ------- | ------- | ------- | ------- | ---- |\n",
    "| Blend (Epi) |         |         |         |         |         |      |\n",
    "| Blend (Epo) |         |         |         |         |         |      |\n",
    "| TD          |         |         |         |         |         |      |\n",
    "| TD  + ????? |         |         |         |         |         |      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
