{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.02148 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 # 0.00782 # 0.00391\n",
    "beta     = 0.80\n",
    "gamma    = 1.00 \n",
    "swapDiv  = 64\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes = 64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   = 32 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = true\n",
    "N_peaks =  32\n",
    "N_steps = 128\n",
    "lambda  =   0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.5600000000000003, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.03, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.47000000000000025, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.17, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.36000000000000015, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.18000000000000002, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.4100000000000002, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.17, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.5100000000000002, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.23000000000000007, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.17984375000000005\n",
      "\n",
      "Epoch 2, Best Score: 0.7700000000000005\n",
      "Training Iteration 4 score: 0.10999999999999999, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.5400000000000003, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.6000000000000003, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 1.1900000000000008, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.2700000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.12999999999999998, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.8000000000000005, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.18000000000000002, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.5600000000000003, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 1.470000000000001, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.6600000000000004, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.49000000000000027, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.6900000000000004, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.37000000000000016, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.4865625000000004\n",
      "\n",
      "Epoch 3, Best Score: 1.6900000000000013\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 4, Best Score: 1.6900000000000013\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 5, Best Score: 1.6900000000000013\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.16, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.6100000000000003, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.7500000000000004, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 1.500000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.5000000000000002, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.22000000000000006, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.24078125000000017\n",
      "\n",
      "Epoch 6, Best Score: 1.7200000000000013\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.10999999999999999, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.34000000000000014, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.12999999999999998, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.09999999999999999, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.08, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.09, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.09999999999999999, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.19000000000000003, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.13999999999999999, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.10109375\n",
      "\n",
      "Epoch 7, Best Score: 1.7200000000000013\n",
      "Training Iteration 4 score: 0.6000000000000003, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.17, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.49000000000000027, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.10531250000000003\n",
      "\n",
      "Epoch 8, Best Score: 1.7200000000000013\n",
      "Training Iteration 4 score: 0.24000000000000007, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.08, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.5700000000000003, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.26000000000000006, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.45000000000000023, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.14609375000000008\n",
      "\n",
      "Epoch 9, Best Score: 1.7200000000000013\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.010156250000000006\n",
      "\n",
      "Epoch 10, Best Score: 1.7200000000000013\n",
      "Training Iteration 4 score: 0.2900000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.4200000000000002, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.19000000000000003, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.6500000000000004, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.4100000000000002, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.24000000000000007, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.22000000000000006, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.1510937500000001\n",
      "\n",
      "Epoch 11, Best Score: 1.7200000000000013\n",
      "Training Iteration 4 score: 0.26000000000000006, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 1.0500000000000007, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.20000000000000004, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.044687500000000026\n",
      "\n",
      "Epoch 12, Best Score: 1.7200000000000013\n",
      "Training Iteration 4 score: 0.7300000000000004, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.6600000000000004, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.3300000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.6500000000000004, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.9700000000000006, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.1400000000000008, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.6500000000000004, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.45000000000000023, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.6000000000000003, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.36250000000000016\n",
      "\n",
      "Epoch 13, Best Score: 1.7200000000000013\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.04265624999999999\n",
      "\n",
      "Epoch 14, Best Score: 2.0899999999999994\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.2900000000000001, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 1.0000000000000007, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.10999999999999999, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.5300000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.21000000000000005, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.2700000000000001, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.7500000000000004, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.1721875000000001\n",
      "\n",
      "Epoch 15, Best Score: 2.0899999999999994\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.3100000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.23000000000000007, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.01, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.05187500000000002\n",
      "\n",
      "Epoch 16, Best Score: 2.0899999999999994\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.2800000000000001, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.6000000000000003, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.17, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.21000000000000005, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.45000000000000023, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.5200000000000002, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.15828125000000004\n",
      "\n",
      "Epoch 17, Best Score: 2.0899999999999994\n",
      "Training Iteration 4 score: 0.2900000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.24000000000000007, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.35000000000000014, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 2.1399999999999983, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.36000000000000015, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.3000000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.7900000000000005, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.21000000000000005, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.5700000000000003, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.26000000000000006, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.2700000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.41781250000000014\n",
      "\n",
      "Epoch 18, Best Score: 2.1399999999999983\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.36000000000000015, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.18000000000000002, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.8900000000000006, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 1.300000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.49000000000000027, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.0300000000000007, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.9300000000000006, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 1.460000000000001, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.4100000000000002, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 1.8400000000000014, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.40406249999999955\n",
      "\n",
      "Epoch 19, Best Score: 4.009999999999959\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.2800000000000001, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 1.0700000000000007, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.19000000000000003, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.10999999999999999, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.6700000000000004, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.1600000000000008, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.7200000000000004, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.3300000000000001, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.5000000000000002, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.3565625000000002\n",
      "\n",
      "Epoch 20, Best Score: 4.009999999999959\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.23000000000000007, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 1.6000000000000012, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.21000000000000005, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.5900000000000003, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.24000000000000007, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.35000000000000014, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.9200000000000006, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.48000000000000026, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 1.380000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.3687500000000001\n",
      "\n",
      "Epoch 21, Best Score: 4.009999999999959\n",
      "Training Iteration 4 score: 0.8300000000000005, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.20000000000000004, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.16, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.10375000000000006\n",
      "\n",
      "Epoch 22, Best Score: 4.009999999999959\n",
      "Training Iteration 4 score: 0.6900000000000004, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 1.8700000000000014, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.25000000000000006, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.9200000000000006, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.7300000000000004, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.21734374999999964\n",
      "\n",
      "Epoch 23, Best Score: 4.009999999999959\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.5900000000000003, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.47000000000000025, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.6500000000000004, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.7300000000000004, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.11843750000000008\n",
      "\n",
      "Epoch 24, Best Score: 4.009999999999959\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.5200000000000002, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.5800000000000012, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.14562499999999964\n",
      "\n",
      "Epoch 25, Best Score: 4.009999999999959\n",
      "Training Iteration 4 score: 0.4400000000000002, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.15, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.21000000000000005, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.4000000000000002, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.7300000000000004, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.6500000000000004, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.5000000000000002, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.6900000000000004, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.49000000000000027, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.6900000000000004, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.2900000000000001, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.4014062500000003\n",
      "\n",
      "Epoch 26, Best Score: 4.009999999999959\n",
      "Training Iteration 4 score: 1.1900000000000008, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.11999999999999998, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.4300000000000002, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 3.569999999999968, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 6.669999999999902, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 1.1506249999999905\n",
      "\n",
      "Epoch 27, Best Score: 18.04000000000002\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.6200000000000003, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.4300000000000002, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.10999999999999999, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.6400000000000003, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.8900000000000006, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.2900000000000001, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.37953124999999793\n",
      "\n",
      "Epoch 28, Best Score: 18.04000000000002\n",
      "Training Iteration 4 score: 0.2800000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.47000000000000025, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.18000000000000002, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.4000000000000002, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.35000000000000014, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.36000000000000015, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.10921875000000007\n",
      "\n",
      "Epoch 29, Best Score: 18.04000000000002\n",
      "Training Iteration 4 score: 0.49000000000000027, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.24000000000000007, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.23000000000000007, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.7000000000000004, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.09984375000000006\n",
      "\n",
      "Epoch 30, Best Score: 18.04000000000002\n",
      "Training Iteration 4 score: 0.7200000000000004, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.11999999999999998, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.4100000000000002, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 5.899999999999919, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.3281249999999974\n",
      "\n",
      "Epoch 31, Best Score: 18.04000000000002\n",
      "Training Iteration 4 score: 0.2800000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.5700000000000003, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.05906250000000004\n",
      "\n",
      "Epoch 32, Best Score: 18.04000000000002\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.8700000000000006, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.10968750000000006\n",
      "Saved a trained Q-table with size (76032,), After 27.270767350991566 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip130\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip130)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip131\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip130)\" d=\"\n",
       "M186.274 1486.45 L2352.76 1486.45 L2352.76 47.2441 L186.274 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip132\">\n",
       "    <rect x=\"186\" y=\"47\" width=\"2167\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip132)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  511.312,1486.45 511.312,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip132)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  840.966,1486.45 840.966,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip132)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1170.62,1486.45 1170.62,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip132)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1500.27,1486.45 1500.27,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip132)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1829.93,1486.45 1829.93,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip132)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2159.58,1486.45 2159.58,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  511.312,1486.45 511.312,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  840.966,1486.45 840.966,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1170.62,1486.45 1170.62,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1500.27,1486.45 1500.27,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1829.93,1486.45 1829.93,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2159.58,1486.45 2159.58,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip130)\" d=\"M501.59 1514.29 L519.946 1514.29 L519.946 1518.22 L505.872 1518.22 L505.872 1526.7 Q506.891 1526.35 507.909 1526.19 Q508.928 1526 509.946 1526 Q515.733 1526 519.113 1529.17 Q522.493 1532.34 522.493 1537.76 Q522.493 1543.34 519.021 1546.44 Q515.548 1549.52 509.229 1549.52 Q507.053 1549.52 504.784 1549.15 Q502.539 1548.78 500.132 1548.04 L500.132 1543.34 Q502.215 1544.47 504.437 1545.03 Q506.659 1545.58 509.136 1545.58 Q513.141 1545.58 515.479 1543.48 Q517.817 1541.37 517.817 1537.76 Q517.817 1534.15 515.479 1532.04 Q513.141 1529.94 509.136 1529.94 Q507.261 1529.94 505.386 1530.35 Q503.534 1530.77 501.59 1531.65 L501.59 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M815.653 1544.91 L823.292 1544.91 L823.292 1518.55 L814.982 1520.21 L814.982 1515.95 L823.246 1514.29 L827.922 1514.29 L827.922 1544.91 L835.561 1544.91 L835.561 1548.85 L815.653 1548.85 L815.653 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M855.005 1517.37 Q851.394 1517.37 849.565 1520.93 Q847.76 1524.47 847.76 1531.6 Q847.76 1538.71 849.565 1542.27 Q851.394 1545.82 855.005 1545.82 Q858.639 1545.82 860.445 1542.27 Q862.273 1538.71 862.273 1531.6 Q862.273 1524.47 860.445 1520.93 Q858.639 1517.37 855.005 1517.37 M855.005 1513.66 Q860.815 1513.66 863.871 1518.27 Q866.949 1522.85 866.949 1531.6 Q866.949 1540.33 863.871 1544.94 Q860.815 1549.52 855.005 1549.52 Q849.195 1549.52 846.116 1544.94 Q843.06 1540.33 843.06 1531.6 Q843.06 1522.85 846.116 1518.27 Q849.195 1513.66 855.005 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M1145.8 1544.91 L1153.44 1544.91 L1153.44 1518.55 L1145.13 1520.21 L1145.13 1515.95 L1153.4 1514.29 L1158.07 1514.29 L1158.07 1544.91 L1165.71 1544.91 L1165.71 1548.85 L1145.8 1548.85 L1145.8 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M1175.2 1514.29 L1193.56 1514.29 L1193.56 1518.22 L1179.48 1518.22 L1179.48 1526.7 Q1180.5 1526.35 1181.52 1526.19 Q1182.54 1526 1183.56 1526 Q1189.35 1526 1192.73 1529.17 Q1196.1 1532.34 1196.1 1537.76 Q1196.1 1543.34 1192.63 1546.44 Q1189.16 1549.52 1182.84 1549.52 Q1180.67 1549.52 1178.4 1549.15 Q1176.15 1548.78 1173.74 1548.04 L1173.74 1543.34 Q1175.83 1544.47 1178.05 1545.03 Q1180.27 1545.58 1182.75 1545.58 Q1186.75 1545.58 1189.09 1543.48 Q1191.43 1541.37 1191.43 1537.76 Q1191.43 1534.15 1189.09 1532.04 Q1186.75 1529.94 1182.75 1529.94 Q1180.87 1529.94 1179 1530.35 Q1177.15 1530.77 1175.2 1531.65 L1175.2 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M1479.05 1544.91 L1495.36 1544.91 L1495.36 1548.85 L1473.42 1548.85 L1473.42 1544.91 Q1476.08 1542.16 1480.67 1537.53 Q1485.27 1532.88 1486.45 1531.53 Q1488.7 1529.01 1489.58 1527.27 Q1490.48 1525.51 1490.48 1523.82 Q1490.48 1521.07 1488.54 1519.33 Q1486.61 1517.6 1483.51 1517.6 Q1481.31 1517.6 1478.86 1518.36 Q1476.43 1519.13 1473.65 1520.68 L1473.65 1515.95 Q1476.48 1514.82 1478.93 1514.24 Q1481.38 1513.66 1483.42 1513.66 Q1488.79 1513.66 1491.99 1516.35 Q1495.18 1519.03 1495.18 1523.52 Q1495.18 1525.65 1494.37 1527.57 Q1493.58 1529.47 1491.48 1532.07 Q1490.9 1532.74 1487.8 1535.95 Q1484.69 1539.15 1479.05 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M1515.18 1517.37 Q1511.57 1517.37 1509.74 1520.93 Q1507.93 1524.47 1507.93 1531.6 Q1507.93 1538.71 1509.74 1542.27 Q1511.57 1545.82 1515.18 1545.82 Q1518.81 1545.82 1520.62 1542.27 Q1522.45 1538.71 1522.45 1531.6 Q1522.45 1524.47 1520.62 1520.93 Q1518.81 1517.37 1515.18 1517.37 M1515.18 1513.66 Q1520.99 1513.66 1524.05 1518.27 Q1527.12 1522.85 1527.12 1531.6 Q1527.12 1540.33 1524.05 1544.94 Q1520.99 1549.52 1515.18 1549.52 Q1509.37 1549.52 1506.29 1544.94 Q1503.24 1540.33 1503.24 1531.6 Q1503.24 1522.85 1506.29 1518.27 Q1509.37 1513.66 1515.18 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M1809.2 1544.91 L1825.52 1544.91 L1825.52 1548.85 L1803.57 1548.85 L1803.57 1544.91 Q1806.23 1542.16 1810.82 1537.53 Q1815.42 1532.88 1816.6 1531.53 Q1818.85 1529.01 1819.73 1527.27 Q1820.63 1525.51 1820.63 1523.82 Q1820.63 1521.07 1818.69 1519.33 Q1816.77 1517.6 1813.66 1517.6 Q1811.47 1517.6 1809.01 1518.36 Q1806.58 1519.13 1803.8 1520.68 L1803.8 1515.95 Q1806.63 1514.82 1809.08 1514.24 Q1811.53 1513.66 1813.57 1513.66 Q1818.94 1513.66 1822.14 1516.35 Q1825.33 1519.03 1825.33 1523.52 Q1825.33 1525.65 1824.52 1527.57 Q1823.73 1529.47 1821.63 1532.07 Q1821.05 1532.74 1817.95 1535.95 Q1814.84 1539.15 1809.2 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M1835.38 1514.29 L1853.73 1514.29 L1853.73 1518.22 L1839.66 1518.22 L1839.66 1526.7 Q1840.68 1526.35 1841.7 1526.19 Q1842.71 1526 1843.73 1526 Q1849.52 1526 1852.9 1529.17 Q1856.28 1532.34 1856.28 1537.76 Q1856.28 1543.34 1852.81 1546.44 Q1849.34 1549.52 1843.02 1549.52 Q1840.84 1549.52 1838.57 1549.15 Q1836.33 1548.78 1833.92 1548.04 L1833.92 1543.34 Q1836 1544.47 1838.22 1545.03 Q1840.45 1545.58 1842.92 1545.58 Q1846.93 1545.58 1849.27 1543.48 Q1851.6 1541.37 1851.6 1537.76 Q1851.6 1534.15 1849.27 1532.04 Q1846.93 1529.94 1842.92 1529.94 Q1841.05 1529.94 1839.17 1530.35 Q1837.32 1530.77 1835.38 1531.65 L1835.38 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M2148.42 1530.21 Q2151.78 1530.93 2153.65 1533.2 Q2155.55 1535.47 2155.55 1538.8 Q2155.55 1543.92 2152.03 1546.72 Q2148.51 1549.52 2142.03 1549.52 Q2139.86 1549.52 2137.54 1549.08 Q2135.25 1548.66 2132.8 1547.81 L2132.8 1543.29 Q2134.74 1544.43 2137.06 1545.01 Q2139.37 1545.58 2141.89 1545.58 Q2146.29 1545.58 2148.58 1543.85 Q2150.9 1542.11 2150.9 1538.8 Q2150.9 1535.75 2148.75 1534.03 Q2146.62 1532.3 2142.8 1532.3 L2138.77 1532.3 L2138.77 1528.45 L2142.98 1528.45 Q2146.43 1528.45 2148.26 1527.09 Q2150.09 1525.7 2150.09 1523.11 Q2150.09 1520.45 2148.19 1519.03 Q2146.32 1517.6 2142.8 1517.6 Q2140.88 1517.6 2138.68 1518.01 Q2136.48 1518.43 2133.84 1519.31 L2133.84 1515.14 Q2136.5 1514.4 2138.82 1514.03 Q2141.15 1513.66 2143.21 1513.66 Q2148.54 1513.66 2151.64 1516.09 Q2154.74 1518.5 2154.74 1522.62 Q2154.74 1525.49 2153.1 1527.48 Q2151.45 1529.45 2148.42 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M2174.42 1517.37 Q2170.81 1517.37 2168.98 1520.93 Q2167.17 1524.47 2167.17 1531.6 Q2167.17 1538.71 2168.98 1542.27 Q2170.81 1545.82 2174.42 1545.82 Q2178.05 1545.82 2179.86 1542.27 Q2181.69 1538.71 2181.69 1531.6 Q2181.69 1524.47 2179.86 1520.93 Q2178.05 1517.37 2174.42 1517.37 M2174.42 1513.66 Q2180.23 1513.66 2183.28 1518.27 Q2186.36 1522.85 2186.36 1531.6 Q2186.36 1540.33 2183.28 1544.94 Q2180.23 1549.52 2174.42 1549.52 Q2168.61 1549.52 2165.53 1544.94 Q2162.47 1540.33 2162.47 1531.6 Q2162.47 1522.85 2165.53 1518.27 Q2168.61 1513.66 2174.42 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip132)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,1445.72 2352.76,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip132)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,1150.72 2352.76,1150.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip132)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,855.715 2352.76,855.715 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip132)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,560.714 2352.76,560.714 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip132)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.274,265.714 2352.76,265.714 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,1486.45 186.274,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,1445.72 205.172,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,1150.72 205.172,1150.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,855.715 205.172,855.715 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,560.714 205.172,560.714 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.274,265.714 205.172,265.714 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip130)\" d=\"M62.9365 1431.51 Q59.3254 1431.51 57.4967 1435.08 Q55.6912 1438.62 55.6912 1445.75 Q55.6912 1452.86 57.4967 1456.42 Q59.3254 1459.96 62.9365 1459.96 Q66.5707 1459.96 68.3763 1456.42 Q70.205 1452.86 70.205 1445.75 Q70.205 1438.62 68.3763 1435.08 Q66.5707 1431.51 62.9365 1431.51 M62.9365 1427.81 Q68.7467 1427.81 71.8022 1432.42 Q74.8809 1437 74.8809 1445.75 Q74.8809 1454.48 71.8022 1459.08 Q68.7467 1463.67 62.9365 1463.67 Q57.1264 1463.67 54.0477 1459.08 Q50.9921 1454.48 50.9921 1445.75 Q50.9921 1437 54.0477 1432.42 Q57.1264 1427.81 62.9365 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M83.0984 1457.12 L87.9827 1457.12 L87.9827 1463 L83.0984 1463 L83.0984 1457.12 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M108.168 1431.51 Q104.557 1431.51 102.728 1435.08 Q100.922 1438.62 100.922 1445.75 Q100.922 1452.86 102.728 1456.42 Q104.557 1459.96 108.168 1459.96 Q111.802 1459.96 113.608 1456.42 Q115.436 1452.86 115.436 1445.75 Q115.436 1438.62 113.608 1435.08 Q111.802 1431.51 108.168 1431.51 M108.168 1427.81 Q113.978 1427.81 117.033 1432.42 Q120.112 1437 120.112 1445.75 Q120.112 1454.48 117.033 1459.08 Q113.978 1463.67 108.168 1463.67 Q102.358 1463.67 99.2789 1459.08 Q96.2234 1454.48 96.2234 1445.75 Q96.2234 1437 99.2789 1432.42 Q102.358 1427.81 108.168 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M138.33 1431.51 Q134.719 1431.51 132.89 1435.08 Q131.084 1438.62 131.084 1445.75 Q131.084 1452.86 132.89 1456.42 Q134.719 1459.96 138.33 1459.96 Q141.964 1459.96 143.769 1456.42 Q145.598 1452.86 145.598 1445.75 Q145.598 1438.62 143.769 1435.08 Q141.964 1431.51 138.33 1431.51 M138.33 1427.81 Q144.14 1427.81 147.195 1432.42 Q150.274 1437 150.274 1445.75 Q150.274 1454.48 147.195 1459.08 Q144.14 1463.67 138.33 1463.67 Q132.519 1463.67 129.441 1459.08 Q126.385 1454.48 126.385 1445.75 Q126.385 1437 129.441 1432.42 Q132.519 1427.81 138.33 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M63.9319 1136.51 Q60.3208 1136.51 58.4921 1140.08 Q56.6865 1143.62 56.6865 1150.75 Q56.6865 1157.86 58.4921 1161.42 Q60.3208 1164.96 63.9319 1164.96 Q67.5661 1164.96 69.3717 1161.42 Q71.2004 1157.86 71.2004 1150.75 Q71.2004 1143.62 69.3717 1140.08 Q67.5661 1136.51 63.9319 1136.51 M63.9319 1132.81 Q69.742 1132.81 72.7976 1137.42 Q75.8763 1142 75.8763 1150.75 Q75.8763 1159.48 72.7976 1164.08 Q69.742 1168.67 63.9319 1168.67 Q58.1217 1168.67 55.043 1164.08 Q51.9875 1159.48 51.9875 1150.75 Q51.9875 1142 55.043 1137.42 Q58.1217 1132.81 63.9319 1132.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M84.0938 1162.12 L88.978 1162.12 L88.978 1168 L84.0938 1168 L84.0938 1162.12 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M103.191 1164.06 L119.51 1164.06 L119.51 1168 L97.566 1168 L97.566 1164.06 Q100.228 1161.31 104.811 1156.68 Q109.418 1152.02 110.598 1150.68 Q112.844 1148.16 113.723 1146.42 Q114.626 1144.66 114.626 1142.97 Q114.626 1140.22 112.682 1138.48 Q110.76 1136.75 107.658 1136.75 Q105.459 1136.75 103.006 1137.51 Q100.575 1138.27 97.7974 1139.82 L97.7974 1135.1 Q100.621 1133.97 103.075 1133.39 Q105.529 1132.81 107.566 1132.81 Q112.936 1132.81 116.131 1135.5 Q119.325 1138.18 119.325 1142.67 Q119.325 1144.8 118.515 1146.72 Q117.728 1148.62 115.621 1151.21 Q115.043 1151.88 111.941 1155.1 Q108.839 1158.3 103.191 1164.06 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M129.371 1133.44 L147.728 1133.44 L147.728 1137.37 L133.654 1137.37 L133.654 1145.84 Q134.672 1145.5 135.691 1145.33 Q136.709 1145.15 137.728 1145.15 Q143.515 1145.15 146.894 1148.32 Q150.274 1151.49 150.274 1156.91 Q150.274 1162.49 146.802 1165.59 Q143.33 1168.67 137.01 1168.67 Q134.834 1168.67 132.566 1168.3 Q130.32 1167.93 127.913 1167.19 L127.913 1162.49 Q129.996 1163.62 132.219 1164.18 Q134.441 1164.73 136.918 1164.73 Q140.922 1164.73 143.26 1162.62 Q145.598 1160.52 145.598 1156.91 Q145.598 1153.3 143.26 1151.19 Q140.922 1149.08 136.918 1149.08 Q135.043 1149.08 133.168 1149.5 Q131.316 1149.92 129.371 1150.8 L129.371 1133.44 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M62.9365 841.514 Q59.3254 841.514 57.4967 845.078 Q55.6912 848.62 55.6912 855.75 Q55.6912 862.856 57.4967 866.421 Q59.3254 869.962 62.9365 869.962 Q66.5707 869.962 68.3763 866.421 Q70.205 862.856 70.205 855.75 Q70.205 848.62 68.3763 845.078 Q66.5707 841.514 62.9365 841.514 M62.9365 837.81 Q68.7467 837.81 71.8022 842.416 Q74.8809 847 74.8809 855.75 Q74.8809 864.476 71.8022 869.083 Q68.7467 873.666 62.9365 873.666 Q57.1264 873.666 54.0477 869.083 Q50.9921 864.476 50.9921 855.75 Q50.9921 847 54.0477 842.416 Q57.1264 837.81 62.9365 837.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M83.0984 867.115 L87.9827 867.115 L87.9827 872.995 L83.0984 872.995 L83.0984 867.115 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M98.2141 838.435 L116.57 838.435 L116.57 842.37 L102.496 842.37 L102.496 850.842 Q103.515 850.495 104.534 850.333 Q105.552 850.148 106.571 850.148 Q112.358 850.148 115.737 853.319 Q119.117 856.49 119.117 861.907 Q119.117 867.486 115.645 870.587 Q112.172 873.666 105.853 873.666 Q103.677 873.666 101.409 873.296 Q99.1632 872.925 96.7558 872.185 L96.7558 867.486 Q98.8391 868.62 101.061 869.175 Q103.284 869.731 105.76 869.731 Q109.765 869.731 112.103 867.625 Q114.441 865.518 114.441 861.907 Q114.441 858.296 112.103 856.189 Q109.765 854.083 105.76 854.083 Q103.885 854.083 102.01 854.5 Q100.159 854.916 98.2141 855.796 L98.2141 838.435 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M138.33 841.514 Q134.719 841.514 132.89 845.078 Q131.084 848.62 131.084 855.75 Q131.084 862.856 132.89 866.421 Q134.719 869.962 138.33 869.962 Q141.964 869.962 143.769 866.421 Q145.598 862.856 145.598 855.75 Q145.598 848.62 143.769 845.078 Q141.964 841.514 138.33 841.514 M138.33 837.81 Q144.14 837.81 147.195 842.416 Q150.274 847 150.274 855.75 Q150.274 864.476 147.195 869.083 Q144.14 873.666 138.33 873.666 Q132.519 873.666 129.441 869.083 Q126.385 864.476 126.385 855.75 Q126.385 847 129.441 842.416 Q132.519 837.81 138.33 837.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M63.9319 546.513 Q60.3208 546.513 58.4921 550.078 Q56.6865 553.62 56.6865 560.749 Q56.6865 567.856 58.4921 571.42 Q60.3208 574.962 63.9319 574.962 Q67.5661 574.962 69.3717 571.42 Q71.2004 567.856 71.2004 560.749 Q71.2004 553.62 69.3717 550.078 Q67.5661 546.513 63.9319 546.513 M63.9319 542.809 Q69.742 542.809 72.7976 547.416 Q75.8763 551.999 75.8763 560.749 Q75.8763 569.476 72.7976 574.082 Q69.742 578.666 63.9319 578.666 Q58.1217 578.666 55.043 574.082 Q51.9875 569.476 51.9875 560.749 Q51.9875 551.999 55.043 547.416 Q58.1217 542.809 63.9319 542.809 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M84.0938 572.115 L88.978 572.115 L88.978 577.994 L84.0938 577.994 L84.0938 572.115 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M97.9826 543.434 L120.205 543.434 L120.205 545.425 L107.658 577.994 L102.774 577.994 L114.58 547.37 L97.9826 547.37 L97.9826 543.434 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M129.371 543.434 L147.728 543.434 L147.728 547.37 L133.654 547.37 L133.654 555.842 Q134.672 555.495 135.691 555.333 Q136.709 555.147 137.728 555.147 Q143.515 555.147 146.894 558.319 Q150.274 561.49 150.274 566.907 Q150.274 572.485 146.802 575.587 Q143.33 578.666 137.01 578.666 Q134.834 578.666 132.566 578.295 Q130.32 577.925 127.913 577.184 L127.913 572.485 Q129.996 573.619 132.219 574.175 Q134.441 574.731 136.918 574.731 Q140.922 574.731 143.26 572.624 Q145.598 570.518 145.598 566.907 Q145.598 563.295 143.26 561.189 Q140.922 559.083 136.918 559.083 Q135.043 559.083 133.168 559.499 Q131.316 559.916 129.371 560.795 L129.371 543.434 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M53.7467 279.059 L61.3856 279.059 L61.3856 252.693 L53.0754 254.36 L53.0754 250.101 L61.3393 248.434 L66.0152 248.434 L66.0152 279.059 L73.654 279.059 L73.654 282.994 L53.7467 282.994 L53.7467 279.059 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M83.0984 277.114 L87.9827 277.114 L87.9827 282.994 L83.0984 282.994 L83.0984 277.114 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M108.168 251.513 Q104.557 251.513 102.728 255.078 Q100.922 258.619 100.922 265.749 Q100.922 272.855 102.728 276.42 Q104.557 279.962 108.168 279.962 Q111.802 279.962 113.608 276.42 Q115.436 272.855 115.436 265.749 Q115.436 258.619 113.608 255.078 Q111.802 251.513 108.168 251.513 M108.168 247.809 Q113.978 247.809 117.033 252.415 Q120.112 256.999 120.112 265.749 Q120.112 274.476 117.033 279.082 Q113.978 283.665 108.168 283.665 Q102.358 283.665 99.2789 279.082 Q96.2234 274.476 96.2234 265.749 Q96.2234 256.999 99.2789 252.415 Q102.358 247.809 108.168 247.809 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M138.33 251.513 Q134.719 251.513 132.89 255.078 Q131.084 258.619 131.084 265.749 Q131.084 272.855 132.89 276.42 Q134.719 279.962 138.33 279.962 Q141.964 279.962 143.769 276.42 Q145.598 272.855 145.598 265.749 Q145.598 258.619 143.769 255.078 Q141.964 251.513 138.33 251.513 M138.33 247.809 Q144.14 247.809 147.195 252.415 Q150.274 256.999 150.274 265.749 Q150.274 274.476 147.195 279.082 Q144.14 283.665 138.33 283.665 Q132.519 283.665 129.441 279.082 Q126.385 274.476 126.385 265.749 Q126.385 256.999 129.441 252.415 Q132.519 247.809 138.33 247.809 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip132)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  247.59,1233.5 313.52,871.571 379.451,1445.72 445.382,1445.72 511.312,1161.59 577.243,1326.42 643.174,1321.45 709.104,1273.32 775.035,1433.73 840.966,1267.42 \n",
       "  906.896,1392.98 972.827,1017.97 1038.76,1395.38 1104.69,1242.53 1170.62,1384.5 1236.55,1258.94 1302.48,952.696 1368.41,968.921 1434.34,1024.97 1500.27,1010.59 \n",
       "  1566.2,1323.29 1632.13,1189.25 1698.06,1305.96 1763.99,1273.88 1829.93,972.056 1895.86,87.9763 1961.79,997.868 2027.72,1316.84 2093.65,1327.9 2159.58,1058.53 \n",
       "  2225.51,1376.02 2291.44,1316.28 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip130)\" d=\"\n",
       "M258.49 198.898 L527.569 198.898 L527.569 95.2176 L258.49 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  258.49,198.898 527.569,198.898 527.569,95.2176 258.49,95.2176 258.49,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip130)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  282.562,147.058 426.994,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip130)\" d=\"M464.909 166.745 Q463.103 171.375 461.39 172.787 Q459.677 174.199 456.807 174.199 L453.404 174.199 L453.404 170.634 L455.904 170.634 Q457.663 170.634 458.636 169.8 Q459.608 168.967 460.788 165.865 L461.552 163.921 L451.066 138.412 L455.58 138.412 L463.682 158.689 L471.784 138.412 L476.298 138.412 L464.909 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip130)\" d=\"M483.589 160.402 L491.228 160.402 L491.228 134.037 L482.918 135.703 L482.918 131.444 L491.182 129.778 L495.858 129.778 L495.858 160.402 L503.497 160.402 L503.497 164.338 L483.589 164.338 L483.589 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    bestEpSc    = -100.0;\n",
    "    statesBest  = zeros( size( X_0, 1 ), T )\n",
    "    actionsBest = zeros( T );\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/(episodes-1)\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        s_l = 0.0\n",
    "        # while s_l == 0\n",
    "        \n",
    "            X  = X_0\n",
    "\n",
    "            ##### Double Q-Learning ###########################################\n",
    "\n",
    "            for k = 1:T\n",
    "\n",
    "                # 1. Choose action\n",
    "                if rand() < epsilon\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                else\n",
    "\n",
    "                    A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                    if A == 1000.0 # Indicates no values in this region\n",
    "                        if rand() < EXPrand \n",
    "                            A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                        else\n",
    "                            A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                # 2. Cache last state\n",
    "                qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "                # 3. Generate the next stae\n",
    "                Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "                # 4. Collect reward R( s, a, s' )\n",
    "                R_t = cartpole_reward( Xp )\n",
    "\n",
    "                # 5. Get the optimal action at the next state\n",
    "                a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "                # 6. Compute the value at the next state\n",
    "\n",
    "                V_tp1_opt = query_value_fuzzy( \n",
    "                    Q_kdTree, G, V, \n",
    "                    get_Q( \n",
    "                        select_X_vector( Xp ), \n",
    "                        a_tp1_opt \n",
    "                    ); \n",
    "                    k = vNN \n",
    "                )\n",
    "                if isnan( V_tp1_opt )\n",
    "                    V_tp1_opt = 0.0\n",
    "                end\n",
    "\n",
    "\n",
    "                # 7. Blend the value back into nearest points\n",
    "\n",
    "                idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "                nNear      = size( idxs, 1 )\n",
    "                for i = 1:nNear\n",
    "                    j    = idxs[i]\n",
    "                    if !isnan( wgts[i] ) \n",
    "\n",
    "                        # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                        VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                states[:,k] = Xp\n",
    "                actions[k]  = A\n",
    "\n",
    "                X = Xp\n",
    "            end\n",
    "\n",
    "            s_l    = vertical_score_s( states, aMargin, ts )\n",
    "            \n",
    "        # end\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if s_l > bestEpSc\n",
    "            bestEpSc    = s_l\n",
    "            statesBest  = copy( states  )\n",
    "            actionsBest = copy( actions )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        # if useElig && (s_l > s_Totl/(1.0*l)) && (s_l > 0.0) \n",
    "        # if useElig && (s_l > 0.0) \n",
    "        if useElig \n",
    "            \n",
    "            # if s_l == 0.0\n",
    "            #     states  = copy( bestXs )\n",
    "            #     actions = copy( bestAs )\n",
    "            # end\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "    \n",
    "    ##### Learning Rate Schedule ##########################################\n",
    "    alpha *= beta\n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709555b9-2598-4281-a634-c7b0681277d0",
   "metadata": {},
   "source": [
    "# Method 2 Performance, Average Vertical Duration [s]\n",
    "Each score is the best average score of the last two epochs: 64 epochs of 64 episodes each, Q-function swap after every episode \n",
    "\n",
    "### TD Tuning\n",
    "\n",
    "$\\alpha = 0.99$: 0.238  \n",
    "$\\alpha = 0.75$: 0.257  \n",
    "$\\alpha = 0.50$: 0.191   \n",
    "$\\alpha = 0.25$: 0.170  \n",
    "$\\alpha = 0.125$: 0.290  \n",
    "$\\alpha = 0.0625$: 0.208, but fantastic performance in the middle of training  \n",
    "$\\alpha = 0.03125$: 0.978  \n",
    "$\\alpha = 0.02344$: 2.567  \n",
    "$\\alpha = 0.01953$: 0.268  \n",
    "$\\alpha = 0.015625$: 0.095  \n",
    " \n",
    "### Add gamma?\n",
    " \n",
    "### Double-Q Tuning, Swap Evey N Episodes\n",
    "$\\%\\ \\ 2$:  \n",
    "$\\%\\ \\ 4$:  \n",
    "$\\%\\ \\ 8$:  \n",
    "$\\%16$:  \n",
    "$\\%32$:  \n",
    "$\\%64$:  \n",
    "\n",
    "\n",
    "\n",
    "### Blend: Best Episode\n",
    "\n",
    "$\\beta = 0.07$:  \n",
    "$\\beta = 0.15$: 0.244\n",
    "\n",
    "| Method      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n",
    "| ----------- | ------- | ------- | ------- | ------- | ------- | ---- |\n",
    "| Blend (Epi) |         |         |         |         |         |      |\n",
    "| Blend (Epo) |         |         |         |         |         |      |\n",
    "| TD          |         |         |         |         |         |      |\n",
    "| TD  + ????? |         |         |         |         |         |      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
