{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.02344 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 \n",
    "gamma    = 1.00 \n",
    "swapDiv  = 1\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes =  64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   =  32 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "beta   = 0.15\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = false\n",
    "N_peaks =  40\n",
    "N_steps = 200\n",
    "lambda  =   0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.23000000000000007, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.12999999999999998, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.15, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.08953125000000003\n",
      "\n",
      "Epoch 2, Best Score: 0.6400000000000003\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.023125000000000014\n",
      "\n",
      "Epoch 3, Best Score: 0.8600000000000005\n",
      "Training Iteration 4 score: 0.34000000000000014, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.11999999999999998, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.22000000000000006, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.020468750000000004\n",
      "\n",
      "Epoch 4, Best Score: 0.8600000000000005\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.3300000000000001, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.18000000000000002, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.12999999999999998, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.47000000000000025, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.05578125000000003\n",
      "\n",
      "Epoch 5, Best Score: 1.1000000000000008\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.09999999999999999, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.6000000000000003, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.2800000000000001, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.24000000000000007, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.034843750000000014\n",
      "\n",
      "Epoch 6, Best Score: 1.1000000000000008\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.49187500000001383\n",
      "\n",
      "Epoch 7, Best Score: 24.100000000000968\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.6200000000000003, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 1.6300000000000012, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.5200000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.11687500000000006\n",
      "\n",
      "Epoch 8, Best Score: 24.100000000000968\n",
      "Training Iteration 4 score: 0.19000000000000003, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.23000000000000007, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.11999999999999998, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.13999999999999999, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 1.5700000000000012, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.24000000000000007, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.17, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.055156250000000025\n",
      "\n",
      "Epoch 9, Best Score: 24.100000000000968\n",
      "Training Iteration 4 score: 0.12999999999999998, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.17, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.09, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.15, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.18000000000000002, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.18000000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.13999999999999999, epsilon: 0.0078125\n",
      "Average Score: 0.04125\n",
      "\n",
      "Epoch 10, Best Score: 24.100000000000968\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.09999999999999999, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.3100000000000001, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.3300000000000001, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.21000000000000005, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.03968750000000001\n",
      "\n",
      "Epoch 11, Best Score: 24.100000000000968\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.46000000000000024, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.16, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.35000000000000014, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.22000000000000006, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.5400000000000003, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.47000000000000025, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.5000000000000002, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.23000000000000007, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.35000000000000014, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.10500000000000004\n",
      "\n",
      "Epoch 12, Best Score: 24.100000000000968\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.20000000000000004, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.7000000000000004, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.3200000000000001, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.5700000000000003, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.35000000000000014, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.36000000000000015, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.15812500000000004\n",
      "\n",
      "Epoch 13, Best Score: 24.100000000000968\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.24000000000000007, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.9400000000000006, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.04781250000000003\n",
      "\n",
      "Epoch 14, Best Score: 24.100000000000968\n",
      "Training Iteration 4 score: 1.0400000000000007, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 6.7899999999999, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.17, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.46000000000000024, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.19000000000000003, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.3209374999999986\n",
      "\n",
      "Epoch 15, Best Score: 24.100000000000968\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.48000000000000026, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.2800000000000001, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 3.45999999999997, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.6401562500000154\n",
      "\n",
      "Epoch 16, Best Score: 24.62000000000105\n",
      "Training Iteration 4 score: 0.2700000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.21000000000000005, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.35000000000000014, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.6600000000000004, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.4100000000000002, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.37000000000000016, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.23000000000000007, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.34000000000000014, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.8200000000000005, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.6800000000000004, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.35000000000000014, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.4200000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.4100000000000002, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.28140625000000014\n",
      "\n",
      "Epoch 17, Best Score: 24.62000000000105\n",
      "Training Iteration 4 score: 0.2700000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.4000000000000002, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.8300000000000005, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.10609375000000007\n",
      "\n",
      "Epoch 18, Best Score: 24.62000000000105\n",
      "Training Iteration 4 score: 0.48000000000000026, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.34000000000000014, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.6000000000000003, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 1.0300000000000007, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.4300000000000002, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.5300000000000002, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.3924999999999984\n",
      "\n",
      "Epoch 19, Best Score: 24.62000000000105\n",
      "Training Iteration 4 score: 0.36000000000000015, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.5400000000000003, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 1.8100000000000014, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 2.07, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 1.6900000000000013, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.25000000000000006, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.26000000000000006, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.5000000000000002, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.21000000000000005, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.12999999999999998, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.20000000000000004, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.2800000000000001, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.34000000000000014, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.5828124999999975\n",
      "\n",
      "Epoch 20, Best Score: 24.62000000000105\n",
      "Training Iteration 4 score: 1.300000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.5800000000000003, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.34000000000000014, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.5064062499999994\n",
      "\n",
      "Epoch 21, Best Score: 24.62000000000105\n",
      "Training Iteration 4 score: 0.4000000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.46000000000000024, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.7300000000000004, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 3.8199999999999625, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.10999999999999999, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.15, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 2.6499999999999875, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.3000000000000001, epsilon: 0.0078125\n",
      "Average Score: 0.3909374999999993\n",
      "\n",
      "Epoch 22, Best Score: 24.62000000000105\n",
      "Training Iteration 4 score: 0.15, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.22000000000000006, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.16, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.17, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.17, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.09999999999999999, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.17, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.10999999999999999, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.2700000000000001, epsilon: 0.0078125\n",
      "Average Score: 0.049218750000000006\n",
      "\n",
      "Epoch 23, Best Score: 24.62000000000105\n",
      "Training Iteration 4 score: 0.13999999999999999, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.11999999999999998, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 7.339999999999888, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.13999999999999999, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 1.7400000000000013, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.22999999999999832\n",
      "\n",
      "Epoch 24, Best Score: 24.62000000000105\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.26000000000000006, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.22000000000000006, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.15, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.18578125000000012\n",
      "\n",
      "Epoch 25, Best Score: 24.62000000000105\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.2900000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.11999999999999998, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.10999999999999999, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.3900000000000002, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.09999999999999999, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.26000000000000006, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.15, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.38000000000000017, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.09, epsilon: 0.0078125\n",
      "Average Score: 0.3432812500000001\n",
      "\n",
      "Epoch 26, Best Score: 24.62000000000105\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.17, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.3218750000000001\n",
      "\n",
      "Epoch 27, Best Score: 24.62000000000105\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.48000000000000026, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.5600000000000003, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.13999999999999999, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.5000000000000002, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.20000000000000004, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.2900000000000001, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.5900000000000003, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.5000000000000002, epsilon: 0.0078125\n",
      "Average Score: 0.20234374999999966\n",
      "\n",
      "Epoch 28, Best Score: 24.62000000000105\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.19000000000000003, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.9000000000000006, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.38000000000000017, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.5500000000000003, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.3300000000000001, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.2700000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.6200000000000003, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.08734375000000004\n",
      "\n",
      "Epoch 29, Best Score: 24.62000000000105\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 1.0500000000000007, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.3900000000000002, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.4200000000000002, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.8500000000000005, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.20000000000000004, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.10015625000000007\n",
      "\n",
      "Epoch 30, Best Score: 24.62000000000105\n",
      "Training Iteration 4 score: 0.25000000000000006, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.15, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.3900000000000002, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.4400000000000002, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.07203125000000003\n",
      "\n",
      "Epoch 31, Best Score: 24.62000000000105\n",
      "Training Iteration 4 score: 0.2700000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.16, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.9500000000000006, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.3100000000000001, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.34000000000000014, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.5400000000000003, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.7100000000000004, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.2900000000000001, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.08562500000000003\n",
      "\n",
      "Epoch 32, Best Score: 24.62000000000105\n",
      "Training Iteration 4 score: 0.12999999999999998, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.02578125000000001\n",
      "Saved a trained Q-table with size (76032,), After 12.318262565135957 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip310\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip310)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip311\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip310)\" d=\"\n",
       "M156.598 1486.45 L2352.76 1486.45 L2352.76 47.2441 L156.598 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip312\">\n",
       "    <rect x=\"156\" y=\"47\" width=\"2197\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip312)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  486.089,1486.45 486.089,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip312)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  820.258,1486.45 820.258,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip312)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1154.43,1486.45 1154.43,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip312)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1488.6,1486.45 1488.6,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip312)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1822.76,1486.45 1822.76,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip312)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2156.93,1486.45 2156.93,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip310)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip310)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  486.089,1486.45 486.089,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip310)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  820.258,1486.45 820.258,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip310)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1154.43,1486.45 1154.43,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip310)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1488.6,1486.45 1488.6,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip310)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1822.76,1486.45 1822.76,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip310)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2156.93,1486.45 2156.93,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip310)\" d=\"M476.367 1514.29 L494.723 1514.29 L494.723 1518.22 L480.649 1518.22 L480.649 1526.7 Q481.667 1526.35 482.686 1526.19 Q483.704 1526 484.723 1526 Q490.51 1526 493.89 1529.17 Q497.269 1532.34 497.269 1537.76 Q497.269 1543.34 493.797 1546.44 Q490.325 1549.52 484.005 1549.52 Q481.829 1549.52 479.561 1549.15 Q477.316 1548.78 474.908 1548.04 L474.908 1543.34 Q476.992 1544.47 479.214 1545.03 Q481.436 1545.58 483.913 1545.58 Q487.917 1545.58 490.255 1543.48 Q492.593 1541.37 492.593 1537.76 Q492.593 1534.15 490.255 1532.04 Q487.917 1529.94 483.913 1529.94 Q482.038 1529.94 480.163 1530.35 Q478.311 1530.77 476.367 1531.65 L476.367 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M794.945 1544.91 L802.584 1544.91 L802.584 1518.55 L794.274 1520.21 L794.274 1515.95 L802.538 1514.29 L807.214 1514.29 L807.214 1544.91 L814.853 1544.91 L814.853 1548.85 L794.945 1548.85 L794.945 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M834.297 1517.37 Q830.686 1517.37 828.857 1520.93 Q827.052 1524.47 827.052 1531.6 Q827.052 1538.71 828.857 1542.27 Q830.686 1545.82 834.297 1545.82 Q837.931 1545.82 839.737 1542.27 Q841.565 1538.71 841.565 1531.6 Q841.565 1524.47 839.737 1520.93 Q837.931 1517.37 834.297 1517.37 M834.297 1513.66 Q840.107 1513.66 843.163 1518.27 Q846.241 1522.85 846.241 1531.6 Q846.241 1540.33 843.163 1544.94 Q840.107 1549.52 834.297 1549.52 Q828.487 1549.52 825.408 1544.94 Q822.352 1540.33 822.352 1531.6 Q822.352 1522.85 825.408 1518.27 Q828.487 1513.66 834.297 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M1129.61 1544.91 L1137.25 1544.91 L1137.25 1518.55 L1128.94 1520.21 L1128.94 1515.95 L1137.2 1514.29 L1141.88 1514.29 L1141.88 1544.91 L1149.52 1544.91 L1149.52 1548.85 L1129.61 1548.85 L1129.61 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M1159.01 1514.29 L1177.37 1514.29 L1177.37 1518.22 L1163.29 1518.22 L1163.29 1526.7 Q1164.31 1526.35 1165.33 1526.19 Q1166.35 1526 1167.37 1526 Q1173.15 1526 1176.53 1529.17 Q1179.91 1532.34 1179.91 1537.76 Q1179.91 1543.34 1176.44 1546.44 Q1172.97 1549.52 1166.65 1549.52 Q1164.47 1549.52 1162.2 1549.15 Q1159.96 1548.78 1157.55 1548.04 L1157.55 1543.34 Q1159.63 1544.47 1161.86 1545.03 Q1164.08 1545.58 1166.56 1545.58 Q1170.56 1545.58 1172.9 1543.48 Q1175.24 1541.37 1175.24 1537.76 Q1175.24 1534.15 1172.9 1532.04 Q1170.56 1529.94 1166.56 1529.94 Q1164.68 1529.94 1162.81 1530.35 Q1160.95 1530.77 1159.01 1531.65 L1159.01 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M1467.37 1544.91 L1483.69 1544.91 L1483.69 1548.85 L1461.74 1548.85 L1461.74 1544.91 Q1464.41 1542.16 1468.99 1537.53 Q1473.6 1532.88 1474.78 1531.53 Q1477.02 1529.01 1477.9 1527.27 Q1478.8 1525.51 1478.8 1523.82 Q1478.8 1521.07 1476.86 1519.33 Q1474.94 1517.6 1471.84 1517.6 Q1469.64 1517.6 1467.18 1518.36 Q1464.75 1519.13 1461.98 1520.68 L1461.98 1515.95 Q1464.8 1514.82 1467.25 1514.24 Q1469.71 1513.66 1471.74 1513.66 Q1477.11 1513.66 1480.31 1516.35 Q1483.5 1519.03 1483.5 1523.52 Q1483.5 1525.65 1482.69 1527.57 Q1481.91 1529.47 1479.8 1532.07 Q1479.22 1532.74 1476.12 1535.95 Q1473.02 1539.15 1467.37 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M1503.5 1517.37 Q1499.89 1517.37 1498.06 1520.93 Q1496.26 1524.47 1496.26 1531.6 Q1496.26 1538.71 1498.06 1542.27 Q1499.89 1545.82 1503.5 1545.82 Q1507.14 1545.82 1508.94 1542.27 Q1510.77 1538.71 1510.77 1531.6 Q1510.77 1524.47 1508.94 1520.93 Q1507.14 1517.37 1503.5 1517.37 M1503.5 1513.66 Q1509.31 1513.66 1512.37 1518.27 Q1515.45 1522.85 1515.45 1531.6 Q1515.45 1540.33 1512.37 1544.94 Q1509.31 1549.52 1503.5 1549.52 Q1497.69 1549.52 1494.61 1544.94 Q1491.56 1540.33 1491.56 1531.6 Q1491.56 1522.85 1494.61 1518.27 Q1497.69 1513.66 1503.5 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M1802.04 1544.91 L1818.35 1544.91 L1818.35 1548.85 L1796.41 1548.85 L1796.41 1544.91 Q1799.07 1542.16 1803.66 1537.53 Q1808.26 1532.88 1809.44 1531.53 Q1811.69 1529.01 1812.57 1527.27 Q1813.47 1525.51 1813.47 1523.82 Q1813.47 1521.07 1811.53 1519.33 Q1809.6 1517.6 1806.5 1517.6 Q1804.3 1517.6 1801.85 1518.36 Q1799.42 1519.13 1796.64 1520.68 L1796.64 1515.95 Q1799.47 1514.82 1801.92 1514.24 Q1804.37 1513.66 1806.41 1513.66 Q1811.78 1513.66 1814.97 1516.35 Q1818.17 1519.03 1818.17 1523.52 Q1818.17 1525.65 1817.36 1527.57 Q1816.57 1529.47 1814.47 1532.07 Q1813.89 1532.74 1810.79 1535.95 Q1807.68 1539.15 1802.04 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M1828.22 1514.29 L1846.57 1514.29 L1846.57 1518.22 L1832.5 1518.22 L1832.5 1526.7 Q1833.52 1526.35 1834.53 1526.19 Q1835.55 1526 1836.57 1526 Q1842.36 1526 1845.74 1529.17 Q1849.12 1532.34 1849.12 1537.76 Q1849.12 1543.34 1845.65 1546.44 Q1842.17 1549.52 1835.85 1549.52 Q1833.68 1549.52 1831.41 1549.15 Q1829.16 1548.78 1826.76 1548.04 L1826.76 1543.34 Q1828.84 1544.47 1831.06 1545.03 Q1833.28 1545.58 1835.76 1545.58 Q1839.77 1545.58 1842.1 1543.48 Q1844.44 1541.37 1844.44 1537.76 Q1844.44 1534.15 1842.1 1532.04 Q1839.77 1529.94 1835.76 1529.94 Q1833.89 1529.94 1832.01 1530.35 Q1830.16 1530.77 1828.22 1531.65 L1828.22 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M2145.78 1530.21 Q2149.13 1530.93 2151.01 1533.2 Q2152.91 1535.47 2152.91 1538.8 Q2152.91 1543.92 2149.39 1546.72 Q2145.87 1549.52 2139.39 1549.52 Q2137.21 1549.52 2134.9 1549.08 Q2132.6 1548.66 2130.15 1547.81 L2130.15 1543.29 Q2132.1 1544.43 2134.41 1545.01 Q2136.72 1545.58 2139.25 1545.58 Q2143.65 1545.58 2145.94 1543.85 Q2148.25 1542.11 2148.25 1538.8 Q2148.25 1535.75 2146.1 1534.03 Q2143.97 1532.3 2140.15 1532.3 L2136.12 1532.3 L2136.12 1528.45 L2140.34 1528.45 Q2143.78 1528.45 2145.61 1527.09 Q2147.44 1525.7 2147.44 1523.11 Q2147.44 1520.45 2145.54 1519.03 Q2143.67 1517.6 2140.15 1517.6 Q2138.23 1517.6 2136.03 1518.01 Q2133.83 1518.43 2131.19 1519.31 L2131.19 1515.14 Q2133.85 1514.4 2136.17 1514.03 Q2138.51 1513.66 2140.57 1513.66 Q2145.89 1513.66 2148.99 1516.09 Q2152.1 1518.5 2152.1 1522.62 Q2152.1 1525.49 2150.45 1527.48 Q2148.81 1529.45 2145.78 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M2171.77 1517.37 Q2168.16 1517.37 2166.33 1520.93 Q2164.53 1524.47 2164.53 1531.6 Q2164.53 1538.71 2166.33 1542.27 Q2168.16 1545.82 2171.77 1545.82 Q2175.41 1545.82 2177.21 1542.27 Q2179.04 1538.71 2179.04 1531.6 Q2179.04 1524.47 2177.21 1520.93 Q2175.41 1517.37 2171.77 1517.37 M2171.77 1513.66 Q2177.58 1513.66 2180.64 1518.27 Q2183.72 1522.85 2183.72 1531.6 Q2183.72 1540.33 2180.64 1544.94 Q2177.58 1549.52 2171.77 1549.52 Q2165.96 1549.52 2162.88 1544.94 Q2159.83 1540.33 2159.83 1531.6 Q2159.83 1522.85 2162.88 1518.27 Q2165.96 1513.66 2171.77 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip312)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,1271.46 2352.76,1271.46 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip312)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,1052.36 2352.76,1052.36 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip312)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,833.261 2352.76,833.261 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip312)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,614.16 2352.76,614.16 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip312)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,395.06 2352.76,395.06 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip312)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,175.959 2352.76,175.959 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip310)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1486.45 156.598,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip310)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1271.46 175.496,1271.46 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip310)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1052.36 175.496,1052.36 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip310)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,833.261 175.496,833.261 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip310)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,614.16 175.496,614.16 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip310)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,395.06 175.496,395.06 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip310)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,175.959 175.496,175.959 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip310)\" d=\"M64.6495 1257.26 Q61.0384 1257.26 59.2097 1260.83 Q57.4041 1264.37 57.4041 1271.5 Q57.4041 1278.6 59.2097 1282.17 Q61.0384 1285.71 64.6495 1285.71 Q68.2837 1285.71 70.0892 1282.17 Q71.9179 1278.6 71.9179 1271.5 Q71.9179 1264.37 70.0892 1260.83 Q68.2837 1257.26 64.6495 1257.26 M64.6495 1253.56 Q70.4596 1253.56 73.5152 1258.16 Q76.5938 1262.75 76.5938 1271.5 Q76.5938 1280.22 73.5152 1284.83 Q70.4596 1289.41 64.6495 1289.41 Q58.8393 1289.41 55.7606 1284.83 Q52.7051 1280.22 52.7051 1271.5 Q52.7051 1262.75 55.7606 1258.16 Q58.8393 1253.56 64.6495 1253.56 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M84.8114 1282.86 L89.6956 1282.86 L89.6956 1288.74 L84.8114 1288.74 L84.8114 1282.86 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M100.691 1284.81 L108.33 1284.81 L108.33 1258.44 L100.02 1260.11 L100.02 1255.85 L108.283 1254.18 L112.959 1254.18 L112.959 1284.81 L120.598 1284.81 L120.598 1288.74 L100.691 1288.74 L100.691 1284.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M65.0198 1038.16 Q61.4087 1038.16 59.58 1041.73 Q57.7745 1045.27 57.7745 1052.4 Q57.7745 1059.5 59.58 1063.07 Q61.4087 1066.61 65.0198 1066.61 Q68.6541 1066.61 70.4596 1063.07 Q72.2883 1059.5 72.2883 1052.4 Q72.2883 1045.27 70.4596 1041.73 Q68.6541 1038.16 65.0198 1038.16 M65.0198 1034.46 Q70.83 1034.46 73.8855 1039.06 Q76.9642 1043.65 76.9642 1052.4 Q76.9642 1061.12 73.8855 1065.73 Q70.83 1070.31 65.0198 1070.31 Q59.2097 1070.31 56.131 1065.73 Q53.0754 1061.12 53.0754 1052.4 Q53.0754 1043.65 56.131 1039.06 Q59.2097 1034.46 65.0198 1034.46 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M85.1818 1063.76 L90.066 1063.76 L90.066 1069.64 L85.1818 1069.64 L85.1818 1063.76 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M104.279 1065.71 L120.598 1065.71 L120.598 1069.64 L98.6539 1069.64 L98.6539 1065.71 Q101.316 1062.95 105.899 1058.32 Q110.506 1053.67 111.686 1052.33 Q113.932 1049.8 114.811 1048.07 Q115.714 1046.31 115.714 1044.62 Q115.714 1041.86 113.77 1040.13 Q111.848 1038.39 108.746 1038.39 Q106.547 1038.39 104.094 1039.16 Q101.663 1039.92 98.8854 1041.47 L98.8854 1036.75 Q101.709 1035.61 104.163 1035.04 Q106.617 1034.46 108.654 1034.46 Q114.024 1034.46 117.219 1037.14 Q120.413 1039.83 120.413 1044.32 Q120.413 1046.45 119.603 1048.37 Q118.816 1050.27 116.709 1052.86 Q116.131 1053.53 113.029 1056.75 Q109.927 1059.94 104.279 1065.71 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M64.0708 819.06 Q60.4597 819.06 58.631 822.624 Q56.8254 826.166 56.8254 833.296 Q56.8254 840.402 58.631 843.967 Q60.4597 847.508 64.0708 847.508 Q67.705 847.508 69.5105 843.967 Q71.3392 840.402 71.3392 833.296 Q71.3392 826.166 69.5105 822.624 Q67.705 819.06 64.0708 819.06 M64.0708 815.356 Q69.8809 815.356 72.9365 819.962 Q76.0151 824.546 76.0151 833.296 Q76.0151 842.022 72.9365 846.629 Q69.8809 851.212 64.0708 851.212 Q58.2606 851.212 55.1819 846.629 Q52.1264 842.022 52.1264 833.296 Q52.1264 824.546 55.1819 819.962 Q58.2606 815.356 64.0708 815.356 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M84.2327 844.661 L89.1169 844.661 L89.1169 850.541 L84.2327 850.541 L84.2327 844.661 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M113.469 831.907 Q116.825 832.624 118.7 834.893 Q120.598 837.161 120.598 840.495 Q120.598 845.61 117.08 848.411 Q113.561 851.212 107.08 851.212 Q104.904 851.212 102.589 850.772 Q100.297 850.356 97.8437 849.499 L97.8437 844.985 Q99.7882 846.12 102.103 846.698 Q104.418 847.277 106.941 847.277 Q111.339 847.277 113.631 845.541 Q115.945 843.805 115.945 840.495 Q115.945 837.439 113.793 835.726 Q111.663 833.99 107.844 833.99 L103.816 833.99 L103.816 830.147 L108.029 830.147 Q111.478 830.147 113.307 828.782 Q115.135 827.393 115.135 824.8 Q115.135 822.138 113.237 820.726 Q111.362 819.291 107.844 819.291 Q105.922 819.291 103.723 819.708 Q101.524 820.124 98.8854 821.004 L98.8854 816.837 Q101.547 816.097 103.862 815.726 Q106.2 815.356 108.26 815.356 Q113.584 815.356 116.686 817.786 Q119.788 820.194 119.788 824.314 Q119.788 827.185 118.145 829.175 Q116.501 831.143 113.469 831.907 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M62.9365 599.959 Q59.3254 599.959 57.4967 603.524 Q55.6912 607.065 55.6912 614.195 Q55.6912 621.301 57.4967 624.866 Q59.3254 628.408 62.9365 628.408 Q66.5707 628.408 68.3763 624.866 Q70.205 621.301 70.205 614.195 Q70.205 607.065 68.3763 603.524 Q66.5707 599.959 62.9365 599.959 M62.9365 596.255 Q68.7467 596.255 71.8022 600.862 Q74.8809 605.445 74.8809 614.195 Q74.8809 622.922 71.8022 627.528 Q68.7467 632.112 62.9365 632.112 Q57.1264 632.112 54.0477 627.528 Q50.9921 622.922 50.9921 614.195 Q50.9921 605.445 54.0477 600.862 Q57.1264 596.255 62.9365 596.255 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M83.0984 625.561 L87.9827 625.561 L87.9827 631.44 L83.0984 631.44 L83.0984 625.561 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M111.015 600.954 L99.2095 619.403 L111.015 619.403 L111.015 600.954 M109.788 596.88 L115.668 596.88 L115.668 619.403 L120.598 619.403 L120.598 623.292 L115.668 623.292 L115.668 631.44 L111.015 631.44 L111.015 623.292 L95.4132 623.292 L95.4132 618.778 L109.788 596.88 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M64.418 380.858 Q60.8069 380.858 58.9782 384.423 Q57.1726 387.965 57.1726 395.094 Q57.1726 402.201 58.9782 405.766 Q60.8069 409.307 64.418 409.307 Q68.0522 409.307 69.8578 405.766 Q71.6865 402.201 71.6865 395.094 Q71.6865 387.965 69.8578 384.423 Q68.0522 380.858 64.418 380.858 M64.418 377.155 Q70.2281 377.155 73.2837 381.761 Q76.3624 386.344 76.3624 395.094 Q76.3624 403.821 73.2837 408.428 Q70.2281 413.011 64.418 413.011 Q58.6078 413.011 55.5291 408.428 Q52.4736 403.821 52.4736 395.094 Q52.4736 386.344 55.5291 381.761 Q58.6078 377.155 64.418 377.155 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M84.5799 406.46 L89.4641 406.46 L89.4641 412.34 L84.5799 412.34 L84.5799 406.46 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M99.6956 377.78 L118.052 377.78 L118.052 381.715 L103.978 381.715 L103.978 390.187 Q104.996 389.84 106.015 389.678 Q107.033 389.492 108.052 389.492 Q113.839 389.492 117.219 392.664 Q120.598 395.835 120.598 401.252 Q120.598 406.83 117.126 409.932 Q113.654 413.011 107.334 413.011 Q105.159 413.011 102.89 412.64 Q100.645 412.27 98.2372 411.529 L98.2372 406.83 Q100.321 407.965 102.543 408.52 Q104.765 409.076 107.242 409.076 Q111.246 409.076 113.584 406.969 Q115.922 404.863 115.922 401.252 Q115.922 397.641 113.584 395.534 Q111.246 393.428 107.242 393.428 Q105.367 393.428 103.492 393.844 Q101.64 394.261 99.6956 395.141 L99.6956 377.78 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M63.2606 161.758 Q59.6495 161.758 57.8208 165.322 Q56.0152 168.864 56.0152 175.994 Q56.0152 183.1 57.8208 186.665 Q59.6495 190.206 63.2606 190.206 Q66.8948 190.206 68.7004 186.665 Q70.5291 183.1 70.5291 175.994 Q70.5291 168.864 68.7004 165.322 Q66.8948 161.758 63.2606 161.758 M63.2606 158.054 Q69.0707 158.054 72.1263 162.66 Q75.205 167.244 75.205 175.994 Q75.205 184.72 72.1263 189.327 Q69.0707 193.91 63.2606 193.91 Q57.4504 193.91 54.3717 189.327 Q51.3162 184.72 51.3162 175.994 Q51.3162 167.244 54.3717 162.66 Q57.4504 158.054 63.2606 158.054 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M83.4225 187.359 L88.3067 187.359 L88.3067 193.239 L83.4225 193.239 L83.4225 187.359 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M109.071 174.095 Q105.922 174.095 104.071 176.248 Q102.242 178.401 102.242 182.151 Q102.242 185.878 104.071 188.054 Q105.922 190.206 109.071 190.206 Q112.219 190.206 114.047 188.054 Q115.899 185.878 115.899 182.151 Q115.899 178.401 114.047 176.248 Q112.219 174.095 109.071 174.095 M118.353 159.443 L118.353 163.702 Q116.594 162.869 114.788 162.429 Q113.006 161.989 111.246 161.989 Q106.617 161.989 104.163 165.114 Q101.733 168.239 101.385 174.558 Q102.751 172.545 104.811 171.48 Q106.871 170.392 109.348 170.392 Q114.557 170.392 117.566 173.563 Q120.598 176.711 120.598 182.151 Q120.598 187.475 117.45 190.693 Q114.302 193.91 109.071 193.91 Q103.075 193.91 99.9039 189.327 Q96.7326 184.72 96.7326 175.994 Q96.7326 167.799 100.621 162.938 Q104.51 158.054 111.061 158.054 Q112.82 158.054 114.603 158.401 Q116.408 158.748 118.353 159.443 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip312)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  218.754,1294.4 285.587,1439.9 352.421,1445.72 419.255,1368.35 486.089,1414.22 552.922,412.861 619.756,1234.49 686.59,1369.72 753.424,1400.18 820.258,1403.61 \n",
       "  887.091,1260.51 953.925,1144.11 1020.76,1385.81 1087.59,787.387 1154.43,87.9763 1221.26,874 1288.09,1258.11 1354.93,630.593 1421.76,213.617 1488.6,381.023 \n",
       "  1555.43,634.016 1622.26,1382.72 1689.1,986.631 1755.93,1083.51 1822.76,738.431 1889.6,785.333 1956.43,1047.23 2023.27,1299.19 2090.1,1271.12 2156.93,1332.74 \n",
       "  2223.77,1302.96 2290.6,1434.08 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip310)\" d=\"\n",
       "M1983.1 198.898 L2279.55 198.898 L2279.55 95.2176 L1983.1 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip310)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1983.1,198.898 2279.55,198.898 2279.55,95.2176 1983.1,95.2176 1983.1,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip310)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2007.5,147.058 2153.92,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip310)\" d=\"M2192.16 166.745 Q2190.35 171.375 2188.64 172.787 Q2186.93 174.199 2184.06 174.199 L2180.65 174.199 L2180.65 170.634 L2183.15 170.634 Q2184.91 170.634 2185.89 169.8 Q2186.86 168.967 2188.04 165.865 L2188.8 163.921 L2178.32 138.412 L2182.83 138.412 L2190.93 158.689 L2199.03 138.412 L2203.55 138.412 L2192.16 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip310)\" d=\"M2210.84 160.402 L2218.48 160.402 L2218.48 134.037 L2210.17 135.703 L2210.17 131.444 L2218.43 129.778 L2223.11 129.778 L2223.11 160.402 L2230.75 160.402 L2230.75 164.338 L2210.84 164.338 L2210.84 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/episodes\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        X  = X_0\n",
    "        \n",
    "        ##### Double Q-Learning ###########################################\n",
    "\n",
    "        for k = 1:T\n",
    "\n",
    "            # 1. Choose action\n",
    "            if rand() < epsilon\n",
    "                if rand() < EXPrand \n",
    "                    A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                else\n",
    "                    A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                end\n",
    "            else\n",
    "\n",
    "                A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                if A == 1000.0 # Indicates no values in this region\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "\n",
    "            # 2. Cache last state\n",
    "            qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "            # 3. Generate the next stae\n",
    "            Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "            # 4. Collect reward R( s, a, s' )\n",
    "            R_t = cartpole_reward( Xp )\n",
    "\n",
    "            # 5. Get the optimal action at the next state\n",
    "            a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "            # 6. Compute the value at the next state\n",
    "\n",
    "            V_tp1_opt = query_value_fuzzy( \n",
    "                Q_kdTree, G, V, \n",
    "                get_Q( \n",
    "                    select_X_vector( Xp ), \n",
    "                    a_tp1_opt \n",
    "                ); \n",
    "                k = vNN \n",
    "            )\n",
    "            if isnan( V_tp1_opt )\n",
    "                V_tp1_opt = 0.0\n",
    "            end\n",
    "\n",
    "\n",
    "            # 7. Blend the value back into nearest points\n",
    "\n",
    "            idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "            nNear      = size( idxs, 1 )\n",
    "            for i = 1:nNear\n",
    "                j    = idxs[i]\n",
    "                if !isnan( wgts[i] ) \n",
    "\n",
    "                    # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                    VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "                    \n",
    "                end\n",
    "            end\n",
    "\n",
    "            states[:,k] = Xp\n",
    "            actions[k]  = A\n",
    "\n",
    "            X = Xp\n",
    "        end\n",
    "\n",
    "        s_l    = vertical_score_s( states, aMargin, ts )\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        if useElig\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709555b9-2598-4281-a634-c7b0681277d0",
   "metadata": {},
   "source": [
    "# Method 2 Performance, Average Vertical Duration [s]\n",
    "Each score is the best average score of the last two epochs: 64 epochs of 64 episodes each, Q-function swap after every episode \n",
    "\n",
    "### TD Tuning\n",
    "\n",
    "$\\alpha = 0.99$: 0.238  \n",
    "$\\alpha = 0.75$: 0.257  \n",
    "$\\alpha = 0.50$: 0.191   \n",
    "$\\alpha = 0.25$: 0.170  \n",
    "$\\alpha = 0.125$: 0.290  \n",
    "$\\alpha = 0.0625$: 0.208, but fantastic performance in the middle of training  \n",
    "$\\alpha = 0.03125$: 0.978  \n",
    "$\\alpha = 0.02344$: 2.567  \n",
    "$\\alpha = 0.01953$: 0.268  \n",
    "$\\alpha = 0.015625$: 0.095  \n",
    " \n",
    "### Add gamma?\n",
    " \n",
    "### Double-Q Tuning, Swap Evey N Episodes\n",
    "$\\%\\ \\ 2$:  \n",
    "$\\%\\ \\ 4$:  \n",
    "$\\%\\ \\ 8$:  \n",
    "$\\%16$:  \n",
    "$\\%32$:  \n",
    "$\\%64$:  \n",
    "\n",
    "\n",
    "\n",
    "### Blend: Best Episode\n",
    "\n",
    "$\\beta = 0.07$:  \n",
    "$\\beta = 0.15$: 0.244\n",
    "\n",
    "| Method      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n",
    "| ----------- | ------- | ------- | ------- | ------- | ------- | ---- |\n",
    "| Blend (Epi) |         |         |         |         |         |      |\n",
    "| Blend (Epo) |         |         |         |         |         |      |\n",
    "| TD          |         |         |         |         |         |      |\n",
    "| TD  + ????? |         |         |         |         |         |      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
