{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.02148 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 # 0.00782 # 0.00391\n",
    "gamma    = 1.00 \n",
    "swapDiv  = 64\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes = 64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   = 32 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "beta   = 0.15\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = true\n",
    "N_peaks =  16\n",
    "N_steps =  16\n",
    "lambda  =   0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.45000000000000023, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.36000000000000015, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.09, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.6100000000000003, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.2900000000000001, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.34000000000000014, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.3900000000000002, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.6300000000000003, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.16, epsilon: 0.0078125\n",
      "Average Score: 0.23234375000000013\n",
      "\n",
      "Epoch 2, Best Score: 2.07\n",
      "Training Iteration 4 score: 0.5800000000000003, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 1.430000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.38000000000000017, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.18000000000000002, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.2700000000000001, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.25000000000000006, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.15, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 1.1400000000000008, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.2564062500000001\n",
      "\n",
      "Epoch 3, Best Score: 2.07\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.10999999999999999, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.11999999999999998, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.10999999999999999, epsilon: 0.0078125\n",
      "Average Score: 0.10968750000000006\n",
      "\n",
      "Epoch 4, Best Score: 2.07\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 5, Best Score: 2.07\n",
      "Training Iteration 4 score: 0.17, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.2700000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.19000000000000003, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.12999999999999998, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 1.7400000000000013, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.7300000000000004, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.15, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.15, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.16, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.24000000000000007, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 3.569999999999968, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.5000000000000002, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.9900000000000007, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 1.0500000000000007, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.3300000000000001, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.4100000000000002, epsilon: 0.0078125\n",
      "Average Score: 0.4420312499999997\n",
      "\n",
      "Epoch 6, Best Score: 3.569999999999968\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 7, Best Score: 3.569999999999968\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.38000000000000017, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.19000000000000003, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.6200000000000003, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.13999999999999999, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.5900000000000003, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.04, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.45000000000000023, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.4200000000000002, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.17, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.3000000000000001, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.16, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.5400000000000003, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.4400000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.23000000000000007, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.3054687500000001\n",
      "\n",
      "Epoch 8, Best Score: 3.569999999999968\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.6800000000000004, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.13999999999999999, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.12999999999999998, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.04281250000000002\n",
      "\n",
      "Epoch 9, Best Score: 3.569999999999968\n",
      "Training Iteration 4 score: 0.35000000000000014, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.11999999999999998, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.058906250000000035\n",
      "\n",
      "Epoch 10, Best Score: 3.569999999999968\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.02015625000000001\n",
      "\n",
      "Epoch 11, Best Score: 3.569999999999968\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 12, Best Score: 3.569999999999968\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.10999999999999999, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.18000000000000002, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.013750000000000005\n",
      "\n",
      "Epoch 13, Best Score: 3.569999999999968\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 14, Best Score: 3.569999999999968\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.16, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.46000000000000024, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.13999999999999999, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.08140625000000003\n",
      "\n",
      "Epoch 15, Best Score: 3.569999999999968\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 16, Best Score: 3.569999999999968\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 17, Best Score: 3.569999999999968\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 18, Best Score: 3.569999999999968\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.08, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.10999999999999999, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.48000000000000026, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.6800000000000004, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.09, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.08343750000000004\n",
      "\n",
      "Epoch 19, Best Score: 3.569999999999968\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.5400000000000003, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.25000000000000006, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.35000000000000014, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.08531250000000004\n",
      "\n",
      "Epoch 20, Best Score: 3.569999999999968\n",
      "Training Iteration 4 score: 0.20000000000000004, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.25000000000000006, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.16, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.22000000000000006, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.7200000000000004, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.8400000000000005, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.7900000000000005, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.8800000000000006, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.7400000000000004, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.8100000000000005, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.17, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 1.5700000000000012, epsilon: 0.0078125\n",
      "Average Score: 0.40515625000000033\n",
      "\n",
      "Epoch 21, Best Score: 3.569999999999968\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 22, Best Score: 3.569999999999968\n",
      "Training Iteration 4 score: 0.5100000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.09, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.09999999999999999, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.13999999999999999, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.09, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.24000000000000007, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.2900000000000001, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.22000000000000006, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.12999999999999998, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.3900000000000002, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.35000000000000014, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 3.47999999999997, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.19000000000000003, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 2.809999999999984, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.4300000000000002, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.26000000000000006, epsilon: 0.0078125\n",
      "Average Score: 0.6198437499999984\n",
      "\n",
      "Epoch 23, Best Score: 3.5899999999999674\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 24, Best Score: 3.5899999999999674\n",
      "Training Iteration 4 score: 0.25000000000000006, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.5100000000000002, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.4000000000000002, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.22000000000000006, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.20000000000000004, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.10999999999999999, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.8400000000000005, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.8700000000000006, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.8700000000000006, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.09, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.08, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.23000000000000007, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 4.9699999999999385, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.5900000000000003, epsilon: 0.0078125\n",
      "Average Score: 0.8851562499999956\n",
      "\n",
      "Epoch 25, Best Score: 4.9699999999999385\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.3300000000000001, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.4200000000000002, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.2700000000000001, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.29515624999999984\n",
      "\n",
      "Epoch 26, Best Score: 4.9699999999999385\n",
      "Training Iteration 4 score: 0.11999999999999998, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.09, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 2.849999999999983, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.08, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.09, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.11999999999999998, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.07, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.10999999999999999, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.07, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.3300000000000001, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 1.1900000000000008, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.47000000000000025, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.060000000000000005, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.22000000000000006, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.07, epsilon: 0.0078125\n",
      "Average Score: 0.2410937499999999\n",
      "\n",
      "Epoch 27, Best Score: 4.9699999999999385\n",
      "Training Iteration 4 score: 0.22000000000000006, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.19000000000000003, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.060000000000000005, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.35000000000000014, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.12999999999999998, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.8500000000000005, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 1.2100000000000009, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.7500000000000004, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.23000000000000007, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.3100000000000001, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.15, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 1.1600000000000008, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 1.0100000000000007, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.13999999999999999, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.8100000000000005, epsilon: 0.0078125\n",
      "Average Score: 0.4757812499999995\n",
      "\n",
      "Epoch 28, Best Score: 4.9699999999999385\n",
      "Training Iteration 4 score: 0.11999999999999998, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.8900000000000006, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 1.1200000000000008, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 2.9899999999999802, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.20000000000000004, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.19000000000000003, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.10999999999999999, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 1.300000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.09, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.12999999999999998, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.09999999999999999, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.13999999999999999, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.09999999999999999, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.30281249999999993\n",
      "\n",
      "Epoch 29, Best Score: 4.9699999999999385\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.7000000000000004, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.48000000000000026, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.11812499999999927\n",
      "\n",
      "Epoch 30, Best Score: 4.9699999999999385\n",
      "Training Iteration 4 score: 0.5300000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 1.2300000000000009, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 1.1200000000000008, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.5000000000000002, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 1.1400000000000008, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.45000000000000023, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.4200000000000002, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.3100000000000001, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 1.6000000000000012, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.5600000000000003, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.5700000000000003, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.060000000000000005, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.48000000000000026, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.4000000000000002, epsilon: 0.0078125\n",
      "Average Score: 0.46953125000000034\n",
      "\n",
      "Epoch 31, Best Score: 4.9699999999999385\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.01875000000000001\n",
      "\n",
      "Epoch 32, Best Score: 4.9699999999999385\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.11999999999999998, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.8000000000000005, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.10999999999999999, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.4400000000000002, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.4400000000000002, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.8400000000000005, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.08, epsilon: 0.0078125\n",
      "Average Score: 0.25171875000000005\n",
      "Saved a trained Q-table with size (76032,), After 12.92950820128123 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip870\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip870)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip871\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip870)\" d=\"\n",
       "M156.598 1486.45 L2352.76 1486.45 L2352.76 47.2441 L156.598 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip872\">\n",
       "    <rect x=\"156\" y=\"47\" width=\"2197\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  486.089,1486.45 486.089,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  820.258,1486.45 820.258,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1154.43,1486.45 1154.43,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1488.6,1486.45 1488.6,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1822.76,1486.45 1822.76,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2156.93,1486.45 2156.93,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  486.089,1486.45 486.089,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  820.258,1486.45 820.258,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1154.43,1486.45 1154.43,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1488.6,1486.45 1488.6,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1822.76,1486.45 1822.76,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2156.93,1486.45 2156.93,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip870)\" d=\"M476.367 1514.29 L494.723 1514.29 L494.723 1518.22 L480.649 1518.22 L480.649 1526.7 Q481.667 1526.35 482.686 1526.19 Q483.704 1526 484.723 1526 Q490.51 1526 493.89 1529.17 Q497.269 1532.34 497.269 1537.76 Q497.269 1543.34 493.797 1546.44 Q490.325 1549.52 484.005 1549.52 Q481.829 1549.52 479.561 1549.15 Q477.316 1548.78 474.908 1548.04 L474.908 1543.34 Q476.992 1544.47 479.214 1545.03 Q481.436 1545.58 483.913 1545.58 Q487.917 1545.58 490.255 1543.48 Q492.593 1541.37 492.593 1537.76 Q492.593 1534.15 490.255 1532.04 Q487.917 1529.94 483.913 1529.94 Q482.038 1529.94 480.163 1530.35 Q478.311 1530.77 476.367 1531.65 L476.367 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M794.945 1544.91 L802.584 1544.91 L802.584 1518.55 L794.274 1520.21 L794.274 1515.95 L802.538 1514.29 L807.214 1514.29 L807.214 1544.91 L814.853 1544.91 L814.853 1548.85 L794.945 1548.85 L794.945 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M834.297 1517.37 Q830.686 1517.37 828.857 1520.93 Q827.052 1524.47 827.052 1531.6 Q827.052 1538.71 828.857 1542.27 Q830.686 1545.82 834.297 1545.82 Q837.931 1545.82 839.737 1542.27 Q841.565 1538.71 841.565 1531.6 Q841.565 1524.47 839.737 1520.93 Q837.931 1517.37 834.297 1517.37 M834.297 1513.66 Q840.107 1513.66 843.163 1518.27 Q846.241 1522.85 846.241 1531.6 Q846.241 1540.33 843.163 1544.94 Q840.107 1549.52 834.297 1549.52 Q828.487 1549.52 825.408 1544.94 Q822.352 1540.33 822.352 1531.6 Q822.352 1522.85 825.408 1518.27 Q828.487 1513.66 834.297 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M1129.61 1544.91 L1137.25 1544.91 L1137.25 1518.55 L1128.94 1520.21 L1128.94 1515.95 L1137.2 1514.29 L1141.88 1514.29 L1141.88 1544.91 L1149.52 1544.91 L1149.52 1548.85 L1129.61 1548.85 L1129.61 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M1159.01 1514.29 L1177.37 1514.29 L1177.37 1518.22 L1163.29 1518.22 L1163.29 1526.7 Q1164.31 1526.35 1165.33 1526.19 Q1166.35 1526 1167.37 1526 Q1173.15 1526 1176.53 1529.17 Q1179.91 1532.34 1179.91 1537.76 Q1179.91 1543.34 1176.44 1546.44 Q1172.97 1549.52 1166.65 1549.52 Q1164.47 1549.52 1162.2 1549.15 Q1159.96 1548.78 1157.55 1548.04 L1157.55 1543.34 Q1159.63 1544.47 1161.86 1545.03 Q1164.08 1545.58 1166.56 1545.58 Q1170.56 1545.58 1172.9 1543.48 Q1175.24 1541.37 1175.24 1537.76 Q1175.24 1534.15 1172.9 1532.04 Q1170.56 1529.94 1166.56 1529.94 Q1164.68 1529.94 1162.81 1530.35 Q1160.95 1530.77 1159.01 1531.65 L1159.01 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M1467.37 1544.91 L1483.69 1544.91 L1483.69 1548.85 L1461.74 1548.85 L1461.74 1544.91 Q1464.41 1542.16 1468.99 1537.53 Q1473.6 1532.88 1474.78 1531.53 Q1477.02 1529.01 1477.9 1527.27 Q1478.8 1525.51 1478.8 1523.82 Q1478.8 1521.07 1476.86 1519.33 Q1474.94 1517.6 1471.84 1517.6 Q1469.64 1517.6 1467.18 1518.36 Q1464.75 1519.13 1461.98 1520.68 L1461.98 1515.95 Q1464.8 1514.82 1467.25 1514.24 Q1469.71 1513.66 1471.74 1513.66 Q1477.11 1513.66 1480.31 1516.35 Q1483.5 1519.03 1483.5 1523.52 Q1483.5 1525.65 1482.69 1527.57 Q1481.91 1529.47 1479.8 1532.07 Q1479.22 1532.74 1476.12 1535.95 Q1473.02 1539.15 1467.37 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M1503.5 1517.37 Q1499.89 1517.37 1498.06 1520.93 Q1496.26 1524.47 1496.26 1531.6 Q1496.26 1538.71 1498.06 1542.27 Q1499.89 1545.82 1503.5 1545.82 Q1507.14 1545.82 1508.94 1542.27 Q1510.77 1538.71 1510.77 1531.6 Q1510.77 1524.47 1508.94 1520.93 Q1507.14 1517.37 1503.5 1517.37 M1503.5 1513.66 Q1509.31 1513.66 1512.37 1518.27 Q1515.45 1522.85 1515.45 1531.6 Q1515.45 1540.33 1512.37 1544.94 Q1509.31 1549.52 1503.5 1549.52 Q1497.69 1549.52 1494.61 1544.94 Q1491.56 1540.33 1491.56 1531.6 Q1491.56 1522.85 1494.61 1518.27 Q1497.69 1513.66 1503.5 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M1802.04 1544.91 L1818.35 1544.91 L1818.35 1548.85 L1796.41 1548.85 L1796.41 1544.91 Q1799.07 1542.16 1803.66 1537.53 Q1808.26 1532.88 1809.44 1531.53 Q1811.69 1529.01 1812.57 1527.27 Q1813.47 1525.51 1813.47 1523.82 Q1813.47 1521.07 1811.53 1519.33 Q1809.6 1517.6 1806.5 1517.6 Q1804.3 1517.6 1801.85 1518.36 Q1799.42 1519.13 1796.64 1520.68 L1796.64 1515.95 Q1799.47 1514.82 1801.92 1514.24 Q1804.37 1513.66 1806.41 1513.66 Q1811.78 1513.66 1814.97 1516.35 Q1818.17 1519.03 1818.17 1523.52 Q1818.17 1525.65 1817.36 1527.57 Q1816.57 1529.47 1814.47 1532.07 Q1813.89 1532.74 1810.79 1535.95 Q1807.68 1539.15 1802.04 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M1828.22 1514.29 L1846.57 1514.29 L1846.57 1518.22 L1832.5 1518.22 L1832.5 1526.7 Q1833.52 1526.35 1834.53 1526.19 Q1835.55 1526 1836.57 1526 Q1842.36 1526 1845.74 1529.17 Q1849.12 1532.34 1849.12 1537.76 Q1849.12 1543.34 1845.65 1546.44 Q1842.17 1549.52 1835.85 1549.52 Q1833.68 1549.52 1831.41 1549.15 Q1829.16 1548.78 1826.76 1548.04 L1826.76 1543.34 Q1828.84 1544.47 1831.06 1545.03 Q1833.28 1545.58 1835.76 1545.58 Q1839.77 1545.58 1842.1 1543.48 Q1844.44 1541.37 1844.44 1537.76 Q1844.44 1534.15 1842.1 1532.04 Q1839.77 1529.94 1835.76 1529.94 Q1833.89 1529.94 1832.01 1530.35 Q1830.16 1530.77 1828.22 1531.65 L1828.22 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M2145.78 1530.21 Q2149.13 1530.93 2151.01 1533.2 Q2152.91 1535.47 2152.91 1538.8 Q2152.91 1543.92 2149.39 1546.72 Q2145.87 1549.52 2139.39 1549.52 Q2137.21 1549.52 2134.9 1549.08 Q2132.6 1548.66 2130.15 1547.81 L2130.15 1543.29 Q2132.1 1544.43 2134.41 1545.01 Q2136.72 1545.58 2139.25 1545.58 Q2143.65 1545.58 2145.94 1543.85 Q2148.25 1542.11 2148.25 1538.8 Q2148.25 1535.75 2146.1 1534.03 Q2143.97 1532.3 2140.15 1532.3 L2136.12 1532.3 L2136.12 1528.45 L2140.34 1528.45 Q2143.78 1528.45 2145.61 1527.09 Q2147.44 1525.7 2147.44 1523.11 Q2147.44 1520.45 2145.54 1519.03 Q2143.67 1517.6 2140.15 1517.6 Q2138.23 1517.6 2136.03 1518.01 Q2133.83 1518.43 2131.19 1519.31 L2131.19 1515.14 Q2133.85 1514.4 2136.17 1514.03 Q2138.51 1513.66 2140.57 1513.66 Q2145.89 1513.66 2148.99 1516.09 Q2152.1 1518.5 2152.1 1522.62 Q2152.1 1525.49 2150.45 1527.48 Q2148.81 1529.45 2145.78 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M2171.77 1517.37 Q2168.16 1517.37 2166.33 1520.93 Q2164.53 1524.47 2164.53 1531.6 Q2164.53 1538.71 2166.33 1542.27 Q2168.16 1545.82 2171.77 1545.82 Q2175.41 1545.82 2177.21 1542.27 Q2179.04 1538.71 2179.04 1531.6 Q2179.04 1524.47 2177.21 1520.93 Q2175.41 1517.37 2171.77 1517.37 M2171.77 1513.66 Q2177.58 1513.66 2180.64 1518.27 Q2183.72 1522.85 2183.72 1531.6 Q2183.72 1540.33 2180.64 1544.94 Q2177.58 1549.52 2171.77 1549.52 Q2165.96 1549.52 2162.88 1544.94 Q2159.83 1540.33 2159.83 1531.6 Q2159.83 1522.85 2162.88 1518.27 Q2165.96 1513.66 2171.77 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,1445.72 2352.76,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,1138.94 2352.76,1138.94 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,832.156 2352.76,832.156 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,525.377 2352.76,525.377 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,218.597 2352.76,218.597 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1486.45 156.598,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1445.72 175.496,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1138.94 175.496,1138.94 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,832.156 175.496,832.156 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,525.377 175.496,525.377 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,218.597 175.496,218.597 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip870)\" d=\"M63.4226 1431.51 Q59.8115 1431.51 57.9828 1435.08 Q56.1773 1438.62 56.1773 1445.75 Q56.1773 1452.86 57.9828 1456.42 Q59.8115 1459.96 63.4226 1459.96 Q67.0569 1459.96 68.8624 1456.42 Q70.6911 1452.86 70.6911 1445.75 Q70.6911 1438.62 68.8624 1435.08 Q67.0569 1431.51 63.4226 1431.51 M63.4226 1427.81 Q69.2328 1427.81 72.2883 1432.42 Q75.367 1437 75.367 1445.75 Q75.367 1454.48 72.2883 1459.08 Q69.2328 1463.67 63.4226 1463.67 Q57.6125 1463.67 54.5338 1459.08 Q51.4782 1454.48 51.4782 1445.75 Q51.4782 1437 54.5338 1432.42 Q57.6125 1427.81 63.4226 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M83.5845 1457.12 L88.4688 1457.12 L88.4688 1463 L83.5845 1463 L83.5845 1457.12 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M108.654 1431.51 Q105.043 1431.51 103.214 1435.08 Q101.409 1438.62 101.409 1445.75 Q101.409 1452.86 103.214 1456.42 Q105.043 1459.96 108.654 1459.96 Q112.288 1459.96 114.094 1456.42 Q115.922 1452.86 115.922 1445.75 Q115.922 1438.62 114.094 1435.08 Q112.288 1431.51 108.654 1431.51 M108.654 1427.81 Q114.464 1427.81 117.52 1432.42 Q120.598 1437 120.598 1445.75 Q120.598 1454.48 117.52 1459.08 Q114.464 1463.67 108.654 1463.67 Q102.844 1463.67 99.765 1459.08 Q96.7095 1454.48 96.7095 1445.75 Q96.7095 1437 99.765 1432.42 Q102.844 1427.81 108.654 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M65.0198 1124.73 Q61.4087 1124.73 59.58 1128.3 Q57.7745 1131.84 57.7745 1138.97 Q57.7745 1146.08 59.58 1149.64 Q61.4087 1153.18 65.0198 1153.18 Q68.6541 1153.18 70.4596 1149.64 Q72.2883 1146.08 72.2883 1138.97 Q72.2883 1131.84 70.4596 1128.3 Q68.6541 1124.73 65.0198 1124.73 M65.0198 1121.03 Q70.83 1121.03 73.8855 1125.64 Q76.9642 1130.22 76.9642 1138.97 Q76.9642 1147.7 73.8855 1152.3 Q70.83 1156.89 65.0198 1156.89 Q59.2097 1156.89 56.131 1152.3 Q53.0754 1147.7 53.0754 1138.97 Q53.0754 1130.22 56.131 1125.64 Q59.2097 1121.03 65.0198 1121.03 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M85.1818 1150.34 L90.066 1150.34 L90.066 1156.22 L85.1818 1156.22 L85.1818 1150.34 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M104.279 1152.28 L120.598 1152.28 L120.598 1156.22 L98.6539 1156.22 L98.6539 1152.28 Q101.316 1149.53 105.899 1144.9 Q110.506 1140.24 111.686 1138.9 Q113.932 1136.38 114.811 1134.64 Q115.714 1132.88 115.714 1131.19 Q115.714 1128.44 113.77 1126.7 Q111.848 1124.97 108.746 1124.97 Q106.547 1124.97 104.094 1125.73 Q101.663 1126.49 98.8854 1128.04 L98.8854 1123.32 Q101.709 1122.19 104.163 1121.61 Q106.617 1121.03 108.654 1121.03 Q114.024 1121.03 117.219 1123.72 Q120.413 1126.4 120.413 1130.89 Q120.413 1133.02 119.603 1134.94 Q118.816 1136.84 116.709 1139.43 Q116.131 1140.11 113.029 1143.32 Q109.927 1146.52 104.279 1152.28 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M62.9365 817.955 Q59.3254 817.955 57.4967 821.52 Q55.6912 825.062 55.6912 832.191 Q55.6912 839.298 57.4967 842.862 Q59.3254 846.404 62.9365 846.404 Q66.5707 846.404 68.3763 842.862 Q70.205 839.298 70.205 832.191 Q70.205 825.062 68.3763 821.52 Q66.5707 817.955 62.9365 817.955 M62.9365 814.251 Q68.7467 814.251 71.8022 818.858 Q74.8809 823.441 74.8809 832.191 Q74.8809 840.918 71.8022 845.524 Q68.7467 850.108 62.9365 850.108 Q57.1264 850.108 54.0477 845.524 Q50.9921 840.918 50.9921 832.191 Q50.9921 823.441 54.0477 818.858 Q57.1264 814.251 62.9365 814.251 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M83.0984 843.557 L87.9827 843.557 L87.9827 849.436 L83.0984 849.436 L83.0984 843.557 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M111.015 818.951 L99.2095 837.4 L111.015 837.4 L111.015 818.951 M109.788 814.876 L115.668 814.876 L115.668 837.4 L120.598 837.4 L120.598 841.288 L115.668 841.288 L115.668 849.436 L111.015 849.436 L111.015 841.288 L95.4132 841.288 L95.4132 836.775 L109.788 814.876 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M63.2606 511.176 Q59.6495 511.176 57.8208 514.74 Q56.0152 518.282 56.0152 525.412 Q56.0152 532.518 57.8208 536.083 Q59.6495 539.624 63.2606 539.624 Q66.8948 539.624 68.7004 536.083 Q70.5291 532.518 70.5291 525.412 Q70.5291 518.282 68.7004 514.74 Q66.8948 511.176 63.2606 511.176 M63.2606 507.472 Q69.0707 507.472 72.1263 512.078 Q75.205 516.662 75.205 525.412 Q75.205 534.138 72.1263 538.745 Q69.0707 543.328 63.2606 543.328 Q57.4504 543.328 54.3717 538.745 Q51.3162 534.138 51.3162 525.412 Q51.3162 516.662 54.3717 512.078 Q57.4504 507.472 63.2606 507.472 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M83.4225 536.777 L88.3067 536.777 L88.3067 542.657 L83.4225 542.657 L83.4225 536.777 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M109.071 523.513 Q105.922 523.513 104.071 525.666 Q102.242 527.819 102.242 531.569 Q102.242 535.296 104.071 537.472 Q105.922 539.624 109.071 539.624 Q112.219 539.624 114.047 537.472 Q115.899 535.296 115.899 531.569 Q115.899 527.819 114.047 525.666 Q112.219 523.513 109.071 523.513 M118.353 508.861 L118.353 513.12 Q116.594 512.287 114.788 511.847 Q113.006 511.407 111.246 511.407 Q106.617 511.407 104.163 514.532 Q101.733 517.657 101.385 523.976 Q102.751 521.963 104.811 520.898 Q106.871 519.81 109.348 519.81 Q114.557 519.81 117.566 522.981 Q120.598 526.129 120.598 531.569 Q120.598 536.893 117.45 540.111 Q114.302 543.328 109.071 543.328 Q103.075 543.328 99.9039 538.745 Q96.7326 534.138 96.7326 525.412 Q96.7326 517.217 100.621 512.356 Q104.51 507.472 111.061 507.472 Q112.82 507.472 114.603 507.819 Q116.408 508.166 118.353 508.861 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M63.5152 204.396 Q59.9041 204.396 58.0754 207.961 Q56.2699 211.502 56.2699 218.632 Q56.2699 225.738 58.0754 229.303 Q59.9041 232.845 63.5152 232.845 Q67.1494 232.845 68.955 229.303 Q70.7837 225.738 70.7837 218.632 Q70.7837 211.502 68.955 207.961 Q67.1494 204.396 63.5152 204.396 M63.5152 200.692 Q69.3254 200.692 72.3809 205.299 Q75.4596 209.882 75.4596 218.632 Q75.4596 227.359 72.3809 231.965 Q69.3254 236.549 63.5152 236.549 Q57.7051 236.549 54.6264 231.965 Q51.5708 227.359 51.5708 218.632 Q51.5708 209.882 54.6264 205.299 Q57.7051 200.692 63.5152 200.692 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M83.6771 229.998 L88.5614 229.998 L88.5614 235.877 L83.6771 235.877 L83.6771 229.998 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M108.746 219.465 Q105.413 219.465 103.492 221.248 Q101.594 223.03 101.594 226.155 Q101.594 229.28 103.492 231.062 Q105.413 232.845 108.746 232.845 Q112.08 232.845 114.001 231.062 Q115.922 229.257 115.922 226.155 Q115.922 223.03 114.001 221.248 Q112.103 219.465 108.746 219.465 M104.071 217.475 Q101.061 216.734 99.3715 214.674 Q97.7048 212.614 97.7048 209.651 Q97.7048 205.507 100.645 203.1 Q103.608 200.692 108.746 200.692 Q113.908 200.692 116.848 203.1 Q119.788 205.507 119.788 209.651 Q119.788 212.614 118.098 214.674 Q116.432 216.734 113.445 217.475 Q116.825 218.262 118.7 220.553 Q120.598 222.845 120.598 226.155 Q120.598 231.178 117.52 233.863 Q114.464 236.549 108.746 236.549 Q103.029 236.549 99.9502 233.863 Q96.8947 231.178 96.8947 226.155 Q96.8947 222.845 98.7928 220.553 Q100.691 218.262 104.071 217.475 M102.358 210.09 Q102.358 212.776 104.024 214.28 Q105.714 215.785 108.746 215.785 Q111.756 215.785 113.445 214.28 Q115.158 212.776 115.158 210.09 Q115.158 207.405 113.445 205.901 Q111.756 204.396 108.746 204.396 Q105.714 204.396 104.024 205.901 Q102.358 207.405 102.358 210.09 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip872)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  218.754,1089.32 285.587,1052.41 352.421,1277.47 419.255,1445.72 486.089,767.685 552.922,1445.72 619.756,977.158 686.59,1380.05 753.424,1355.36 820.258,1414.8 \n",
       "  887.091,1445.72 953.925,1424.62 1020.76,1445.72 1087.59,1320.85 1154.43,1445.72 1221.26,1445.72 1288.09,1445.72 1354.93,1317.73 1421.76,1314.86 1488.6,824.247 \n",
       "  1555.43,1445.72 1622.26,494.939 1689.1,1445.72 1755.93,87.9763 1822.76,992.976 1889.6,1075.9 1956.43,715.916 2023.27,981.232 2090.1,1264.52 2156.93,725.503 \n",
       "  2223.77,1416.96 2290.6,1059.6 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip870)\" d=\"\n",
       "M1983.1 198.898 L2279.55 198.898 L2279.55 95.2176 L1983.1 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1983.1,198.898 2279.55,198.898 2279.55,95.2176 1983.1,95.2176 1983.1,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2007.5,147.058 2153.92,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip870)\" d=\"M2192.16 166.745 Q2190.35 171.375 2188.64 172.787 Q2186.93 174.199 2184.06 174.199 L2180.65 174.199 L2180.65 170.634 L2183.15 170.634 Q2184.91 170.634 2185.89 169.8 Q2186.86 168.967 2188.04 165.865 L2188.8 163.921 L2178.32 138.412 L2182.83 138.412 L2190.93 158.689 L2199.03 138.412 L2203.55 138.412 L2192.16 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M2210.84 160.402 L2218.48 160.402 L2218.48 134.037 L2210.17 135.703 L2210.17 131.444 L2218.43 129.778 L2223.11 129.778 L2223.11 160.402 L2230.75 160.402 L2230.75 164.338 L2210.84 164.338 L2210.84 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/episodes\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        X  = X_0\n",
    "        \n",
    "        ##### Double Q-Learning ###########################################\n",
    "\n",
    "        for k = 1:T\n",
    "\n",
    "            # 1. Choose action\n",
    "            if rand() < epsilon\n",
    "                if rand() < EXPrand \n",
    "                    A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                else\n",
    "                    A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                end\n",
    "            else\n",
    "\n",
    "                A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                if A == 1000.0 # Indicates no values in this region\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "\n",
    "            # 2. Cache last state\n",
    "            qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "            # 3. Generate the next stae\n",
    "            Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "            # 4. Collect reward R( s, a, s' )\n",
    "            R_t = cartpole_reward( Xp )\n",
    "\n",
    "            # 5. Get the optimal action at the next state\n",
    "            a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "            # 6. Compute the value at the next state\n",
    "\n",
    "            V_tp1_opt = query_value_fuzzy( \n",
    "                Q_kdTree, G, V, \n",
    "                get_Q( \n",
    "                    select_X_vector( Xp ), \n",
    "                    a_tp1_opt \n",
    "                ); \n",
    "                k = vNN \n",
    "            )\n",
    "            if isnan( V_tp1_opt )\n",
    "                V_tp1_opt = 0.0\n",
    "            end\n",
    "\n",
    "\n",
    "            # 7. Blend the value back into nearest points\n",
    "\n",
    "            idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "            nNear      = size( idxs, 1 )\n",
    "            for i = 1:nNear\n",
    "                j    = idxs[i]\n",
    "                if !isnan( wgts[i] ) \n",
    "\n",
    "                    # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                    VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "                    \n",
    "                end\n",
    "            end\n",
    "\n",
    "            states[:,k] = Xp\n",
    "            actions[k]  = A\n",
    "\n",
    "            X = Xp\n",
    "        end\n",
    "\n",
    "        s_l    = vertical_score_s( states, aMargin, ts )\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        if useElig\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709555b9-2598-4281-a634-c7b0681277d0",
   "metadata": {},
   "source": [
    "# Method 2 Performance, Average Vertical Duration [s]\n",
    "Each score is the best average score of the last two epochs: 64 epochs of 64 episodes each, Q-function swap after every episode \n",
    "\n",
    "### TD Tuning\n",
    "\n",
    "$\\alpha = 0.99$: 0.238  \n",
    "$\\alpha = 0.75$: 0.257  \n",
    "$\\alpha = 0.50$: 0.191   \n",
    "$\\alpha = 0.25$: 0.170  \n",
    "$\\alpha = 0.125$: 0.290  \n",
    "$\\alpha = 0.0625$: 0.208, but fantastic performance in the middle of training  \n",
    "$\\alpha = 0.03125$: 0.978  \n",
    "$\\alpha = 0.02344$: 2.567  \n",
    "$\\alpha = 0.01953$: 0.268  \n",
    "$\\alpha = 0.015625$: 0.095  \n",
    " \n",
    "### Add gamma?\n",
    " \n",
    "### Double-Q Tuning, Swap Evey N Episodes\n",
    "$\\%\\ \\ 2$:  \n",
    "$\\%\\ \\ 4$:  \n",
    "$\\%\\ \\ 8$:  \n",
    "$\\%16$:  \n",
    "$\\%32$:  \n",
    "$\\%64$:  \n",
    "\n",
    "\n",
    "\n",
    "### Blend: Best Episode\n",
    "\n",
    "$\\beta = 0.07$:  \n",
    "$\\beta = 0.15$: 0.244\n",
    "\n",
    "| Method      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n",
    "| ----------- | ------- | ------- | ------- | ------- | ------- | ---- |\n",
    "| Blend (Epi) |         |         |         |         |         |      |\n",
    "| Blend (Epo) |         |         |         |         |         |      |\n",
    "| TD          |         |         |         |         |         |      |\n",
    "| TD  + ????? |         |         |         |         |         |      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
