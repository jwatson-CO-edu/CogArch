{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.02148 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 # 0.00782 # 0.00391\n",
    "beta     = 0.99\n",
    "gamma    = 1.00 \n",
    "swapDiv  = 64\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes = 64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   = 32 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = true\n",
    "N_peaks =  32\n",
    "N_steps = 128\n",
    "lambda  =   0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.48000000000000026, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.6500000000000004, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.3300000000000001, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.4300000000000002, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.48000000000000026, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.34000000000000014, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.20109375000000004\n",
      "\n",
      "Epoch 2, Best Score: 0.9000000000000006\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.7500000000000004, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.3100000000000001, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.6600000000000004, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.12999999999999998, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.25000000000000006, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.2700000000000001, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.23000000000000007, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.19750000000000006\n",
      "\n",
      "Epoch 3, Best Score: 0.9000000000000006\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.17, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.2900000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.12999999999999998, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.19000000000000003, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.23000000000000007, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.3200000000000001, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.12890625000000008\n",
      "\n",
      "Epoch 4, Best Score: 0.9300000000000006\n",
      "Training Iteration 4 score: 1.1400000000000008, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.7400000000000004, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.37000000000000016, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.34000000000000014, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 1.1600000000000008, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.20000000000000004, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.37000000000000016, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.3200000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.26000000000000006, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.2662500000000002\n",
      "\n",
      "Epoch 5, Best Score: 1.1600000000000008\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.9200000000000006, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 1.270000000000001, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.5800000000000003, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 2.209999999999997, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.6300000000000003, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.5700000000000003, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.3000000000000001, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.21000000000000005, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.4400000000000002, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.3645312500000002\n",
      "\n",
      "Epoch 6, Best Score: 2.209999999999997\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.20000000000000004, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.12999999999999998, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.07, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.13999999999999999, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.10999999999999999, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.20000000000000004, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.09, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.3100000000000001, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.08, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.09, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.10999999999999999, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.11140625\n",
      "\n",
      "Epoch 7, Best Score: 2.209999999999997\n",
      "Training Iteration 4 score: 0.5300000000000002, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.4200000000000002, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.24000000000000007, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.26000000000000006, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.18000000000000002, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.18000000000000002, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.16, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.17, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.17, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.16, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.20000000000000004, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.20000000000000004, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.11999999999999998, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.10999999999999999, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.10999999999999999, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.21000000000000005, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.3100000000000002\n",
      "\n",
      "Epoch 8, Best Score: 2.209999999999997\n",
      "Training Iteration 4 score: 0.13999999999999999, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.12999999999999998, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.08, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.7500000000000004, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.7500000000000004, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.6800000000000004, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 1.1800000000000008, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.5500000000000003, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.2800000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.5700000000000003, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.5600000000000003, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.6300000000000003, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.5600000000000003, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.7100000000000004, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.5137500000000004\n",
      "\n",
      "Epoch 9, Best Score: 2.209999999999997\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.25000000000000006, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 1.1500000000000008, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.09, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.09999999999999999, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.07, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.07, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.05, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.35000000000000014, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.17, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.2095312500000001\n",
      "\n",
      "Epoch 10, Best Score: 2.209999999999997\n",
      "Training Iteration 4 score: 0.8000000000000005, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.6200000000000003, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.8300000000000005, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.8500000000000005, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 1.1500000000000008, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.49000000000000027, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.6000000000000003, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.15, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.0400000000000007, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.7300000000000004, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.8300000000000005, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.6700000000000004, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.23000000000000007, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.22000000000000006, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.19000000000000003, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.6700000000000004, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.5157812500000004\n",
      "\n",
      "Epoch 11, Best Score: 2.209999999999997\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 12, Best Score: 2.209999999999997\n",
      "Training Iteration 4 score: 0.09, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 1.0300000000000007, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.7400000000000004, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.36000000000000015, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.45000000000000023, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.3200000000000001, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.25000000000000006, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 1.1700000000000008, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 7.279999999999889, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.7685937499999959\n",
      "\n",
      "Epoch 13, Best Score: 7.279999999999889\n",
      "Training Iteration 4 score: 1.6000000000000012, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.9600000000000006, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.5900000000000003, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.5500000000000003, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 1.2000000000000008, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 1.490000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.7000000000000004, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 1.9400000000000015, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 2.259999999999996, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 1.7500000000000013, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 1.5200000000000011, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 1.1600000000000008, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 2.619999999999988, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.9000000000000006, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 1.8700000000000014, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.6400000000000003, epsilon: 8.881784197001252e-16\n",
      "Average Score: 1.1023437500000006\n",
      "\n",
      "Epoch 14, Best Score: 7.279999999999889\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.006562500000000003\n",
      "\n",
      "Epoch 15, Best Score: 7.279999999999889\n",
      "Training Iteration 4 score: 0.4000000000000002, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 1.7700000000000014, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 1.5500000000000012, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.9500000000000006, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.37000000000000016, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 1.7700000000000014, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 2.869999999999983, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 1.1800000000000008, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.7185937499999996\n",
      "\n",
      "Epoch 16, Best Score: 7.279999999999889\n",
      "Training Iteration 4 score: 4.839999999999941, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 5.549999999999926, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 5.519999999999927, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 13.78999999999975, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 4.729999999999944, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 5.989999999999917, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 4.489999999999949, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 2.1065624999999746\n",
      "\n",
      "Epoch 17, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 0.3000000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.38000000000000017, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.8600000000000005, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.7000000000000004, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.5400000000000003, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.18171875000000012\n",
      "\n",
      "Epoch 18, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 0.6400000000000003, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 1.270000000000001, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.6300000000000003, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.8700000000000006, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.3100000000000001, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.8000000000000005, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 1.5500000000000012, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.23609375000000013\n",
      "\n",
      "Epoch 19, Best Score: 17.129999999999878\n",
      "Training Iteration 4 score: 0.22000000000000006, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 19.1900000000002, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.2700000000000001, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 1.5700000000000012, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.6500000000000004, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 1.6009375000000243\n",
      "\n",
      "Epoch 20, Best Score: 31.390000000002107\n",
      "Training Iteration 4 score: 1.370000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 3.0599999999999787, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.8700000000000006, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.46000000000000024, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 1.0000000000000007, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.48000000000000026, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.8100000000000005, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.0800000000000007, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 1.0600000000000007, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 1.8400000000000014, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.12999999999999998, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 2.149999999999998, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 1.380000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 2.0400000000000005, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 1.8100000000000014, epsilon: 8.881784197001252e-16\n",
      "Average Score: 1.2384374999999996\n",
      "\n",
      "Epoch 21, Best Score: 31.390000000002107\n",
      "Training Iteration 4 score: 0.3300000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.019531250000000003\n",
      "\n",
      "Epoch 22, Best Score: 31.390000000002107\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 15.70999999999971, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 2.3799999999999932, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 18.050000000000022, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 22.20000000000067, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 15.799999999999708, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 24.270000000000994, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 24.340000000001005, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 25.370000000001166, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 11.956562500000224\n",
      "\n",
      "Epoch 23, Best Score: 31.390000000002107\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 24, Best Score: 31.390000000002107\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 25, Best Score: 31.390000000002107\n",
      "Training Iteration 4 score: 1.5200000000000011, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.5000000000000002, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.17, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.7300000000000004, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.6600000000000004, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.1670312500000001\n",
      "\n",
      "Epoch 26, Best Score: 31.390000000002107\n",
      "Training Iteration 4 score: 0.4000000000000002, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.49000000000000027, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.8300000000000005, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.16, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.8000000000000005, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.8600000000000005, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.3200000000000001, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.20000000000000004, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.19000000000000003, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.6700000000000004, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 1.6600000000000013, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.33468749999999986\n",
      "\n",
      "Epoch 27, Best Score: 31.390000000002107\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.5707812499999916\n",
      "\n",
      "Epoch 28, Best Score: 31.390000000002107\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 29, Best Score: 31.390000000002107\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.010625000000000006\n",
      "\n",
      "Epoch 30, Best Score: 31.390000000002107\n",
      "Training Iteration 4 score: 0.3000000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.4300000000000002, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.8100000000000005, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.3200000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 1.1100000000000008, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.34000000000000014, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.3300000000000001, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 20.41000000000039, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.3200000000000001, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.8100000000000005, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.7200000000000004, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.4400000000000002, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.5200000000000002, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 1.8387500000000128\n",
      "\n",
      "Epoch 31, Best Score: 31.390000000002107\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.22000000000000006, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.2900000000000001, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.07828125000000004\n",
      "\n",
      "Epoch 32, Best Score: 31.390000000002107\n",
      "Training Iteration 4 score: 0.4000000000000002, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.4400000000000002, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.46000000000000024, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.3900000000000002, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.7900000000000005, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.6300000000000003, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.4200000000000002, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 1.0100000000000007, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.4000000000000002, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.8300000000000005, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.8700000000000006, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.7100000000000004, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.9000000000000006, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.47000000000000025, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.5803125000000003\n",
      "Saved a trained Q-table with size (76032,), After 13.2286106189092 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip340\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip340)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip341\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip340)\" d=\"\n",
       "M184.191 1486.45 L2352.76 1486.45 L2352.76 47.2441 L184.191 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip342\">\n",
       "    <rect x=\"184\" y=\"47\" width=\"2170\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip342)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  509.541,1486.45 509.541,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip342)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  839.512,1486.45 839.512,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip342)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1169.48,1486.45 1169.48,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip342)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1499.45,1486.45 1499.45,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip342)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1829.42,1486.45 1829.42,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip342)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2159.39,1486.45 2159.39,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip340)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip340)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  509.541,1486.45 509.541,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip340)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  839.512,1486.45 839.512,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip340)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1169.48,1486.45 1169.48,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip340)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1499.45,1486.45 1499.45,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip340)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1829.42,1486.45 1829.42,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip340)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2159.39,1486.45 2159.39,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip340)\" d=\"M499.819 1514.29 L518.176 1514.29 L518.176 1518.22 L504.102 1518.22 L504.102 1526.7 Q505.12 1526.35 506.139 1526.19 Q507.157 1526 508.176 1526 Q513.963 1526 517.342 1529.17 Q520.722 1532.34 520.722 1537.76 Q520.722 1543.34 517.25 1546.44 Q513.778 1549.52 507.458 1549.52 Q505.282 1549.52 503.014 1549.15 Q500.768 1548.78 498.361 1548.04 L498.361 1543.34 Q500.444 1544.47 502.666 1545.03 Q504.889 1545.58 507.366 1545.58 Q511.37 1545.58 513.708 1543.48 Q516.046 1541.37 516.046 1537.76 Q516.046 1534.15 513.708 1532.04 Q511.37 1529.94 507.366 1529.94 Q505.491 1529.94 503.616 1530.35 Q501.764 1530.77 499.819 1531.65 L499.819 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M814.199 1544.91 L821.838 1544.91 L821.838 1518.55 L813.528 1520.21 L813.528 1515.95 L821.792 1514.29 L826.468 1514.29 L826.468 1544.91 L834.107 1544.91 L834.107 1548.85 L814.199 1548.85 L814.199 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M853.551 1517.37 Q849.94 1517.37 848.111 1520.93 Q846.306 1524.47 846.306 1531.6 Q846.306 1538.71 848.111 1542.27 Q849.94 1545.82 853.551 1545.82 Q857.185 1545.82 858.991 1542.27 Q860.82 1538.71 860.82 1531.6 Q860.82 1524.47 858.991 1520.93 Q857.185 1517.37 853.551 1517.37 M853.551 1513.66 Q859.361 1513.66 862.417 1518.27 Q865.495 1522.85 865.495 1531.6 Q865.495 1540.33 862.417 1544.94 Q859.361 1549.52 853.551 1549.52 Q847.741 1549.52 844.662 1544.94 Q841.607 1540.33 841.607 1531.6 Q841.607 1522.85 844.662 1518.27 Q847.741 1513.66 853.551 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M1144.67 1544.91 L1152.31 1544.91 L1152.31 1518.55 L1144 1520.21 L1144 1515.95 L1152.26 1514.29 L1156.94 1514.29 L1156.94 1544.91 L1164.57 1544.91 L1164.57 1548.85 L1144.67 1548.85 L1144.67 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M1174.07 1514.29 L1192.42 1514.29 L1192.42 1518.22 L1178.35 1518.22 L1178.35 1526.7 Q1179.37 1526.35 1180.38 1526.19 Q1181.4 1526 1182.42 1526 Q1188.21 1526 1191.59 1529.17 Q1194.97 1532.34 1194.97 1537.76 Q1194.97 1543.34 1191.5 1546.44 Q1188.02 1549.52 1181.7 1549.52 Q1179.53 1549.52 1177.26 1549.15 Q1175.01 1548.78 1172.61 1548.04 L1172.61 1543.34 Q1174.69 1544.47 1176.91 1545.03 Q1179.13 1545.58 1181.61 1545.58 Q1185.62 1545.58 1187.95 1543.48 Q1190.29 1541.37 1190.29 1537.76 Q1190.29 1534.15 1187.95 1532.04 Q1185.62 1529.94 1181.61 1529.94 Q1179.74 1529.94 1177.86 1530.35 Q1176.01 1530.77 1174.07 1531.65 L1174.07 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M1478.23 1544.91 L1494.55 1544.91 L1494.55 1548.85 L1472.6 1548.85 L1472.6 1544.91 Q1475.26 1542.16 1479.85 1537.53 Q1484.45 1532.88 1485.63 1531.53 Q1487.88 1529.01 1488.76 1527.27 Q1489.66 1525.51 1489.66 1523.82 Q1489.66 1521.07 1487.72 1519.33 Q1485.8 1517.6 1482.69 1517.6 Q1480.49 1517.6 1478.04 1518.36 Q1475.61 1519.13 1472.83 1520.68 L1472.83 1515.95 Q1475.66 1514.82 1478.11 1514.24 Q1480.56 1513.66 1482.6 1513.66 Q1487.97 1513.66 1491.17 1516.35 Q1494.36 1519.03 1494.36 1523.52 Q1494.36 1525.65 1493.55 1527.57 Q1492.76 1529.47 1490.66 1532.07 Q1490.08 1532.74 1486.98 1535.95 Q1483.87 1539.15 1478.23 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M1514.36 1517.37 Q1510.75 1517.37 1508.92 1520.93 Q1507.11 1524.47 1507.11 1531.6 Q1507.11 1538.71 1508.92 1542.27 Q1510.75 1545.82 1514.36 1545.82 Q1517.99 1545.82 1519.8 1542.27 Q1521.63 1538.71 1521.63 1531.6 Q1521.63 1524.47 1519.8 1520.93 Q1517.99 1517.37 1514.36 1517.37 M1514.36 1513.66 Q1520.17 1513.66 1523.23 1518.27 Q1526.3 1522.85 1526.3 1531.6 Q1526.3 1540.33 1523.23 1544.94 Q1520.17 1549.52 1514.36 1549.52 Q1508.55 1549.52 1505.47 1544.94 Q1502.42 1540.33 1502.42 1531.6 Q1502.42 1522.85 1505.47 1518.27 Q1508.55 1513.66 1514.36 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M1808.69 1544.91 L1825.01 1544.91 L1825.01 1548.85 L1803.07 1548.85 L1803.07 1544.91 Q1805.73 1542.16 1810.31 1537.53 Q1814.92 1532.88 1816.1 1531.53 Q1818.35 1529.01 1819.23 1527.27 Q1820.13 1525.51 1820.13 1523.82 Q1820.13 1521.07 1818.18 1519.33 Q1816.26 1517.6 1813.16 1517.6 Q1810.96 1517.6 1808.51 1518.36 Q1806.08 1519.13 1803.3 1520.68 L1803.3 1515.95 Q1806.12 1514.82 1808.58 1514.24 Q1811.03 1513.66 1813.07 1513.66 Q1818.44 1513.66 1821.63 1516.35 Q1824.83 1519.03 1824.83 1523.52 Q1824.83 1525.65 1824.02 1527.57 Q1823.23 1529.47 1821.12 1532.07 Q1820.55 1532.74 1817.44 1535.95 Q1814.34 1539.15 1808.69 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M1834.87 1514.29 L1853.23 1514.29 L1853.23 1518.22 L1839.16 1518.22 L1839.16 1526.7 Q1840.18 1526.35 1841.19 1526.19 Q1842.21 1526 1843.23 1526 Q1849.02 1526 1852.4 1529.17 Q1855.78 1532.34 1855.78 1537.76 Q1855.78 1543.34 1852.3 1546.44 Q1848.83 1549.52 1842.51 1549.52 Q1840.34 1549.52 1838.07 1549.15 Q1835.82 1548.78 1833.42 1548.04 L1833.42 1543.34 Q1835.5 1544.47 1837.72 1545.03 Q1839.94 1545.58 1842.42 1545.58 Q1846.43 1545.58 1848.76 1543.48 Q1851.1 1541.37 1851.1 1537.76 Q1851.1 1534.15 1848.76 1532.04 Q1846.43 1529.94 1842.42 1529.94 Q1840.55 1529.94 1838.67 1530.35 Q1836.82 1530.77 1834.87 1531.65 L1834.87 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M2148.24 1530.21 Q2151.59 1530.93 2153.47 1533.2 Q2155.37 1535.47 2155.37 1538.8 Q2155.37 1543.92 2151.85 1546.72 Q2148.33 1549.52 2141.85 1549.52 Q2139.67 1549.52 2137.36 1549.08 Q2135.06 1548.66 2132.61 1547.81 L2132.61 1543.29 Q2134.56 1544.43 2136.87 1545.01 Q2139.19 1545.58 2141.71 1545.58 Q2146.11 1545.58 2148.4 1543.85 Q2150.71 1542.11 2150.71 1538.8 Q2150.71 1535.75 2148.56 1534.03 Q2146.43 1532.3 2142.61 1532.3 L2138.58 1532.3 L2138.58 1528.45 L2142.8 1528.45 Q2146.25 1528.45 2148.07 1527.09 Q2149.9 1525.7 2149.9 1523.11 Q2149.9 1520.45 2148 1519.03 Q2146.13 1517.6 2142.61 1517.6 Q2140.69 1517.6 2138.49 1518.01 Q2136.29 1518.43 2133.65 1519.31 L2133.65 1515.14 Q2136.31 1514.4 2138.63 1514.03 Q2140.97 1513.66 2143.03 1513.66 Q2148.35 1513.66 2151.45 1516.09 Q2154.56 1518.5 2154.56 1522.62 Q2154.56 1525.49 2152.91 1527.48 Q2151.27 1529.45 2148.24 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M2174.23 1517.37 Q2170.62 1517.37 2168.79 1520.93 Q2166.99 1524.47 2166.99 1531.6 Q2166.99 1538.71 2168.79 1542.27 Q2170.62 1545.82 2174.23 1545.82 Q2177.87 1545.82 2179.67 1542.27 Q2181.5 1538.71 2181.5 1531.6 Q2181.5 1524.47 2179.67 1520.93 Q2177.87 1517.37 2174.23 1517.37 M2174.23 1513.66 Q2180.04 1513.66 2183.1 1518.27 Q2186.18 1522.85 2186.18 1531.6 Q2186.18 1540.33 2183.1 1544.94 Q2180.04 1549.52 2174.23 1549.52 Q2168.42 1549.52 2165.34 1544.94 Q2162.29 1540.33 2162.29 1531.6 Q2162.29 1522.85 2165.34 1518.27 Q2168.42 1513.66 2174.23 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip342)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,1445.72 2352.76,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip342)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,1161.83 2352.76,1161.83 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip342)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,877.936 2352.76,877.936 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip342)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,594.046 2352.76,594.046 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip342)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,310.156 2352.76,310.156 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip340)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,1486.45 184.191,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip340)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,1445.72 203.088,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip340)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,1161.83 203.088,1161.83 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip340)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,877.936 203.088,877.936 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip340)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,594.046 203.088,594.046 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip340)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,310.156 203.088,310.156 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip340)\" d=\"M91.0151 1431.51 Q87.404 1431.51 85.5753 1435.08 Q83.7697 1438.62 83.7697 1445.75 Q83.7697 1452.86 85.5753 1456.42 Q87.404 1459.96 91.0151 1459.96 Q94.6493 1459.96 96.4548 1456.42 Q98.2835 1452.86 98.2835 1445.75 Q98.2835 1438.62 96.4548 1435.08 Q94.6493 1431.51 91.0151 1431.51 M91.0151 1427.81 Q96.8252 1427.81 99.8808 1432.42 Q102.959 1437 102.959 1445.75 Q102.959 1454.48 99.8808 1459.08 Q96.8252 1463.67 91.0151 1463.67 Q85.2049 1463.67 82.1262 1459.08 Q79.0707 1454.48 79.0707 1445.75 Q79.0707 1437 82.1262 1432.42 Q85.2049 1427.81 91.0151 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M111.177 1457.12 L116.061 1457.12 L116.061 1463 L111.177 1463 L111.177 1457.12 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M136.246 1431.51 Q132.635 1431.51 130.807 1435.08 Q129.001 1438.62 129.001 1445.75 Q129.001 1452.86 130.807 1456.42 Q132.635 1459.96 136.246 1459.96 Q139.881 1459.96 141.686 1456.42 Q143.515 1452.86 143.515 1445.75 Q143.515 1438.62 141.686 1435.08 Q139.881 1431.51 136.246 1431.51 M136.246 1427.81 Q142.056 1427.81 145.112 1432.42 Q148.191 1437 148.191 1445.75 Q148.191 1454.48 145.112 1459.08 Q142.056 1463.67 136.246 1463.67 Q130.436 1463.67 127.357 1459.08 Q124.302 1454.48 124.302 1445.75 Q124.302 1437 127.357 1432.42 Q130.436 1427.81 136.246 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M86.0382 1175.17 L102.358 1175.17 L102.358 1179.11 L80.4133 1179.11 L80.4133 1175.17 Q83.0753 1172.42 87.6586 1167.79 Q92.2651 1163.13 93.4456 1161.79 Q95.691 1159.27 96.5706 1157.53 Q97.4734 1155.77 97.4734 1154.08 Q97.4734 1151.33 95.5289 1149.59 Q93.6076 1147.86 90.5058 1147.86 Q88.3067 1147.86 85.8531 1148.62 Q83.4225 1149.38 80.6447 1150.93 L80.6447 1146.21 Q83.4688 1145.08 85.9225 1144.5 Q88.3762 1143.92 90.4132 1143.92 Q95.7836 1143.92 98.978 1146.61 Q102.172 1149.29 102.172 1153.78 Q102.172 1155.91 101.362 1157.83 Q100.575 1159.73 98.4687 1162.32 Q97.89 1162.99 94.7882 1166.21 Q91.6864 1169.41 86.0382 1175.17 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M112.172 1173.23 L117.057 1173.23 L117.057 1179.11 L112.172 1179.11 L112.172 1173.23 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M127.288 1144.55 L145.644 1144.55 L145.644 1148.48 L131.57 1148.48 L131.57 1156.95 Q132.589 1156.61 133.607 1156.44 Q134.626 1156.26 135.644 1156.26 Q141.431 1156.26 144.811 1159.43 Q148.191 1162.6 148.191 1168.02 Q148.191 1173.6 144.718 1176.7 Q141.246 1179.78 134.927 1179.78 Q132.751 1179.78 130.482 1179.41 Q128.237 1179.04 125.83 1178.3 L125.83 1173.6 Q127.913 1174.73 130.135 1175.29 Q132.357 1175.84 134.834 1175.84 Q138.839 1175.84 141.177 1173.74 Q143.515 1171.63 143.515 1168.02 Q143.515 1164.41 141.177 1162.3 Q138.839 1160.19 134.834 1160.19 Q132.959 1160.19 131.084 1160.61 Q129.232 1161.03 127.288 1161.91 L127.288 1144.55 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M81.0614 860.656 L99.4178 860.656 L99.4178 864.591 L85.3438 864.591 L85.3438 873.063 Q86.3623 872.716 87.3808 872.554 Q88.3993 872.369 89.4178 872.369 Q95.2049 872.369 98.5845 875.54 Q101.964 878.711 101.964 884.128 Q101.964 889.706 98.4919 892.808 Q95.0197 895.887 88.7003 895.887 Q86.5243 895.887 84.2558 895.517 Q82.0105 895.146 79.6031 894.406 L79.6031 889.706 Q81.6864 890.841 83.9086 891.396 Q86.1308 891.952 88.6077 891.952 Q92.6123 891.952 94.9502 889.845 Q97.2882 887.739 97.2882 884.128 Q97.2882 880.517 94.9502 878.41 Q92.6123 876.304 88.6077 876.304 Q86.7327 876.304 84.8577 876.72 Q83.0058 877.137 81.0614 878.017 L81.0614 860.656 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M111.177 889.336 L116.061 889.336 L116.061 895.216 L111.177 895.216 L111.177 889.336 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M136.246 863.734 Q132.635 863.734 130.807 867.299 Q129.001 870.841 129.001 877.97 Q129.001 885.077 130.807 888.642 Q132.635 892.183 136.246 892.183 Q139.881 892.183 141.686 888.642 Q143.515 885.077 143.515 877.97 Q143.515 870.841 141.686 867.299 Q139.881 863.734 136.246 863.734 M136.246 860.031 Q142.056 860.031 145.112 864.637 Q148.191 869.22 148.191 877.97 Q148.191 886.697 145.112 891.304 Q142.056 895.887 136.246 895.887 Q130.436 895.887 127.357 891.304 Q124.302 886.697 124.302 877.97 Q124.302 869.22 127.357 864.637 Q130.436 860.031 136.246 860.031 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M80.8299 576.766 L103.052 576.766 L103.052 578.756 L90.5058 611.326 L85.6216 611.326 L97.4271 580.701 L80.8299 580.701 L80.8299 576.766 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M112.172 605.446 L117.057 605.446 L117.057 611.326 L112.172 611.326 L112.172 605.446 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M127.288 576.766 L145.644 576.766 L145.644 580.701 L131.57 580.701 L131.57 589.173 Q132.589 588.826 133.607 588.664 Q134.626 588.479 135.644 588.479 Q141.431 588.479 144.811 591.65 Q148.191 594.821 148.191 600.238 Q148.191 605.816 144.718 608.918 Q141.246 611.997 134.927 611.997 Q132.751 611.997 130.482 611.627 Q128.237 611.256 125.83 610.516 L125.83 605.816 Q127.913 606.951 130.135 607.506 Q132.357 608.062 134.834 608.062 Q138.839 608.062 141.177 605.955 Q143.515 603.849 143.515 600.238 Q143.515 596.627 141.177 594.52 Q138.839 592.414 134.834 592.414 Q132.959 592.414 131.084 592.83 Q129.232 593.247 127.288 594.127 L127.288 576.766 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M51.6634 323.501 L59.3023 323.501 L59.3023 297.135 L50.9921 298.802 L50.9921 294.542 L59.256 292.876 L63.9319 292.876 L63.9319 323.501 L71.5707 323.501 L71.5707 327.436 L51.6634 327.436 L51.6634 323.501 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M91.0151 295.954 Q87.404 295.954 85.5753 299.519 Q83.7697 303.061 83.7697 310.19 Q83.7697 317.297 85.5753 320.862 Q87.404 324.403 91.0151 324.403 Q94.6493 324.403 96.4548 320.862 Q98.2835 317.297 98.2835 310.19 Q98.2835 303.061 96.4548 299.519 Q94.6493 295.954 91.0151 295.954 M91.0151 292.251 Q96.8252 292.251 99.8808 296.857 Q102.959 301.44 102.959 310.19 Q102.959 318.917 99.8808 323.524 Q96.8252 328.107 91.0151 328.107 Q85.2049 328.107 82.1262 323.524 Q79.0707 318.917 79.0707 310.19 Q79.0707 301.44 82.1262 296.857 Q85.2049 292.251 91.0151 292.251 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M111.177 321.556 L116.061 321.556 L116.061 327.436 L111.177 327.436 L111.177 321.556 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M136.246 295.954 Q132.635 295.954 130.807 299.519 Q129.001 303.061 129.001 310.19 Q129.001 317.297 130.807 320.862 Q132.635 324.403 136.246 324.403 Q139.881 324.403 141.686 320.862 Q143.515 317.297 143.515 310.19 Q143.515 303.061 141.686 299.519 Q139.881 295.954 136.246 295.954 M136.246 292.251 Q142.056 292.251 145.112 296.857 Q148.191 301.44 148.191 310.19 Q148.191 318.917 145.112 323.524 Q142.056 328.107 136.246 328.107 Q130.436 328.107 127.357 323.524 Q124.302 318.917 124.302 310.19 Q124.302 301.44 127.357 296.857 Q130.436 292.251 136.246 292.251 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip342)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  245.565,1422.88 311.559,1423.29 377.553,1431.08 443.547,1415.48 509.541,1404.32 575.536,1433.06 641.53,1410.51 707.524,1387.38 773.518,1421.92 839.512,1387.15 \n",
       "  905.506,1445.72 971.5,1358.44 1037.49,1320.54 1103.49,1444.97 1169.48,1364.12 1235.48,1206.5 1301.47,1425.08 1367.46,1418.91 1433.46,1263.92 1499.45,1305.08 \n",
       "  1565.45,1443.5 1631.44,87.9763 1697.43,1445.72 1763.43,1445.72 1829.42,1426.75 1895.42,1407.71 1961.41,1380.9 2027.41,1445.72 2093.4,1444.51 2159.39,1236.91 \n",
       "  2225.39,1436.83 2291.38,1379.82 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip340)\" d=\"\n",
       "M1987.09 198.898 L2280.47 198.898 L2280.47 95.2176 L1987.09 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip340)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1987.09,198.898 2280.47,198.898 2280.47,95.2176 1987.09,95.2176 1987.09,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip340)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2011.18,147.058 2155.75,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip340)\" d=\"M2193.69 166.745 Q2191.89 171.375 2190.17 172.787 Q2188.46 174.199 2185.59 174.199 L2182.19 174.199 L2182.19 170.634 L2184.69 170.634 Q2186.45 170.634 2187.42 169.8 Q2188.39 168.967 2189.57 165.865 L2190.34 163.921 L2179.85 138.412 L2184.36 138.412 L2192.47 158.689 L2200.57 138.412 L2205.08 138.412 L2193.69 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip340)\" d=\"M2212.37 160.402 L2220.01 160.402 L2220.01 134.037 L2211.7 135.703 L2211.7 131.444 L2219.97 129.778 L2224.64 129.778 L2224.64 160.402 L2232.28 160.402 L2232.28 164.338 L2212.37 164.338 L2212.37 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    bestEpSc    = -100.0;\n",
    "    statesBest  = zeros( size( X_0, 1 ), T )\n",
    "    actionsBest = zeros( T );\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/(episodes-1)\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        s_l = 0.0\n",
    "        # while s_l == 0\n",
    "        \n",
    "            X  = X_0\n",
    "\n",
    "            ##### Double Q-Learning ###########################################\n",
    "\n",
    "            for k = 1:T\n",
    "\n",
    "                # 1. Choose action\n",
    "                if rand() < epsilon\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                else\n",
    "\n",
    "                    A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                    if A == 1000.0 # Indicates no values in this region\n",
    "                        if rand() < EXPrand \n",
    "                            A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                        else\n",
    "                            A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                # 2. Cache last state\n",
    "                qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "                # 3. Generate the next stae\n",
    "                Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "                # 4. Collect reward R( s, a, s' )\n",
    "                R_t = cartpole_reward( Xp )\n",
    "\n",
    "                # 5. Get the optimal action at the next state\n",
    "                a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "                # 6. Compute the value at the next state\n",
    "\n",
    "                V_tp1_opt = query_value_fuzzy( \n",
    "                    Q_kdTree, G, V, \n",
    "                    get_Q( \n",
    "                        select_X_vector( Xp ), \n",
    "                        a_tp1_opt \n",
    "                    ); \n",
    "                    k = vNN \n",
    "                )\n",
    "                if isnan( V_tp1_opt )\n",
    "                    V_tp1_opt = 0.0\n",
    "                end\n",
    "\n",
    "\n",
    "                # 7. Blend the value back into nearest points\n",
    "\n",
    "                idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "                nNear      = size( idxs, 1 )\n",
    "                for i = 1:nNear\n",
    "                    j    = idxs[i]\n",
    "                    if !isnan( wgts[i] ) \n",
    "\n",
    "                        # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                        VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                states[:,k] = Xp\n",
    "                actions[k]  = A\n",
    "\n",
    "                X = Xp\n",
    "            end\n",
    "\n",
    "            s_l    = vertical_score_s( states, aMargin, ts )\n",
    "            \n",
    "        # end\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if s_l > bestEpSc\n",
    "            bestEpSc    = s_l\n",
    "            statesBest  = copy( states  )\n",
    "            actionsBest = copy( actions )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        # if useElig && (s_l > s_Totl/(1.0*l)) && (s_l > 0.0) \n",
    "        # if useElig && (s_l > 0.0) \n",
    "        if useElig \n",
    "            \n",
    "            # if s_l == 0.0\n",
    "            #     states  = copy( bestXs )\n",
    "            #     actions = copy( bestAs )\n",
    "            # end\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "    \n",
    "    ##### Learning Rate Schedule ##########################################\n",
    "    alpha *= beta\n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709555b9-2598-4281-a634-c7b0681277d0",
   "metadata": {},
   "source": [
    "# Method 2 Performance, Average Vertical Duration [s]\n",
    "Each score is the best average score of the last two epochs: 64 epochs of 64 episodes each, Q-function swap after every episode \n",
    "\n",
    "### TD Tuning\n",
    "\n",
    "$\\alpha = 0.99$: 0.238  \n",
    "$\\alpha = 0.75$: 0.257  \n",
    "$\\alpha = 0.50$: 0.191   \n",
    "$\\alpha = 0.25$: 0.170  \n",
    "$\\alpha = 0.125$: 0.290  \n",
    "$\\alpha = 0.0625$: 0.208, but fantastic performance in the middle of training  \n",
    "$\\alpha = 0.03125$: 0.978  \n",
    "$\\alpha = 0.02344$: 2.567  \n",
    "$\\alpha = 0.01953$: 0.268  \n",
    "$\\alpha = 0.015625$: 0.095  \n",
    " \n",
    "### Add gamma?\n",
    " \n",
    "### Double-Q Tuning, Swap Evey N Episodes\n",
    "$\\%\\ \\ 2$:  \n",
    "$\\%\\ \\ 4$:  \n",
    "$\\%\\ \\ 8$:  \n",
    "$\\%16$:  \n",
    "$\\%32$:  \n",
    "$\\%64$:  \n",
    "\n",
    "\n",
    "\n",
    "### Blend: Best Episode\n",
    "\n",
    "$\\beta = 0.07$:  \n",
    "$\\beta = 0.15$: 0.244\n",
    "\n",
    "| Method      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n",
    "| ----------- | ------- | ------- | ------- | ------- | ------- | ---- |\n",
    "| Blend (Epi) |         |         |         |         |         |      |\n",
    "| Blend (Epo) |         |         |         |         |         |      |\n",
    "| TD          |         |         |         |         |         |      |\n",
    "| TD  + ????? |         |         |         |         |         |      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
