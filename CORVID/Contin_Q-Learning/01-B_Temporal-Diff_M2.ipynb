{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.125 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 \n",
    "gamma    = 1.00 \n",
    "swapDiv  = 1\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes =  64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   =  32 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "beta   = 0.15\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = false\n",
    "N_peaks =  40\n",
    "N_steps = 200\n",
    "lambda  =   0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.24000000000000007, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.06484375000000003\n",
      "\n",
      "Epoch 2, Best Score: 0.8100000000000005\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.4400000000000002, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.17, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.6499999999999917\n",
      "\n",
      "Epoch 3, Best Score: 11.629999999999797\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.5900000000000003, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.5200000000000002, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.060312500000000026\n",
      "\n",
      "Epoch 4, Best Score: 11.629999999999797\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.2900000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.2700000000000001, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.24000000000000007, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.3200000000000001, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.6100000000000003, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.5164062500000266\n",
      "\n",
      "Epoch 5, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 0.20000000000000004, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.18000000000000002, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.4300000000000002, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.4000000000000002, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.03062500000000001\n",
      "\n",
      "Epoch 6, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.5300000000000002, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.13999999999999999, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.16796874999999892\n",
      "\n",
      "Epoch 7, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 0.9900000000000007, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.26640624999999696\n",
      "\n",
      "Epoch 8, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.35000000000000014, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 3.239999999999975, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.11999999999999998, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 6.679999999999902, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.7917187499999927\n",
      "\n",
      "Epoch 9, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 0.5200000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.6000000000000003, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 1.1300000000000008, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.09, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.1814062500000001\n",
      "\n",
      "Epoch 10, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.38000000000000017, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.059843750000000036\n",
      "\n",
      "Epoch 11, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 0.38000000000000017, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.48000000000000026, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.7600000000000005, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.3200000000000001, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 1.6600000000000013, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.18000000000000002, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.20000000000000004, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.5800000000000003, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.20249999999999843\n",
      "\n",
      "Epoch 12, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 0.19000000000000003, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.26000000000000006, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.011718750000000003\n",
      "\n",
      "Epoch 13, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.17, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.6100000000000003, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.18000000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.16, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.2700000000000001, epsilon: 0.0078125\n",
      "Average Score: 0.07312500000000004\n",
      "\n",
      "Epoch 14, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 0.46000000000000024, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.11999999999999998, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.25000000000000006, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.12999999999999998, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.3100000000000001, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.16, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.12999999999999998, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.13999999999999999, epsilon: 0.0078125\n",
      "Average Score: 0.11265625000000007\n",
      "\n",
      "Epoch 15, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.45000000000000023, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.20000000000000004, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.4300000000000002, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.10999999999999999, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.17, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.25000000000000006, epsilon: 0.0078125\n",
      "Average Score: 0.12390625000000006\n",
      "\n",
      "Epoch 16, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 0.3000000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.16, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.13999999999999999, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.15, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.48000000000000026, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.23000000000000007, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.34000000000000014, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.17, epsilon: 0.0078125\n",
      "Average Score: 0.18171875000000007\n",
      "\n",
      "Epoch 17, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 1.300000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.09, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.5900000000000003, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.20000000000000004, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.3100000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.12999999999999998, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.13999999999999999, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.2700000000000001, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.4300000000000002, epsilon: 0.0078125\n",
      "Average Score: 0.14406250000000004\n",
      "\n",
      "Epoch 18, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.07, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.2700000000000001, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.3300000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.21000000000000005, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.2900000000000001, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.09, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.3200000000000001, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.4200000000000002, epsilon: 0.0078125\n",
      "Average Score: 0.21015625000000013\n",
      "\n",
      "Epoch 19, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.13999999999999999, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.2900000000000001, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.3100000000000001, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.09, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.17, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.3300000000000001, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.13999999999999999, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.16, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.5200000000000002, epsilon: 0.0078125\n",
      "Average Score: 0.14828125000000006\n",
      "\n",
      "Epoch 20, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 0.19000000000000003, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.18000000000000002, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.13999999999999999, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.12999999999999998, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.24000000000000007, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.2900000000000001, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.08, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.13500000000000004\n",
      "\n",
      "Epoch 21, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.2700000000000001, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.17, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.4300000000000002, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.24000000000000007, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.4300000000000002, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.8400000000000005, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.17, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.3100000000000001, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.08, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.2104687500000001\n",
      "\n",
      "Epoch 22, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 0.5100000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.5800000000000003, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.15, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.2700000000000001, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.24000000000000007, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.15, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.13999999999999999, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.3000000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.4000000000000002, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.5300000000000002, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.13999999999999999, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.35000000000000014, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.8400000000000005, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.09999999999999999, epsilon: 0.0078125\n",
      "Average Score: 0.21203125000000006\n",
      "\n",
      "Epoch 23, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.15, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.16, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.2900000000000001, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.09, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.2700000000000001, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 1.0700000000000007, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.17, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.9900000000000007, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.18000000000000002, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 1.1400000000000008, epsilon: 0.0078125\n",
      "Average Score: 0.27437500000000015\n",
      "\n",
      "Epoch 24, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 1.410000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.18000000000000002, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.16, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.09999999999999999, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.16, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.7400000000000004, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.25000000000000006, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.2800000000000001, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.26000000000000006, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.19000000000000003, epsilon: 0.0078125\n",
      "Average Score: 0.12984375000000006\n",
      "\n",
      "Epoch 25, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 1.0100000000000007, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.5200000000000002, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.21000000000000005, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.3000000000000001, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.09999999999999999, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.38000000000000017, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.14250000000000002\n",
      "\n",
      "Epoch 26, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.2900000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.26000000000000006, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.19000000000000003, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.20000000000000004, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.24000000000000007, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.4300000000000002, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.3200000000000001, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.6800000000000004, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.21515625000000008\n",
      "\n",
      "Epoch 27, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.19000000000000003, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.3200000000000001, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.37000000000000016, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.4400000000000002, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.07, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.13062500000000005\n",
      "\n",
      "Epoch 28, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.17, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.15, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.2800000000000001, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.3200000000000001, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.5300000000000002, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.6600000000000004, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.5000000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.15, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.20000000000000004, epsilon: 0.0078125\n",
      "Average Score: 0.22515625000000014\n",
      "\n",
      "Epoch 29, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.3300000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.3900000000000002, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.25000000000000006, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.45000000000000023, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.47000000000000025, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.26000000000000006, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.6800000000000004, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.20000000000000004, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.9800000000000006, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.4200000000000002, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.17, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.20500000000000007\n",
      "\n",
      "Epoch 30, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 1.490000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.17, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.23000000000000007, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.2800000000000001, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.6700000000000004, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.38000000000000017, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.2900000000000001, epsilon: 0.0078125\n",
      "Average Score: 0.21484375000000008\n",
      "\n",
      "Epoch 31, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.11999999999999998, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.26000000000000006, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.18000000000000002, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.2900000000000001, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.2900000000000001, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.16, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 1.2300000000000009, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.060000000000000005, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.16, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.060000000000000005, epsilon: 0.0078125\n",
      "Average Score: 0.17703125000000006\n",
      "\n",
      "Epoch 32, Best Score: 28.800000000001702\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.35000000000000014, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.15, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.18000000000000002, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.24000000000000007, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.4400000000000002, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.3900000000000002, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.20000000000000004, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.7500000000000004, epsilon: 0.0078125\n",
      "Average Score: 0.15968750000000007\n",
      "Saved a trained Q-table with size (76032,), After 13.12398848136266 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip080\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip080)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip081\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip080)\" d=\"\n",
       "M156.598 1486.45 L2352.76 1486.45 L2352.76 47.2441 L156.598 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip082\">\n",
       "    <rect x=\"156\" y=\"47\" width=\"2197\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  486.089,1486.45 486.089,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  820.258,1486.45 820.258,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1154.43,1486.45 1154.43,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1488.6,1486.45 1488.6,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1822.76,1486.45 1822.76,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2156.93,1486.45 2156.93,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  486.089,1486.45 486.089,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  820.258,1486.45 820.258,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1154.43,1486.45 1154.43,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1488.6,1486.45 1488.6,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1822.76,1486.45 1822.76,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2156.93,1486.45 2156.93,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip080)\" d=\"M476.367 1514.29 L494.723 1514.29 L494.723 1518.22 L480.649 1518.22 L480.649 1526.7 Q481.667 1526.35 482.686 1526.19 Q483.704 1526 484.723 1526 Q490.51 1526 493.89 1529.17 Q497.269 1532.34 497.269 1537.76 Q497.269 1543.34 493.797 1546.44 Q490.325 1549.52 484.005 1549.52 Q481.829 1549.52 479.561 1549.15 Q477.316 1548.78 474.908 1548.04 L474.908 1543.34 Q476.992 1544.47 479.214 1545.03 Q481.436 1545.58 483.913 1545.58 Q487.917 1545.58 490.255 1543.48 Q492.593 1541.37 492.593 1537.76 Q492.593 1534.15 490.255 1532.04 Q487.917 1529.94 483.913 1529.94 Q482.038 1529.94 480.163 1530.35 Q478.311 1530.77 476.367 1531.65 L476.367 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M794.945 1544.91 L802.584 1544.91 L802.584 1518.55 L794.274 1520.21 L794.274 1515.95 L802.538 1514.29 L807.214 1514.29 L807.214 1544.91 L814.853 1544.91 L814.853 1548.85 L794.945 1548.85 L794.945 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M834.297 1517.37 Q830.686 1517.37 828.857 1520.93 Q827.052 1524.47 827.052 1531.6 Q827.052 1538.71 828.857 1542.27 Q830.686 1545.82 834.297 1545.82 Q837.931 1545.82 839.737 1542.27 Q841.565 1538.71 841.565 1531.6 Q841.565 1524.47 839.737 1520.93 Q837.931 1517.37 834.297 1517.37 M834.297 1513.66 Q840.107 1513.66 843.163 1518.27 Q846.241 1522.85 846.241 1531.6 Q846.241 1540.33 843.163 1544.94 Q840.107 1549.52 834.297 1549.52 Q828.487 1549.52 825.408 1544.94 Q822.352 1540.33 822.352 1531.6 Q822.352 1522.85 825.408 1518.27 Q828.487 1513.66 834.297 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M1129.61 1544.91 L1137.25 1544.91 L1137.25 1518.55 L1128.94 1520.21 L1128.94 1515.95 L1137.2 1514.29 L1141.88 1514.29 L1141.88 1544.91 L1149.52 1544.91 L1149.52 1548.85 L1129.61 1548.85 L1129.61 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M1159.01 1514.29 L1177.37 1514.29 L1177.37 1518.22 L1163.29 1518.22 L1163.29 1526.7 Q1164.31 1526.35 1165.33 1526.19 Q1166.35 1526 1167.37 1526 Q1173.15 1526 1176.53 1529.17 Q1179.91 1532.34 1179.91 1537.76 Q1179.91 1543.34 1176.44 1546.44 Q1172.97 1549.52 1166.65 1549.52 Q1164.47 1549.52 1162.2 1549.15 Q1159.96 1548.78 1157.55 1548.04 L1157.55 1543.34 Q1159.63 1544.47 1161.86 1545.03 Q1164.08 1545.58 1166.56 1545.58 Q1170.56 1545.58 1172.9 1543.48 Q1175.24 1541.37 1175.24 1537.76 Q1175.24 1534.15 1172.9 1532.04 Q1170.56 1529.94 1166.56 1529.94 Q1164.68 1529.94 1162.81 1530.35 Q1160.95 1530.77 1159.01 1531.65 L1159.01 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M1467.37 1544.91 L1483.69 1544.91 L1483.69 1548.85 L1461.74 1548.85 L1461.74 1544.91 Q1464.41 1542.16 1468.99 1537.53 Q1473.6 1532.88 1474.78 1531.53 Q1477.02 1529.01 1477.9 1527.27 Q1478.8 1525.51 1478.8 1523.82 Q1478.8 1521.07 1476.86 1519.33 Q1474.94 1517.6 1471.84 1517.6 Q1469.64 1517.6 1467.18 1518.36 Q1464.75 1519.13 1461.98 1520.68 L1461.98 1515.95 Q1464.8 1514.82 1467.25 1514.24 Q1469.71 1513.66 1471.74 1513.66 Q1477.11 1513.66 1480.31 1516.35 Q1483.5 1519.03 1483.5 1523.52 Q1483.5 1525.65 1482.69 1527.57 Q1481.91 1529.47 1479.8 1532.07 Q1479.22 1532.74 1476.12 1535.95 Q1473.02 1539.15 1467.37 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M1503.5 1517.37 Q1499.89 1517.37 1498.06 1520.93 Q1496.26 1524.47 1496.26 1531.6 Q1496.26 1538.71 1498.06 1542.27 Q1499.89 1545.82 1503.5 1545.82 Q1507.14 1545.82 1508.94 1542.27 Q1510.77 1538.71 1510.77 1531.6 Q1510.77 1524.47 1508.94 1520.93 Q1507.14 1517.37 1503.5 1517.37 M1503.5 1513.66 Q1509.31 1513.66 1512.37 1518.27 Q1515.45 1522.85 1515.45 1531.6 Q1515.45 1540.33 1512.37 1544.94 Q1509.31 1549.52 1503.5 1549.52 Q1497.69 1549.52 1494.61 1544.94 Q1491.56 1540.33 1491.56 1531.6 Q1491.56 1522.85 1494.61 1518.27 Q1497.69 1513.66 1503.5 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M1802.04 1544.91 L1818.35 1544.91 L1818.35 1548.85 L1796.41 1548.85 L1796.41 1544.91 Q1799.07 1542.16 1803.66 1537.53 Q1808.26 1532.88 1809.44 1531.53 Q1811.69 1529.01 1812.57 1527.27 Q1813.47 1525.51 1813.47 1523.82 Q1813.47 1521.07 1811.53 1519.33 Q1809.6 1517.6 1806.5 1517.6 Q1804.3 1517.6 1801.85 1518.36 Q1799.42 1519.13 1796.64 1520.68 L1796.64 1515.95 Q1799.47 1514.82 1801.92 1514.24 Q1804.37 1513.66 1806.41 1513.66 Q1811.78 1513.66 1814.97 1516.35 Q1818.17 1519.03 1818.17 1523.52 Q1818.17 1525.65 1817.36 1527.57 Q1816.57 1529.47 1814.47 1532.07 Q1813.89 1532.74 1810.79 1535.95 Q1807.68 1539.15 1802.04 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M1828.22 1514.29 L1846.57 1514.29 L1846.57 1518.22 L1832.5 1518.22 L1832.5 1526.7 Q1833.52 1526.35 1834.53 1526.19 Q1835.55 1526 1836.57 1526 Q1842.36 1526 1845.74 1529.17 Q1849.12 1532.34 1849.12 1537.76 Q1849.12 1543.34 1845.65 1546.44 Q1842.17 1549.52 1835.85 1549.52 Q1833.68 1549.52 1831.41 1549.15 Q1829.16 1548.78 1826.76 1548.04 L1826.76 1543.34 Q1828.84 1544.47 1831.06 1545.03 Q1833.28 1545.58 1835.76 1545.58 Q1839.77 1545.58 1842.1 1543.48 Q1844.44 1541.37 1844.44 1537.76 Q1844.44 1534.15 1842.1 1532.04 Q1839.77 1529.94 1835.76 1529.94 Q1833.89 1529.94 1832.01 1530.35 Q1830.16 1530.77 1828.22 1531.65 L1828.22 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M2145.78 1530.21 Q2149.13 1530.93 2151.01 1533.2 Q2152.91 1535.47 2152.91 1538.8 Q2152.91 1543.92 2149.39 1546.72 Q2145.87 1549.52 2139.39 1549.52 Q2137.21 1549.52 2134.9 1549.08 Q2132.6 1548.66 2130.15 1547.81 L2130.15 1543.29 Q2132.1 1544.43 2134.41 1545.01 Q2136.72 1545.58 2139.25 1545.58 Q2143.65 1545.58 2145.94 1543.85 Q2148.25 1542.11 2148.25 1538.8 Q2148.25 1535.75 2146.1 1534.03 Q2143.97 1532.3 2140.15 1532.3 L2136.12 1532.3 L2136.12 1528.45 L2140.34 1528.45 Q2143.78 1528.45 2145.61 1527.09 Q2147.44 1525.7 2147.44 1523.11 Q2147.44 1520.45 2145.54 1519.03 Q2143.67 1517.6 2140.15 1517.6 Q2138.23 1517.6 2136.03 1518.01 Q2133.83 1518.43 2131.19 1519.31 L2131.19 1515.14 Q2133.85 1514.4 2136.17 1514.03 Q2138.51 1513.66 2140.57 1513.66 Q2145.89 1513.66 2148.99 1516.09 Q2152.1 1518.5 2152.1 1522.62 Q2152.1 1525.49 2150.45 1527.48 Q2148.81 1529.45 2145.78 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M2171.77 1517.37 Q2168.16 1517.37 2166.33 1520.93 Q2164.53 1524.47 2164.53 1531.6 Q2164.53 1538.71 2166.33 1542.27 Q2168.16 1545.82 2171.77 1545.82 Q2175.41 1545.82 2177.21 1542.27 Q2179.04 1538.71 2179.04 1531.6 Q2179.04 1524.47 2177.21 1520.93 Q2175.41 1517.37 2171.77 1517.37 M2171.77 1513.66 Q2177.58 1513.66 2180.64 1518.27 Q2183.72 1522.85 2183.72 1531.6 Q2183.72 1540.33 2180.64 1544.94 Q2177.58 1549.52 2171.77 1549.52 Q2165.96 1549.52 2162.88 1544.94 Q2159.83 1540.33 2159.83 1531.6 Q2159.83 1522.85 2162.88 1518.27 Q2165.96 1513.66 2171.77 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,1466.11 2352.76,1466.11 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,1117.98 2352.76,1117.98 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,769.838 2352.76,769.838 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,421.699 2352.76,421.699 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,73.5612 2352.76,73.5612 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1486.45 156.598,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1466.11 175.496,1466.11 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1117.98 175.496,1117.98 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,769.838 175.496,769.838 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,421.699 175.496,421.699 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,73.5612 175.496,73.5612 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip080)\" d=\"M63.4226 1451.91 Q59.8115 1451.91 57.9828 1455.48 Q56.1773 1459.02 56.1773 1466.15 Q56.1773 1473.26 57.9828 1476.82 Q59.8115 1480.36 63.4226 1480.36 Q67.0569 1480.36 68.8624 1476.82 Q70.6911 1473.26 70.6911 1466.15 Q70.6911 1459.02 68.8624 1455.48 Q67.0569 1451.91 63.4226 1451.91 M63.4226 1448.21 Q69.2328 1448.21 72.2883 1452.82 Q75.367 1457.4 75.367 1466.15 Q75.367 1474.88 72.2883 1479.48 Q69.2328 1484.07 63.4226 1484.07 Q57.6125 1484.07 54.5338 1479.48 Q51.4782 1474.88 51.4782 1466.15 Q51.4782 1457.4 54.5338 1452.82 Q57.6125 1448.21 63.4226 1448.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M83.5845 1477.51 L88.4688 1477.51 L88.4688 1483.39 L83.5845 1483.39 L83.5845 1477.51 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M108.654 1451.91 Q105.043 1451.91 103.214 1455.48 Q101.409 1459.02 101.409 1466.15 Q101.409 1473.26 103.214 1476.82 Q105.043 1480.36 108.654 1480.36 Q112.288 1480.36 114.094 1476.82 Q115.922 1473.26 115.922 1466.15 Q115.922 1459.02 114.094 1455.48 Q112.288 1451.91 108.654 1451.91 M108.654 1448.21 Q114.464 1448.21 117.52 1452.82 Q120.598 1457.4 120.598 1466.15 Q120.598 1474.88 117.52 1479.48 Q114.464 1484.07 108.654 1484.07 Q102.844 1484.07 99.765 1479.48 Q96.7095 1474.88 96.7095 1466.15 Q96.7095 1457.4 99.765 1452.82 Q102.844 1448.21 108.654 1448.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M65.0198 1103.77 Q61.4087 1103.77 59.58 1107.34 Q57.7745 1110.88 57.7745 1118.01 Q57.7745 1125.12 59.58 1128.68 Q61.4087 1132.22 65.0198 1132.22 Q68.6541 1132.22 70.4596 1128.68 Q72.2883 1125.12 72.2883 1118.01 Q72.2883 1110.88 70.4596 1107.34 Q68.6541 1103.77 65.0198 1103.77 M65.0198 1100.07 Q70.83 1100.07 73.8855 1104.68 Q76.9642 1109.26 76.9642 1118.01 Q76.9642 1126.74 73.8855 1131.34 Q70.83 1135.93 65.0198 1135.93 Q59.2097 1135.93 56.131 1131.34 Q53.0754 1126.74 53.0754 1118.01 Q53.0754 1109.26 56.131 1104.68 Q59.2097 1100.07 65.0198 1100.07 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M85.1818 1129.38 L90.066 1129.38 L90.066 1135.26 L85.1818 1135.26 L85.1818 1129.38 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M104.279 1131.32 L120.598 1131.32 L120.598 1135.26 L98.6539 1135.26 L98.6539 1131.32 Q101.316 1128.57 105.899 1123.94 Q110.506 1119.28 111.686 1117.94 Q113.932 1115.42 114.811 1113.68 Q115.714 1111.92 115.714 1110.23 Q115.714 1107.48 113.77 1105.74 Q111.848 1104.01 108.746 1104.01 Q106.547 1104.01 104.094 1104.77 Q101.663 1105.53 98.8854 1107.08 L98.8854 1102.36 Q101.709 1101.23 104.163 1100.65 Q106.617 1100.07 108.654 1100.07 Q114.024 1100.07 117.219 1102.76 Q120.413 1105.44 120.413 1109.93 Q120.413 1112.06 119.603 1113.98 Q118.816 1115.88 116.709 1118.47 Q116.131 1119.15 113.029 1122.36 Q109.927 1125.56 104.279 1131.32 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M62.9365 755.636 Q59.3254 755.636 57.4967 759.201 Q55.6912 762.743 55.6912 769.873 Q55.6912 776.979 57.4967 780.544 Q59.3254 784.085 62.9365 784.085 Q66.5707 784.085 68.3763 780.544 Q70.205 776.979 70.205 769.873 Q70.205 762.743 68.3763 759.201 Q66.5707 755.636 62.9365 755.636 M62.9365 751.933 Q68.7467 751.933 71.8022 756.539 Q74.8809 761.123 74.8809 769.873 Q74.8809 778.599 71.8022 783.206 Q68.7467 787.789 62.9365 787.789 Q57.1264 787.789 54.0477 783.206 Q50.9921 778.599 50.9921 769.873 Q50.9921 761.123 54.0477 756.539 Q57.1264 751.933 62.9365 751.933 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M83.0984 781.238 L87.9827 781.238 L87.9827 787.118 L83.0984 787.118 L83.0984 781.238 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M111.015 756.632 L99.2095 775.081 L111.015 775.081 L111.015 756.632 M109.788 752.558 L115.668 752.558 L115.668 775.081 L120.598 775.081 L120.598 778.97 L115.668 778.97 L115.668 787.118 L111.015 787.118 L111.015 778.97 L95.4132 778.97 L95.4132 774.456 L109.788 752.558 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M63.2606 407.498 Q59.6495 407.498 57.8208 411.063 Q56.0152 414.605 56.0152 421.734 Q56.0152 428.841 57.8208 432.405 Q59.6495 435.947 63.2606 435.947 Q66.8948 435.947 68.7004 432.405 Q70.5291 428.841 70.5291 421.734 Q70.5291 414.605 68.7004 411.063 Q66.8948 407.498 63.2606 407.498 M63.2606 403.794 Q69.0707 403.794 72.1263 408.401 Q75.205 412.984 75.205 421.734 Q75.205 430.461 72.1263 435.067 Q69.0707 439.651 63.2606 439.651 Q57.4504 439.651 54.3717 435.067 Q51.3162 430.461 51.3162 421.734 Q51.3162 412.984 54.3717 408.401 Q57.4504 403.794 63.2606 403.794 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M83.4225 433.1 L88.3067 433.1 L88.3067 438.979 L83.4225 438.979 L83.4225 433.1 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M109.071 419.836 Q105.922 419.836 104.071 421.989 Q102.242 424.142 102.242 427.892 Q102.242 431.618 104.071 433.794 Q105.922 435.947 109.071 435.947 Q112.219 435.947 114.047 433.794 Q115.899 431.618 115.899 427.892 Q115.899 424.142 114.047 421.989 Q112.219 419.836 109.071 419.836 M118.353 405.183 L118.353 409.443 Q116.594 408.609 114.788 408.169 Q113.006 407.73 111.246 407.73 Q106.617 407.73 104.163 410.855 Q101.733 413.98 101.385 420.299 Q102.751 418.285 104.811 417.22 Q106.871 416.132 109.348 416.132 Q114.557 416.132 117.566 419.304 Q120.598 422.452 120.598 427.892 Q120.598 433.216 117.45 436.433 Q114.302 439.651 109.071 439.651 Q103.075 439.651 99.9039 435.067 Q96.7326 430.461 96.7326 421.734 Q96.7326 413.54 100.621 408.679 Q104.51 403.794 111.061 403.794 Q112.82 403.794 114.603 404.142 Q116.408 404.489 118.353 405.183 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M63.5152 59.3599 Q59.9041 59.3599 58.0754 62.9247 Q56.2699 66.4663 56.2699 73.5959 Q56.2699 80.7023 58.0754 84.2671 Q59.9041 87.8088 63.5152 87.8088 Q67.1494 87.8088 68.955 84.2671 Q70.7837 80.7023 70.7837 73.5959 Q70.7837 66.4663 68.955 62.9247 Q67.1494 59.3599 63.5152 59.3599 M63.5152 55.6562 Q69.3254 55.6562 72.3809 60.2626 Q75.4596 64.8459 75.4596 73.5959 Q75.4596 82.3227 72.3809 86.9292 Q69.3254 91.5125 63.5152 91.5125 Q57.7051 91.5125 54.6264 86.9292 Q51.5708 82.3227 51.5708 73.5959 Q51.5708 64.8459 54.6264 60.2626 Q57.7051 55.6562 63.5152 55.6562 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M83.6771 84.9616 L88.5614 84.9616 L88.5614 90.8412 L83.6771 90.8412 L83.6771 84.9616 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M108.746 74.4292 Q105.413 74.4292 103.492 76.2116 Q101.594 77.994 101.594 81.119 Q101.594 84.244 103.492 86.0264 Q105.413 87.8088 108.746 87.8088 Q112.08 87.8088 114.001 86.0264 Q115.922 84.2208 115.922 81.119 Q115.922 77.994 114.001 76.2116 Q112.103 74.4292 108.746 74.4292 M104.071 72.4385 Q101.061 71.6978 99.3715 69.6376 Q97.7048 67.5774 97.7048 64.6145 Q97.7048 60.471 100.645 58.0636 Q103.608 55.6562 108.746 55.6562 Q113.908 55.6562 116.848 58.0636 Q119.788 60.471 119.788 64.6145 Q119.788 67.5774 118.098 69.6376 Q116.432 71.6978 113.445 72.4385 Q116.825 73.2255 118.7 75.5172 Q120.598 77.8088 120.598 81.119 Q120.598 86.1421 117.52 88.8273 Q114.464 91.5125 108.746 91.5125 Q103.029 91.5125 99.9502 88.8273 Q96.8947 86.1421 96.8947 81.119 Q96.8947 77.8088 98.7928 75.5172 Q100.691 73.2255 104.071 72.4385 M102.358 65.0543 Q102.358 67.7394 104.024 69.2441 Q105.714 70.7487 108.746 70.7487 Q111.756 70.7487 113.445 69.2441 Q115.158 67.7394 115.158 65.0543 Q115.158 62.3691 113.445 60.8645 Q111.756 59.3599 108.746 59.3599 Q105.714 59.3599 104.024 60.8645 Q102.358 62.3691 102.358 65.0543 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip082)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  218.754,1353.24 285.587,334.665 352.421,1361.13 419.255,567.21 486.089,1412.81 552.922,1173.73 619.756,1002.38 686.59,87.9763 753.424,1150.34 820.258,1361.94 \n",
       "  887.091,1113.62 953.925,1445.72 1020.76,1338.83 1087.59,1270.01 1154.43,1250.43 1221.26,1149.8 1288.09,1215.35 1354.93,1100.3 1421.76,1208 1488.6,1231.12 \n",
       "  1555.43,1099.75 1622.26,1097.03 1689.1,988.512 1755.93,1240.1 1822.76,1218.07 1889.6,1091.59 1956.43,1238.74 2023.27,1074.19 2090.1,1109.27 2156.93,1092.14 \n",
       "  2223.77,1157.96 2290.6,1188.15 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip080)\" d=\"\n",
       "M1983.1 198.898 L2279.55 198.898 L2279.55 95.2176 L1983.1 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1983.1,198.898 2279.55,198.898 2279.55,95.2176 1983.1,95.2176 1983.1,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2007.5,147.058 2153.92,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip080)\" d=\"M2192.16 166.745 Q2190.35 171.375 2188.64 172.787 Q2186.93 174.199 2184.06 174.199 L2180.65 174.199 L2180.65 170.634 L2183.15 170.634 Q2184.91 170.634 2185.89 169.8 Q2186.86 168.967 2188.04 165.865 L2188.8 163.921 L2178.32 138.412 L2182.83 138.412 L2190.93 158.689 L2199.03 138.412 L2203.55 138.412 L2192.16 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M2210.84 160.402 L2218.48 160.402 L2218.48 134.037 L2210.17 135.703 L2210.17 131.444 L2218.43 129.778 L2223.11 129.778 L2223.11 160.402 L2230.75 160.402 L2230.75 164.338 L2210.84 164.338 L2210.84 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/episodes\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        X  = X_0\n",
    "        \n",
    "        ##### Double Q-Learning ###########################################\n",
    "\n",
    "        for k = 1:T\n",
    "\n",
    "            # 1. Choose action\n",
    "            if rand() < epsilon\n",
    "                if rand() < EXPrand \n",
    "                    A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                else\n",
    "                    A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                end\n",
    "            else\n",
    "\n",
    "                A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                if A == 1000.0 # Indicates no values in this region\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "\n",
    "            # 2. Cache last state\n",
    "            qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "            # 3. Generate the next stae\n",
    "            Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "            # 4. Collect reward R( s, a, s' )\n",
    "            R_t = cartpole_reward( Xp )\n",
    "\n",
    "            # 5. Get the optimal action at the next state\n",
    "            a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "            # 6. Compute the value at the next state\n",
    "\n",
    "            V_tp1_opt = query_value_fuzzy( \n",
    "                Q_kdTree, G, V, \n",
    "                get_Q( \n",
    "                    select_X_vector( Xp ), \n",
    "                    a_tp1_opt \n",
    "                ); \n",
    "                k = vNN \n",
    "            )\n",
    "            if isnan( V_tp1_opt )\n",
    "                V_tp1_opt = 0.0\n",
    "            end\n",
    "\n",
    "\n",
    "            # 7. Blend the value back into nearest points\n",
    "\n",
    "            idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "            nNear      = size( idxs, 1 )\n",
    "            for i = 1:nNear\n",
    "                j    = idxs[i]\n",
    "                if !isnan( wgts[i] ) \n",
    "\n",
    "                    # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                    VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "                    \n",
    "                end\n",
    "            end\n",
    "\n",
    "            states[:,k] = Xp\n",
    "            actions[k]  = A\n",
    "\n",
    "            X = Xp\n",
    "        end\n",
    "\n",
    "        s_l    = vertical_score_s( states, aMargin, ts )\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        if useElig\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709555b9-2598-4281-a634-c7b0681277d0",
   "metadata": {},
   "source": [
    "# Method 2 Performance, Average Vertical Duration [s]\n",
    "Each score is the best average score of the last two epochs: 64 epochs of 64 episodes each, Q-function swap after every episode \n",
    "\n",
    "### TD Tuning\n",
    "\n",
    "$\\alpha = 0.99$: 0.238  \n",
    "$\\alpha = 0.75$: 0.257  \n",
    "$\\alpha = 0.50$: 0.191   \n",
    "$\\alpha = 0.25$: 0.170  \n",
    "$\\alpha = 0.125$: 0.290  \n",
    "$\\alpha = 0.0625$: 0.208, but fantastic performance in the middle of training  \n",
    "$\\alpha = 0.03125$: 0.978  \n",
    "$\\alpha = 0.02344$: 2.567  \n",
    "$\\alpha = 0.01953$: 0.268  \n",
    "$\\alpha = 0.015625$: 0.095  \n",
    " \n",
    "### Add gamma?\n",
    " \n",
    "### Double-Q Tuning, Swap Evey N Episodes\n",
    "$\\%\\ \\ 2$:  \n",
    "$\\%\\ \\ 4$:  \n",
    "$\\%\\ \\ 8$:  \n",
    "$\\%16$:  \n",
    "$\\%32$:  \n",
    "$\\%64$:  \n",
    "\n",
    "\n",
    "\n",
    "### Blend: Best Episode\n",
    "\n",
    "$\\beta = 0.07$:  \n",
    "$\\beta = 0.15$: 0.244\n",
    "\n",
    "| Method      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n",
    "| ----------- | ------- | ------- | ------- | ------- | ------- | ---- |\n",
    "| Blend (Epi) |         |         |         |         |         |      |\n",
    "| Blend (Epo) |         |         |         |         |         |      |\n",
    "| TD          |         |         |         |         |         |      |\n",
    "| TD  + ????? |         |         |         |         |         |      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
