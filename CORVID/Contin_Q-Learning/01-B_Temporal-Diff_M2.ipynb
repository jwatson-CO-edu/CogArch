{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.02148 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 # 0.00782 # 0.00391\n",
    "gamma    = 1.00 \n",
    "swapDiv  = 64\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes = 128 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   =  16 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "beta   = 0.15\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = false\n",
    "N_peaks =  40\n",
    "N_steps = 200\n",
    "lambda  =   0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.4300000000000002, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.21000000000000005, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.5000000000000002, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.17, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.6300000000000003, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.25000000000000006, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.15, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.2700000000000001, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.23000000000000007, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.5700000000000003, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.12999999999999998, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.22000000000000006, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.21000000000000005, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 1.330000000000001, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.16, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.2900000000000001, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.23000000000000007, epsilon: 0.00390625\n",
      "Average Score: 0.18890625000000008\n",
      "\n",
      "Epoch 2, Best Score: 1.9400000000000015\n",
      "Training Iteration 4 score: 0.3000000000000001, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.0064843750000000006\n",
      "\n",
      "Epoch 3, Best Score: 1.9400000000000015\n",
      "Training Iteration 4 score: 0.5600000000000003, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.8000000000000005, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.8000000000000005, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.11999999999999998, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.2900000000000001, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.09999999999999999, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.12070312500000008\n",
      "\n",
      "Epoch 4, Best Score: 1.9400000000000015\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.13999999999999999, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.6200000000000003, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.09999999999999999, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.3000000000000001, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.10999999999999999, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.25000000000000006, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.09999999999999999, epsilon: 0.00390625\n",
      "Average Score: 0.11679687500000006\n",
      "\n",
      "Epoch 5, Best Score: 1.9400000000000015\n",
      "Training Iteration 4 score: 0.15, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.10999999999999999, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.16, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.09999999999999999, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.026953125\n",
      "\n",
      "Epoch 6, Best Score: 1.9400000000000015\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.13999999999999999, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.002421875\n",
      "\n",
      "Epoch 7, Best Score: 1.9400000000000015\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.4300000000000002, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.18000000000000002, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.012265625000000004\n",
      "\n",
      "Epoch 8, Best Score: 1.9400000000000015\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.13999999999999999, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.012890625000000005\n",
      "\n",
      "Epoch 9, Best Score: 1.9400000000000015\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.11999999999999998, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.09999999999999999, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.16, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.11999999999999998, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.6200000000000003, epsilon: 0.00390625\n",
      "Average Score: 0.04085937500000001\n",
      "\n",
      "Epoch 10, Best Score: 1.9400000000000015\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.24000000000000007, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.3300000000000001, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.5400000000000003, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.5000000000000002, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.06492187500000003\n",
      "\n",
      "Epoch 11, Best Score: 1.9400000000000015\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.35000000000000014, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.5100000000000002, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.8200000000000005, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.22000000000000006, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.19000000000000003, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.38000000000000017, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.6100000000000003, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.9000000000000006, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.11999999999999998, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.6200000000000003, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.48000000000000026, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.9400000000000006, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.5600000000000003, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.35000000000000014, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.12999999999999998, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.11999999999999998, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.3000000000000001, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.13999999999999999, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.13999999999999999, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.12999999999999998, epsilon: 0.00390625\n",
      "Average Score: 0.21367187500000007\n",
      "\n",
      "Epoch 12, Best Score: 1.9400000000000015\n",
      "Training Iteration 4 score: 0.6300000000000003, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.35000000000000014, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 1.2400000000000009, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.35000000000000014, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 2.010000000000001, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.09, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.6520312500000168\n",
      "\n",
      "Epoch 13, Best Score: 28.7900000000017\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 14, Best Score: 28.7900000000017\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 15, Best Score: 28.7900000000017\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.2700000000000001, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.5600000000000003, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.18000000000000002, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.5700000000000003, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.049453125000000014\n",
      "\n",
      "Epoch 16, Best Score: 28.7900000000017\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.48828125\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.47265625\n",
      "Training Iteration 12 score: 0.4200000000000002, epsilon: 0.45703125\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.44140625\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.42578125\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.41015625\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.39453125\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.37890625\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.36328125\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.34765625\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.33203125\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.31640625\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.30078125\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.28515625\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.26953125\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.25390625\n",
      "Training Iteration 68 score: 0.0, epsilon: 0.23828125\n",
      "Training Iteration 72 score: 0.0, epsilon: 0.22265625\n",
      "Training Iteration 76 score: 0.0, epsilon: 0.20703125\n",
      "Training Iteration 80 score: 0.0, epsilon: 0.19140625\n",
      "Training Iteration 84 score: 0.0, epsilon: 0.17578125\n",
      "Training Iteration 88 score: 0.0, epsilon: 0.16015625\n",
      "Training Iteration 92 score: 0.0, epsilon: 0.14453125\n",
      "Training Iteration 96 score: 0.0, epsilon: 0.12890625\n",
      "Training Iteration 100 score: 0.0, epsilon: 0.11328125\n",
      "Training Iteration 104 score: 0.0, epsilon: 0.09765625\n",
      "Training Iteration 108 score: 0.0, epsilon: 0.08203125\n",
      "Training Iteration 112 score: 0.0, epsilon: 0.06640625\n",
      "Training Iteration 116 score: 0.0, epsilon: 0.05078125\n",
      "Training Iteration 120 score: 0.0, epsilon: 0.03515625\n",
      "Training Iteration 124 score: 0.0, epsilon: 0.01953125\n",
      "Training Iteration 128 score: 0.0, epsilon: 0.00390625\n",
      "Average Score: 0.010468750000000006\n",
      "Saved a trained Q-table with size (76032,), After 26.932877516746522 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip620\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip620)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip621\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip620)\" d=\"\n",
       "M156.598 1486.45 L2352.76 1486.45 L2352.76 47.2441 L156.598 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip622\">\n",
       "    <rect x=\"156\" y=\"47\" width=\"2197\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip622)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  495,1486.45 495,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip622)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  909.369,1486.45 909.369,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip622)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1323.74,1486.45 1323.74,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip622)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1738.11,1486.45 1738.11,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip622)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2152.48,1486.45 2152.48,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  495,1486.45 495,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  909.369,1486.45 909.369,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1323.74,1486.45 1323.74,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1738.11,1486.45 1738.11,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2152.48,1486.45 2152.48,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip620)\" d=\"M499.248 1530.21 Q502.604 1530.93 504.479 1533.2 Q506.377 1535.47 506.377 1538.8 Q506.377 1543.92 502.859 1546.72 Q499.34 1549.52 492.859 1549.52 Q490.683 1549.52 488.368 1549.08 Q486.076 1548.66 483.623 1547.81 L483.623 1543.29 Q485.567 1544.43 487.882 1545.01 Q490.197 1545.58 492.72 1545.58 Q497.118 1545.58 499.41 1543.85 Q501.724 1542.11 501.724 1538.8 Q501.724 1535.75 499.572 1534.03 Q497.442 1532.3 493.623 1532.3 L489.595 1532.3 L489.595 1528.45 L493.808 1528.45 Q497.257 1528.45 499.086 1527.09 Q500.914 1525.7 500.914 1523.11 Q500.914 1520.45 499.016 1519.03 Q497.141 1517.6 493.623 1517.6 Q491.701 1517.6 489.502 1518.01 Q487.303 1518.43 484.664 1519.31 L484.664 1515.14 Q487.326 1514.4 489.641 1514.03 Q491.979 1513.66 494.039 1513.66 Q499.363 1513.66 502.465 1516.09 Q505.567 1518.5 505.567 1522.62 Q505.567 1525.49 503.923 1527.48 Q502.28 1529.45 499.248 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M909.774 1529.7 Q906.626 1529.7 904.774 1531.86 Q902.946 1534.01 902.946 1537.76 Q902.946 1541.49 904.774 1543.66 Q906.626 1545.82 909.774 1545.82 Q912.922 1545.82 914.751 1543.66 Q916.603 1541.49 916.603 1537.76 Q916.603 1534.01 914.751 1531.86 Q912.922 1529.7 909.774 1529.7 M919.057 1515.05 L919.057 1519.31 Q917.297 1518.48 915.492 1518.04 Q913.71 1517.6 911.95 1517.6 Q907.321 1517.6 904.867 1520.72 Q902.436 1523.85 902.089 1530.17 Q903.455 1528.15 905.515 1527.09 Q907.575 1526 910.052 1526 Q915.26 1526 918.27 1529.17 Q921.302 1532.32 921.302 1537.76 Q921.302 1543.08 918.154 1546.3 Q915.006 1549.52 909.774 1549.52 Q903.779 1549.52 900.608 1544.94 Q897.436 1540.33 897.436 1531.6 Q897.436 1523.41 901.325 1518.55 Q905.214 1513.66 911.765 1513.66 Q913.524 1513.66 915.307 1514.01 Q917.112 1514.36 919.057 1515.05 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1314.04 1548.13 L1314.04 1543.87 Q1315.8 1544.7 1317.6 1545.14 Q1319.41 1545.58 1321.15 1545.58 Q1325.78 1545.58 1328.21 1542.48 Q1330.66 1539.36 1331.01 1533.01 Q1329.66 1535.01 1327.6 1536.07 Q1325.54 1537.13 1323.04 1537.13 Q1317.86 1537.13 1314.83 1534.01 Q1311.82 1530.86 1311.82 1525.42 Q1311.82 1520.1 1314.97 1516.88 Q1318.11 1513.66 1323.35 1513.66 Q1329.34 1513.66 1332.49 1518.27 Q1335.66 1522.85 1335.66 1531.6 Q1335.66 1539.77 1331.77 1544.66 Q1327.91 1549.52 1321.35 1549.52 Q1319.6 1549.52 1317.79 1549.17 Q1315.98 1548.82 1314.04 1548.13 M1323.35 1533.48 Q1326.49 1533.48 1328.32 1531.32 Q1330.17 1529.17 1330.17 1525.42 Q1330.17 1521.7 1328.32 1519.54 Q1326.49 1517.37 1323.35 1517.37 Q1320.2 1517.37 1318.35 1519.54 Q1316.52 1521.7 1316.52 1525.42 Q1316.52 1529.17 1318.35 1531.32 Q1320.2 1533.48 1323.35 1533.48 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1713.59 1544.91 L1721.23 1544.91 L1721.23 1518.55 L1712.92 1520.21 L1712.92 1515.95 L1721.19 1514.29 L1725.86 1514.29 L1725.86 1544.91 L1733.5 1544.91 L1733.5 1548.85 L1713.59 1548.85 L1713.59 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1746.97 1544.91 L1763.29 1544.91 L1763.29 1548.85 L1741.35 1548.85 L1741.35 1544.91 Q1744.01 1542.16 1748.59 1537.53 Q1753.2 1532.88 1754.38 1531.53 Q1756.63 1529.01 1757.51 1527.27 Q1758.41 1525.51 1758.41 1523.82 Q1758.41 1521.07 1756.46 1519.33 Q1754.54 1517.6 1751.44 1517.6 Q1749.24 1517.6 1746.79 1518.36 Q1744.36 1519.13 1741.58 1520.68 L1741.58 1515.95 Q1744.4 1514.82 1746.86 1514.24 Q1749.31 1513.66 1751.35 1513.66 Q1756.72 1513.66 1759.91 1516.35 Q1763.11 1519.03 1763.11 1523.52 Q1763.11 1525.65 1762.3 1527.57 Q1761.51 1529.47 1759.4 1532.07 Q1758.83 1532.74 1755.72 1535.95 Q1752.62 1539.15 1746.97 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M2127.66 1544.91 L2135.3 1544.91 L2135.3 1518.55 L2126.99 1520.21 L2126.99 1515.95 L2135.26 1514.29 L2139.93 1514.29 L2139.93 1544.91 L2147.57 1544.91 L2147.57 1548.85 L2127.66 1548.85 L2127.66 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M2157.06 1514.29 L2175.42 1514.29 L2175.42 1518.22 L2161.34 1518.22 L2161.34 1526.7 Q2162.36 1526.35 2163.38 1526.19 Q2164.4 1526 2165.42 1526 Q2171.2 1526 2174.58 1529.17 Q2177.96 1532.34 2177.96 1537.76 Q2177.96 1543.34 2174.49 1546.44 Q2171.02 1549.52 2164.7 1549.52 Q2162.52 1549.52 2160.26 1549.15 Q2158.01 1548.78 2155.6 1548.04 L2155.6 1543.34 Q2157.69 1544.47 2159.91 1545.03 Q2162.13 1545.58 2164.61 1545.58 Q2168.61 1545.58 2170.95 1543.48 Q2173.29 1541.37 2173.29 1537.76 Q2173.29 1534.15 2170.95 1532.04 Q2168.61 1529.94 2164.61 1529.94 Q2162.73 1529.94 2160.86 1530.35 Q2159.01 1530.77 2157.06 1531.65 L2157.06 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip622)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,1445.72 2352.76,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip622)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,1237.48 2352.76,1237.48 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip622)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,1029.25 2352.76,1029.25 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip622)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,821.019 2352.76,821.019 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip622)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,612.787 2352.76,612.787 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip622)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,404.554 2352.76,404.554 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip622)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,196.322 2352.76,196.322 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1486.45 156.598,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1445.72 175.496,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1237.48 175.496,1237.48 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1029.25 175.496,1029.25 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,821.019 175.496,821.019 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,612.787 175.496,612.787 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,404.554 175.496,404.554 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,196.322 175.496,196.322 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip620)\" d=\"M63.4226 1431.51 Q59.8115 1431.51 57.9828 1435.08 Q56.1773 1438.62 56.1773 1445.75 Q56.1773 1452.86 57.9828 1456.42 Q59.8115 1459.96 63.4226 1459.96 Q67.0569 1459.96 68.8624 1456.42 Q70.6911 1452.86 70.6911 1445.75 Q70.6911 1438.62 68.8624 1435.08 Q67.0569 1431.51 63.4226 1431.51 M63.4226 1427.81 Q69.2328 1427.81 72.2883 1432.42 Q75.367 1437 75.367 1445.75 Q75.367 1454.48 72.2883 1459.08 Q69.2328 1463.67 63.4226 1463.67 Q57.6125 1463.67 54.5338 1459.08 Q51.4782 1454.48 51.4782 1445.75 Q51.4782 1437 54.5338 1432.42 Q57.6125 1427.81 63.4226 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M83.5845 1457.12 L88.4688 1457.12 L88.4688 1463 L83.5845 1463 L83.5845 1457.12 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M108.654 1431.51 Q105.043 1431.51 103.214 1435.08 Q101.409 1438.62 101.409 1445.75 Q101.409 1452.86 103.214 1456.42 Q105.043 1459.96 108.654 1459.96 Q112.288 1459.96 114.094 1456.42 Q115.922 1452.86 115.922 1445.75 Q115.922 1438.62 114.094 1435.08 Q112.288 1431.51 108.654 1431.51 M108.654 1427.81 Q114.464 1427.81 117.52 1432.42 Q120.598 1437 120.598 1445.75 Q120.598 1454.48 117.52 1459.08 Q114.464 1463.67 108.654 1463.67 Q102.844 1463.67 99.765 1459.08 Q96.7095 1454.48 96.7095 1445.75 Q96.7095 1437 99.765 1432.42 Q102.844 1427.81 108.654 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M64.6495 1223.28 Q61.0384 1223.28 59.2097 1226.85 Q57.4041 1230.39 57.4041 1237.52 Q57.4041 1244.62 59.2097 1248.19 Q61.0384 1251.73 64.6495 1251.73 Q68.2837 1251.73 70.0892 1248.19 Q71.9179 1244.62 71.9179 1237.52 Q71.9179 1230.39 70.0892 1226.85 Q68.2837 1223.28 64.6495 1223.28 M64.6495 1219.58 Q70.4596 1219.58 73.5152 1224.18 Q76.5938 1228.77 76.5938 1237.52 Q76.5938 1246.24 73.5152 1250.85 Q70.4596 1255.43 64.6495 1255.43 Q58.8393 1255.43 55.7606 1250.85 Q52.7051 1246.24 52.7051 1237.52 Q52.7051 1228.77 55.7606 1224.18 Q58.8393 1219.58 64.6495 1219.58 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M84.8114 1248.88 L89.6956 1248.88 L89.6956 1254.76 L84.8114 1254.76 L84.8114 1248.88 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M100.691 1250.83 L108.33 1250.83 L108.33 1224.46 L100.02 1226.13 L100.02 1221.87 L108.283 1220.2 L112.959 1220.2 L112.959 1250.83 L120.598 1250.83 L120.598 1254.76 L100.691 1254.76 L100.691 1250.83 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M65.0198 1015.05 Q61.4087 1015.05 59.58 1018.61 Q57.7745 1022.16 57.7745 1029.29 Q57.7745 1036.39 59.58 1039.96 Q61.4087 1043.5 65.0198 1043.5 Q68.6541 1043.5 70.4596 1039.96 Q72.2883 1036.39 72.2883 1029.29 Q72.2883 1022.16 70.4596 1018.61 Q68.6541 1015.05 65.0198 1015.05 M65.0198 1011.35 Q70.83 1011.35 73.8855 1015.95 Q76.9642 1020.54 76.9642 1029.29 Q76.9642 1038.01 73.8855 1042.62 Q70.83 1047.2 65.0198 1047.2 Q59.2097 1047.2 56.131 1042.62 Q53.0754 1038.01 53.0754 1029.29 Q53.0754 1020.54 56.131 1015.95 Q59.2097 1011.35 65.0198 1011.35 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M85.1818 1040.65 L90.066 1040.65 L90.066 1046.53 L85.1818 1046.53 L85.1818 1040.65 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M104.279 1042.6 L120.598 1042.6 L120.598 1046.53 L98.6539 1046.53 L98.6539 1042.6 Q101.316 1039.84 105.899 1035.21 Q110.506 1030.56 111.686 1029.22 Q113.932 1026.69 114.811 1024.96 Q115.714 1023.2 115.714 1021.51 Q115.714 1018.75 113.77 1017.02 Q111.848 1015.28 108.746 1015.28 Q106.547 1015.28 104.094 1016.05 Q101.663 1016.81 98.8854 1018.36 L98.8854 1013.64 Q101.709 1012.5 104.163 1011.92 Q106.617 1011.35 108.654 1011.35 Q114.024 1011.35 117.219 1014.03 Q120.413 1016.72 120.413 1021.21 Q120.413 1023.34 119.603 1025.26 Q118.816 1027.16 116.709 1029.75 Q116.131 1030.42 113.029 1033.64 Q109.927 1036.83 104.279 1042.6 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M64.0708 806.818 Q60.4597 806.818 58.631 810.382 Q56.8254 813.924 56.8254 821.054 Q56.8254 828.16 58.631 831.725 Q60.4597 835.267 64.0708 835.267 Q67.705 835.267 69.5105 831.725 Q71.3392 828.16 71.3392 821.054 Q71.3392 813.924 69.5105 810.382 Q67.705 806.818 64.0708 806.818 M64.0708 803.114 Q69.8809 803.114 72.9365 807.72 Q76.0151 812.304 76.0151 821.054 Q76.0151 829.78 72.9365 834.387 Q69.8809 838.97 64.0708 838.97 Q58.2606 838.97 55.1819 834.387 Q52.1264 829.78 52.1264 821.054 Q52.1264 812.304 55.1819 807.72 Q58.2606 803.114 64.0708 803.114 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M84.2327 832.419 L89.1169 832.419 L89.1169 838.299 L84.2327 838.299 L84.2327 832.419 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M113.469 819.665 Q116.825 820.382 118.7 822.651 Q120.598 824.919 120.598 828.253 Q120.598 833.368 117.08 836.169 Q113.561 838.97 107.08 838.97 Q104.904 838.97 102.589 838.53 Q100.297 838.114 97.8437 837.257 L97.8437 832.743 Q99.7882 833.878 102.103 834.456 Q104.418 835.035 106.941 835.035 Q111.339 835.035 113.631 833.299 Q115.945 831.563 115.945 828.253 Q115.945 825.197 113.793 823.484 Q111.663 821.748 107.844 821.748 L103.816 821.748 L103.816 817.905 L108.029 817.905 Q111.478 817.905 113.307 816.54 Q115.135 815.151 115.135 812.558 Q115.135 809.896 113.237 808.484 Q111.362 807.049 107.844 807.049 Q105.922 807.049 103.723 807.466 Q101.524 807.882 98.8854 808.762 L98.8854 804.595 Q101.547 803.855 103.862 803.484 Q106.2 803.114 108.26 803.114 Q113.584 803.114 116.686 805.544 Q119.788 807.952 119.788 812.072 Q119.788 814.943 118.145 816.933 Q116.501 818.901 113.469 819.665 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M62.9365 598.585 Q59.3254 598.585 57.4967 602.15 Q55.6912 605.692 55.6912 612.821 Q55.6912 619.928 57.4967 623.493 Q59.3254 627.034 62.9365 627.034 Q66.5707 627.034 68.3763 623.493 Q70.205 619.928 70.205 612.821 Q70.205 605.692 68.3763 602.15 Q66.5707 598.585 62.9365 598.585 M62.9365 594.882 Q68.7467 594.882 71.8022 599.488 Q74.8809 604.071 74.8809 612.821 Q74.8809 621.548 71.8022 626.155 Q68.7467 630.738 62.9365 630.738 Q57.1264 630.738 54.0477 626.155 Q50.9921 621.548 50.9921 612.821 Q50.9921 604.071 54.0477 599.488 Q57.1264 594.882 62.9365 594.882 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M83.0984 624.187 L87.9827 624.187 L87.9827 630.067 L83.0984 630.067 L83.0984 624.187 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M111.015 599.581 L99.2095 618.03 L111.015 618.03 L111.015 599.581 M109.788 595.507 L115.668 595.507 L115.668 618.03 L120.598 618.03 L120.598 621.919 L115.668 621.919 L115.668 630.067 L111.015 630.067 L111.015 621.919 L95.4132 621.919 L95.4132 617.405 L109.788 595.507 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M64.418 390.353 Q60.8069 390.353 58.9782 393.918 Q57.1726 397.46 57.1726 404.589 Q57.1726 411.696 58.9782 415.26 Q60.8069 418.802 64.418 418.802 Q68.0522 418.802 69.8578 415.26 Q71.6865 411.696 71.6865 404.589 Q71.6865 397.46 69.8578 393.918 Q68.0522 390.353 64.418 390.353 M64.418 386.649 Q70.2281 386.649 73.2837 391.256 Q76.3624 395.839 76.3624 404.589 Q76.3624 413.316 73.2837 417.922 Q70.2281 422.506 64.418 422.506 Q58.6078 422.506 55.5291 417.922 Q52.4736 413.316 52.4736 404.589 Q52.4736 395.839 55.5291 391.256 Q58.6078 386.649 64.418 386.649 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M84.5799 415.955 L89.4641 415.955 L89.4641 421.834 L84.5799 421.834 L84.5799 415.955 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M99.6956 387.274 L118.052 387.274 L118.052 391.21 L103.978 391.21 L103.978 399.682 Q104.996 399.335 106.015 399.172 Q107.033 398.987 108.052 398.987 Q113.839 398.987 117.219 402.159 Q120.598 405.33 120.598 410.746 Q120.598 416.325 117.126 419.427 Q113.654 422.506 107.334 422.506 Q105.159 422.506 102.89 422.135 Q100.645 421.765 98.2372 421.024 L98.2372 416.325 Q100.321 417.459 102.543 418.015 Q104.765 418.571 107.242 418.571 Q111.246 418.571 113.584 416.464 Q115.922 414.358 115.922 410.746 Q115.922 407.135 113.584 405.029 Q111.246 402.922 107.242 402.922 Q105.367 402.922 103.492 403.339 Q101.64 403.756 99.6956 404.635 L99.6956 387.274 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M63.2606 182.121 Q59.6495 182.121 57.8208 185.686 Q56.0152 189.227 56.0152 196.357 Q56.0152 203.463 57.8208 207.028 Q59.6495 210.57 63.2606 210.57 Q66.8948 210.57 68.7004 207.028 Q70.5291 203.463 70.5291 196.357 Q70.5291 189.227 68.7004 185.686 Q66.8948 182.121 63.2606 182.121 M63.2606 178.417 Q69.0707 178.417 72.1263 183.024 Q75.205 187.607 75.205 196.357 Q75.205 205.084 72.1263 209.69 Q69.0707 214.273 63.2606 214.273 Q57.4504 214.273 54.3717 209.69 Q51.3162 205.084 51.3162 196.357 Q51.3162 187.607 54.3717 183.024 Q57.4504 178.417 63.2606 178.417 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M83.4225 207.723 L88.3067 207.723 L88.3067 213.602 L83.4225 213.602 L83.4225 207.723 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M109.071 194.459 Q105.922 194.459 104.071 196.611 Q102.242 198.764 102.242 202.514 Q102.242 206.241 104.071 208.417 Q105.922 210.57 109.071 210.57 Q112.219 210.57 114.047 208.417 Q115.899 206.241 115.899 202.514 Q115.899 198.764 114.047 196.611 Q112.219 194.459 109.071 194.459 M118.353 179.806 L118.353 184.065 Q116.594 183.232 114.788 182.792 Q113.006 182.352 111.246 182.352 Q106.617 182.352 104.163 185.477 Q101.733 188.602 101.385 194.922 Q102.751 192.908 104.811 191.843 Q106.871 190.755 109.348 190.755 Q114.557 190.755 117.566 193.926 Q120.598 197.074 120.598 202.514 Q120.598 207.838 117.45 211.056 Q114.302 214.273 109.071 214.273 Q103.075 214.273 99.9039 209.69 Q96.7326 205.084 96.7326 196.357 Q96.7326 188.162 100.621 183.301 Q104.51 178.417 111.061 178.417 Q112.82 178.417 114.603 178.764 Q116.408 179.112 118.353 179.806 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip622)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  218.754,1052.35 356.877,1432.21 495,1194.37 633.123,1202.51 771.246,1389.59 909.369,1440.67 1047.49,1420.17 1185.62,1418.87 1323.74,1360.63 1461.86,1310.53 \n",
       "  1599.98,1000.78 1738.11,87.9763 1876.23,1445.72 2014.35,1445.72 2152.48,1342.74 2290.6,1423.92 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip620)\" d=\"\n",
       "M2007.5 198.898 L2279.55 198.898 L2279.55 95.2176 L2007.5 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2007.5,198.898 2279.55,198.898 2279.55,95.2176 2007.5,95.2176 2007.5,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip620)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2031.91,147.058 2178.32,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip620)\" d=\"M2216.56 166.745 Q2214.76 171.375 2213.04 172.787 Q2211.33 174.199 2208.46 174.199 L2205.06 174.199 L2205.06 170.634 L2207.56 170.634 Q2209.32 170.634 2210.29 169.8 Q2211.26 168.967 2212.44 165.865 L2213.2 163.921 L2202.72 138.412 L2207.23 138.412 L2215.33 158.689 L2223.44 138.412 L2227.95 138.412 L2216.56 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M2235.24 160.402 L2242.88 160.402 L2242.88 134.037 L2234.57 135.703 L2234.57 131.444 L2242.83 129.778 L2247.51 129.778 L2247.51 160.402 L2255.15 160.402 L2255.15 164.338 L2235.24 164.338 L2235.24 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/episodes\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        X  = X_0\n",
    "        \n",
    "        ##### Double Q-Learning ###########################################\n",
    "\n",
    "        for k = 1:T\n",
    "\n",
    "            # 1. Choose action\n",
    "            if rand() < epsilon\n",
    "                if rand() < EXPrand \n",
    "                    A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                else\n",
    "                    A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                end\n",
    "            else\n",
    "\n",
    "                A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                if A == 1000.0 # Indicates no values in this region\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "\n",
    "            # 2. Cache last state\n",
    "            qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "            # 3. Generate the next stae\n",
    "            Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "            # 4. Collect reward R( s, a, s' )\n",
    "            R_t = cartpole_reward( Xp )\n",
    "\n",
    "            # 5. Get the optimal action at the next state\n",
    "            a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "            # 6. Compute the value at the next state\n",
    "\n",
    "            V_tp1_opt = query_value_fuzzy( \n",
    "                Q_kdTree, G, V, \n",
    "                get_Q( \n",
    "                    select_X_vector( Xp ), \n",
    "                    a_tp1_opt \n",
    "                ); \n",
    "                k = vNN \n",
    "            )\n",
    "            if isnan( V_tp1_opt )\n",
    "                V_tp1_opt = 0.0\n",
    "            end\n",
    "\n",
    "\n",
    "            # 7. Blend the value back into nearest points\n",
    "\n",
    "            idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "            nNear      = size( idxs, 1 )\n",
    "            for i = 1:nNear\n",
    "                j    = idxs[i]\n",
    "                if !isnan( wgts[i] ) \n",
    "\n",
    "                    # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                    VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "                    \n",
    "                end\n",
    "            end\n",
    "\n",
    "            states[:,k] = Xp\n",
    "            actions[k]  = A\n",
    "\n",
    "            X = Xp\n",
    "        end\n",
    "\n",
    "        s_l    = vertical_score_s( states, aMargin, ts )\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        if useElig\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709555b9-2598-4281-a634-c7b0681277d0",
   "metadata": {},
   "source": [
    "# Method 2 Performance, Average Vertical Duration [s]\n",
    "Each score is the best average score of the last two epochs: 64 epochs of 64 episodes each, Q-function swap after every episode \n",
    "\n",
    "### TD Tuning\n",
    "\n",
    "$\\alpha = 0.99$: 0.238  \n",
    "$\\alpha = 0.75$: 0.257  \n",
    "$\\alpha = 0.50$: 0.191   \n",
    "$\\alpha = 0.25$: 0.170  \n",
    "$\\alpha = 0.125$: 0.290  \n",
    "$\\alpha = 0.0625$: 0.208, but fantastic performance in the middle of training  \n",
    "$\\alpha = 0.03125$: 0.978  \n",
    "$\\alpha = 0.02344$: 2.567  \n",
    "$\\alpha = 0.01953$: 0.268  \n",
    "$\\alpha = 0.015625$: 0.095  \n",
    " \n",
    "### Add gamma?\n",
    " \n",
    "### Double-Q Tuning, Swap Evey N Episodes\n",
    "$\\%\\ \\ 2$:  \n",
    "$\\%\\ \\ 4$:  \n",
    "$\\%\\ \\ 8$:  \n",
    "$\\%16$:  \n",
    "$\\%32$:  \n",
    "$\\%64$:  \n",
    "\n",
    "\n",
    "\n",
    "### Blend: Best Episode\n",
    "\n",
    "$\\beta = 0.07$:  \n",
    "$\\beta = 0.15$: 0.244\n",
    "\n",
    "| Method      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n",
    "| ----------- | ------- | ------- | ------- | ------- | ------- | ---- |\n",
    "| Blend (Epi) |         |         |         |         |         |      |\n",
    "| Blend (Epo) |         |         |         |         |         |      |\n",
    "| TD          |         |         |         |         |         |      |\n",
    "| TD  + ????? |         |         |         |         |         |      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
