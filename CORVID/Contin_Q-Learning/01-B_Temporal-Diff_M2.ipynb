{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  2 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  2; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.02148 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 # 0.00782 # 0.00391\n",
    "gamma    = 1.00 \n",
    "swapDiv  = 64\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes = 64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   = 32 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "beta   = 0.15\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = true\n",
    "N_peaks =  32\n",
    "N_steps = 128\n",
    "lambda  =   0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.07, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.10999999999999999, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.3100000000000001, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.07, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.2900000000000001, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.36000000000000015, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.19000000000000003, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.6400000000000003, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.19000000000000003, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.35000000000000014, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.26000000000000006, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.15687500000000004\n",
      "\n",
      "Epoch 2, Best Score: 0.9600000000000006\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 1.0800000000000007, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.2700000000000001, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.19000000000000003, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.34000000000000014, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.5300000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.5700000000000012, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.7700000000000005, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.4000000000000002, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.7300000000000004, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.09, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.08, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.26062500000000016\n",
      "\n",
      "Epoch 3, Best Score: 1.5700000000000012\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 4, Best Score: 1.5700000000000012\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 1.490000000000001, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.03062500000000002\n",
      "\n",
      "Epoch 5, Best Score: 1.5700000000000012\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.46000000000000024, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.34000000000000014, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.9700000000000006, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.4200000000000002, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.17, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.1396875000000001\n",
      "\n",
      "Epoch 6, Best Score: 1.5700000000000012\n",
      "Training Iteration 4 score: 0.34000000000000014, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.4200000000000002, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.3300000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.6100000000000003, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.8000000000000005, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.7300000000000013, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 2.5199999999999902, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.5800000000000003, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.37000000000000016, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 2.3199999999999945, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.5700000000000003, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 2.5199999999999902, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 1.6700000000000013, epsilon: 8.881784197001252e-16\n",
      "Average Score: 1.020156249999993\n",
      "\n",
      "Epoch 7, Best Score: 7.809999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.15, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.34000000000000014, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.6800000000000004, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.07, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.08484375000000006\n",
      "\n",
      "Epoch 8, Best Score: 7.809999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 9, Best Score: 7.809999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.09, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.09999999999999999, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.38000000000000017, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.09999999999999999, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.13999999999999999, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.06703125000000003\n",
      "\n",
      "Epoch 10, Best Score: 7.809999999999878\n",
      "Training Iteration 4 score: 0.6800000000000004, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.4300000000000002, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.03656250000000002\n",
      "\n",
      "Epoch 11, Best Score: 7.809999999999878\n",
      "Training Iteration 4 score: 0.26000000000000006, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.6700000000000004, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.18000000000000002, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.09, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.06406250000000002\n",
      "\n",
      "Epoch 12, Best Score: 7.809999999999878\n",
      "Training Iteration 4 score: 0.11999999999999998, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.22000000000000006, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.09, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.10999999999999999, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.061875000000000006\n",
      "\n",
      "Epoch 13, Best Score: 7.809999999999878\n",
      "Training Iteration 4 score: 0.2800000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.10999999999999999, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.5900000000000003, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.10999999999999999, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.13999999999999999, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.10999999999999999, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.11999999999999998, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.4000000000000002, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.35000000000000014, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.4000000000000002, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.19265625000000008\n",
      "\n",
      "Epoch 14, Best Score: 7.809999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.13999999999999999, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.10999999999999999, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.7100000000000004, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.21000000000000005, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.8900000000000006, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.23000000000000007, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.2900000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.20000000000000004, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.10999999999999999, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.11999999999999998, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.09999999999999999, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.18000000000000002, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.12999999999999998, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.12999999999999998, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.22796875000000005\n",
      "\n",
      "Epoch 15, Best Score: 7.809999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0017187499999999998\n",
      "\n",
      "Epoch 16, Best Score: 7.809999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.015937500000000007\n",
      "\n",
      "Epoch 17, Best Score: 7.809999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0031250000000000006\n",
      "\n",
      "Epoch 18, Best Score: 7.809999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.03656250000000002\n",
      "\n",
      "Epoch 19, Best Score: 7.809999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.7600000000000005, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.5700000000000003, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.09093750000000005\n",
      "\n",
      "Epoch 20, Best Score: 7.809999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.025468750000000012\n",
      "\n",
      "Epoch 21, Best Score: 7.809999999999878\n",
      "Training Iteration 4 score: 0.18000000000000002, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.18000000000000002, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.13999999999999999, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.18000000000000002, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.13999999999999999, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.09999999999999999, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.5200000000000002, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.15, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.6700000000000004, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.13999999999999999, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.13593750000000007\n",
      "\n",
      "Epoch 22, Best Score: 7.809999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.21000000000000005, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.12999999999999998, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.03234375000000002\n",
      "\n",
      "Epoch 23, Best Score: 7.809999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.2800000000000001, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.5100000000000002, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 1.0500000000000007, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.38000000000000017, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.1428125000000001\n",
      "\n",
      "Epoch 24, Best Score: 7.809999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 25, Best Score: 7.809999999999878\n",
      "Training Iteration 4 score: 0.5700000000000003, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.3100000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.5000000000000002, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 1.2500000000000009, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 1.290000000000001, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.4226562500000003\n",
      "\n",
      "Epoch 26, Best Score: 7.809999999999878\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.22000000000000006, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.49000000000000027, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.06671875000000003\n",
      "\n",
      "Epoch 27, Best Score: 7.809999999999878\n",
      "Training Iteration 4 score: 0.24000000000000007, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.6600000000000004, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.08, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.21000000000000005, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.10999999999999999, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.3100000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.07, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.48000000000000026, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.6900000000000004, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.45000000000000023, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.24203125000000011\n",
      "\n",
      "Epoch 28, Best Score: 7.809999999999878\n",
      "Training Iteration 4 score: 0.6800000000000004, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.09999999999999999, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.3200000000000001, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.10999999999999999, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.3200000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.11999999999999998, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.5500000000000003, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.8100000000000005, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.3200000000000001, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.2023437500000001\n",
      "\n",
      "Epoch 29, Best Score: 7.809999999999878\n",
      "Training Iteration 4 score: 18.980000000000167, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.6100000000000003, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 2.9799999999999804, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 1.300000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 27.56000000000151, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 29.640000000001834, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 28.510000000001657, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 30.33000000000194, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 32.33000000000214, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.7900000000000005, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 2.3199999999999945, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.7700000000000005, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.5700000000000003, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.6800000000000004, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.6600000000000004, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 1.1700000000000008, epsilon: 8.881784197001252e-16\n",
      "Average Score: 12.771718750000707\n",
      "\n",
      "Epoch 30, Best Score: 34.66000000000167\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.37000000000000016, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.03500000000000001\n",
      "\n",
      "Epoch 31, Best Score: 34.66000000000167\n",
      "Training Iteration 4 score: 0.49000000000000027, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.21000000000000005, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.09, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.09999999999999999, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.13999999999999999, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.5000000000000002, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.2900000000000001, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.6500000000000004, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 31.73000000000216, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 28.380000000001637, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.15, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.16, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.17, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.25000000000000006, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.23000000000000007, epsilon: 8.881784197001252e-16\n",
      "Average Score: 4.686562500000243\n",
      "\n",
      "Epoch 32, Best Score: 34.66000000000167\n",
      "Training Iteration 4 score: 0.24000000000000007, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.25000000000000006, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.03406250000000001\n",
      "Saved a trained Q-table with size (76032,), After 12.447063799699148 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip930\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip930)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip931\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip930)\" d=\"\n",
       "M138.959 1486.45 L2352.76 1486.45 L2352.76 47.2441 L138.959 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip932\">\n",
       "    <rect x=\"138\" y=\"47\" width=\"2215\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip932)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  471.096,1486.45 471.096,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip932)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  807.949,1486.45 807.949,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip932)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1144.8,1486.45 1144.8,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip932)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1481.65,1486.45 1481.65,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip932)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1818.51,1486.45 1818.51,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip932)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2155.36,1486.45 2155.36,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip930)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  138.959,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip930)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  471.096,1486.45 471.096,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip930)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  807.949,1486.45 807.949,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip930)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1144.8,1486.45 1144.8,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip930)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1481.65,1486.45 1481.65,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip930)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1818.51,1486.45 1818.51,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip930)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2155.36,1486.45 2155.36,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip930)\" d=\"M461.374 1514.29 L479.73 1514.29 L479.73 1518.22 L465.656 1518.22 L465.656 1526.7 Q466.675 1526.35 467.694 1526.19 Q468.712 1526 469.731 1526 Q475.518 1526 478.897 1529.17 Q482.277 1532.34 482.277 1537.76 Q482.277 1543.34 478.805 1546.44 Q475.332 1549.52 469.013 1549.52 Q466.837 1549.52 464.569 1549.15 Q462.323 1548.78 459.916 1548.04 L459.916 1543.34 Q461.999 1544.47 464.221 1545.03 Q466.444 1545.58 468.92 1545.58 Q472.925 1545.58 475.263 1543.48 Q477.601 1541.37 477.601 1537.76 Q477.601 1534.15 475.263 1532.04 Q472.925 1529.94 468.92 1529.94 Q467.045 1529.94 465.17 1530.35 Q463.319 1530.77 461.374 1531.65 L461.374 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip930)\" d=\"M782.637 1544.91 L790.276 1544.91 L790.276 1518.55 L781.965 1520.21 L781.965 1515.95 L790.229 1514.29 L794.905 1514.29 L794.905 1544.91 L802.544 1544.91 L802.544 1548.85 L782.637 1548.85 L782.637 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip930)\" d=\"M821.988 1517.37 Q818.377 1517.37 816.549 1520.93 Q814.743 1524.47 814.743 1531.6 Q814.743 1538.71 816.549 1542.27 Q818.377 1545.82 821.988 1545.82 Q825.623 1545.82 827.428 1542.27 Q829.257 1538.71 829.257 1531.6 Q829.257 1524.47 827.428 1520.93 Q825.623 1517.37 821.988 1517.37 M821.988 1513.66 Q827.798 1513.66 830.854 1518.27 Q833.933 1522.85 833.933 1531.6 Q833.933 1540.33 830.854 1544.94 Q827.798 1549.52 821.988 1549.52 Q816.178 1549.52 813.099 1544.94 Q810.044 1540.33 810.044 1531.6 Q810.044 1522.85 813.099 1518.27 Q816.178 1513.66 821.988 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip930)\" d=\"M1119.99 1544.91 L1127.63 1544.91 L1127.63 1518.55 L1119.32 1520.21 L1119.32 1515.95 L1127.58 1514.29 L1132.26 1514.29 L1132.26 1544.91 L1139.89 1544.91 L1139.89 1548.85 L1119.99 1548.85 L1119.99 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip930)\" d=\"M1149.39 1514.29 L1167.74 1514.29 L1167.74 1518.22 L1153.67 1518.22 L1153.67 1526.7 Q1154.69 1526.35 1155.7 1526.19 Q1156.72 1526 1157.74 1526 Q1163.53 1526 1166.91 1529.17 Q1170.29 1532.34 1170.29 1537.76 Q1170.29 1543.34 1166.82 1546.44 Q1163.34 1549.52 1157.02 1549.52 Q1154.85 1549.52 1152.58 1549.15 Q1150.33 1548.78 1147.93 1548.04 L1147.93 1543.34 Q1150.01 1544.47 1152.23 1545.03 Q1154.45 1545.58 1156.93 1545.58 Q1160.94 1545.58 1163.27 1543.48 Q1165.61 1541.37 1165.61 1537.76 Q1165.61 1534.15 1163.27 1532.04 Q1160.94 1529.94 1156.93 1529.94 Q1155.06 1529.94 1153.18 1530.35 Q1151.33 1530.77 1149.39 1531.65 L1149.39 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip930)\" d=\"M1460.43 1544.91 L1476.75 1544.91 L1476.75 1548.85 L1454.8 1548.85 L1454.8 1544.91 Q1457.46 1542.16 1462.05 1537.53 Q1466.65 1532.88 1467.84 1531.53 Q1470.08 1529.01 1470.96 1527.27 Q1471.86 1525.51 1471.86 1523.82 Q1471.86 1521.07 1469.92 1519.33 Q1468 1517.6 1464.9 1517.6 Q1462.7 1517.6 1460.24 1518.36 Q1457.81 1519.13 1455.03 1520.68 L1455.03 1515.95 Q1457.86 1514.82 1460.31 1514.24 Q1462.77 1513.66 1464.8 1513.66 Q1470.17 1513.66 1473.37 1516.35 Q1476.56 1519.03 1476.56 1523.52 Q1476.56 1525.65 1475.75 1527.57 Q1474.96 1529.47 1472.86 1532.07 Q1472.28 1532.74 1469.18 1535.95 Q1466.08 1539.15 1460.43 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip930)\" d=\"M1496.56 1517.37 Q1492.95 1517.37 1491.12 1520.93 Q1489.32 1524.47 1489.32 1531.6 Q1489.32 1538.71 1491.12 1542.27 Q1492.95 1545.82 1496.56 1545.82 Q1500.2 1545.82 1502 1542.27 Q1503.83 1538.71 1503.83 1531.6 Q1503.83 1524.47 1502 1520.93 Q1500.2 1517.37 1496.56 1517.37 M1496.56 1513.66 Q1502.37 1513.66 1505.43 1518.27 Q1508.51 1522.85 1508.51 1531.6 Q1508.51 1540.33 1505.43 1544.94 Q1502.37 1549.52 1496.56 1549.52 Q1490.75 1549.52 1487.67 1544.94 Q1484.62 1540.33 1484.62 1531.6 Q1484.62 1522.85 1487.67 1518.27 Q1490.75 1513.66 1496.56 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip930)\" d=\"M1797.78 1544.91 L1814.1 1544.91 L1814.1 1548.85 L1792.15 1548.85 L1792.15 1544.91 Q1794.82 1542.16 1799.4 1537.53 Q1804.01 1532.88 1805.19 1531.53 Q1807.43 1529.01 1808.31 1527.27 Q1809.21 1525.51 1809.21 1523.82 Q1809.21 1521.07 1807.27 1519.33 Q1805.35 1517.6 1802.25 1517.6 Q1800.05 1517.6 1797.59 1518.36 Q1795.16 1519.13 1792.38 1520.68 L1792.38 1515.95 Q1795.21 1514.82 1797.66 1514.24 Q1800.12 1513.66 1802.15 1513.66 Q1807.52 1513.66 1810.72 1516.35 Q1813.91 1519.03 1813.91 1523.52 Q1813.91 1525.65 1813.1 1527.57 Q1812.32 1529.47 1810.21 1532.07 Q1809.63 1532.74 1806.53 1535.95 Q1803.43 1539.15 1797.78 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip930)\" d=\"M1823.96 1514.29 L1842.32 1514.29 L1842.32 1518.22 L1828.24 1518.22 L1828.24 1526.7 Q1829.26 1526.35 1830.28 1526.19 Q1831.3 1526 1832.32 1526 Q1838.1 1526 1841.48 1529.17 Q1844.86 1532.34 1844.86 1537.76 Q1844.86 1543.34 1841.39 1546.44 Q1837.92 1549.52 1831.6 1549.52 Q1829.42 1549.52 1827.15 1549.15 Q1824.91 1548.78 1822.5 1548.04 L1822.5 1543.34 Q1824.58 1544.47 1826.81 1545.03 Q1829.03 1545.58 1831.51 1545.58 Q1835.51 1545.58 1837.85 1543.48 Q1840.19 1541.37 1840.19 1537.76 Q1840.19 1534.15 1837.85 1532.04 Q1835.51 1529.94 1831.51 1529.94 Q1829.63 1529.94 1827.76 1530.35 Q1825.9 1530.77 1823.96 1531.65 L1823.96 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip930)\" d=\"M2144.2 1530.21 Q2147.56 1530.93 2149.43 1533.2 Q2151.33 1535.47 2151.33 1538.8 Q2151.33 1543.92 2147.81 1546.72 Q2144.3 1549.52 2137.81 1549.52 Q2135.64 1549.52 2133.32 1549.08 Q2131.03 1548.66 2128.58 1547.81 L2128.58 1543.29 Q2130.52 1544.43 2132.84 1545.01 Q2135.15 1545.58 2137.68 1545.58 Q2142.07 1545.58 2144.36 1543.85 Q2146.68 1542.11 2146.68 1538.8 Q2146.68 1535.75 2144.53 1534.03 Q2142.4 1532.3 2138.58 1532.3 L2134.55 1532.3 L2134.55 1528.45 L2138.76 1528.45 Q2142.21 1528.45 2144.04 1527.09 Q2145.87 1525.7 2145.87 1523.11 Q2145.87 1520.45 2143.97 1519.03 Q2142.1 1517.6 2138.58 1517.6 Q2136.66 1517.6 2134.46 1518.01 Q2132.26 1518.43 2129.62 1519.31 L2129.62 1515.14 Q2132.28 1514.4 2134.6 1514.03 Q2136.93 1513.66 2138.99 1513.66 Q2144.32 1513.66 2147.42 1516.09 Q2150.52 1518.5 2150.52 1522.62 Q2150.52 1525.49 2148.88 1527.48 Q2147.24 1529.45 2144.2 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip930)\" d=\"M2170.2 1517.37 Q2166.59 1517.37 2164.76 1520.93 Q2162.95 1524.47 2162.95 1531.6 Q2162.95 1538.71 2164.76 1542.27 Q2166.59 1545.82 2170.2 1545.82 Q2173.83 1545.82 2175.64 1542.27 Q2177.47 1538.71 2177.47 1531.6 Q2177.47 1524.47 2175.64 1520.93 Q2173.83 1517.37 2170.2 1517.37 M2170.2 1513.66 Q2176.01 1513.66 2179.06 1518.27 Q2182.14 1522.85 2182.14 1531.6 Q2182.14 1540.33 2179.06 1544.94 Q2176.01 1549.52 2170.2 1549.52 Q2164.39 1549.52 2161.31 1544.94 Q2158.25 1540.33 2158.25 1531.6 Q2158.25 1522.85 2161.31 1518.27 Q2164.39 1513.66 2170.2 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip932)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  138.959,1445.72 2352.76,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip932)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  138.959,1233.1 2352.76,1233.1 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip932)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  138.959,1020.48 2352.76,1020.48 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip932)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  138.959,807.866 2352.76,807.866 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip932)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  138.959,595.249 2352.76,595.249 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip932)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  138.959,382.633 2352.76,382.633 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip932)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  138.959,170.016 2352.76,170.016 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip930)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  138.959,1486.45 138.959,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip930)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  138.959,1445.72 157.857,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip930)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  138.959,1233.1 157.857,1233.1 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip930)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  138.959,1020.48 157.857,1020.48 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip930)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  138.959,807.866 157.857,807.866 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip930)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  138.959,595.249 157.857,595.249 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip930)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  138.959,382.633 157.857,382.633 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip930)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  138.959,170.016 157.857,170.016 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip930)\" d=\"M91.0151 1431.51 Q87.404 1431.51 85.5753 1435.08 Q83.7697 1438.62 83.7697 1445.75 Q83.7697 1452.86 85.5753 1456.42 Q87.404 1459.96 91.0151 1459.96 Q94.6493 1459.96 96.4548 1456.42 Q98.2835 1452.86 98.2835 1445.75 Q98.2835 1438.62 96.4548 1435.08 Q94.6493 1431.51 91.0151 1431.51 M91.0151 1427.81 Q96.8252 1427.81 99.8808 1432.42 Q102.959 1437 102.959 1445.75 Q102.959 1454.48 99.8808 1459.08 Q96.8252 1463.67 91.0151 1463.67 Q85.2049 1463.67 82.1262 1459.08 Q79.0707 1454.48 79.0707 1445.75 Q79.0707 1437 82.1262 1432.42 Q85.2049 1427.81 91.0151 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip930)\" d=\"M86.6401 1246.44 L102.959 1246.44 L102.959 1250.38 L81.0151 1250.38 L81.0151 1246.44 Q83.6771 1243.69 88.2604 1239.06 Q92.8669 1234.41 94.0475 1233.06 Q96.2928 1230.54 97.1724 1228.81 Q98.0752 1227.05 98.0752 1225.36 Q98.0752 1222.6 96.1308 1220.87 Q94.2095 1219.13 91.1077 1219.13 Q88.9086 1219.13 86.4549 1219.89 Q84.0244 1220.66 81.2466 1222.21 L81.2466 1217.49 Q84.0707 1216.35 86.5243 1215.77 Q88.978 1215.19 91.0151 1215.19 Q96.3854 1215.19 99.5798 1217.88 Q102.774 1220.56 102.774 1225.06 Q102.774 1227.18 101.964 1229.11 Q101.177 1231 99.0706 1233.6 Q98.4919 1234.27 95.39 1237.49 Q92.2882 1240.68 86.6401 1246.44 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip930)\" d=\"M93.3762 1007.28 L81.5707 1025.73 L93.3762 1025.73 L93.3762 1007.28 M92.1493 1003.2 L98.0289 1003.2 L98.0289 1025.73 L102.959 1025.73 L102.959 1029.61 L98.0289 1029.61 L98.0289 1037.76 L93.3762 1037.76 L93.3762 1029.61 L77.7744 1029.61 L77.7744 1025.1 L92.1493 1003.2 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip930)\" d=\"M91.4317 806.003 Q88.2836 806.003 86.4318 808.155 Q84.6031 810.308 84.6031 814.058 Q84.6031 817.785 86.4318 819.961 Q88.2836 822.114 91.4317 822.114 Q94.5799 822.114 96.4085 819.961 Q98.2604 817.785 98.2604 814.058 Q98.2604 810.308 96.4085 808.155 Q94.5799 806.003 91.4317 806.003 M100.714 791.35 L100.714 795.609 Q98.9548 794.776 97.1493 794.336 Q95.3669 793.896 93.6076 793.896 Q88.978 793.896 86.5243 797.021 Q84.0938 800.146 83.7466 806.466 Q85.1123 804.452 87.1725 803.387 Q89.2327 802.299 91.7095 802.299 Q96.9178 802.299 99.927 805.47 Q102.959 808.618 102.959 814.058 Q102.959 819.382 99.8113 822.6 Q96.6632 825.817 91.4317 825.817 Q85.4364 825.817 82.2651 821.234 Q79.0938 816.628 79.0938 807.901 Q79.0938 799.706 82.9827 794.845 Q86.8716 789.961 93.4225 789.961 Q95.1817 789.961 96.9641 790.308 Q98.7696 790.655 100.714 791.35 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip930)\" d=\"M91.1077 596.118 Q87.7743 596.118 85.8531 597.9 Q83.9549 599.682 83.9549 602.807 Q83.9549 605.932 85.8531 607.715 Q87.7743 609.497 91.1077 609.497 Q94.441 609.497 96.3623 607.715 Q98.2835 605.909 98.2835 602.807 Q98.2835 599.682 96.3623 597.9 Q94.4641 596.118 91.1077 596.118 M86.4318 594.127 Q83.4225 593.386 81.7327 591.326 Q80.066 589.266 80.066 586.303 Q80.066 582.159 83.0058 579.752 Q85.9688 577.344 91.1077 577.344 Q96.2697 577.344 99.2095 579.752 Q102.149 582.159 102.149 586.303 Q102.149 589.266 100.459 591.326 Q98.7928 593.386 95.8067 594.127 Q99.1863 594.914 101.061 597.205 Q102.959 599.497 102.959 602.807 Q102.959 607.83 99.8808 610.516 Q96.8252 613.201 91.1077 613.201 Q85.3901 613.201 82.3114 610.516 Q79.2559 607.83 79.2559 602.807 Q79.2559 599.497 81.154 597.205 Q83.0521 594.914 86.4318 594.127 M84.7188 586.743 Q84.7188 589.428 86.3855 590.932 Q88.0753 592.437 91.1077 592.437 Q94.1169 592.437 95.8067 590.932 Q97.5197 589.428 97.5197 586.743 Q97.5197 584.057 95.8067 582.553 Q94.1169 581.048 91.1077 581.048 Q88.0753 581.048 86.3855 582.553 Q84.7188 584.057 84.7188 586.743 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip930)\" d=\"M51.6634 395.978 L59.3023 395.978 L59.3023 369.612 L50.9921 371.279 L50.9921 367.02 L59.256 365.353 L63.9319 365.353 L63.9319 395.978 L71.5707 395.978 L71.5707 399.913 L51.6634 399.913 L51.6634 395.978 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip930)\" d=\"M91.0151 368.432 Q87.404 368.432 85.5753 371.996 Q83.7697 375.538 83.7697 382.668 Q83.7697 389.774 85.5753 393.339 Q87.404 396.881 91.0151 396.881 Q94.6493 396.881 96.4548 393.339 Q98.2835 389.774 98.2835 382.668 Q98.2835 375.538 96.4548 371.996 Q94.6493 368.432 91.0151 368.432 M91.0151 364.728 Q96.8252 364.728 99.8808 369.334 Q102.959 373.918 102.959 382.668 Q102.959 391.394 99.8808 396.001 Q96.8252 400.584 91.0151 400.584 Q85.2049 400.584 82.1262 396.001 Q79.0707 391.394 79.0707 382.668 Q79.0707 373.918 82.1262 369.334 Q85.2049 364.728 91.0151 364.728 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip930)\" d=\"M53.2606 183.361 L60.8995 183.361 L60.8995 156.996 L52.5893 158.662 L52.5893 154.403 L60.8532 152.736 L65.5291 152.736 L65.5291 183.361 L73.1679 183.361 L73.1679 187.296 L53.2606 187.296 L53.2606 183.361 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip930)\" d=\"M86.6401 183.361 L102.959 183.361 L102.959 187.296 L81.0151 187.296 L81.0151 183.361 Q83.6771 180.607 88.2604 175.977 Q92.8669 171.324 94.0475 169.982 Q96.2928 167.459 97.1724 165.722 Q98.0752 163.963 98.0752 162.273 Q98.0752 159.519 96.1308 157.783 Q94.2095 156.047 91.1077 156.047 Q88.9086 156.047 86.4549 156.81 Q84.0244 157.574 81.2466 159.125 L81.2466 154.403 Q84.0707 153.269 86.5243 152.69 Q88.978 152.111 91.0151 152.111 Q96.3854 152.111 99.5798 154.797 Q102.774 157.482 102.774 161.972 Q102.774 164.102 101.964 166.023 Q101.177 167.921 99.0706 170.514 Q98.4919 171.185 95.39 174.403 Q92.2882 177.597 86.6401 183.361 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip932)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  201.614,1429.04 268.985,1418.01 336.355,1445.72 403.726,1442.46 471.096,1430.87 538.467,1337.26 605.837,1436.7 673.208,1445.72 740.579,1438.59 807.949,1441.83 \n",
       "  875.32,1438.91 942.69,1439.14 1010.06,1425.23 1077.43,1421.48 1144.8,1445.53 1212.17,1444.02 1279.54,1445.38 1346.91,1441.83 1414.28,1436.05 1481.65,1443.01 \n",
       "  1549.03,1431.26 1616.4,1442.28 1683.77,1430.53 1751.14,1445.72 1818.51,1400.78 1885.88,1438.62 1953.25,1419.99 2020.62,1424.2 2087.99,87.9763 2155.36,1441.99 \n",
       "  2222.73,947.495 2290.1,1442.09 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip930)\" d=\"\n",
       "M1980.56 198.898 L2278.96 198.898 L2278.96 95.2176 L1980.56 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip930)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1980.56,198.898 2278.96,198.898 2278.96,95.2176 1980.56,95.2176 1980.56,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip930)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2005.15,147.058 2152.74,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip930)\" d=\"M2191.18 166.745 Q2189.37 171.375 2187.66 172.787 Q2185.95 174.199 2183.08 174.199 L2179.67 174.199 L2179.67 170.634 L2182.17 170.634 Q2183.93 170.634 2184.91 169.8 Q2185.88 168.967 2187.06 165.865 L2187.82 163.921 L2177.34 138.412 L2181.85 138.412 L2189.95 158.689 L2198.05 138.412 L2202.57 138.412 L2191.18 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip930)\" d=\"M2209.86 160.402 L2217.5 160.402 L2217.5 134.037 L2209.19 135.703 L2209.19 131.444 L2217.45 129.778 L2222.13 129.778 L2222.13 160.402 L2229.77 160.402 L2229.77 164.338 L2209.86 164.338 L2209.86 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    bestEpSc    = -100.0;\n",
    "    statesBest  = zeros( size( X_0, 1 ), T )\n",
    "    actionsBest = zeros( T );\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/(episodes-1)\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        s_l = 0.0\n",
    "        # while s_l == 0\n",
    "        \n",
    "            X  = X_0\n",
    "\n",
    "            ##### Double Q-Learning ###########################################\n",
    "\n",
    "            for k = 1:T\n",
    "\n",
    "                # 1. Choose action\n",
    "                if rand() < epsilon\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                else\n",
    "\n",
    "                    A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                    if A == 1000.0 # Indicates no values in this region\n",
    "                        if rand() < EXPrand \n",
    "                            A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                        else\n",
    "                            A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                # 2. Cache last state\n",
    "                qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "                # 3. Generate the next stae\n",
    "                Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "                # 4. Collect reward R( s, a, s' )\n",
    "                R_t = cartpole_reward( Xp )\n",
    "\n",
    "                # 5. Get the optimal action at the next state\n",
    "                a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "                # 6. Compute the value at the next state\n",
    "\n",
    "                V_tp1_opt = query_value_fuzzy( \n",
    "                    Q_kdTree, G, V, \n",
    "                    get_Q( \n",
    "                        select_X_vector( Xp ), \n",
    "                        a_tp1_opt \n",
    "                    ); \n",
    "                    k = vNN \n",
    "                )\n",
    "                if isnan( V_tp1_opt )\n",
    "                    V_tp1_opt = 0.0\n",
    "                end\n",
    "\n",
    "\n",
    "                # 7. Blend the value back into nearest points\n",
    "\n",
    "                idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "                nNear      = size( idxs, 1 )\n",
    "                for i = 1:nNear\n",
    "                    j    = idxs[i]\n",
    "                    if !isnan( wgts[i] ) \n",
    "\n",
    "                        # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                        VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                states[:,k] = Xp\n",
    "                actions[k]  = A\n",
    "\n",
    "                X = Xp\n",
    "            end\n",
    "\n",
    "            s_l    = vertical_score_s( states, aMargin, ts )\n",
    "            \n",
    "        # end\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if s_l > bestEpSc\n",
    "            bestEpSc    = s_l\n",
    "            statesBest  = copy( states  )\n",
    "            actionsBest = copy( actions )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        # if useElig && (s_l > s_Totl/(1.0*l)) && (s_l > 0.0) \n",
    "        # if useElig && (s_l > 0.0) \n",
    "        if useElig \n",
    "            \n",
    "            # if s_l == 0.0\n",
    "            #     states  = copy( bestXs )\n",
    "            #     actions = copy( bestAs )\n",
    "            # end\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709555b9-2598-4281-a634-c7b0681277d0",
   "metadata": {},
   "source": [
    "# Method 2 Performance, Average Vertical Duration [s]\n",
    "Each score is the best average score of the last two epochs: 64 epochs of 64 episodes each, Q-function swap after every episode \n",
    "\n",
    "### TD Tuning\n",
    "\n",
    "$\\alpha = 0.99$: 0.238  \n",
    "$\\alpha = 0.75$: 0.257  \n",
    "$\\alpha = 0.50$: 0.191   \n",
    "$\\alpha = 0.25$: 0.170  \n",
    "$\\alpha = 0.125$: 0.290  \n",
    "$\\alpha = 0.0625$: 0.208, but fantastic performance in the middle of training  \n",
    "$\\alpha = 0.03125$: 0.978  \n",
    "$\\alpha = 0.02344$: 2.567  \n",
    "$\\alpha = 0.01953$: 0.268  \n",
    "$\\alpha = 0.015625$: 0.095  \n",
    " \n",
    "### Add gamma?\n",
    " \n",
    "### Double-Q Tuning, Swap Evey N Episodes\n",
    "$\\%\\ \\ 2$:  \n",
    "$\\%\\ \\ 4$:  \n",
    "$\\%\\ \\ 8$:  \n",
    "$\\%16$:  \n",
    "$\\%32$:  \n",
    "$\\%64$:  \n",
    "\n",
    "\n",
    "\n",
    "### Blend: Best Episode\n",
    "\n",
    "$\\beta = 0.07$:  \n",
    "$\\beta = 0.15$: 0.244\n",
    "\n",
    "| Method      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n",
    "| ----------- | ------- | ------- | ------- | ------- | ------- | ---- |\n",
    "| Blend (Epi) |         |         |         |         |         |      |\n",
    "| Blend (Epo) |         |         |         |         |         |      |\n",
    "| TD          |         |         |         |         |         |      |\n",
    "| TD  + ????? |         |         |         |         |         |      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
