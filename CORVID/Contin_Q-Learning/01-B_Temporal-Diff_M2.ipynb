{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.02148 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 # 0.00782 # 0.00391\n",
    "gamma    = 1.00 \n",
    "swapDiv  = 64\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes = 64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   = 32 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "beta   = 0.15\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = true\n",
    "N_peaks =  32\n",
    "N_steps =  96\n",
    "lambda  =   0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.6600000000000004, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.16, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.6000000000000003, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 1.1400000000000008, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.6800000000000004, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.26000000000000006, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.20000000000000004, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.35000000000000014, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.23000000000000012\n",
      "\n",
      "Epoch 2, Best Score: 1.280000000000001\n",
      "Training Iteration 4 score: 0.13999999999999999, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.08, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.5300000000000002, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.48000000000000026, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 1.0400000000000007, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.7400000000000004, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.5900000000000003, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.49000000000000027, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 1.400000000000001, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.7700000000000005, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 1.1100000000000008, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.18000000000000002, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 1.330000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.09999999999999999, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 1.5100000000000011, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.5393749999999995\n",
      "\n",
      "Epoch 3, Best Score: 3.7199999999999647\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 4, Best Score: 3.7199999999999647\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.12999999999999998, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.09999999999999999, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.035468750000000014\n",
      "\n",
      "Epoch 5, Best Score: 3.7199999999999647\n",
      "Training Iteration 4 score: 0.3200000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.46000000000000024, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.09999999999999999, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.08687500000000004\n",
      "\n",
      "Epoch 6, Best Score: 3.7199999999999647\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.47000000000000025, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.35000000000000014, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.7400000000000004, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.10593750000000006\n",
      "\n",
      "Epoch 7, Best Score: 3.7199999999999647\n",
      "Training Iteration 4 score: 0.09999999999999999, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.5100000000000002, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.47000000000000025, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.3100000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.12999999999999998, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.21000000000000005, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.23000000000000007, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.09999999999999999, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.09, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.20000000000000004, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.48000000000000026, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.35000000000000014, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.18000000000000002, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.08, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.23000000000000007, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.10999999999999999, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.27796875\n",
      "\n",
      "Epoch 8, Best Score: 3.7199999999999647\n",
      "Training Iteration 4 score: 0.24000000000000007, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.8100000000000005, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.26000000000000006, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.36000000000000015, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.34000000000000014, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.25000000000000006, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.3200000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.36000000000000015, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.25484375000000015\n",
      "\n",
      "Epoch 9, Best Score: 3.7199999999999647\n",
      "Training Iteration 4 score: 2.4199999999999924, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.6700000000000004, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 2.399999999999993, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.6600000000000004, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 1.0100000000000007, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 1.500000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 4.2199999999999545, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 1.360000000000001, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.310000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.8700000000000006, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 5.189999999999934, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 1.400000000000001, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 2.629999999999988, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 5.179999999999934, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.45000000000000023, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.5800000000000003, epsilon: 8.881784197001252e-16\n",
      "Average Score: 1.6095312499999916\n",
      "\n",
      "Epoch 10, Best Score: 5.699999999999923\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 1.6700000000000013, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.7400000000000004, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.5600000000000003, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.2900000000000001, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.9700000000000006, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.2906249999999997\n",
      "\n",
      "Epoch 11, Best Score: 5.699999999999923\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.028125000000000008\n",
      "\n",
      "Epoch 12, Best Score: 5.699999999999923\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.6700000000000004, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.6800000000000004, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 2.489999999999991, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.3200000000000001, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.6100000000000003, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.8000000000000005, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 2.489999999999991, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.7400000000000004, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 1.0500000000000007, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.7400000000000004, epsilon: 8.881784197001252e-16\n",
      "Average Score: 1.1481250000000203\n",
      "\n",
      "Epoch 13, Best Score: 27.520000000001502\n",
      "Training Iteration 4 score: 0.36000000000000015, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.7000000000000004, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.2800000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.9500000000000006, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.26000000000000006, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 1.1225000000000234\n",
      "\n",
      "Epoch 14, Best Score: 27.520000000001502\n",
      "Training Iteration 4 score: 0.21000000000000005, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.20000000000000004, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.3100000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.09999999999999999, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.37000000000000016, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.1300000000000008, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.07, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.1846875000000001\n",
      "\n",
      "Epoch 15, Best Score: 27.520000000001502\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.34000000000000014, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.04437500000000002\n",
      "\n",
      "Epoch 16, Best Score: 27.520000000001502\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.45000000000000023, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 1.9200000000000015, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 1.7800000000000014, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.8900000000000006, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.7600000000000005, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.37234375000000003\n",
      "\n",
      "Epoch 17, Best Score: 27.520000000001502\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 1.0500000000000007, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.09, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.24000000000000007, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.37000000000000016, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.5000000000000002, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.5200000000000002, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.2700000000000001, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.17843750000000005\n",
      "\n",
      "Epoch 18, Best Score: 27.520000000001502\n",
      "Training Iteration 4 score: 0.2700000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.5200000000000002, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.6100000000000003, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.5200000000000002, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.6200000000000003, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.47000000000000025, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.6200000000000003, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.21000000000000005, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.6900000000000004, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.5900000000000003, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.3000000000000001, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.5200000000000002, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.4200000000000002, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.37000000000000016, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.4368750000000003\n",
      "\n",
      "Epoch 19, Best Score: 27.520000000001502\n",
      "Training Iteration 4 score: 0.5600000000000003, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.08, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.6600000000000004, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.37000000000000016, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.0, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.9812499999999917\n",
      "\n",
      "Epoch 20, Best Score: 27.520000000001502\n",
      "Training Iteration 4 score: 0.6000000000000003, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.3100000000000001, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.48000000000000026, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.2700000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.7400000000000004, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.2800000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.24000000000000007, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.36000000000000015, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 3.699999999999965, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 1.0700000000000007, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.4100000000000002, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.2700000000000001, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.3000000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.2700000000000001, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.6100000000000003, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.4178124999999996\n",
      "\n",
      "Epoch 21, Best Score: 27.520000000001502\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.20000000000000004, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.3000000000000001, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.3300000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.21000000000000005, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.35000000000000014, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.26000000000000006, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.45000000000000023, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.24000000000000007, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.22234375000000012\n",
      "\n",
      "Epoch 22, Best Score: 27.520000000001502\n",
      "Training Iteration 4 score: 0.6400000000000003, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.6700000000000004, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.8700000000000006, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.7100000000000004, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.47000000000000025, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.1100000000000008, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.7500000000000004, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.24000000000000007, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.3300000000000001, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.47000000000000025, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.7000000000000004, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.35000000000000014, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.4018750000000002\n",
      "\n",
      "Epoch 23, Best Score: 27.520000000001502\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.4200000000000002, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.20000000000000004, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.16, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.7400000000000004, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.2800000000000001, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.2700000000000001, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 1.0500000000000007, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.15, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.3900000000000002, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.35000000000000014, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.45000000000000023, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.2800000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.11999999999999998, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.3000000000000001, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.3210937500000002\n",
      "\n",
      "Epoch 24, Best Score: 27.520000000001502\n",
      "Training Iteration 4 score: 0.3000000000000001, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.2700000000000001, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.18000000000000002, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.37000000000000016, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.19000000000000003, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.20000000000000004, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.5000000000000002, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.2800000000000001, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.48000000000000026, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.21000000000000005, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.49000000000000027, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.4100000000000002, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.4200000000000002, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.47000000000000025, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.46000000000000024, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.46000000000000024, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.3629687500000003\n",
      "\n",
      "Epoch 25, Best Score: 27.520000000001502\n",
      "Training Iteration 4 score: 0.38000000000000017, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.6400000000000003, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.2700000000000001, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.2800000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.23000000000000007, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.7600000000000005, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.09, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.5700000000000003, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.6100000000000003, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 1.1200000000000008, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.21000000000000005, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.38000000000000017, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.49000000000000027, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.4400000000000002, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.23000000000000007, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.3100000000000001, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.41921875000000025\n",
      "\n",
      "Epoch 26, Best Score: 27.520000000001502\n",
      "Training Iteration 4 score: 0.17, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.18000000000000002, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 1.310000000000001, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.08, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.4400000000000002, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.23000000000000007, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.2700000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.2900000000000001, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.3300000000000001, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.3100000000000001, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.12999999999999998, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.24000000000000007, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.24000000000000007, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.4100000000000002, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.35468750000000004\n",
      "\n",
      "Epoch 27, Best Score: 27.520000000001502\n",
      "Training Iteration 4 score: 0.7300000000000004, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.35000000000000014, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.48000000000000026, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.4300000000000002, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 1.340000000000001, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.34000000000000014, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.4100000000000002, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.2900000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.6600000000000004, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.36000000000000015, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.30062500000000025\n",
      "\n",
      "Epoch 28, Best Score: 27.520000000001502\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.5800000000000003, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.7700000000000005, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.16, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.23000000000000007, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.47000000000000025, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.5400000000000003, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.3200000000000001, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.2900000000000001, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.2900000000000001, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.26000000000000006, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.5200000000000002, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.7800000000000005, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.4300000000000002, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.5000000000000002, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.38234375000000026\n",
      "\n",
      "Epoch 29, Best Score: 27.520000000001502\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 1.2500000000000009, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 1.0800000000000007, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.5500000000000003, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.5700000000000003, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.6800000000000004, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.6200000000000003, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.5300000000000002, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.5400000000000003, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.3725000000000002\n",
      "\n",
      "Epoch 30, Best Score: 27.520000000001502\n",
      "Training Iteration 4 score: 0.8800000000000006, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 0.8500000000000005, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.9800000000000006, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.6800000000000004, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.2700000000000001, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.26000000000000006, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.7700000000000005, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.6100000000000003, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.24000000000000007, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.3300000000000001, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.2800000000000001, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.2700000000000001, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.3200000000000001, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.2800000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 0.4200000000000002, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 0.2900000000000001, epsilon: 8.881784197001252e-16\n",
      "Average Score: 0.44718750000000035\n",
      "\n",
      "Epoch 31, Best Score: 27.520000000001502\n",
      "Training Iteration 4 score: 2.9299999999999815, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 31.430000000002114, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 0.5500000000000003, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.23000000000000007, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 1.7400000000000013, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 17.559999999999945, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 0.26000000000000006, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 29.4300000000018, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.26000000000000006, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.2700000000000001, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.20000000000000004, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 28.370000000001635, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 0.25000000000000006, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 0.2800000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 22.720000000000752, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 5.929999999999918, epsilon: 8.881784197001252e-16\n",
      "Average Score: 12.01218750000049\n",
      "\n",
      "Epoch 32, Best Score: 31.430000000002114\n",
      "Training Iteration 4 score: 0.4200000000000002, epsilon: 0.4761904761904763\n",
      "Training Iteration 8 score: 2.06, epsilon: 0.44444444444444464\n",
      "Training Iteration 12 score: 2.909999999999982, epsilon: 0.412698412698413\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3809523809523814\n",
      "Training Iteration 20 score: 0.25000000000000006, epsilon: 0.34920634920634974\n",
      "Training Iteration 24 score: 0.8900000000000006, epsilon: 0.3174603174603181\n",
      "Training Iteration 28 score: 1.9900000000000015, epsilon: 0.2857142857142865\n",
      "Training Iteration 32 score: 0.8600000000000005, epsilon: 0.25396825396825484\n",
      "Training Iteration 36 score: 0.9700000000000006, epsilon: 0.2222222222222231\n",
      "Training Iteration 40 score: 0.8200000000000005, epsilon: 0.19047619047619135\n",
      "Training Iteration 44 score: 0.8700000000000006, epsilon: 0.1587301587301596\n",
      "Training Iteration 48 score: 0.7000000000000004, epsilon: 0.12698412698412787\n",
      "Training Iteration 52 score: 2.709999999999986, epsilon: 0.09523809523809612\n",
      "Training Iteration 56 score: 1.370000000000001, epsilon: 0.06349206349206438\n",
      "Training Iteration 60 score: 2.1899999999999973, epsilon: 0.03174603174603263\n",
      "Training Iteration 64 score: 5.139999999999935, epsilon: 8.881784197001252e-16\n",
      "Average Score: 1.2439062499999962\n",
      "Saved a trained Q-table with size (76032,), After 13.366842218240102 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip510\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip510)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip511\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip510)\" d=\"\n",
       "M184.191 1486.45 L2352.76 1486.45 L2352.76 47.2441 L184.191 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip512\">\n",
       "    <rect x=\"184\" y=\"47\" width=\"2170\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  509.541,1486.45 509.541,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  839.512,1486.45 839.512,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1169.48,1486.45 1169.48,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1499.45,1486.45 1499.45,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1829.42,1486.45 1829.42,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2159.39,1486.45 2159.39,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  509.541,1486.45 509.541,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  839.512,1486.45 839.512,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1169.48,1486.45 1169.48,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1499.45,1486.45 1499.45,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1829.42,1486.45 1829.42,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2159.39,1486.45 2159.39,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip510)\" d=\"M499.819 1514.29 L518.176 1514.29 L518.176 1518.22 L504.102 1518.22 L504.102 1526.7 Q505.12 1526.35 506.139 1526.19 Q507.157 1526 508.176 1526 Q513.963 1526 517.342 1529.17 Q520.722 1532.34 520.722 1537.76 Q520.722 1543.34 517.25 1546.44 Q513.778 1549.52 507.458 1549.52 Q505.282 1549.52 503.014 1549.15 Q500.768 1548.78 498.361 1548.04 L498.361 1543.34 Q500.444 1544.47 502.666 1545.03 Q504.889 1545.58 507.366 1545.58 Q511.37 1545.58 513.708 1543.48 Q516.046 1541.37 516.046 1537.76 Q516.046 1534.15 513.708 1532.04 Q511.37 1529.94 507.366 1529.94 Q505.491 1529.94 503.616 1530.35 Q501.764 1530.77 499.819 1531.65 L499.819 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M814.199 1544.91 L821.838 1544.91 L821.838 1518.55 L813.528 1520.21 L813.528 1515.95 L821.792 1514.29 L826.468 1514.29 L826.468 1544.91 L834.107 1544.91 L834.107 1548.85 L814.199 1548.85 L814.199 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M853.551 1517.37 Q849.94 1517.37 848.111 1520.93 Q846.306 1524.47 846.306 1531.6 Q846.306 1538.71 848.111 1542.27 Q849.94 1545.82 853.551 1545.82 Q857.185 1545.82 858.991 1542.27 Q860.82 1538.71 860.82 1531.6 Q860.82 1524.47 858.991 1520.93 Q857.185 1517.37 853.551 1517.37 M853.551 1513.66 Q859.361 1513.66 862.417 1518.27 Q865.495 1522.85 865.495 1531.6 Q865.495 1540.33 862.417 1544.94 Q859.361 1549.52 853.551 1549.52 Q847.741 1549.52 844.662 1544.94 Q841.607 1540.33 841.607 1531.6 Q841.607 1522.85 844.662 1518.27 Q847.741 1513.66 853.551 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1144.67 1544.91 L1152.31 1544.91 L1152.31 1518.55 L1144 1520.21 L1144 1515.95 L1152.26 1514.29 L1156.94 1514.29 L1156.94 1544.91 L1164.57 1544.91 L1164.57 1548.85 L1144.67 1548.85 L1144.67 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1174.07 1514.29 L1192.42 1514.29 L1192.42 1518.22 L1178.35 1518.22 L1178.35 1526.7 Q1179.37 1526.35 1180.38 1526.19 Q1181.4 1526 1182.42 1526 Q1188.21 1526 1191.59 1529.17 Q1194.97 1532.34 1194.97 1537.76 Q1194.97 1543.34 1191.5 1546.44 Q1188.02 1549.52 1181.7 1549.52 Q1179.53 1549.52 1177.26 1549.15 Q1175.01 1548.78 1172.61 1548.04 L1172.61 1543.34 Q1174.69 1544.47 1176.91 1545.03 Q1179.13 1545.58 1181.61 1545.58 Q1185.62 1545.58 1187.95 1543.48 Q1190.29 1541.37 1190.29 1537.76 Q1190.29 1534.15 1187.95 1532.04 Q1185.62 1529.94 1181.61 1529.94 Q1179.74 1529.94 1177.86 1530.35 Q1176.01 1530.77 1174.07 1531.65 L1174.07 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1478.23 1544.91 L1494.55 1544.91 L1494.55 1548.85 L1472.6 1548.85 L1472.6 1544.91 Q1475.26 1542.16 1479.85 1537.53 Q1484.45 1532.88 1485.63 1531.53 Q1487.88 1529.01 1488.76 1527.27 Q1489.66 1525.51 1489.66 1523.82 Q1489.66 1521.07 1487.72 1519.33 Q1485.8 1517.6 1482.69 1517.6 Q1480.49 1517.6 1478.04 1518.36 Q1475.61 1519.13 1472.83 1520.68 L1472.83 1515.95 Q1475.66 1514.82 1478.11 1514.24 Q1480.56 1513.66 1482.6 1513.66 Q1487.97 1513.66 1491.17 1516.35 Q1494.36 1519.03 1494.36 1523.52 Q1494.36 1525.65 1493.55 1527.57 Q1492.76 1529.47 1490.66 1532.07 Q1490.08 1532.74 1486.98 1535.95 Q1483.87 1539.15 1478.23 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1514.36 1517.37 Q1510.75 1517.37 1508.92 1520.93 Q1507.11 1524.47 1507.11 1531.6 Q1507.11 1538.71 1508.92 1542.27 Q1510.75 1545.82 1514.36 1545.82 Q1517.99 1545.82 1519.8 1542.27 Q1521.63 1538.71 1521.63 1531.6 Q1521.63 1524.47 1519.8 1520.93 Q1517.99 1517.37 1514.36 1517.37 M1514.36 1513.66 Q1520.17 1513.66 1523.23 1518.27 Q1526.3 1522.85 1526.3 1531.6 Q1526.3 1540.33 1523.23 1544.94 Q1520.17 1549.52 1514.36 1549.52 Q1508.55 1549.52 1505.47 1544.94 Q1502.42 1540.33 1502.42 1531.6 Q1502.42 1522.85 1505.47 1518.27 Q1508.55 1513.66 1514.36 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1808.69 1544.91 L1825.01 1544.91 L1825.01 1548.85 L1803.07 1548.85 L1803.07 1544.91 Q1805.73 1542.16 1810.31 1537.53 Q1814.92 1532.88 1816.1 1531.53 Q1818.35 1529.01 1819.23 1527.27 Q1820.13 1525.51 1820.13 1523.82 Q1820.13 1521.07 1818.18 1519.33 Q1816.26 1517.6 1813.16 1517.6 Q1810.96 1517.6 1808.51 1518.36 Q1806.08 1519.13 1803.3 1520.68 L1803.3 1515.95 Q1806.12 1514.82 1808.58 1514.24 Q1811.03 1513.66 1813.07 1513.66 Q1818.44 1513.66 1821.63 1516.35 Q1824.83 1519.03 1824.83 1523.52 Q1824.83 1525.65 1824.02 1527.57 Q1823.23 1529.47 1821.12 1532.07 Q1820.55 1532.74 1817.44 1535.95 Q1814.34 1539.15 1808.69 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1834.87 1514.29 L1853.23 1514.29 L1853.23 1518.22 L1839.16 1518.22 L1839.16 1526.7 Q1840.18 1526.35 1841.19 1526.19 Q1842.21 1526 1843.23 1526 Q1849.02 1526 1852.4 1529.17 Q1855.78 1532.34 1855.78 1537.76 Q1855.78 1543.34 1852.3 1546.44 Q1848.83 1549.52 1842.51 1549.52 Q1840.34 1549.52 1838.07 1549.15 Q1835.82 1548.78 1833.42 1548.04 L1833.42 1543.34 Q1835.5 1544.47 1837.72 1545.03 Q1839.94 1545.58 1842.42 1545.58 Q1846.43 1545.58 1848.76 1543.48 Q1851.1 1541.37 1851.1 1537.76 Q1851.1 1534.15 1848.76 1532.04 Q1846.43 1529.94 1842.42 1529.94 Q1840.55 1529.94 1838.67 1530.35 Q1836.82 1530.77 1834.87 1531.65 L1834.87 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M2148.24 1530.21 Q2151.59 1530.93 2153.47 1533.2 Q2155.37 1535.47 2155.37 1538.8 Q2155.37 1543.92 2151.85 1546.72 Q2148.33 1549.52 2141.85 1549.52 Q2139.67 1549.52 2137.36 1549.08 Q2135.06 1548.66 2132.61 1547.81 L2132.61 1543.29 Q2134.56 1544.43 2136.87 1545.01 Q2139.19 1545.58 2141.71 1545.58 Q2146.11 1545.58 2148.4 1543.85 Q2150.71 1542.11 2150.71 1538.8 Q2150.71 1535.75 2148.56 1534.03 Q2146.43 1532.3 2142.61 1532.3 L2138.58 1532.3 L2138.58 1528.45 L2142.8 1528.45 Q2146.25 1528.45 2148.07 1527.09 Q2149.9 1525.7 2149.9 1523.11 Q2149.9 1520.45 2148 1519.03 Q2146.13 1517.6 2142.61 1517.6 Q2140.69 1517.6 2138.49 1518.01 Q2136.29 1518.43 2133.65 1519.31 L2133.65 1515.14 Q2136.31 1514.4 2138.63 1514.03 Q2140.97 1513.66 2143.03 1513.66 Q2148.35 1513.66 2151.45 1516.09 Q2154.56 1518.5 2154.56 1522.62 Q2154.56 1525.49 2152.91 1527.48 Q2151.27 1529.45 2148.24 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M2174.23 1517.37 Q2170.62 1517.37 2168.79 1520.93 Q2166.99 1524.47 2166.99 1531.6 Q2166.99 1538.71 2168.79 1542.27 Q2170.62 1545.82 2174.23 1545.82 Q2177.87 1545.82 2179.67 1542.27 Q2181.5 1538.71 2181.5 1531.6 Q2181.5 1524.47 2179.67 1520.93 Q2177.87 1517.37 2174.23 1517.37 M2174.23 1513.66 Q2180.04 1513.66 2183.1 1518.27 Q2186.18 1522.85 2186.18 1531.6 Q2186.18 1540.33 2183.1 1544.94 Q2180.04 1549.52 2174.23 1549.52 Q2168.42 1549.52 2165.34 1544.94 Q2162.29 1540.33 2162.29 1531.6 Q2162.29 1522.85 2165.34 1518.27 Q2168.42 1513.66 2174.23 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,1445.72 2352.76,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,1163.14 2352.76,1163.14 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,880.565 2352.76,880.565 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,597.99 2352.76,597.99 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  184.191,315.414 2352.76,315.414 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,1486.45 184.191,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,1445.72 203.088,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,1163.14 203.088,1163.14 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,880.565 203.088,880.565 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,597.99 203.088,597.99 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  184.191,315.414 203.088,315.414 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip510)\" d=\"M91.0151 1431.51 Q87.404 1431.51 85.5753 1435.08 Q83.7697 1438.62 83.7697 1445.75 Q83.7697 1452.86 85.5753 1456.42 Q87.404 1459.96 91.0151 1459.96 Q94.6493 1459.96 96.4548 1456.42 Q98.2835 1452.86 98.2835 1445.75 Q98.2835 1438.62 96.4548 1435.08 Q94.6493 1431.51 91.0151 1431.51 M91.0151 1427.81 Q96.8252 1427.81 99.8808 1432.42 Q102.959 1437 102.959 1445.75 Q102.959 1454.48 99.8808 1459.08 Q96.8252 1463.67 91.0151 1463.67 Q85.2049 1463.67 82.1262 1459.08 Q79.0707 1454.48 79.0707 1445.75 Q79.0707 1437 82.1262 1432.42 Q85.2049 1427.81 91.0151 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M111.177 1457.12 L116.061 1457.12 L116.061 1463 L111.177 1463 L111.177 1457.12 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M136.246 1431.51 Q132.635 1431.51 130.807 1435.08 Q129.001 1438.62 129.001 1445.75 Q129.001 1452.86 130.807 1456.42 Q132.635 1459.96 136.246 1459.96 Q139.881 1459.96 141.686 1456.42 Q143.515 1452.86 143.515 1445.75 Q143.515 1438.62 141.686 1435.08 Q139.881 1431.51 136.246 1431.51 M136.246 1427.81 Q142.056 1427.81 145.112 1432.42 Q148.191 1437 148.191 1445.75 Q148.191 1454.48 145.112 1459.08 Q142.056 1463.67 136.246 1463.67 Q130.436 1463.67 127.357 1459.08 Q124.302 1454.48 124.302 1445.75 Q124.302 1437 127.357 1432.42 Q130.436 1427.81 136.246 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M86.0382 1176.49 L102.358 1176.49 L102.358 1180.42 L80.4133 1180.42 L80.4133 1176.49 Q83.0753 1173.73 87.6586 1169.1 Q92.2651 1164.45 93.4456 1163.11 Q95.691 1160.58 96.5706 1158.85 Q97.4734 1157.09 97.4734 1155.4 Q97.4734 1152.64 95.5289 1150.91 Q93.6076 1149.17 90.5058 1149.17 Q88.3067 1149.17 85.8531 1149.93 Q83.4225 1150.7 80.6447 1152.25 L80.6447 1147.53 Q83.4688 1146.39 85.9225 1145.81 Q88.3762 1145.24 90.4132 1145.24 Q95.7836 1145.24 98.978 1147.92 Q102.172 1150.61 102.172 1155.1 Q102.172 1157.23 101.362 1159.15 Q100.575 1161.05 98.4687 1163.64 Q97.89 1164.31 94.7882 1167.53 Q91.6864 1170.72 86.0382 1176.49 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M112.172 1174.54 L117.057 1174.54 L117.057 1180.42 L112.172 1180.42 L112.172 1174.54 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M127.288 1145.86 L145.644 1145.86 L145.644 1149.8 L131.57 1149.8 L131.57 1158.27 Q132.589 1157.92 133.607 1157.76 Q134.626 1157.57 135.644 1157.57 Q141.431 1157.57 144.811 1160.74 Q148.191 1163.92 148.191 1169.33 Q148.191 1174.91 144.718 1178.01 Q141.246 1181.09 134.927 1181.09 Q132.751 1181.09 130.482 1180.72 Q128.237 1180.35 125.83 1179.61 L125.83 1174.91 Q127.913 1176.05 130.135 1176.6 Q132.357 1177.16 134.834 1177.16 Q138.839 1177.16 141.177 1175.05 Q143.515 1172.94 143.515 1169.33 Q143.515 1165.72 141.177 1163.61 Q138.839 1161.51 134.834 1161.51 Q132.959 1161.51 131.084 1161.93 Q129.232 1162.34 127.288 1163.22 L127.288 1145.86 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M81.0614 863.285 L99.4178 863.285 L99.4178 867.22 L85.3438 867.22 L85.3438 875.692 Q86.3623 875.345 87.3808 875.183 Q88.3993 874.998 89.4178 874.998 Q95.2049 874.998 98.5845 878.169 Q101.964 881.34 101.964 886.757 Q101.964 892.336 98.4919 895.438 Q95.0197 898.516 88.7003 898.516 Q86.5243 898.516 84.2558 898.146 Q82.0105 897.775 79.6031 897.035 L79.6031 892.336 Q81.6864 893.47 83.9086 894.025 Q86.1308 894.581 88.6077 894.581 Q92.6123 894.581 94.9502 892.475 Q97.2882 890.368 97.2882 886.757 Q97.2882 883.146 94.9502 881.039 Q92.6123 878.933 88.6077 878.933 Q86.7327 878.933 84.8577 879.35 Q83.0058 879.766 81.0614 880.646 L81.0614 863.285 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M111.177 891.965 L116.061 891.965 L116.061 897.845 L111.177 897.845 L111.177 891.965 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M136.246 866.364 Q132.635 866.364 130.807 869.928 Q129.001 873.47 129.001 880.6 Q129.001 887.706 130.807 891.271 Q132.635 894.813 136.246 894.813 Q139.881 894.813 141.686 891.271 Q143.515 887.706 143.515 880.6 Q143.515 873.47 141.686 869.928 Q139.881 866.364 136.246 866.364 M136.246 862.66 Q142.056 862.66 145.112 867.266 Q148.191 871.85 148.191 880.6 Q148.191 889.326 145.112 893.933 Q142.056 898.516 136.246 898.516 Q130.436 898.516 127.357 893.933 Q124.302 889.326 124.302 880.6 Q124.302 871.85 127.357 867.266 Q130.436 862.66 136.246 862.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M80.8299 580.71 L103.052 580.71 L103.052 582.7 L90.5058 615.27 L85.6216 615.27 L97.4271 584.645 L80.8299 584.645 L80.8299 580.71 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M112.172 609.39 L117.057 609.39 L117.057 615.27 L112.172 615.27 L112.172 609.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M127.288 580.71 L145.644 580.71 L145.644 584.645 L131.57 584.645 L131.57 593.117 Q132.589 592.77 133.607 592.608 Q134.626 592.422 135.644 592.422 Q141.431 592.422 144.811 595.594 Q148.191 598.765 148.191 604.182 Q148.191 609.76 144.718 612.862 Q141.246 615.941 134.927 615.941 Q132.751 615.941 130.482 615.57 Q128.237 615.2 125.83 614.459 L125.83 609.76 Q127.913 610.895 130.135 611.45 Q132.357 612.006 134.834 612.006 Q138.839 612.006 141.177 609.899 Q143.515 607.793 143.515 604.182 Q143.515 600.571 141.177 598.464 Q138.839 596.358 134.834 596.358 Q132.959 596.358 131.084 596.774 Q129.232 597.191 127.288 598.071 L127.288 580.71 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M51.6634 328.759 L59.3023 328.759 L59.3023 302.393 L50.9921 304.06 L50.9921 299.801 L59.256 298.134 L63.9319 298.134 L63.9319 328.759 L71.5707 328.759 L71.5707 332.694 L51.6634 332.694 L51.6634 328.759 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M91.0151 301.213 Q87.404 301.213 85.5753 304.778 Q83.7697 308.319 83.7697 315.449 Q83.7697 322.555 85.5753 326.12 Q87.404 329.662 91.0151 329.662 Q94.6493 329.662 96.4548 326.12 Q98.2835 322.555 98.2835 315.449 Q98.2835 308.319 96.4548 304.778 Q94.6493 301.213 91.0151 301.213 M91.0151 297.509 Q96.8252 297.509 99.8808 302.116 Q102.959 306.699 102.959 315.449 Q102.959 324.176 99.8808 328.782 Q96.8252 333.365 91.0151 333.365 Q85.2049 333.365 82.1262 328.782 Q79.0707 324.176 79.0707 315.449 Q79.0707 306.699 82.1262 302.116 Q85.2049 297.509 91.0151 297.509 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M111.177 326.815 L116.061 326.815 L116.061 332.694 L111.177 332.694 L111.177 326.815 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M136.246 301.213 Q132.635 301.213 130.807 304.778 Q129.001 308.319 129.001 315.449 Q129.001 322.555 130.807 326.12 Q132.635 329.662 136.246 329.662 Q139.881 329.662 141.686 326.12 Q143.515 322.555 143.515 315.449 Q143.515 308.319 141.686 304.778 Q139.881 301.213 136.246 301.213 M136.246 297.509 Q142.056 297.509 145.112 302.116 Q148.191 306.699 148.191 315.449 Q148.191 324.176 145.112 328.782 Q142.056 333.365 136.246 333.365 Q130.436 333.365 127.357 328.782 Q124.302 324.176 124.302 315.449 Q124.302 306.699 127.357 302.116 Q130.436 297.509 136.246 297.509 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip512)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  245.565,1419.72 311.559,1384.75 377.553,1445.72 443.547,1441.71 509.541,1435.9 575.536,1433.74 641.53,1414.3 707.524,1416.91 773.518,1263.79 839.512,1412.87 \n",
       "  905.506,1442.54 971.5,1315.94 1037.49,1318.84 1103.49,1424.84 1169.48,1440.7 1235.48,1403.63 1301.47,1425.55 1367.46,1396.34 1433.46,1334.8 1499.45,1398.49 \n",
       "  1565.45,1420.58 1631.44,1400.29 1697.43,1409.42 1763.43,1404.69 1829.42,1398.33 1895.42,1405.63 1961.41,1411.74 2027.41,1402.5 2093.4,1403.61 2159.39,1395.17 \n",
       "  2225.39,87.9763 2291.38,1305.12 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip510)\" d=\"\n",
       "M1987.09 198.898 L2280.47 198.898 L2280.47 95.2176 L1987.09 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1987.09,198.898 2280.47,198.898 2280.47,95.2176 1987.09,95.2176 1987.09,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2011.18,147.058 2155.75,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip510)\" d=\"M2193.69 166.745 Q2191.89 171.375 2190.17 172.787 Q2188.46 174.199 2185.59 174.199 L2182.19 174.199 L2182.19 170.634 L2184.69 170.634 Q2186.45 170.634 2187.42 169.8 Q2188.39 168.967 2189.57 165.865 L2190.34 163.921 L2179.85 138.412 L2184.36 138.412 L2192.47 158.689 L2200.57 138.412 L2205.08 138.412 L2193.69 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M2212.37 160.402 L2220.01 160.402 L2220.01 134.037 L2211.7 135.703 L2211.7 131.444 L2219.97 129.778 L2224.64 129.778 L2224.64 160.402 L2232.28 160.402 L2232.28 164.338 L2212.37 164.338 L2212.37 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    bestEpSc    = -100.0;\n",
    "    statesBest  = zeros( size( X_0, 1 ), T )\n",
    "    actionsBest = zeros( T );\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/(episodes-1)\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        s_l = 0.0\n",
    "        # while s_l == 0\n",
    "        \n",
    "            X  = X_0\n",
    "\n",
    "            ##### Double Q-Learning ###########################################\n",
    "\n",
    "            for k = 1:T\n",
    "\n",
    "                # 1. Choose action\n",
    "                if rand() < epsilon\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                else\n",
    "\n",
    "                    A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                    if A == 1000.0 # Indicates no values in this region\n",
    "                        if rand() < EXPrand \n",
    "                            A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                        else\n",
    "                            A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                # 2. Cache last state\n",
    "                qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "                # 3. Generate the next stae\n",
    "                Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "                # 4. Collect reward R( s, a, s' )\n",
    "                R_t = cartpole_reward( Xp )\n",
    "\n",
    "                # 5. Get the optimal action at the next state\n",
    "                a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "                # 6. Compute the value at the next state\n",
    "\n",
    "                V_tp1_opt = query_value_fuzzy( \n",
    "                    Q_kdTree, G, V, \n",
    "                    get_Q( \n",
    "                        select_X_vector( Xp ), \n",
    "                        a_tp1_opt \n",
    "                    ); \n",
    "                    k = vNN \n",
    "                )\n",
    "                if isnan( V_tp1_opt )\n",
    "                    V_tp1_opt = 0.0\n",
    "                end\n",
    "\n",
    "\n",
    "                # 7. Blend the value back into nearest points\n",
    "\n",
    "                idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "                nNear      = size( idxs, 1 )\n",
    "                for i = 1:nNear\n",
    "                    j    = idxs[i]\n",
    "                    if !isnan( wgts[i] ) \n",
    "\n",
    "                        # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                        VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                states[:,k] = Xp\n",
    "                actions[k]  = A\n",
    "\n",
    "                X = Xp\n",
    "            end\n",
    "\n",
    "            s_l    = vertical_score_s( states, aMargin, ts )\n",
    "            \n",
    "        # end\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if s_l > bestEpSc\n",
    "            bestEpSc    = s_l\n",
    "            statesBest  = copy( states  )\n",
    "            actionsBest = copy( actions )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        # if useElig && (s_l > s_Totl/(1.0*l)) && (s_l > 0.0) \n",
    "        # if useElig && (s_l > 0.0) \n",
    "        if useElig \n",
    "            \n",
    "            # if s_l == 0.0\n",
    "            #     states  = copy( bestXs )\n",
    "            #     actions = copy( bestAs )\n",
    "            # end\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709555b9-2598-4281-a634-c7b0681277d0",
   "metadata": {},
   "source": [
    "# Method 2 Performance, Average Vertical Duration [s]\n",
    "Each score is the best average score of the last two epochs: 64 epochs of 64 episodes each, Q-function swap after every episode \n",
    "\n",
    "### TD Tuning\n",
    "\n",
    "$\\alpha = 0.99$: 0.238  \n",
    "$\\alpha = 0.75$: 0.257  \n",
    "$\\alpha = 0.50$: 0.191   \n",
    "$\\alpha = 0.25$: 0.170  \n",
    "$\\alpha = 0.125$: 0.290  \n",
    "$\\alpha = 0.0625$: 0.208, but fantastic performance in the middle of training  \n",
    "$\\alpha = 0.03125$: 0.978  \n",
    "$\\alpha = 0.02344$: 2.567  \n",
    "$\\alpha = 0.01953$: 0.268  \n",
    "$\\alpha = 0.015625$: 0.095  \n",
    " \n",
    "### Add gamma?\n",
    " \n",
    "### Double-Q Tuning, Swap Evey N Episodes\n",
    "$\\%\\ \\ 2$:  \n",
    "$\\%\\ \\ 4$:  \n",
    "$\\%\\ \\ 8$:  \n",
    "$\\%16$:  \n",
    "$\\%32$:  \n",
    "$\\%64$:  \n",
    "\n",
    "\n",
    "\n",
    "### Blend: Best Episode\n",
    "\n",
    "$\\beta = 0.07$:  \n",
    "$\\beta = 0.15$: 0.244\n",
    "\n",
    "| Method      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n",
    "| ----------- | ------- | ------- | ------- | ------- | ------- | ---- |\n",
    "| Blend (Epi) |         |         |         |         |         |      |\n",
    "| Blend (Epo) |         |         |         |         |         |      |\n",
    "| TD          |         |         |         |         |         |      |\n",
    "| TD  + ????? |         |         |         |         |         |      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
