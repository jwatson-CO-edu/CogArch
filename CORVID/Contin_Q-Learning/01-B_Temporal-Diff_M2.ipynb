{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cefc7-7c60-4838-9399-26a98ec9736e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43290374-89de-4616-8800-c86799248c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using NearestNeighbors\n",
    "using StaticArrays\n",
    "using Luxor\n",
    "using DataStructures\n",
    "include(\"utils.jl\"   )\n",
    "include(\"kernels.jl\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851743ab-a511-40fb-850b-bf90efa9232d",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d39765-4abe-409a-bea1-f44fa8ec2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DIM_X    = 4\n",
    "_DIM_A    = 1\n",
    "Fmax      = 10.0 #7.5 #15.0 #25.0 #5.0 #10.0 #20.0\n",
    "Fdiv      = 4.0 #8.0 # 4.0\n",
    "_X_DOMAIN = [ -30.0 +30.0 ; # thetaDotDot\n",
    "              -15.0 +15.0 ; # thetaDot\n",
    "              -20.0 +20.0 ; # theta\n",
    "              -10.0 +10.0 ] # xDot\n",
    "_A_DOMAIN = [ -Fmax +Fmax ]\n",
    "_Q_DOMAIN = [_X_DOMAIN; _A_DOMAIN]\n",
    "_LEAFLEN  = 10;\n",
    "\n",
    "nX = _DIM_X; # ---- State    dims\n",
    "nA = _DIM_A; # ---- Action   dims\n",
    "nQ = nX + nA; # --- Combined dims\n",
    "X  = zeros( nX ); # Current position\n",
    "A  = zeros( nA ); # Current effort\n",
    "Q  = zeros( nQ ); # Current Q state\n",
    "\n",
    "include(\"env_cartpole.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf920d4-46af-4f22-8933-c3db011ff716",
   "metadata": {},
   "source": [
    "# Q-Learning Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f605b904-b397-4617-9dbe-a27c0b4fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function get_Q( X, A )\n",
    "    res = zeros( nQ );\n",
    "    res[ 1:nX ] = X[:];\n",
    "    if typeof( A ) == Float64\n",
    "        res[ nX+1 ] = A;\n",
    "    else\n",
    "        res[ nX+1:nQ ] = A;\n",
    "    end\n",
    "    return res;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Disassemble <State,Action> into Q-state\n",
    "\"\"\"\n",
    "function XA_from_Q( Q )\n",
    "    return Q[ 1:nX ], Q[ nX+1:nQ ];\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Select the relvant variables from the state vector\n",
    "\"\"\"\n",
    "function select_X_vector( Xbig )\n",
    "    return [ Xbig[1], Xbig[2], Xbig[3], Xbig[5] ]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Normalize `theta` to shortest angle to zero\n",
    "\"\"\"\n",
    "function norm_turn( theta )\n",
    "    thetaN = abs( theta % (2*pi) )\n",
    "    if thetaN > pi\n",
    "        thetaN = (2*pi) - thetaN\n",
    "    end\n",
    "    return thetaN\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reward high speed at the bottom and low speed at the top\n",
    "\"\"\"\n",
    "function cartpole_reward( X )\n",
    "    \n",
    "    # 0. Set limits\n",
    "    maxThetaDot =  10.0\n",
    "    maxX        =   2.0\n",
    "    # 1. Set weights\n",
    "    thFactor    = 100.0\n",
    "    thDotFactor =   8.0\n",
    "    \n",
    "    # 2. Unpack & Normalize state\n",
    "    thetaDotN   = abs( X[2] ) # ----- Angular velocity\n",
    "    thetaN      = X[3] # Angle\n",
    "    xN          = abs( X[6] ) # ----- Fulcrum position\n",
    "    # 3. Reward high speed at the bottom and low speed at the top\n",
    "    R = thFactor*cos(thetaN) - thDotFactor*cos(thetaN)*(thetaDotN)\n",
    "    \n",
    "    \n",
    "    if xN > maxX\n",
    "        R -= xN\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Return the indices and scores of all the peak rewards in the data\n",
    "\"\"\"\n",
    "function find_state_history_R_peaks( X_hist, N_pks )\n",
    "    \n",
    "    epLen   = size( X_hist, 2 )\n",
    "    rising  = false\n",
    "    lastVal = 1e9\n",
    "    lastRis = false\n",
    "    pqPeaks = PriorityQueue();\n",
    "    rtnPeak = []\n",
    "    \n",
    "    for j = 1:epLen\n",
    "        X       = X_hist[:,j]\n",
    "        currVal = cartpole_reward( X )\n",
    "        rising  = (currVal > lastVal)\n",
    "        if (!rising) && lastRis\n",
    "            pqPeaks[j] = -currVal # Store the current index at its current (negative) value\n",
    "        end\n",
    "        lastVal = currVal\n",
    "        lastRis = rising\n",
    "    end\n",
    "    for i = 1:min( N_pks, length( pqPeaks ) )\n",
    "        append!( rtnPeak, dequeue!( pqPeaks ) )\n",
    "    end\n",
    "    \n",
    "    return rtnPeak;\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function optimal_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   = 0.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = cartpole_reward( Xp )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if (Ra != 0.0) && (Ra > bestR)\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a state `X`, determine the best action\n",
    "\"\"\"\n",
    "function learned_action_for_state_exp( X, domain, res, ts )\n",
    "    testPts = regular_grid_pts_nD( domain, res )[:]\n",
    "    N       = length( testPts )\n",
    "    bestR   = -1000.0\n",
    "    bestA   =  1000.0\n",
    "    # println( testPts )\n",
    "    for j = 1:N\n",
    "        A  = testPts[j]\n",
    "        Xp = cartpole_dyn( X, A, ts )\n",
    "        Ra = query_value_fuzzy_exp( \n",
    "            Q_kdTree, G, V, \n",
    "            get_Q( \n",
    "                select_X_vector( Xp ), \n",
    "                A \n",
    "            ); \n",
    "            k = vNN \n",
    "        )\n",
    "        if Ra > bestR\n",
    "            bestR = Ra\n",
    "            bestA = A\n",
    "        end\n",
    "    end\n",
    "    # println( bestR )\n",
    "    return bestA\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return number of seconds that penulum was within double-sided `angleMargin` of vertical\n",
    "\"\"\"\n",
    "function vertical_score_s( stateHistory, angleMargin, ts )\n",
    "    angles = stateHistory[3,:]\n",
    "    N      = length( angles )\n",
    "    score  = 0.0\n",
    "    # println( \"vertical_score_s: Analize series of \", N, \" timesteps.\" )\n",
    "    for j = 1:N\n",
    "        if abs( angles[j] ) <= angleMargin\n",
    "            score += ts\n",
    "        end\n",
    "    end\n",
    "    return score\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d663e-1ccd-441f-807f-44f84a43e4d0",
   "metadata": {},
   "source": [
    "# Q-Function Hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91f06c-df14-4fe7-b81d-12c3184b807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blend two vectors by element\n",
    "\"\"\"\n",
    "function blend_alpha_of_A_into_B( alpha, A, B )\n",
    "    return A*alpha + B*(1.0 - alpha)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exchange nonzero values\n",
    "\"\"\"\n",
    "function exchange_nonzeros( A, B )\n",
    "    rtnA = zeros( size(A, 1) )    \n",
    "    rtnB = zeros( size(B, 1) )\n",
    "    N    = size(A, 1)\n",
    "    for j = 1:N\n",
    "        \n",
    "        # Handle A\n",
    "        if A[j] == 0.0\n",
    "            rtnA[j] = B[j]\n",
    "        else\n",
    "            rtnA[j] = A[j]\n",
    "        end\n",
    "        \n",
    "        # Handle B\n",
    "        if B[j] == 0.0\n",
    "            rtnB[j] = A[j]\n",
    "        else\n",
    "            rtnB[j] = B[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return rtnA, rtnB\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5721c7-88a9-4b57-bf9f-ad9f9acbf786",
   "metadata": {},
   "source": [
    "# CartPole Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc4097d-9b96-453c-ba4f-4b06fce7fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_s     = 40\n",
    "ts        = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f083b48-38dc-4616-979a-da8874303d32",
   "metadata": {},
   "source": [
    "# Agent Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f648d5-8d8e-4da4-bd1e-3f3d9ec7c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 76032)\n"
     ]
    }
   ],
   "source": [
    "Fres     = Fmax/Fdiv\n",
    "spaceDiv = 4.0 # 1.0 # 2.0 # 5.0 # 7.5  \n",
    "\n",
    "### Construct grid of anchors ###\n",
    "G    = regular_grid_pts_nD( _Q_DOMAIN, [ spaceDiv, spaceDiv, spaceDiv, spaceDiv, Fres ] );\n",
    "nPts = size( G )[2]; # ------- Number of anchors\n",
    "mDim = size( G )[1]; # ------- Dimensionality of anchors \n",
    "V    = zeros(Float64, nPts); # Values at anchors\n",
    "VS   = zeros(Float64, nPts); # Scratch values\n",
    "vsts = zeros(Int64, nPts); # - Set number of visits to zero\n",
    "println( size( G ) )\n",
    "\n",
    "# Construct spatial trees over anchors (WITHOUT reordering!)\n",
    "Q_kdTree = KDTree( G            ; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "X_kdTree = KDTree( G[1:_DIM_X,:]; leafsize = _LEAFLEN, reorder = false ); # Vals must remain assoc w pnts!\n",
    "Q_blTree = BallTree( G             ); \n",
    "X_blTree = BallTree( G[1:_DIM_X,:] ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82db1609-9df1-438b-9675-0286bf01a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T       = Int64((1/ts)*dur_s)\n",
    "N_0     = N_cart( 0.0, 0.0, pi/2.0 )\n",
    "X_0     = [ 0.0, 0.0, pi, 0.0, 0.0, 10.0 , N_0 ]\n",
    "states  = zeros( size( X_0, 1 ), T )\n",
    "actions = zeros( T );\n",
    "bestXs  = zeros( size( X_0, 1 ), T )\n",
    "bestAs  = zeros( T );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb9f1ef-79bc-41fd-b6e9-ab0554460bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vSwp = zeros(Float64, nPts); # Swap values\n",
    "vBst = zeros(Float64, nPts); # Best values\n",
    "vBAv = zeros(Float64, nPts); # Values for best average\n",
    "vBlA = zeros(Float64, nPts); # Values for best average\n",
    "vAll = zeros(Float64, nPts); # Absorbs all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49b4c6-8353-4a01-8a16-9b544e1ef378",
   "metadata": {},
   "outputs": [],
   "source": [
    "vB25 = zeros(Float64, nPts); # Best 25 : Train 75\n",
    "vB50 = zeros(Float64, nPts); # Best 50 : Train 50\n",
    "vB75 = zeros(Float64, nPts); # Best 75 : Train 25\n",
    "vB90 = zeros(Float64, nPts); # Best 90 : Train 10\n",
    "vB95 = zeros(Float64, nPts); # Best 95 : Train  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c954412-18b9-45a8-97a6-e61cf19f15d2",
   "metadata": {},
   "source": [
    "# Agent Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358ff3d-44a5-491e-9597-0a0a73c6b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Q(TD)-Learning Params #####\n",
    "scale = 7.5; #1.650; # ----------- scale\n",
    "vNN   =  4 #10 #4 #6 #3 # Value nearest neighbors\n",
    "bNN   =  1; #1 # Blend nearest neighbors\n",
    "\n",
    "@assert Fres < scale \"!! `scale` SET TOO LOW !!\"\n",
    "\n",
    "alpha    = 0.02148 # 0.99 # 0.75 # 0.5 # 0.25 # 0.125 # 0.0625 # 0.03125 # 0.015625 # 0.00782 # 0.00391\n",
    "gamma    = 1.00 \n",
    "swapDiv  = 64\n",
    "epsMin   = 0.00 # Last iter is policy eval\n",
    "epsMax   = 0.50 #0.50 #0.15 #0.50 # 0.3 # 0.75 # 1.00\n",
    "episodes = 64 # 32 #64 #2048 #1024 #128 #512 #256 #20 # 160 # 40 # 80\n",
    "epochs   = 32 #128 #64 # 32 #16\n",
    "EXPrand  = 1.00 #0.25 #0.5 # 0.75\n",
    "Alpha    = 0.875\n",
    "aMargin  = (pi/180)*15.0;\n",
    "\n",
    "##### Q-Function Hacks #####\n",
    "beta   = 0.15\n",
    "blSode = false\n",
    "blPoch = false\n",
    "\n",
    "##### Eligibility Params #####\n",
    "useElig = true\n",
    "N_peaks =  16\n",
    "N_steps =  16\n",
    "lambda  =   0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e910ca2-281c-4d06-98e2-1c96fa7c1916",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d3689b-947a-400b-9031-9f1a13f4df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Best Score: -100.0\n",
      "Training Iteration 4 score: 0.16, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.6300000000000003, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.17, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.5500000000000003, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.13999999999999999, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.36000000000000015, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.8100000000000005, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.17, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.25000000000000006, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.2800000000000001, epsilon: 0.0078125\n",
      "Average Score: 0.22234375000000006\n",
      "\n",
      "Epoch 2, Best Score: 0.9900000000000007\n",
      "Training Iteration 4 score: 0.16, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 1.390000000000001, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.5500000000000003, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.8400000000000005, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.21000000000000005, epsilon: 0.0078125\n",
      "Average Score: 0.16249999999999984\n",
      "\n",
      "Epoch 3, Best Score: 2.7999999999999843\n",
      "Training Iteration 4 score: 0.7200000000000004, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.4400000000000002, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.35000000000000014, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.18000000000000002, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.4000000000000002, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.46000000000000024, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.20000000000000004, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.5600000000000003, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.09999999999999999, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.36000000000000015, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.2825000000000002\n",
      "\n",
      "Epoch 4, Best Score: 2.7999999999999843\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 19.26000000000021, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 1.1606250000000466\n",
      "\n",
      "Epoch 5, Best Score: 26.830000000001395\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.6100000000000003, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.12999999999999998, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.24000000000000007, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.15, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.17, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.4000000000000002, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.21000000000000005, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.23156250000000014\n",
      "\n",
      "Epoch 6, Best Score: 26.830000000001395\n",
      "Training Iteration 4 score: 0.2900000000000001, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.7000000000000004, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.08, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.07, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.08, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.4100000000000002, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.09999999999999999, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.060000000000000005, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.12484375000000003\n",
      "\n",
      "Epoch 7, Best Score: 26.830000000001395\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0029687500000000005\n",
      "\n",
      "Epoch 8, Best Score: 26.830000000001395\n",
      "Training Iteration 4 score: 0.5600000000000003, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.15, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.10999999999999999, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.24000000000000007, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.3100000000000001, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.2900000000000001, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.25000000000000006, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.8900000000000006, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.09, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 23.780000000000918, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.08, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.18000000000000002, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 1.0900000000000007, epsilon: 0.0078125\n",
      "Average Score: 1.9492187500000568\n",
      "\n",
      "Epoch 9, Best Score: 32.86000000000203\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.4400000000000002, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.11999999999999998, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.24000000000000007, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.05062500000000002\n",
      "\n",
      "Epoch 10, Best Score: 32.86000000000203\n",
      "Training Iteration 4 score: 0.03, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.5400000000000003, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.11999999999999998, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.6200000000000003, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.2800000000000001, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.05328125000000003\n",
      "\n",
      "Epoch 11, Best Score: 32.86000000000203\n",
      "Training Iteration 4 score: 0.5500000000000003, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.11999999999999998, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.26000000000000006, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.2800000000000001, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.36000000000000015, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.4000000000000002, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.060000000000000005, epsilon: 0.0078125\n",
      "Average Score: 0.18921875000000019\n",
      "\n",
      "Epoch 12, Best Score: 32.86000000000203\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 13, Best Score: 32.86000000000203\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.34000000000000014, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.5500000000000003, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.3200000000000001, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.2700000000000001, epsilon: 0.0078125\n",
      "Average Score: 0.10078125000000004\n",
      "\n",
      "Epoch 14, Best Score: 32.86000000000203\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.2800000000000001, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 8.739999999999858, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 14.639999999999732, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 1.6459375000000287\n",
      "\n",
      "Epoch 15, Best Score: 32.86000000000203\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 16, Best Score: 32.86000000000203\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.009218750000000001\n",
      "\n",
      "Epoch 17, Best Score: 32.86000000000203\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.8500000000000005, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 1.330000000000001, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 1.460000000000001, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 6.409999999999908, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 7.24999999999989, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 5.899999999999919, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 13.959999999999747, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 5.35999999999993, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 6.859999999999898, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 2.819999999999984, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 3.6899999999999653, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 3.9043750000000133\n",
      "\n",
      "Epoch 18, Best Score: 32.86000000000203\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.6900000000000004, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.046406250000000024\n",
      "\n",
      "Epoch 19, Best Score: 32.86000000000203\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0075\n",
      "\n",
      "Epoch 20, Best Score: 32.86000000000203\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.0\n",
      "\n",
      "Epoch 21, Best Score: 32.86000000000203\n",
      "Training Iteration 4 score: 0.17, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.2800000000000001, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.3200000000000001, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.2800000000000001, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.7000000000000004, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.4200000000000002, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.5500000000000003, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.35000000000000014, epsilon: 0.0078125\n",
      "Average Score: 0.28390625000000014\n",
      "\n",
      "Epoch 22, Best Score: 32.86000000000203\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.6400000000000003, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.17, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.5300000000000002, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.5500000000000003, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.5700000000000003, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.23000000000000007, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.1904687500000001\n",
      "\n",
      "Epoch 23, Best Score: 32.86000000000203\n",
      "Training Iteration 4 score: 0.6100000000000003, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.7800000000000005, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 9.009999999999852, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.36000000000000015, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 5.009999999999938, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 16.659999999999805, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.5500000000000003, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 1.280000000000001, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 25.52000000000119, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 25.170000000001135, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 17.78999999999998, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 7.109999999999893, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 30.040000000001896, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.3200000000000001, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.3200000000000001, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.2900000000000001, epsilon: 0.0078125\n",
      "Average Score: 7.874531250000249\n",
      "\n",
      "Epoch 24, Best Score: 32.86000000000203\n",
      "Training Iteration 4 score: 0.24000000000000007, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.5400000000000003, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.4200000000000002, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.47000000000000025, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.25000000000000006, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.45000000000000023, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.17, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.12031250000000003\n",
      "\n",
      "Epoch 25, Best Score: 32.86000000000203\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.17, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.23000000000000007, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.17, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.13999999999999999, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.12437500000000005\n",
      "\n",
      "Epoch 26, Best Score: 32.86000000000203\n",
      "Training Iteration 4 score: 0.6600000000000004, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.19000000000000003, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.12999999999999998, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.2900000000000001, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.15, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.16, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.11999999999999998, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.16, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.08, epsilon: 0.0078125\n",
      "Average Score: 0.13343750000000004\n",
      "\n",
      "Epoch 27, Best Score: 32.86000000000203\n",
      "Training Iteration 4 score: 0.4100000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.15, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.09999999999999999, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.09, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.5800000000000003, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.09656250000000004\n",
      "\n",
      "Epoch 28, Best Score: 32.86000000000203\n",
      "Training Iteration 4 score: 1.6400000000000012, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.13999999999999999, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.15, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.25000000000000006, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.09999999999999999, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 1.490000000000001, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.12999999999999998, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.3000000000000001, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.3900000000000002, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.12999999999999998, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.25000000000000006, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.17, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.16, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.18000000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.18000000000000002, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.13999999999999999, epsilon: 0.0078125\n",
      "Average Score: 0.2946875000000002\n",
      "\n",
      "Epoch 29, Best Score: 32.86000000000203\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.0, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.0, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.5600000000000003, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.05921875000000003\n",
      "\n",
      "Epoch 30, Best Score: 32.86000000000203\n",
      "Training Iteration 4 score: 0.5000000000000002, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.45000000000000023, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.3900000000000002, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.24000000000000007, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.34000000000000014, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.2900000000000001, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.37000000000000016, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.34000000000000014, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.48000000000000026, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 1.1300000000000008, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.09999999999999999, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.3000000000000001, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.5200000000000002, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.2700000000000001, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.22000000000000006, epsilon: 0.0078125\n",
      "Average Score: 0.3653125000000004\n",
      "\n",
      "Epoch 31, Best Score: 32.86000000000203\n",
      "Training Iteration 4 score: 0.13999999999999999, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.08, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.10999999999999999, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.22000000000000006, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.15, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.23000000000000007, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.18000000000000002, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 0.15, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.15, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.10999999999999999, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.16, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.12999999999999998, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.09999999999999999, epsilon: 0.0078125\n",
      "Average Score: 0.12125000000000001\n",
      "\n",
      "Epoch 32, Best Score: 32.86000000000203\n",
      "Training Iteration 4 score: 0.0, epsilon: 0.4765625\n",
      "Training Iteration 8 score: 0.0, epsilon: 0.4453125\n",
      "Training Iteration 12 score: 0.0, epsilon: 0.4140625\n",
      "Training Iteration 16 score: 0.20000000000000004, epsilon: 0.3828125\n",
      "Training Iteration 20 score: 0.0, epsilon: 0.3515625\n",
      "Training Iteration 24 score: 0.0, epsilon: 0.3203125\n",
      "Training Iteration 28 score: 0.0, epsilon: 0.2890625\n",
      "Training Iteration 32 score: 0.0, epsilon: 0.2578125\n",
      "Training Iteration 36 score: 0.0, epsilon: 0.2265625\n",
      "Training Iteration 40 score: 0.0, epsilon: 0.1953125\n",
      "Training Iteration 44 score: 1.1100000000000008, epsilon: 0.1640625\n",
      "Training Iteration 48 score: 0.0, epsilon: 0.1328125\n",
      "Training Iteration 52 score: 0.0, epsilon: 0.1015625\n",
      "Training Iteration 56 score: 0.0, epsilon: 0.0703125\n",
      "Training Iteration 60 score: 0.0, epsilon: 0.0390625\n",
      "Training Iteration 64 score: 0.0, epsilon: 0.0078125\n",
      "Average Score: 0.08203125000000006\n",
      "Saved a trained Q-table with size (76032,), After 12.276514534155528 minutes of training!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip810\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip810)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip811\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip810)\" d=\"\n",
       "M112.177 1486.45 L2352.76 1486.45 L2352.76 47.2441 L112.177 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip812\">\n",
       "    <rect x=\"112\" y=\"47\" width=\"2242\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip812)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  448.332,1486.45 448.332,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip812)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  789.26,1486.45 789.26,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip812)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1130.19,1486.45 1130.19,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip812)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1471.12,1486.45 1471.12,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip812)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1812.04,1486.45 1812.04,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip812)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2152.97,1486.45 2152.97,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip810)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  112.177,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip810)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  448.332,1486.45 448.332,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip810)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  789.26,1486.45 789.26,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip810)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1130.19,1486.45 1130.19,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip810)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1471.12,1486.45 1471.12,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip810)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1812.04,1486.45 1812.04,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip810)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2152.97,1486.45 2152.97,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip810)\" d=\"M438.61 1514.29 L456.966 1514.29 L456.966 1518.22 L442.892 1518.22 L442.892 1526.7 Q443.911 1526.35 444.929 1526.19 Q445.948 1526 446.966 1526 Q452.753 1526 456.133 1529.17 Q459.513 1532.34 459.513 1537.76 Q459.513 1543.34 456.04 1546.44 Q452.568 1549.52 446.249 1549.52 Q444.073 1549.52 441.804 1549.15 Q439.559 1548.78 437.152 1548.04 L437.152 1543.34 Q439.235 1544.47 441.457 1545.03 Q443.679 1545.58 446.156 1545.58 Q450.161 1545.58 452.499 1543.48 Q454.837 1541.37 454.837 1537.76 Q454.837 1534.15 452.499 1532.04 Q450.161 1529.94 446.156 1529.94 Q444.281 1529.94 442.406 1530.35 Q440.554 1530.77 438.61 1531.65 L438.61 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip810)\" d=\"M763.948 1544.91 L771.587 1544.91 L771.587 1518.55 L763.277 1520.21 L763.277 1515.95 L771.54 1514.29 L776.216 1514.29 L776.216 1544.91 L783.855 1544.91 L783.855 1548.85 L763.948 1548.85 L763.948 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip810)\" d=\"M803.299 1517.37 Q799.688 1517.37 797.86 1520.93 Q796.054 1524.47 796.054 1531.6 Q796.054 1538.71 797.86 1542.27 Q799.688 1545.82 803.299 1545.82 Q806.934 1545.82 808.739 1542.27 Q810.568 1538.71 810.568 1531.6 Q810.568 1524.47 808.739 1520.93 Q806.934 1517.37 803.299 1517.37 M803.299 1513.66 Q809.11 1513.66 812.165 1518.27 Q815.244 1522.85 815.244 1531.6 Q815.244 1540.33 812.165 1544.94 Q809.11 1549.52 803.299 1549.52 Q797.489 1549.52 794.411 1544.94 Q791.355 1540.33 791.355 1531.6 Q791.355 1522.85 794.411 1518.27 Q797.489 1513.66 803.299 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip810)\" d=\"M1105.37 1544.91 L1113.01 1544.91 L1113.01 1518.55 L1104.7 1520.21 L1104.7 1515.95 L1112.97 1514.29 L1117.64 1514.29 L1117.64 1544.91 L1125.28 1544.91 L1125.28 1548.85 L1105.37 1548.85 L1105.37 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip810)\" d=\"M1134.77 1514.29 L1153.13 1514.29 L1153.13 1518.22 L1139.05 1518.22 L1139.05 1526.7 Q1140.07 1526.35 1141.09 1526.19 Q1142.11 1526 1143.13 1526 Q1148.91 1526 1152.29 1529.17 Q1155.67 1532.34 1155.67 1537.76 Q1155.67 1543.34 1152.2 1546.44 Q1148.73 1549.52 1142.41 1549.52 Q1140.23 1549.52 1137.97 1549.15 Q1135.72 1548.78 1133.31 1548.04 L1133.31 1543.34 Q1135.4 1544.47 1137.62 1545.03 Q1139.84 1545.58 1142.32 1545.58 Q1146.32 1545.58 1148.66 1543.48 Q1151 1541.37 1151 1537.76 Q1151 1534.15 1148.66 1532.04 Q1146.32 1529.94 1142.32 1529.94 Q1140.44 1529.94 1138.57 1530.35 Q1136.72 1530.77 1134.77 1531.65 L1134.77 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip810)\" d=\"M1449.89 1544.91 L1466.21 1544.91 L1466.21 1548.85 L1444.26 1548.85 L1444.26 1544.91 Q1446.93 1542.16 1451.51 1537.53 Q1456.12 1532.88 1457.3 1531.53 Q1459.54 1529.01 1460.42 1527.27 Q1461.32 1525.51 1461.32 1523.82 Q1461.32 1521.07 1459.38 1519.33 Q1457.46 1517.6 1454.36 1517.6 Q1452.16 1517.6 1449.7 1518.36 Q1447.27 1519.13 1444.5 1520.68 L1444.5 1515.95 Q1447.32 1514.82 1449.77 1514.24 Q1452.23 1513.66 1454.26 1513.66 Q1459.63 1513.66 1462.83 1516.35 Q1466.02 1519.03 1466.02 1523.52 Q1466.02 1525.65 1465.21 1527.57 Q1464.43 1529.47 1462.32 1532.07 Q1461.74 1532.74 1458.64 1535.95 Q1455.54 1539.15 1449.89 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip810)\" d=\"M1486.02 1517.37 Q1482.41 1517.37 1480.58 1520.93 Q1478.78 1524.47 1478.78 1531.6 Q1478.78 1538.71 1480.58 1542.27 Q1482.41 1545.82 1486.02 1545.82 Q1489.66 1545.82 1491.46 1542.27 Q1493.29 1538.71 1493.29 1531.6 Q1493.29 1524.47 1491.46 1520.93 Q1489.66 1517.37 1486.02 1517.37 M1486.02 1513.66 Q1491.83 1513.66 1494.89 1518.27 Q1497.97 1522.85 1497.97 1531.6 Q1497.97 1540.33 1494.89 1544.94 Q1491.83 1549.52 1486.02 1549.52 Q1480.21 1549.52 1477.13 1544.94 Q1474.08 1540.33 1474.08 1531.6 Q1474.08 1522.85 1477.13 1518.27 Q1480.21 1513.66 1486.02 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip810)\" d=\"M1791.32 1544.91 L1807.63 1544.91 L1807.63 1548.85 L1785.69 1548.85 L1785.69 1544.91 Q1788.35 1542.16 1792.94 1537.53 Q1797.54 1532.88 1798.72 1531.53 Q1800.97 1529.01 1801.85 1527.27 Q1802.75 1525.51 1802.75 1523.82 Q1802.75 1521.07 1800.81 1519.33 Q1798.88 1517.6 1795.78 1517.6 Q1793.58 1517.6 1791.13 1518.36 Q1788.7 1519.13 1785.92 1520.68 L1785.92 1515.95 Q1788.75 1514.82 1791.2 1514.24 Q1793.65 1513.66 1795.69 1513.66 Q1801.06 1513.66 1804.25 1516.35 Q1807.45 1519.03 1807.45 1523.52 Q1807.45 1525.65 1806.64 1527.57 Q1805.85 1529.47 1803.75 1532.07 Q1803.17 1532.74 1800.07 1535.95 Q1796.96 1539.15 1791.32 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip810)\" d=\"M1817.5 1514.29 L1835.85 1514.29 L1835.85 1518.22 L1821.78 1518.22 L1821.78 1526.7 Q1822.8 1526.35 1823.81 1526.19 Q1824.83 1526 1825.85 1526 Q1831.64 1526 1835.02 1529.17 Q1838.4 1532.34 1838.4 1537.76 Q1838.4 1543.34 1834.93 1546.44 Q1831.45 1549.52 1825.13 1549.52 Q1822.96 1549.52 1820.69 1549.15 Q1818.44 1548.78 1816.04 1548.04 L1816.04 1543.34 Q1818.12 1544.47 1820.34 1545.03 Q1822.56 1545.58 1825.04 1545.58 Q1829.05 1545.58 1831.38 1543.48 Q1833.72 1541.37 1833.72 1537.76 Q1833.72 1534.15 1831.38 1532.04 Q1829.05 1529.94 1825.04 1529.94 Q1823.17 1529.94 1821.29 1530.35 Q1819.44 1530.77 1817.5 1531.65 L1817.5 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip810)\" d=\"M2141.81 1530.21 Q2145.17 1530.93 2147.05 1533.2 Q2148.94 1535.47 2148.94 1538.8 Q2148.94 1543.92 2145.43 1546.72 Q2141.91 1549.52 2135.43 1549.52 Q2133.25 1549.52 2130.94 1549.08 Q2128.64 1548.66 2126.19 1547.81 L2126.19 1543.29 Q2128.13 1544.43 2130.45 1545.01 Q2132.76 1545.58 2135.29 1545.58 Q2139.69 1545.58 2141.98 1543.85 Q2144.29 1542.11 2144.29 1538.8 Q2144.29 1535.75 2142.14 1534.03 Q2140.01 1532.3 2136.19 1532.3 L2132.16 1532.3 L2132.16 1528.45 L2136.37 1528.45 Q2139.82 1528.45 2141.65 1527.09 Q2143.48 1525.7 2143.48 1523.11 Q2143.48 1520.45 2141.58 1519.03 Q2139.71 1517.6 2136.19 1517.6 Q2134.27 1517.6 2132.07 1518.01 Q2129.87 1518.43 2127.23 1519.31 L2127.23 1515.14 Q2129.89 1514.4 2132.21 1514.03 Q2134.55 1513.66 2136.61 1513.66 Q2141.93 1513.66 2145.03 1516.09 Q2148.13 1518.5 2148.13 1522.62 Q2148.13 1525.49 2146.49 1527.48 Q2144.85 1529.45 2141.81 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip810)\" d=\"M2167.81 1517.37 Q2164.2 1517.37 2162.37 1520.93 Q2160.56 1524.47 2160.56 1531.6 Q2160.56 1538.71 2162.37 1542.27 Q2164.2 1545.82 2167.81 1545.82 Q2171.44 1545.82 2173.25 1542.27 Q2175.08 1538.71 2175.08 1531.6 Q2175.08 1524.47 2173.25 1520.93 Q2171.44 1517.37 2167.81 1517.37 M2167.81 1513.66 Q2173.62 1513.66 2176.68 1518.27 Q2179.75 1522.85 2179.75 1531.6 Q2179.75 1540.33 2176.68 1544.94 Q2173.62 1549.52 2167.81 1549.52 Q2162 1549.52 2158.92 1544.94 Q2155.87 1540.33 2155.87 1531.6 Q2155.87 1522.85 2158.92 1518.27 Q2162 1513.66 2167.81 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip812)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  112.177,1445.72 2352.76,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip812)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  112.177,1100.87 2352.76,1100.87 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip812)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  112.177,756.029 2352.76,756.029 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip812)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  112.177,411.186 2352.76,411.186 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip812)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  112.177,66.3428 2352.76,66.3428 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip810)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  112.177,1486.45 112.177,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip810)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  112.177,1445.72 131.075,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip810)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  112.177,1100.87 131.075,1100.87 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip810)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  112.177,756.029 131.075,756.029 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip810)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  112.177,411.186 131.075,411.186 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip810)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  112.177,66.3428 131.075,66.3428 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip810)\" d=\"M64.2328 1431.51 Q60.6217 1431.51 58.793 1435.08 Q56.9875 1438.62 56.9875 1445.75 Q56.9875 1452.86 58.793 1456.42 Q60.6217 1459.96 64.2328 1459.96 Q67.867 1459.96 69.6726 1456.42 Q71.5013 1452.86 71.5013 1445.75 Q71.5013 1438.62 69.6726 1435.08 Q67.867 1431.51 64.2328 1431.51 M64.2328 1427.81 Q70.0429 1427.81 73.0985 1432.42 Q76.1772 1437 76.1772 1445.75 Q76.1772 1454.48 73.0985 1459.08 Q70.0429 1463.67 64.2328 1463.67 Q58.4226 1463.67 55.344 1459.08 Q52.2884 1454.48 52.2884 1445.75 Q52.2884 1437 55.344 1432.42 Q58.4226 1427.81 64.2328 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip810)\" d=\"M59.8578 1114.22 L76.1772 1114.22 L76.1772 1118.15 L54.2328 1118.15 L54.2328 1114.22 Q56.8949 1111.46 61.4782 1106.83 Q66.0846 1102.18 67.2652 1100.84 Q69.5105 1098.31 70.3902 1096.58 Q71.2929 1094.82 71.2929 1093.13 Q71.2929 1090.37 69.3485 1088.64 Q67.4272 1086.9 64.3254 1086.9 Q62.1263 1086.9 59.6726 1087.67 Q57.2421 1088.43 54.4643 1089.98 L54.4643 1085.26 Q57.2884 1084.12 59.7421 1083.55 Q62.1958 1082.97 64.2328 1082.97 Q69.6031 1082.97 72.7976 1085.65 Q75.992 1088.34 75.992 1092.83 Q75.992 1094.96 75.1818 1096.88 Q74.3948 1098.78 72.2883 1101.37 Q71.7096 1102.04 68.6078 1105.26 Q65.5059 1108.45 59.8578 1114.22 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip810)\" d=\"M66.5939 742.823 L54.7884 761.272 L66.5939 761.272 L66.5939 742.823 M65.367 738.749 L71.2466 738.749 L71.2466 761.272 L76.1772 761.272 L76.1772 765.161 L71.2466 765.161 L71.2466 773.309 L66.5939 773.309 L66.5939 765.161 L50.9921 765.161 L50.9921 760.647 L65.367 738.749 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip810)\" d=\"M64.6495 409.323 Q61.5013 409.323 59.6495 411.475 Q57.8208 413.628 57.8208 417.378 Q57.8208 421.105 59.6495 423.281 Q61.5013 425.434 64.6495 425.434 Q67.7976 425.434 69.6263 423.281 Q71.4781 421.105 71.4781 417.378 Q71.4781 413.628 69.6263 411.475 Q67.7976 409.323 64.6495 409.323 M73.9318 394.67 L73.9318 398.929 Q72.1726 398.096 70.367 397.656 Q68.5846 397.216 66.8254 397.216 Q62.1958 397.216 59.7421 400.341 Q57.3115 403.466 56.9643 409.786 Q58.33 407.772 60.3902 406.707 Q62.4504 405.619 64.9272 405.619 Q70.1355 405.619 73.1448 408.79 Q76.1772 411.938 76.1772 417.378 Q76.1772 422.702 73.029 425.92 Q69.8809 429.137 64.6495 429.137 Q58.6541 429.137 55.4828 424.554 Q52.3116 419.948 52.3116 411.221 Q52.3116 403.026 56.2004 398.165 Q60.0893 393.281 66.6402 393.281 Q68.3994 393.281 70.1818 393.628 Q71.9874 393.975 73.9318 394.67 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip810)\" d=\"M64.3254 67.2108 Q60.9921 67.2108 59.0708 68.9932 Q57.1726 70.7756 57.1726 73.9006 Q57.1726 77.0256 59.0708 78.808 Q60.9921 80.5904 64.3254 80.5904 Q67.6587 80.5904 69.58 78.808 Q71.5013 77.0024 71.5013 73.9006 Q71.5013 70.7756 69.58 68.9932 Q67.6819 67.2108 64.3254 67.2108 M59.6495 65.2201 Q56.6402 64.4793 54.9504 62.4192 Q53.2838 60.359 53.2838 57.396 Q53.2838 53.2525 56.2236 50.8451 Q59.1865 48.4378 64.3254 48.4378 Q69.4874 48.4378 72.4272 50.8451 Q75.367 53.2525 75.367 57.396 Q75.367 60.359 73.6772 62.4192 Q72.0105 64.4793 69.0244 65.2201 Q72.404 66.0071 74.279 68.2988 Q76.1772 70.5904 76.1772 73.9006 Q76.1772 78.9237 73.0985 81.6089 Q70.0429 84.294 64.3254 84.294 Q58.6078 84.294 55.5291 81.6089 Q52.4736 78.9237 52.4736 73.9006 Q52.4736 70.5904 54.3717 68.2988 Q56.2699 66.0071 59.6495 65.2201 M57.9365 57.8359 Q57.9365 60.521 59.6032 62.0256 Q61.293 63.5303 64.3254 63.5303 Q67.3346 63.5303 69.0244 62.0256 Q70.7374 60.521 70.7374 57.8359 Q70.7374 55.1507 69.0244 53.6461 Q67.3346 52.1414 64.3254 52.1414 Q61.293 52.1414 59.6032 53.6461 Q57.9365 55.1507 57.9365 57.8359 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip812)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  175.59,1407.38 243.775,1417.7 311.961,1397.01 380.147,1245.6 448.332,1405.79 516.518,1424.19 584.703,1445.2 652.889,1109.63 721.075,1436.99 789.26,1436.53 \n",
       "  857.446,1413.09 925.631,1445.72 993.817,1428.34 1062,1161.92 1130.19,1445.72 1198.37,1444.13 1266.56,772.517 1334.74,1437.71 1402.93,1444.42 1471.12,1445.72 \n",
       "  1539.3,1396.76 1607.49,1412.87 1675.67,87.9763 1743.86,1424.97 1812.04,1424.27 1880.23,1422.71 1948.42,1429.07 2016.6,1394.91 2084.79,1435.51 2152.97,1382.73 \n",
       "  2221.16,1424.81 2289.34,1431.57 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip810)\" d=\"\n",
       "M1976.69 198.898 L2278.07 198.898 L2278.07 95.2176 L1976.69 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip810)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1976.69,198.898 2278.07,198.898 2278.07,95.2176 1976.69,95.2176 1976.69,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip810)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2001.58,147.058 2150.95,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip810)\" d=\"M2189.69 166.745 Q2187.89 171.375 2186.17 172.787 Q2184.46 174.199 2181.59 174.199 L2178.19 174.199 L2178.19 170.634 L2180.69 170.634 Q2182.45 170.634 2183.42 169.8 Q2184.39 168.967 2185.57 165.865 L2186.34 163.921 L2175.85 138.412 L2180.36 138.412 L2188.46 158.689 L2196.57 138.412 L2201.08 138.412 L2189.69 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip810)\" d=\"M2208.37 160.402 L2216.01 160.402 L2216.01 134.037 L2207.7 135.703 L2207.7 131.444 L2215.96 129.778 L2220.64 129.778 L2220.64 160.402 L2228.28 160.402 L2228.28 164.338 L2208.37 164.338 L2208.37 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgn       = time()\n",
    "averages  = []\n",
    "bestScore = -100.0;\n",
    "bestAvg   = -100.0;\n",
    "\n",
    "\n",
    "for m = 1:epochs\n",
    "    \n",
    "    if blSode\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    elseif blPoch\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore, \", Best Average: \", bestAvg )\n",
    "    else\n",
    "        println( \"\\nEpoch \", m, \", Best Score: \", bestScore )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    epsilon = epsMax \n",
    "    deltaEp = (epsMax - epsMin)/episodes\n",
    "    s_Prev  = 0.0\n",
    "    s_Totl  = 0.0\n",
    "    \n",
    "    for l = 1:episodes\n",
    "        X  = X_0\n",
    "        \n",
    "        ##### Double Q-Learning ###########################################\n",
    "\n",
    "        for k = 1:T\n",
    "\n",
    "            # 1. Choose action\n",
    "            if rand() < epsilon\n",
    "                if rand() < EXPrand \n",
    "                    A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                else\n",
    "                    A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                end\n",
    "            else\n",
    "\n",
    "                A = learned_action_for_state( X, _A_DOMAIN, [ Fmax/Fdiv ], ts )\n",
    "                if A == 1000.0 # Indicates no values in this region\n",
    "                    if rand() < EXPrand \n",
    "                        A = sample_uniform_real( _A_DOMAIN[1] , _A_DOMAIN[2] )\n",
    "                    else\n",
    "                        A = optimal_action_for_state( X, _A_DOMAIN, [ Fres ], ts )\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "\n",
    "            # 2. Cache last state\n",
    "            qLast = get_Q( select_X_vector( X ), A )\n",
    "\n",
    "            # 3. Generate the next stae\n",
    "            Xp = cartpole_dyn( X, A, ts )\n",
    "\n",
    "            # 4. Collect reward R( s, a, s' )\n",
    "            R_t = cartpole_reward( Xp )\n",
    "\n",
    "            # 5. Get the optimal action at the next state\n",
    "            a_tp1_opt = optimal_action_for_state( Xp, _A_DOMAIN, [ Fres ], ts )\n",
    "\n",
    "            # 6. Compute the value at the next state\n",
    "\n",
    "            V_tp1_opt = query_value_fuzzy( \n",
    "                Q_kdTree, G, V, \n",
    "                get_Q( \n",
    "                    select_X_vector( Xp ), \n",
    "                    a_tp1_opt \n",
    "                ); \n",
    "                k = vNN \n",
    "            )\n",
    "            if isnan( V_tp1_opt )\n",
    "                V_tp1_opt = 0.0\n",
    "            end\n",
    "\n",
    "\n",
    "            # 7. Blend the value back into nearest points\n",
    "\n",
    "            idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, qLast; k = bNN )\n",
    "\n",
    "            nNear      = size( idxs, 1 )\n",
    "            for i = 1:nNear\n",
    "                j    = idxs[i]\n",
    "                if !isnan( wgts[i] ) \n",
    "\n",
    "                    # VS[j] = R_t + gamma * V_tp1_opt # Q-Learning\n",
    "                    VS[j] = VS[j] + alpha*( R_t + gamma*V_tp1_opt - V[j] ) # Q(TD)-Learning\n",
    "                    \n",
    "                end\n",
    "            end\n",
    "\n",
    "            states[:,k] = Xp\n",
    "            actions[k]  = A\n",
    "\n",
    "            X = Xp\n",
    "        end\n",
    "\n",
    "        s_l    = vertical_score_s( states, aMargin, ts )\n",
    "        s_Totl += s_l\n",
    "    \n",
    "        if s_l > bestScore\n",
    "            bestScore = s_l\n",
    "            bestXs    = copy( states  )\n",
    "            bestAs    = copy( actions )\n",
    "            vBst      = copy( V )\n",
    "        end\n",
    "        \n",
    "        if l%4 == 0\n",
    "            println( \"Training Iteration \", l, \" score: \", s_l, \", epsilon: \", epsilon )\n",
    "        end\n",
    "        \n",
    "        ##### Eligibility Traces ##########################################\n",
    "        if useElig\n",
    "        \n",
    "            # 1. Find `N_peaks`\n",
    "            peakDices = find_state_history_R_peaks( states, N_peaks )\n",
    "            # 2. For each peak, iterate back in time through states\n",
    "            for ii = 1:min(N_peaks, length(peakDices))\n",
    "                topDex = peakDices[ ii ]\n",
    "                X      = states[:,topDex]\n",
    "                R_jj    = cartpole_reward( X )\n",
    "                # 3. For each Q-state in the trace\n",
    "                for jj = (topDex-1):-1:max(1,topDex-N_steps)\n",
    "                    X = states[:,jj]\n",
    "                    R_jj *= lambda\n",
    "                    a_jj = actions[jj]\n",
    "                    q_jj = get_Q( select_X_vector( X ), a_jj )\n",
    "                    V_jj = query_value_fuzzy( Q_kdTree, G, V, q_jj; k = vNN )\n",
    "\n",
    "                    idxs, wgts = query_contrib_to_neighbors( Q_kdTree, G, V, q_jj; k = bNN )\n",
    "                    nNear      = size( idxs, 1 )\n",
    "\n",
    "                    for kk = 1:nNear\n",
    "                        ll = idxs[kk]\n",
    "                        if !isnan( wgts[kk] ) \n",
    "                            VS[ll] = VS[ll] + alpha*( R_jj + V_jj - V[ll] ) # Q(TD)-Learning\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        # Decay the exploration probability\n",
    "        epsilon -= deltaEp\n",
    "        \n",
    "        \n",
    "        ##### Double Q-Learning ##########################################\n",
    "        # Every `swapDiv` episodes, swap Q-functions for Double Q-Learning\n",
    "        \n",
    "        if (l % swapDiv == 0)\n",
    "            \n",
    "            vSwp = copy( VS   )\n",
    "            VS   = copy( V    )\n",
    "            V    = copy( vSwp )\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s_Avg = s_Totl / episodes\n",
    "    println( \"Average Score: \", s_Avg )\n",
    "    \n",
    "    append!( averages, s_Avg )\n",
    "     \n",
    "    \n",
    "    ##### Q-Function Hacks ################################################\n",
    "    \n",
    "    # Blend Method 1: Best Episode\n",
    "    if blSode\n",
    "        V  = blend_alpha_of_A_into_B( beta, vBst, V  )\n",
    "        VS = blend_alpha_of_A_into_B( beta, vBst, VS )\n",
    "    end\n",
    "    \n",
    "    # if (s_Avg > bestAvg) && true\n",
    "    #     println( \"BLEND\" )\n",
    "    #     bestAvg = s_Avg\n",
    "    #     vBAv    = copy( V ) # Try a blend of both next # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    #     vBlA    = blend_alpha_of_A_into_B( 0.50, VS, V ) # FIXME: WE NEVER ACTUALLY USE THIS MATRIX!\n",
    "    # end\n",
    "        \n",
    "end\n",
    "\n",
    "vTrn = copy( V )\n",
    "println( \"Saved a trained Q-table with size \", size( vTrn ), \", After \", (time()-bgn)/60.0, \" minutes of training!\" )\n",
    "\n",
    "using Plots\n",
    "\n",
    "plot( averages )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709555b9-2598-4281-a634-c7b0681277d0",
   "metadata": {},
   "source": [
    "# Method 2 Performance, Average Vertical Duration [s]\n",
    "Each score is the best average score of the last two epochs: 64 epochs of 64 episodes each, Q-function swap after every episode \n",
    "\n",
    "### TD Tuning\n",
    "\n",
    "$\\alpha = 0.99$: 0.238  \n",
    "$\\alpha = 0.75$: 0.257  \n",
    "$\\alpha = 0.50$: 0.191   \n",
    "$\\alpha = 0.25$: 0.170  \n",
    "$\\alpha = 0.125$: 0.290  \n",
    "$\\alpha = 0.0625$: 0.208, but fantastic performance in the middle of training  \n",
    "$\\alpha = 0.03125$: 0.978  \n",
    "$\\alpha = 0.02344$: 2.567  \n",
    "$\\alpha = 0.01953$: 0.268  \n",
    "$\\alpha = 0.015625$: 0.095  \n",
    " \n",
    "### Add gamma?\n",
    " \n",
    "### Double-Q Tuning, Swap Evey N Episodes\n",
    "$\\%\\ \\ 2$:  \n",
    "$\\%\\ \\ 4$:  \n",
    "$\\%\\ \\ 8$:  \n",
    "$\\%16$:  \n",
    "$\\%32$:  \n",
    "$\\%64$:  \n",
    "\n",
    "\n",
    "\n",
    "### Blend: Best Episode\n",
    "\n",
    "$\\beta = 0.07$:  \n",
    "$\\beta = 0.15$: 0.244\n",
    "\n",
    "| Method      | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n",
    "| ----------- | ------- | ------- | ------- | ------- | ------- | ---- |\n",
    "| Blend (Epi) |         |         |         |         |         |      |\n",
    "| Blend (Epo) |         |         |         |         |         |      |\n",
    "| TD          |         |         |         |         |         |      |\n",
    "| TD  + ????? |         |         |         |         |         |      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c1d8a-58c5-4719-89c8-b69bf6623266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
